Position,Company_Name,Location,Post_Month,Post_Year,Details,parsed_description
IT Manager,10 Percent Recruiting Ltd.,"Vancouver, British Columbia, Canada",June,2024,"Position Title: IT Manager

Location: Vancouver, BC

Type: Permanent, full-time, hybrid

The Position

Our client is seeking a dynamic, communicative, and strategic IT Manager to join their team in the engineering space. Successful candidates will bring hands-on technical prowess, mastery of vendor management, exceptional stakeholder engagement and communication, and familiarity with engineering environments and technologies.

What You'll Do

IT Operational Management -

Oversee performance of third-party Managed Service Providers (MSPs) and Managed Security Service Providers (MSSPs), including monitoring service agreements covering hardware and network administration, helpdesk support, data backup, and retention.
Ensure IT infrastructure and information systems are secure, compatible, and scalable to meet current and future company needs.
Lead IT project management and business analysis, collecting requirements, prioritizing projects, and ensuring alignment with business needs and budget.
Perform routine audits of MSP reports, including inventory, security patches, and administrative actions.
Draft and submit incident reports for adverse incidents affecting information systems.
Document and evaluate change management activities impacting IT infrastructure and systems.
Conduct security and risk assessments prior to implementing system changes and maintain assessment records.
Lead disaster recovery efforts, ensuring plans are maintained and communicated.

Leadership –

Develop and maintain policies, processes, and procedures for IT infrastructure, cybersecurity, and data management.
Provide training to system users on proper use and interaction with information systems and technology.
Deliver regulatory training on cybersecurity, insider threats, and information systems security.
Prepare annual department plans and budgets, including objectives, KPIs, hiring, training, and spending, for approval by the VP of Business Operations.
Monitor and report on actual spending against the IT budget.

Mandatories

Bachelor’s degree in Computer Science, Information Systems, or similar field.
Experience in an engineering environment utilizing technologies such as AutoCad, Rhino, etc.
10+ years of post-graduation industry experience.
Proven experience as an IT Manager, or similar.
Vendor management experience.
Broad knowledge in technical personnel management, network infrastructure, software applications, information systems security, and data management.
Knowledge of information security regulatory compliance (North America) is highly beneficial.
Ability to manage personnel, both internal and outsourced.

If you are interested in this position and meet the above criteria, please click the 'Apply for Job' button below to send your resume securely and in confidence directly to the recruiter in charge of this position. We thank all applicants; however, only those selected for interviews will be contacted.

All applicants must be legally entitled to work in Canada.

WE APPRECIATE YOUR INTEREST IN 10 PERCENT RECRUITING LTD.

We invite you to become one of our satisfied candidates! 10 Percent Recruiting Ltd. believes in transparency with our candidates and our employers; we understand that open communication and collaboration are fundamental to our success. Our professional recruiters are passionate about helping you find a fulfilling job or career and ensuring your complete satisfaction with our process. We are committed to actively building lasting relationships and building trust by listening, following through, and keeping our word. We look forward to exceeding your expectations!

Learn more about 10 Percent Recruiting Ltd. and view our current job opportunities, career tips, and tools at https://10percentrecruiting.com","{""role_summary"":""The IT Manager will oversee IT operational management, lead IT project management, and ensure IT infrastructure and information systems are secure, compatible, and scalable to meet current and future company needs."",""key_terms"":[{""term"":""Managed Service Providers (MSPs)"",""explanation"":""Third-party providers that manage IT services, hardware, and network administration for a company.""},{""term"":""Managed Security Service Providers (MSSPs)"",""explanation"":""Third-party providers that manage security services, including monitoring and incident response for a company.""},{""term"":""Engineering environments and technologies"",""explanation"":""Software and systems used in engineering, such as AutoCad and Rhino.""},{""term"":""Vendor management"",""explanation"":""The process of managing and contracts with third-party providers of goods and services.""}],""skill_priorities"":{""must_have"":[""10+ years of post-graduation industry experience"",""Proven experience as an IT Manager or similar"",""Vendor management experience"",""Broad knowledge in technical personnel management, network infrastructure, software applications, information systems security, and data management""],""nice_to_have"":[""Knowledge of information security regulatory compliance (North America)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with vendor management and how you ensure successful partnerships?"",""example_answer"":""I have managed multiple vendors in my previous role, and I ensure successful partnerships by setting clear expectations, regular check-ins, and evaluating their performance.""},{""question"":""How do you stay current with the latest developments in information systems security and data management?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and read relevant publications to stay current with the latest developments.""}],""red_flags"":[""Lack of experience in an engineering environment"",""Inability to manage personnel, both internal and outsourced""],""confidence_score"":90.0}"
"Manager, Information Technology Services",Town of Tillsonburg,"Tillsonburg, Ontario, Canada",June,2024,"The Town of Tillsonburg is looking for a Manager, Information Technology Services who would be responsible for planning, development and maintenance of a comprehensive information technology program and strategy for the Town. Coordinates Town-wide information systems planning and ensures mid to long-term plans are prioritized and consistent with available funding. Works closely with Town Department Heads and staff to co-ordinate automated systems operations for the Town.

This is a permanent full-time position with an excellent benefits package including immediate group benefits coverage, OMERS defined pension plan and free Employee Health Club Membership at the Tillsonburg Community Centre.

Department: Corporate Services

Division: Information Technology Services

Reports To: Director of Corporate Services/Clerk

Hourly rate: $48.66 - $56.92/hour

Weekly hours: 40

Criminal Record Check is required for this position.

Interested candidates please apply prior to the end of a business day on Thursday July 18, 2024

Responsibilities

Directs, manages and coordinates the Information Systems’ activities
Develops and implements a Town-wide long-range information systems strategy which involves facilitating discussions with Town management regarding current and anticipated information services requirements, applications development and enhancement requests
Prioritizes the acquisition, development and/or implementation of new and enhanced information technology systems to meet user needs
Coordinates Town-wide acquisition of software and hardware, including reviewing department requests and making recommendations on alternative options
Develops and implements a long-range funding plan for maintenance and replacement of hardware
Recommends Town-wide standards for hardware, software and local area networks
Oversees the operation and maintenance of telephone and other communication systems
Manages customer support for business applications, personal computers, networks and telecommunication equipment
Develops, plans and implements goals, objectives and work plans
Ensures compliance with legislative and regulatory requirements and professional standards
Evaluates services and directs the development and implementation of new/improved programs and procedures
Recommends and communicates appropriate application of policy and operational procedures
Prepares and presents written and oral reports and recommendations for consideration of the Director of Corporate Services/Clerk
Serves as a technical advisor
Participates in Management team meetings during the review and development of IT technological approaches in order to ensure achievement of Town goals and objectives
Monitors and reviews IT operations in order to ensure customer satisfaction and efficient, effective Town operations and, as required, develops and implements staff development programs
In conjunction with the Director of Corporate Services/Clerk, develops and oversees implementation of systems that encourage productive and exceptional performance throughout the organization
Prepares the annual Capital and Operating Budgets for IT in cooperation with the Clerk
Manages and assures compliances of all software licensing agreements
Monitors the network on a daily basis and corrects all network problems, referring unusual problems to outside consultants or vendors
If requested by the Director of Corporate Services/Clerk, attends meetings of Town Council to answer specific questions about the Town’s IT systems
If requested by the Director of Corporate Services/Clerk, assists with special projects and assists neighbouring municipalities with IT problems
Follow safe work practices related to job responsibilities and have basic understanding of the Occupational Health & Safety Act as it relates to the work environment
Adhere to all Town policies and procedures
Perform other duties as assigned by Supervisor

Qualifications

Post-secondary degree or diploma in Computer Science, Information Technology or related field
Five (5) years of relevant progressive experience
Two (2) years of leadership and supervisory experience
Strong knowledge of operating systems, networks, virtualized server environments and storage.
Hands-on experience in the administration of enterprise IT networks & infrastructure
Proficiency in the hands-on use of cybersecurity tools and technologies
Excellent interpersonal, communication and presentation skills
Ability to be self-directed and work independently
Strong organizational skills
Ability to prioritize competing tasks and meet multiple deadlines
Experience managing IT projects using project management methodologies an asset

About The Recruitment Process

All new Town of Tillsonburg employees are required to complete a police record check.

The Town will accommodate any individual needs you have throughout the recruitment process in accordance with the

The Town of Tillsonburg is an equal opportunity employer and all information collected will be used in accordance with the Municipal Freedom of Information and Protection of Privacy Act for the purpose of job selection.

We thank all those who apply for positions, but only applicants invited for an interview will be contacted.

Powered by JazzHR

y5iPZIIvy5","{""role_summary"":""The Manager, Information Technology Services is responsible for planning, developing, and maintaining a comprehensive IT program and strategy for the Town of Tillsonburg."",""key_terms"":[{""term"":""Information Technology Services"",""explanation"":""The department responsible for planning, developing, and maintaining the Town's IT systems and infrastructure.""},{""term"":""Enterprise IT networks & infrastructure"",""explanation"":""Large-scale IT systems and infrastructure that support the Town's operations.""},{""term"":""Cybersecurity tools and technologies"",""explanation"":""Software and systems used to protect the Town's IT systems and data from unauthorized access or malicious attacks.""},{""term"":""Virtualized server environments"",""explanation"":""A technology that allows multiple virtual servers to run on a single physical server, improving efficiency and reducing costs.""}],""skill_priorities"":{""must_have"":[""Post-secondary degree or diploma in Computer Science, Information Technology or related field"",""Five (5) years of relevant progressive experience"",""Two (2) years of leadership and supervisory experience"",""Strong knowledge of operating systems, networks, virtualized server environments and storage"",""Hands-on experience in the administration of enterprise IT networks & infrastructure"",""Proficiency in the hands-on use of cybersecurity tools and technologies""],""nice_to_have"":[""Experience managing IT projects using project management methodologies""]},""proposed_screening_questions_with_answers"":[{""question"":""What experience do you have with developing and implementing a Town-wide long-range information systems strategy?"",""example_answer"":""I have developed and implemented a similar-sized organization's IT strategy, which involved facilitating discussions with management regarding current and anticipated information services requirements, applications development and enhancement requests.""},{""question"":""How do you prioritize the acquisition, development and/or implementation of new and enhanced information technology systems to meet user needs?"",""example_answer"":""I prioritize based on user needs, available funding, and alignment with the organization's goals and objectives. I also consider the potential return on investment and the impact on the organization's operations and customer satisfaction.""}],""red_flags"":[""Lack of experience with enterprise IT networks & infrastructure"",""Inability to prioritize competing tasks and meet multiple deadlines""],""confidence_score"":90.0}"
Information Technology (IT) Manager,Alpha Auto Group,"Ottawa, Ontario, Canada",June,2024,"Job Description

Interested in developing or advancing your career with one of the fastest growing automotive dealer groups? Alpha Auto Group is a growing and nationally focused auto dealer group. We are focused on delivering best in class service for our valued customers. As our Group continues to grow, we are looking for highly motivated, enthusiastic team players that share the same vision and desire for success. We are looking for you to join us, to grow with us, and to excel with us!

The Information Technology Manager will provide management of personnel, services infrastructure required to support dealerships across the Alpha Auto-Group.

Responsibilities

Lead IT projects for network/system upgrades and business initiatives
Establish and monitor IT KPIs, mentoring team members
Manage vendor relationships and establish new ones in new geographies
Collaborate with business leaders to align technology investments with business goals
Translate complex tech solutions into business-friendly terms
Support and develop enterprise cyber security solutions
Provide user support for applications, OS, and network issues
Manage Hyper-V servers, Office 365 tenancies, and Azure AD Sync
Administer Active Directory and Group Policy
Configure and report on backups for applications and VMs
Manage Fortinet firewalls and core networking
Administer wireless access points, switches, and routers
Configure and manage RingCentral phone system
Monitor network/application performance across stores
Develop and maintain IT documentation

Qualifications

Post-secondary degree/diploma in Information Technology, Computer Science, or a related field
3+ years IT management experience
5+ years of IT support and Administration experience in a 1000+ network user environment
5+ years of experience deploying and managing MS-Windows Services
5+ years of experience administering a Hyper-V virtual environment
2+ years of experience managing Azure infrastructure services/ Office 365
Strong DHCP, DNS, Active Directory and Group Policy administration skills
Work experience in Automotive Industry will be considered an asset
Work Experience with Dealer Management Systems will be considered and asset
N-Able N-Central experience is considered an asset

Please note: Must be willing to travel up to 30% of the time to oversee multiple dealerships.","{""role_summary"":""The Information Technology Manager will lead IT projects, manage personnel, and services infrastructure to support dealerships across the Alpha Auto Group."",""key_terms"":[{""term"":""Hyper-V"",""explanation"":""A virtual environment technology used to manage and host multiple virtual machines.""},{""term"":""Azure AD Sync"",""explanation"":""A cloud-based identity and access management solution that synchronizes user data.""},{""term"":""Fortinet firewalls"",""explanation"":""A type of network security system that protects against unauthorized access.""},{""term"":""RingCentral phone system"",""explanation"":""A cloud-based business phone system that provides communication and collaboration tools.""},{""term"":""N-Able N-Central"",""explanation"":""A remote monitoring and management tool used to manage IT infrastructure and provide technical support.""}],""skill_priorities"":{""must_have"":[""Post-secondary degree/diploma in Information Technology, Computer Science, or a related field"",""3+ years IT management experience"",""5+ years of IT support and Administration experience in a 1000+ network user environment"",""5+ years of experience deploying and managing MS-Windows Services"",""5+ years of experience administering a Hyper-V virtual environment"",""2+ years of experience managing Azure infrastructure services/ Office 365""],""nice_to_have"":[""Work experience in Automotive Industry"",""Work Experience with Dealer Management Systems"",""N-Able N-Central experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with Hyper-V virtual environment administration?"",""example_answer"":""I have 5+ years of experience administering Hyper-V virtual environments, including configuring and managing virtual machines.""},{""question"":""How do you stay current with the latest developments in Azure infrastructure services and Office 365?"",""example_answer"":""I regularly attend webinars, participate in online forums, and read industry blogs to stay up-to-date with the latest developments.""}],""red_flags"":[""Avoid candidates without experience in IT management and support in a large network user environment."",""Be cautious of candidates without experience in deploying and managing MS-Windows Services.""],""confidence_score"":90.0}"
IT Support Manager,Logistec Corporation,"Montreal, Quebec, Canada",June,2024,"CAREER OPPORTUNITY AT LOGISTEC

LOGISTEC offers a unique combination of maritime and environmental services, both water related. Our reputation rests on excellence, thanks to the dedication of over 3,500 employees throughout North America, committed to finding solutions to support reliable and sustainable supply chains, while also protecting our environment and water resources.

Diversity helps us grow, and inclusion propels us forward. When everyone is included, great things can be achieved together. That's why we continue to strengthen our commitment to employment equity, inclusive recruitment, and development.

We are determined to find and support the best talent, and we are currently looking to fill a position for an IT Support Manager in Montreal.

Seize this opportunity and come make great things happen with us!

What does your day look like as an IT Support Manager?
Overseeing the day-to-day operations of the service desk.
Ensuring timely and effective resolution of customer issues and inquiries.
Managing a team of service desk agents, including hiring, training, and performance management.
Developing and implementing service desk policies, procedures, and best practices based on ITSM methodologies.
Monitoring and analyzing service desk performance metrics to identify areas for improvement.
Collaborating with other departments to streamline processes and improve service delivery.
Serving as a point of escalation for complex or high-priority issues.
Implementing and maintaining service desk technologies and tools.
Providing regular reports and updates to senior management on service desk performance and initiatives.
Staying current on industry trends and best practices in service desk management.

To succeed as an IT Support Manager, you must have:
Bachelor's degree in information technology, computer science, or a related field (or equivalent work experience)
Proven experience in a service desk or technical support role, with at least 3-5 years in a leadership or managerial position
Strong understanding of ITIL framework and best practices
Excellent communication and interpersonal skills, with the ability to effectively communicate technical information to non-technical stakeholders
Demonstrated leadership abilities, including the ability to motivate and manage a team
Experience in hiring, training, and performance management of service desk staff
Proficiency in service desk management tools and technologies
Strong analytical and problem-solving skills, with the ability to identify trends and patterns in service desk data
Ability to work well under pressure and prioritize tasks in a fast-paced environment
Knowledge of IT service management principles and methodologies
Certifications such as ITIL Foundation, HDI Support Center Manager, or similar are preferred but not required.","{""role_summary"":""Oversee the day-to-day operations of the service desk, manage a team of service desk agents, and ensure effective resolution of customer issues."",""key_terms"":[{""term"":""ITSM"",""explanation"":""Information Technology Service Management, a set of policies, procedures, and best practices for managing IT services.""},{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a framework for IT service management that provides best practices for delivering high-quality IT services.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in information technology, computer science, or a related field"",""Proven experience in a service desk or technical support role"",""Strong understanding of ITIL framework and best practices"",""Excellent communication and interpersonal skills"",""Demonstrated leadership abilities"",""Experience in hiring, training, and performance management of service desk staff"",""Proficiency in service desk management tools and technologies"",""Strong analytical and problem-solving skills""],""nice_to_have"":[""Certifications such as ITIL Foundation, HDI Support Center Manager, or similar""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with ITIL framework and best practices in a service desk environment?"",""example_answer"":""I have worked in a service desk environment for 5 years, and I have implemented ITIL best practices to improve our service desk operations.""},{""question"":""How do you motivate and manage a team of service desk agents?"",""example_answer"":""I believe in regular feedback and coaching, and I have a proven track record of improving team performance through effective leadership and management.""}],""red_flags"":[""Lack of experience in a leadership or managerial position"",""Inability to effectively communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
IT Service Center Director,Leclerc Foods,"Brockville, Ontario, Canada",June,2024,"Leclerc is a family business with 117 years of experience, tradition and know-how passed down from people with heart. Thanks to our 1,400 employees in nine plants in Canada and the United States, we are constantly innovating to exceed the expectations of both small and large appetites.

Working at Leclerc means...

Working in a family business
Evolving in a clean, temperate environment with the latest technology
Starting a new job with paid and adapted training
Benefit from a complete benefits program (drug and dental insurance, 1 week of sick leave [conditions apply], telemedicine, group RRSP with employer participation and more)
Enjoy quality meals at low prices in the cafeteria (unlimited coffee, tea, cookies and bars)
Enjoy free use of the sports facilities (basketball court, training room and cardio room)
Save on our delicious products and discover exclusive novelties
Take advantage of job security and opportunities for advancement within the company
Integrate a rich company culture (Christmas, birthday and maternity gifts, use of the Poka platform and more)

Summary Of The Function

Reporting to the Senior Director of Information Technology, the IT Service Center Manager manages the activities surrounding user services and the technical services outsourcing process. He plays an important role in the service delivery strategy, and his concern for security and customer satisfaction is constant. His experience enables him to act as an expert in recommending the solutions and investments required, and in justifying them. Aware of the CYBER risk, he is highly committed to immediate proactivity and reactivity to actions required to reduce risk exposure.

Responsibilities

Coordinate the activities of your group and ensure that projects and recurring activities are carried out efficiently;
Participate in the planning and monitoring of budgets;
Ensure the resolution of problems related to the systems under your responsibility;
Identify opportunities for improvement and optimization of these systems;
Proactively recommend technological enhancements and investments in information systems and ensure their implementation;
Promote interactions and synergy between the various IT teams;
Coordinate and ensure the follow-up of service agreements with external suppliers related to the technologies under your responsibility;
Be responsible for the development of case studies leading to decision-making;
Monitor new developments in your area of expertise and assess the relevance of these advances for the organization according to the determined business strategy;
Report on the status of internal and external operational services (outsourcing) and maintain metrics such as open tickets, technician performance and SLAs;
Ensure that the tools and processes put in place are respected and improved;
Supervise IT technical support activities (helpdesk) and ensure customer satisfaction while respecting predefined IT norms and standards;
Audit the documentation update of the user procedures, technical documentation, support processes and operations manual;
Maintain close contact with customers by conducting regular satisfaction surveys.

Skills And Abilities Required

University degree in computer science or bachelor's degree in business administration specializing in information technology;
6 to 9 years' relevant experience, including 3 as an IT support manager;
Good knowledge of Windows environments, O365 and equipment lifecycle management;
In-depth knowledge of the indicators and best practices required to manage your environment;
Certification and/or knowledge of ITIL, CoBit
Fluent in spoken and written French and English;
Customer service oriented;
Autonomy / Initiative / Creativity;
Leadership / Ability to influence / Teamwork;
Analysis / Synthesis / Judgement;
Ability to solve problems / Ability to make recommendations;
Stress resistance / Time and priority management;
Professional / Rigorous / Proactive and able to react quickly;
Results-oriented;
Ability to respect budgets and deadlines.

Biscuits Leclerc is committed to recruiting and hiring the best candidates for all roles and is committed to integration and equal opportunity. Upon request, Biscuits Leclerc will provide suitable accommodations during the recruitment and hiring process to candidates with accessibility needs due to disability to ensure that the standards outlined in Accessibility for Ontarians with Disabilities Act (AODA) are upheld. If you require an accommodation during the application or interview process, please contact the HR responsible at 613-632-0777 ext: 4204","{""role_summary"":""Manage the IT Service Center, ensuring efficient project delivery, budget planning, and problem resolution, while promoting customer satisfaction and security."",""key_terms"":[{""term"":""ITIL"",""explanation"":""A framework for IT service management that provides best practices for delivering high-quality IT services.""},{""term"":""CoBit"",""explanation"":""A framework for IT governance and management that provides best practices for managing and governing IT.""},{""term"":""O365"",""explanation"":""A cloud-based suite of productivity applications, including Office, Exchange, and SharePoint.""},{""term"":""Equipment lifecycle management"",""explanation"":""The process of managing the acquisition, deployment, maintenance, and disposal of IT equipment.""}],""skill_priorities"":{""must_have"":[""University degree in computer science or business administration"",""6-9 years' relevant experience, including 3 as an IT support manager"",""Good knowledge of Windows environments"",""Fluent in spoken and written French and English"",""Customer service oriented""],""nice_to_have"":[""Certification and/or knowledge of ITIL, CoBit""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with IT service management frameworks, such as ITIL?"",""example_answer"":""Yes, I have worked with ITIL in my previous role, and I'm familiar with its best practices for delivering high-quality IT services.""},{""question"":""How do you ensure customer satisfaction in an IT support role?"",""example_answer"":""I prioritize communication, set clear expectations, and follow up with customers to ensure their issues are resolved efficiently.""}],""red_flags"":[""Lack of experience with IT service management frameworks"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Information Technology Manager,Hays,"Jasper, Alberta, Canada",June,2024,"About the job
Consistently offer professional, engaging, and friendly service.
Deliver high levels of service and support to each property as per Service Level Agreement (SLA).
Resolve complex problems in consultation with other senior IT resources.
Provide training and guidance to less experienced staff.
Recommend improvements to established incident management processes.
Assist in maintaining IT standard guidelines.
Ensure monitoring of ALL recovery systems (tape backup and virus protection).
Provide escalated support to Technology Services staff.
Assist and support strategic plan implementation.
Implement and support best practices.
Contribute to Technology Services knowledge base.
Look for opportunities for new technology that may benefit customers.
Provide after-hours pager support.
Participate in managing all aspects of a project as directed by RSM.
Follow all safety policies.
Perform other duties as assigned.

Skills required

University degree or equivalent experience.
Microsoft Certified System Engineer.
Cisco certification or equivalent experience.
Understanding of hotel operations (an asset).
Good verbal and written communication skills.
Strong interpersonal skills.
Self-starter with a strong sense of commitment.
Previous supervisory experience.","{""role_summary"":""Provide high-level technical support to ensure smooth hotel operations, while also mentoring junior staff and contributing to process improvements."",""key_terms"":[{""term"":""Service Level Agreement (SLA)"",""explanation"":""A formal agreement outlining the expected service quality and responsiveness between IT and hotel properties.""},{""term"":""Incident management processes"",""explanation"":""Standard procedures for identifying, resolving, and documenting technical issues.""},{""term"":""IT standard guidelines"",""explanation"":""Established rules and best practices for IT operations to ensure consistency and quality.""},{""term"":""Recovery systems"",""explanation"":""Backup and protection systems, such as tape backup and virus protection, to ensure business continuity.""}],""skill_priorities"":{""must_have"":[""Microsoft Certified System Engineer"",""Cisco certification or equivalent experience"",""Good verbal and written communication skills"",""Strong interpersonal skills"",""Self-starter with a strong sense of commitment"",""Previous supervisory experience""],""nice_to_have"":[""Understanding of hotel operations""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to resolve a complex technical issue in a fast-paced environment?"",""example_answer"":""In my previous role, I worked with senior IT resources to troubleshoot a critical system failure, ensuring timely resolution and minimal impact on hotel operations.""},{""question"":""How do you approach mentoring junior staff and providing guidance on technical best practices?"",""example_answer"":""I believe in leading by example, providing clear explanations, and encouraging open communication to foster a culture of continuous learning and improvement.""}],""red_flags"":[""Lack of experience in a supervisory role"",""Inability to work independently with minimal supervision""],""confidence_score"":85.0}"
IT Manager - Construction,Team Construction Inc.,"Vancouver, British Columbia, Canada",June,2024,"The IT Manager will be responsible for responsible for the overall planning, organizing, and execution of all information technology functions within the organization. This includes directing all IT operations to meet customer requirements as well as the support and maintenance of existing applications and development of new technical solutions.

Responsibilities

Strategic Planning: Recommend technologies aligned with organizational goals; evaluate and adopt emerging technologies; stay informed on industry trends.
Team Leadership: Lead the IT team; partner with departments to meet their IT needs.
Infrastructure Management: Manage IT infrastructure including networks and cloud systems; maintain software applications.
Project Management: Oversee IT projects, ensuring effective management of timelines, budgets, and stakeholder communication.
Security and Compliance: Implement cybersecurity measures; ensure compliance with standards; oversee disaster recovery planning.
Vendor Management: Handle vendor relationships and contract negotiations to optimize organizational value.
IT Support: Provide technical support and maintain IT policies to ensure user compliance.
Budgeting and Cost Control: Oversee the IT budget and identify cost efficiencies.
Continuous Improvement: Monitor and implement best practices for IT governance and improvements.

Qualifications

Bachelor's degree in computer science, information technology, or a related field.
Proven experience (3 to 5 years) as an IT Manager or a similar leadership role.
Strong knowledge of IT systems, infrastructure, and cybersecurity best practices.
Excellent leadership and team management skills.
Exceptional problem-solving and decision-making abilities.
Effective communication and interpersonal skills.
Experience in strategic planning and execution.","{""role_summary"":""The IT Manager is responsible for planning, organizing, and executing IT functions to meet organizational goals, including leading the IT team, managing infrastructure, and ensuring cybersecurity and compliance."",""key_terms"":[{""term"":""Cybersecurity"",""explanation"":""Protecting computer systems and networks from unauthorized access, use, disclosure, disruption, modification, or destruction.""},{""term"":""Cloud Systems"",""explanation"":""A model of delivering computing services over the internet, allowing users to access and store data on remote servers.""},{""term"":""Disaster Recovery Planning"",""explanation"":""Creating a strategy to restore business operations and IT systems after a disaster or data loss.""},{""term"":""IT Governance"",""explanation"":""A framework for managing IT resources to meet organizational goals, and ensuring accountability and transparency.""}],""skill_priorities"":{""must_have"":[""Strong knowledge of IT systems, infrastructure, and cybersecurity best practices"",""Proven experience as an IT Manager or similar leadership role"",""Excellent leadership and team management skills"",""Exceptional problem-solving and decision-making abilities""],""nice_to_have"":[""Experience in strategic planning and execution""]},""proposed_screening_questions_with_answers"":[{""question"":""What strategies would you use to ensure IT infrastructure meets customer requirements?"",""example_answer"":""I would conduct regular customer surveys, analyze industry trends, and collaborate with departments to identify areas for improvement.""},{""question"":""How would you approach cybersecurity and compliance in our organization?"",""example_answer"":""I would implement a risk-based approach, conduct regular security audits, and ensure employee training and awareness programs are in place.""}],""red_flags"":[""Lack of experience in IT leadership roles"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
IT Operations Manager,"Dragados Canada, Inc.","Surrey, British Columbia, Canada",June,2024,"Dragados Canada, Inc., the Canadian construction arm of the ACS Group (one of the world’s largest international construction and engineering companies), is seeking a talented and experienced IT Operations Manager to join its dynamic and energetic team.

Dragados Canada was established in 2008 and has grown steadily into an industry-leader in Canada, with offices in Toronto, Vancouver and Montreal, successfully performing a variety of large-scale transportation, bridge, dam, tunnel, and other major infrastructure projects.

Salary range: $80,000-$110,000 (based on relevant experience, qualifications and skills).

Responsibilities

Maintain facility’s IT environment to ensure business continuity and progression
Prepare relevant and concise written status update reports within established timeframe for IT team leads
Liaison between the site clients/stakeholders and the rest of the IT team and their leads
Install, configure, and deploy software/hardware
Establish vendor relations and perform purchasing comparisons for goods and services
Collaboration to perform maintenance activities such as upgrades, system patching, and backups
Act as a link between end-users and higher tier advanced support as needed
Coordinate with manufacturers, vendors, and service providers to ensure best possible outcome based on economics, schedule, and solution provided terms
Ensure established policies and procedures are followed and adhered to while communicating anomalies accordingly
Provide input and guidance towards the implementation of IT solutions
Maintain accurate licensing, inventory, and maintenance contracts
Assist with budgeting, including the purchase of new equipment and software and consequent billing review
Ensure accurate and up to date records between local and online portal systems
Promote continued utilization of IT service management solutions

Qualifications

BS/BA in information technology or computer science is preferred
Comprehensive knowledge of infrastructure and network topologies
Solid knowledge of IT systems and applications
Past role as IT manager or similar position
Understanding of M365 and Azure cloud offerings
Cybersecurity conscious and conforming
Project and time management skills
Exceptional attention to detail
Excellent organizational and coordination abilities
Extensive experience working in a team-oriented, collaborative environment
Able to explain technical details to non-technical personnel in a clear and coherent manner
Guide and mentor junior team members
Communicate clearly with both technical and non-technical team members
Accept accountability and scheduling of tasks assigned
Willing and able to accept and provide objective based criticism
Observant and willing to express and adopt new ideas
No agency phone calls/emails/submissions please**

Dragados is an equal opportunity employer. While only qualified candidates will be contacted for an interview, be sure to continually check our website for other related positions as they are posted.

Appropriate accommodations will be provided upon request throughout the recruitment and hiring process.","{""role_summary"":""The IT Operations Manager is responsible for ensuring business continuity and progression by maintaining the facility's IT infrastructure, managing vendor relations, and providing technical guidance to the team."",""key_terms"":[{""term"":""M365"",""explanation"":""Microsoft 365, a cloud-based productivity platform""},{""term"":""Azure"",""explanation"":""Microsoft Azure, a cloud computing platform for building, deploying, and managing applications and services""},{""term"":""Cybersecurity"",""explanation"":""The practice of protecting computer systems, networks, and sensitive information from unauthorized access, disruption, or malicious attacks""}],""skill_priorities"":{""must_have"":[""Comprehensive knowledge of infrastructure and network topologies"",""Solid knowledge of IT systems and applications"",""Past experience as IT manager or similar position"",""Understanding of M365 and Azure cloud offerings"",""Cybersecurity conscious and conforming"",""Project and time management skills"",""Exceptional attention to detail"",""Excellent organizational and coordination abilities""],""nice_to_have"":[""BS/BA in information technology or computer science"",""Extensive experience working in a team-oriented, collaborative environment"",""Able to explain technical details to non-technical personnel in a clear and coherent manner"",""Guide and mentor junior team members"",""Communicate clearly with both technical and non-technical team members"",""Accept accountability and scheduling of tasks assigned"",""Willing and able to accept and provide objective based criticism"",""Observant and willing to express and adopt new ideas""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with IT infrastructure and network topologies?"",""example_answer"":""I have worked with various infrastructure and network topologies, including cloud-based solutions, and have a solid understanding of how they integrate with IT systems and applications.""},{""question"":""How do you stay current with cybersecurity threats and best practices?"",""example_answer"":""I regularly review industry publications and attend webinars to stay informed about the latest cybersecurity threats and best practices, and I ensure that our team is aware of and follows established policies and procedures.""}],""red_flags"":[""Lack of experience with M365 and Azure cloud offerings"",""Inability to explain technical details to non-technical personnel"",""Poor project and time management skills""],""confidence_score"":90.0}"
Information Technology Manager – Consumer & Dealer,Toyota North America,"Toronto, Ontario, Canada",June,2024,"Rank P6 /P7

Scarborough, ON

Toyota Canada currently has an exciting opportunity - Information Technology Manager – Consumer & Dealer. We are looking for a leader in the Application Development and Business Relationship areas. This is a full-time role and will report to the National Manager, Enterprise Business Solutions. The selected candidate will provide leadership to technical teams, guidance and mentoring SDLC and Application Portfolio Management, and build relationship with several internal business units and our dealer stakeholders.

What We’ll Bring

Company & Culture

A hybrid work environment
A work environment built on teamwork, flexibility and respect
Professional growth and development programs to help advance your career
A focus on respect for people and continuous improvement
Summer Hours – condensed work week during the summer

Benefits

Competitive compensation package including bonus
Extended health care and dental benefits effective immediately
Company pension plan with additional employer contributions
Company demo vehicle
Associate vehicle discount program
Reimbursement programs (tuition & fitness)
Paid holiday shutdown and competitive paid time off benefits
Sabbatical leave program

What You’ll Be Doing

Leadership

Lead a team of Analysts, Developers, Solution Architects, Development Lead, vendors, and partners, throughout the PMLC, SDLC, from requirement, design, and delivery, to support and on-going maintenance
Guide and develop competencies in Application Portfolio Management and Technology Roadmaps
Define and deliver IT capabilities and solutions across multiple platforms and technologies for the TCI enterprise and the TCI Dealer network
Lead Continuous Improvement initiatives towards excellence in service delivery
Set goals and objectives, provide feedback, coach for performance, develop technical, analytical, and interpersonal skills of the team and mature their knowledge of the business

Business Relationship Management

Act as a Business Relationship Manager for several TCI business units Network (8 to 12, in average), and the TCI Dealer network to deliver technology consulting in business terms, lead initiatives around process definition, budget planning, intake and prioritization of new enhancement, requests, and projects

Administration

Provide guidance and direction in vendor negotiation, RFP Vendor Selection, definition of SOW and KPI
Manage budgets, purchase orders, vendors, contracts, and daily departmental tasks
Manage resources, scheduling, performance, and provide support to your staff
Manage daily activities, issue resolution, and communication across project execution teams in order to deliver projects on-time, and on-budget

PMLS & SDLC & Technical Practices

Ensure projects do not diverge from approved and established architecture guidelines
Lead the following practices: DevSecOps, Adobe, Salesforce, and Software Development. Ensure SDLC best practices are followed, technical roadmaps are kept up to date and facilitate dissemination of knowledge across Enterprise Business Solutions
Manage teams of Application Managed Services (AMS) partners including contract renewals, performance metrics, and resource management

Collaboration

Built relationship and work collaboratively with other Toyota affiliates, peers from other IS functional areas, external vendors, and leaders across the organization

What You’ll Bring

University Degree in computer science or related discipline
Minimum of 7 years’ experience leading teams in large scale business systems implementations
Minimum of 5 years related work in a supervisory/managerial and business support role within IT environment
Experience in implementation and leadership on technical practices
Ability to lead, motivate and direct within a matrixed organization structure
Strong understanding of application architecture and how it interconnects with enterprise architecture strategy, middleware, and security standards
Experience in application development including DevSecOps and SDLC utilizing varied environments including Azure DevOps, MuleSoft, AWS (Ruby, Lambda, S3, Cognito) Java, SaaS, PaaS solutions running on multiple databases and integration across varying types of systems e.g., SAP, Salesforce, Adobe Experience Manager and Dealer Management Systems
Ability to organize several teams and focus on best practices, particularly regarding coding standards and quality assurance
Solid experience in the following areas: Project Management, Change Management, Release Management, Systems Development Life Cycle Methodologies, Quality Assurance and Testing, Requirements Gathering, and Systems Analysis and Design. Certifications related to PMP, ITIL, Agile, CMMI, and TOGAF will be considered asset
Proven ability facilitating negotiation of competing requirements among stakeholders
Understanding of organizational change management practices and how to bridge the gap between technology and the business
Ability to work with other teams, partners, and external organizations for the resolution of business or technical problems
Outstanding communication, organization, time management, presentation, problem-solving, interpersonal skills
Ability to demonstrate initiative, good judgment, and effective decision-making, exhibit strong process improvement orientation, and have the experience to lead discussions and achieve positive results amongst inter-disciplinary groups

About Us

Toyota Canada Inc. (TCI) is the exclusive Canadian distributor of Toyota and Lexus vehicles. Toyota Canada's head office is in Toronto, with regional offices in Vancouver, Calgary, Montreal and Halifax. Toyota parts and accessories are distributed through TCI's Parts Distribution Centres in Bowmanville and Vancouver. TCI supports over 287 Toyota and Lexus dealers in Canada with services that include training, sales, marketing, environmental and customer satisfaction initiatives.

What Sets Us Apart?

A focus on People, Passion for Toyota, Innovation and Make Things Better has made us an award-winning company, recognized worldwide for our technological leadership and superior standards of quality, community involvement and environmental responsibility.

What You Should Know

Our success begins and ends with our people. We embrace diverse perspectives and value unique human experiences. We are proud to be an equal opportunity employer that celebrates the diversity of the communities where we live and do business. Applicants for our positions are considered without regard to race, ethnicity, national origin, sex, sexual orientation, gender identity or expression, age, disability, religion, or any other characteristics protected by law. Please advise us at any point during the recruitment and selection process or your employment if you require accommodation.","{""role_summary"":""The Information Technology Manager – Consumer & Dealer leads technical teams, provides guidance on SDLC and Application Portfolio Management, and builds relationships with internal business units and dealer stakeholders."",""key_terms"":[{""term"":""SDLC"",""explanation"":""Software Development Life Cycle, a process used to design, develop, test, and deliver software applications.""},{""term"":""Application Portfolio Management"",""explanation"":""A process of managing and governing an organization's software applications to meet business objectives.""},{""term"":""DevSecOps"",""explanation"":""A set of practices that combines software development (Dev) and IT operations (Ops) with security to improve collaboration and reduce risks.""},{""term"":""PMLC"",""explanation"":""Project Management Life Cycle, a process used to plan, execute, and deliver projects.""}],""skill_priorities"":{""must_have"":[""Leadership experience in IT"",""Experience in application development and SDLC"",""Strong understanding of application architecture and enterprise architecture strategy"",""Ability to lead, motivate, and direct within a matrixed organization structure""],""nice_to_have"":[""Certifications related to PMP, ITIL, Agile, CMMI, and TOGAF"",""Experience in implementation and leadership on technical practices"",""Ability to facilitate negotiation of competing requirements among stakeholders""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience in leading technical teams and guiding SDLC practices?"",""example_answer"":""I have led teams of developers, solution architects, and vendors, and guided SDLC practices to ensure projects are delivered on time and meet business requirements.""},{""question"":""How do you stay current with industry trends and emerging technologies in application development?"",""example_answer"":""I participate in industry conferences, read relevant publications, and network with peers to stay current with industry trends and emerging technologies.""}],""red_flags"":[""Lack of experience in leading technical teams and guiding SDLC practices"",""Inability to communicate technical information to non-technical stakeholders"",""Limited experience in application development and SDLC""],""confidence_score"":90.0}"
IT Service Desk Manager,"Canadian Bank Note Company, Limited","Sault Ste. Marie, Ontario, Canada",June,2024,"Description

Job Title: IT Service Desk Manager 
Job Type: Permanent, Fulltime 
Location: Sault Ste. Marie, Ontario 
Work Model: Hybrid  
Deadline for Submissions: July 19th, 2024
Position Summary 
As an IT Service Desk Manager in our Lotteries department, you will be accountable for the day-to-day operations of the IT Service Desk and Tier 2 support team, ensuring efficient incident management and asset tracking processes.  By delivering world-class IT support to North American electronic raffle and bingo customers, you will contribute to positive customer experiences, reduced downtime, and support charitable initiatives and community development. 
What We Can Offer You 
Compensation: We seek long term relationships with our employees and recognize and reward them with a competitive total compensation package that includes:  
An industry leading defined contribution pension plan with company matching contributions (up to 5%) and payment of service fees, 
Best-in-class health, medical and life insurance benefits;  
Access to virtual and telehealth services and apps; and  
Very progressive fertility, adoption and surrogacy benefits to support all definitions of family. 
Career: As a knowledge-based organization we will provide you with a wealth of learning opportunities and challenging work that will grow your knowledge, skills and abilities. At CBN, we encourage and empower our employees to chart their own career path, putting you in control of your future. 
Culture: Personal character is the foundation of our culture. CBN’s 7 Core Principles shape and guide our behaviors and underpin the sense of community you will experience at CBN. Equality, diversity and inclusivity are important to us as an organization, and we are committed to fostering and developing a work environment where every employee is treated with dignity and respect. 
What You Will Do 
Manage day-to-day operations of IT Service Desk and IT Operations support team; 
Review and update standard operating procedures (SOP) regularly; 
Continually monitor and improve customer service. 
Maintain up-to-date support documentation and training materials; 
Foster a positive work environment, set clear performance objectives, and provide training and feedback to team members; 
Manage staff schedule with equity and fairness;  
Produce Service Levels and KPI reports; and 
Various other duties and responsibilities. 
Qualifications 
Knowledge and Experience 
Bachelor’s degree in an IT related field or an equivalent combination of education and experience.   
5+ years of experience working in a fast paced/high-volume IT Service Desk or other IT support role in a management capacity 
Broad knowledge of ITIL processes and functions (ITIL certification is an asset). 
Deep experience in Incident Management and Asset Management.  
Understanding of Service Level Agreements   
Experience working in an Agile environment. 
Skills and Abilities 
Hard Skills (Working Knowledge) 
Software: MS 365 (Excel, Outlook, Teams, PowerPoint, SharePoint, Visio)  
ITSM/IVR: FreshDesk, FreshCaller (or equivalent ITSM products)  
O/S: Windows (Desktop, Server, Active Directory)  
Workflow Automation: Developing and testing workflows in FreshService. 
System Administration: Configuration and administration of ITSM and IVR. 
Presentation skills 
Soft Skills and Traits 
Leadership skills (conflict resolution, negotiation, decision and problem analysis) 
Mentoring and coaching skills 
Communication skills (verbal and written)  
Analytical/trouble shooting skills 
Organization/time management/prioritization skills.  
Customer focused 
Mandatory Requirements 
Ability to work outside of core hours and be on-call for incident escalation. 
Ability to travel domestically and internationally approximately 2-4 times per year. 
About Us 
CBN designs and develops industry leading solutions for the following domains: Border Security, Civil Identity, Driver Identification and Vehicle Information, Currency and Excise Control, and Lottery and Charitable Gaming. To learn more, visit www.cbnco.com. 
As an Equal Opportunity Employer, Canadian Bank Note Company, Limited is committed to achieving a skilled workforce that reflects the diversity of the Canadian population. We encourage applications from women, visible minorities, people with disabilities and Aboriginal people. Canadian Bank Note Company Limited is committed to developing inclusive, barrier-free selection processes and work environments. If contacted regarding this competition, please advise the interview coordinator of any accommodation measures you may require. ","{""role_summary"":""Manage the day-to-day operations and Tier 2 support team, ensuring efficient incident management and asset tracking processes, and delivering world-class IT support to contribute to positive customer experiences."",""key_terms"":[{""term"":""ITIL"",""explanation"":""A set of practices for IT service management that focuses on aligning IT services with business needs.""},{""term"":""Agile environment"",""explanation"":""A project management approach that emphasizes flexibility, collaboration, and rapid delivery.""},{""term"":""ITSM/IVR"",""explanation"":""IT Service Management and Interactive Voice Response systems used for incident management and customer support.""},{""term"":""FreshDesk"",""explanation"":""A cloud-based customer support software that provides IT service management and helpdesk functionality.""},{""term"":""FreshCaller"",""explanation"":""A cloud-based call center software that provides IVR and call management functionality.""},{""term"":""Service Level Agreements"",""explanation"":""Formal agreements between IT service providers and customers that define the expected service quality, availability, and responsiveness.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in an IT related field or equivalent experience"",""5+ years of experience working in a fast-paced/high-volume IT Service Desk or other IT support role"",""Broad knowledge of ITIL processes and functions"",""Deep experience in Incident Management and Asset Management"",""Understanding of Service Level Agreements"",""Experience working in an Agile environment"",""MS 365 (Excel, Outlook, Teams, PowerPoint, SharePoint, Visio)"",""ITSM/IVR: FreshDesk, FreshCaller (or equivalent ITSM products)"",""O/S: Windows (Desktop, Server, Active Directory)"",""Workflow Automation: Developing and testing workflows in FreshService"",""System Administration: Configuration and administration of ITSM and IVR"",""Presentation skills"",""Leadership skills (conflict resolution, negotiation, decision and problem analysis)"",""Mentoring and coaching skills"",""Communication skills (verbal and written)"",""Analytical/trouble shooting skills"",""Organization/time management/prioritization skills"",""Customer focused""],""nice_to_have"":[""ITIL certification"",""Experience working in a hybrid work model""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with ITIL processes and functions?"",""example_answer"":""I have worked with ITIL for 3 years, and I'm familiar with incident management, problem management, and change management processes.""},{""question"":""How do you ensure efficient incident management and asset tracking processes?"",""example_answer"":""I use ITSM tools like FreshDesk to track incidents and assets, and I prioritize incidents based on their impact and urgency.""},{""question"":""Can you give an example of a time when you had to negotiate with a stakeholder to resolve an IT issue?"",""example_answer"":""I once had to negotiate with a vendor to resolve a software issue that was impacting our customers. I worked with the vendor to identify the root cause and implemented a solution that met our customer's needs.""}],""red_flags"":[""Avoid candidates without experience in IT service management or IT support roles"",""Be cautious of candidates who lack experience working in an Agile environment""],""confidence_score"":90.0}"
"Manager, IT Service Desk",Canucks Sports & Entertainment (CSE),"Vancouver, British Columbia, Canada",June,2024,"Position: Manager, IT Service Desk

Department: Information Technology

Reports to: Director, Technology

Position Summary

The Aquilini Group (AG) encompasses a wide range of businesses, among them Canucks Sports & Entertainment (CSE). The Manager, IT Service Desk will lead the service desk team and play a crucial role in planning and coordinating the provision of user applications and systems essential for smooth business operations.

The Manager, IT Service Desk leads a service desk team that provides exceptional customer service for both AG and CSE on technical issues. The incumbent will be the subject matter expert regarding all end-user applications within the organization’s infrastructure, including technology training, software and hardware procurement, and spearheading customer-focused initiatives. This role works with a diverse group of important clients, visitors, and internal contacts at all levels; independent judgement is required to plan, prioritize, and organize a diverse workload.

This Role Will Focus On

Leading and managing the IT Service Desk team, fostering a culture of excellent customer service and high performance
Overseeing a team responsible for maintaining optimal functionality of user components, including computers, laptops, and mobile devices
Developing and implementing comprehensive IT training initiatives for new hires and ongoing staff development for AG and CSE employees
Acting as the initial point of escalation for unresolved calls, technical issues, and complex requests, providing effective resolutions and support
Proactively monitoring and managing the Help Desk ticket system queue, ensuring timely resolution of issues and efficient ticket handling
Collaborating in the procurement process of IT resources for various AG divisions
Coordinating event support scheduling, working with event managers to ensure seamless IT support during events
Providing expert first- and second-level support for computer hardware and software issues on both Microsoft and Apple platforms
Maintaining a comprehensive hardware and software inventory to facilitate efficient asset management
Providing support outside normal business hours, including events at Rogers Arena and at various offsite locations

We Have

A team you can belong to and believe in
A fun, high energy environment
An open mind for new ideas
The opportunity to embark on a career development journey
Lots of fun staff events throughout the year
Onsite gym underground parking

You Have

At least four years of experience within the Information Technology industry in a support capacity
A post-secondary degree or diploma in a technical field
Strong competence in the Microsoft Ecosystem (Office365, Exchange 2013/16, Remote Desktop, Server, and Desktop OS)
Strong knowledge of MacOS and iOS devices
Ability to thrive in a fast-paced, team-oriented environment
Strong attention to detail and organization skills, with the ability to balance priorities and multitask
Exceptional communication and customer service skills, with an ability to interact in a professional and friendly manner with end users at all levels within the organization
Solid problem-solving and troubleshooting skills coupled with a willingness to learn
A valid driver’s license and access to a vehicle
Ability to work flexible, extended hours
A strong understanding of and commitment to uphold our company values of discipline, respect, excellent, attitude, and mindset (DREAM)
Onsite role at our office in downtown Vancouver

You May Also Have

Previous experience with Point-of-Sale hardware and software

Vancouver is one of the most diverse cities in the world, and Canucks Sports & Entertainment strives to create a workforce that is inclusive, equitable and represents our beautiful, unique community. We value unique perspectives, ideas, and creativity that support a diverse, inclusive, respectful, collaborative, and fun work environment. Canucks Sports & Entertainment is committed to building and supporting a diverse team.

This position will remain open until filled.","{""role_summary"":""The Manager, IT Service Desk leads a team providing exceptional customer service for technical issues, planning and coordinating user applications and systems for smooth business operations."",""key_terms"":[{""term"":""IT Service Desk"",""explanation"":""A team that provides technical support and resolves user issues within an organization.""},{""term"":""Microsoft Ecosystem"",""explanation"":""A suite of Microsoft products and services, including Office365, Exchange, Remote Desktop, Server, and Desktop OS.""},{""term"":""Point-of-Sale hardware and software"",""explanation"":""Technology used for transactions, such as cash registers and credit card machines.""}],""skill_priorities"":{""must_have"":[""At least four years of experience in IT support"",""Post-secondary degree or diploma"",""Strong competence in Microsoft Ecosystem"",""Strong knowledge of MacOS and iOS devices"",""Exceptional communication and customer service skills""],""nice_to_have"":[""Previous experience with Point-of-Sale hardware and software""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach resolving a complex technical issue escalated to you?"",""example_answer"":""I would first assess the issue, then use my knowledge of the Microsoft Ecosystem to troubleshoot and resolve the problem, ensuring timely resolution and effective communication with the end-user.""},{""question"":""Can you give an example of a time when you had to balance multiple priorities and multitask in a fast-paced environment?"",""example_answer"":""In my previous role, I had to manage multiple IT projects simultaneously, prioritizing tasks and ensuring timely completion while maintaining strong attention to detail.""}],""red_flags"":[""Lack of experience in IT support or technical field"",""Inability to work flexible, extended hours""],""confidence_score"":90.0}"
"Manager, Application Support",Canada Goose,"Toronto, Ontario, Canada",June,2024,"Company Description

Canada Goose isn't like anything else. We've built something great, something special - an iconic lifestyle brand with an inspirational and authentic story. At the heart of it is our promise to inspire and enable all people to thrive in the world outside. To Live in the Open. At Canada Goose, you're part of a movement that belongs to something bigger. One that seeks out the restorative power of nature and is driven by a purpose to keep the planet cold and the people on it warm. We endure any condition, observe every detail, and are building a community that believes in living bravely and coming together to support game-changing people.

Here, opportunities are everywhere - to try something new, to learn, to do meaningful and impactful work, and they're yours for the taking.

Job Description

The Application Support Manager will oversee the resolution of incidents related to enterprise applications used throughout Canada Goose. The successful candidate will manage a team responsible for troubleshooting, resolving issues, and optimizing the performance of our ERP applications, with a focus on D365 Finance & Operations. They will be responsible for managing the end-to-end incident management process, ensuring timely resolution, minimizing business impact, and driving continuous improvement in our support services. This role requires strong leadership, technical expertise, and a commitment to delivering high-quality support to our internal stakeholders.

What You’ll Do:

Lead and mentor a team of Application support specialists, providing guidance, coaching, and performance feedback.
Foster a culture of collaboration, innovation, and continuous improvement within the support team.
Set clear objectives and priorities for the team, ensuring alignment with business goals and objectives.
Serve as the primary point of contact for all incidents related to all enterprise applications, including initial triage, assessment, and prioritization.
Coordinate the resolution efforts of cross-functional teams, including support specialists, developers, and business stakeholders.
Monitor the progress of incidents, escalate as necessary to ensure timely resolution, and communicate updates to stakeholders.
Conduct root cause analysis for major incidents and identify underlying issues contributing to recurring problems.
Develop and implement corrective actions and preventive measures to address identified problems and prevent future incidents.
Collaborate with technical teams to implement system changes or enhancements aimed at improving system stability and reliability.
Serve as the primary point of contact for application-related issues.
Communicate effectively with stakeholders to provide status updates and gather requirements.
Collaborate with other IT teams and departments to ensure cohesive support efforts.
Maintain accurate records of all incidents, including details of the incident, resolution activities, and any follow-up actions taken.
Analyze incident trends and performance metrics to identify opportunities for service improvement and optimization.
Prepare regular reports and presentations for management, highlighting key performance indicators and areas for improvement.
Manage relationships with software vendors and service providers.
Monitor vendor performance to ensure they meet contractual obligations.
Coordinate with vendors for application updates, patches, and technical support.
Drive a culture of continuous improvement within the incident management process, seeking opportunities to streamline workflows and enhance efficiency.
Collaborate with other teams to implement best practices and standards for incident management and service delivery.

Let's Talk About You:

A post-secondary education in Computer Science, Information Systems, or related field.
Minimum of 5 years of experience in IT incident management, with a focus on enterprise applications such as Microsoft Dynamics 365.
Strong technical knowledge of Dynamics 365 applications, including configuration, customization, and integration capabilities.
Proven leadership skills with the ability to inspire and motivate a team.
Excellent communication and stakeholder management skills, with the ability to coordinate and collaborate effectively across teams.
Experience working in an Agile Environment
Experience with compliance and governance frameworks (SOX preferred)
Industry certifications preferred such as: Microsoft Certified: Dynamics 365 Functional Consultant Associate (MB-300, MB-320, MB-330, MB-310)
Knowledge of the ITIL framework and related support processes
Experience supporting applications in a Discrete Manufacturing or Retail vertical
Strong organizational, writing, interpersonal and communication skills
Exceptional attention to detail and committed to a high degree of accuracy
A team player who builds strong relationships based on trust and integrity
Creativity and demonstrated ability working in a fast-paced environment with a high degree of change
Embraces continuous improvement by proposing new and/or better ways of doing things
Ability to work efficiently under pressure and effectively multi-task

Additional Information

What’s in it For You?

A company built on Canadian roots and heritage
Your work is recognized with a comprehensive and competitive Total Rewards Program
Opportunities for career growth through numerous internal and external programs
Recognize and be recognized by your peers with our Goose Rewards & ICON Rewards
Be a part of CG Gives. Donation matching and paid volunteer time to help the organizations you care about
Access to tools and resources to support physical and mental health, embracing change and connecting with colleagues
Inspiring leaders and colleagues who will lift you up and help you grow

We believe in the power of inclusion and are passionate about building and sustaining an inclusive and equitable working environment where all employees can bring their authentic selves to work everyday. We believe every one of our team members enriches our diversity by exposing us to varying ways to understand the world, identify challenges, and to discover, design, produce, and deliver great products and service. Our different perspectives are what enable us to create, dream and live in the open.

Canada Goose is an equal opportunity employer and is committed to providing employment accommodation in accordance with the Ontario Human Rights Code and the Accessibility for Ontarians with Disabilities Act.

There are multiple ways to interview with us! If you require any interview accommodation for your interview, please e-mail us at HR@canadagoose.com.","{""role_summary"":""The Application Support Manager oversees incident resolution, manages a team, and ensures timely resolution, minimizing business impact, and driving continuous improvement in support services."",""key_terms"":[{""term"":""ERP"",""explanation"":""Enterprise Resource Planning, a type of software that manages business operations.""},{""term"":""D365 Finance & Operations"",""explanation"":""A Microsoft Dynamics 365 module for financial and operational management.""},{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a framework for IT service management.""}],""skill_priorities"":{""must_have"":[""Strong leadership and technical expertise"",""Experience in IT incident management with a focus on enterprise applications"",""Knowledge of Dynamics 365 applications""],""nice_to_have"":[""Industry certifications such as Microsoft Certified: Dynamics 365 Functional Consultant Associate"",""Experience working in an Agile Environment"",""Knowledge of compliance and governance frameworks""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach root cause analysis for major incidents?"",""example_answer"":""I would use a structured approach, identifying underlying issues and implementing corrective actions to prevent future incidents.""},{""question"":""Can you give an example of how you've driven continuous improvement in incident management?"",""example_answer"":""I've implemented process changes, streamlined workflows, and enhanced training for the support team, resulting in improved incident resolution times.""}],""red_flags"":[""Lack of experience in IT incident management"",""Inability to lead and mentor a team""],""confidence_score"":90.0}"
Director of IT,isgSearch,"Greater Toronto Area, Canada",June,2024,"DIRECTOR OF IT The IT Development & Operations Director will lead and manage the IT department, responsible for Development, Operations, Security, and Compliance of the entire IT platform for a growing digital insurance brokerage company. The main objective is to create and execute an IT roadmap of projects to achieve the company's business plan (application and domain integration after multiple acquisitions and creating a future-proof technology stack for further profitable growth). This role involves building out more mature processes and teams for both the Agile development and Operations support areas of the IT department, as well as managing the ecosystem of vendors and partners that are part of the digital platform.

The IT Development & Operations Director requires experience in developing and building out application platforms (preferably in the insurance industry) with a good understanding of the AWS stack. You should know how to build cross-platform web applications and be familiar with security guidelines and frameworks for the web.

Key Accountabilities:

People Leader: Lead a multidisciplinary team of Business Analysts, Development, Quality Assurance, Data Engineers, and the IT Operations Manager.

Target Architecture: Maintain, develop, and ensure compliance of the IT and Data architecture in line with integration plans and company strategy. Ensure effective, secure, and available system architecture and consistent data storage and maintenance.

Development & Code Quality: Lead and manage web/external developers, BA, and QA teams. Support them in integrating and building out the capabilities of the company's digital brokerage platform and infrastructure. Develop a strategy to meet the company's goals and improve service quality. Assure the quality of the codebase, monitor it constantly, ensure the right third-party frameworks are used, and collaborate with the product owner on improving/refactoring the codebase.

Release Management & QA: Plan the release of project deliverables and oversee the release life cycle. Oversee the team establishing and enforcing quality standards for products and services. Build and release new features on the platform and work with the development team to deliver new features for each sprint as the company expands its products nationally.

Data Migration and Analytics capabilities: Align on data requirements needed to migrate insurance portfolios from another platform to a broker management system. Ensure the buildout of the data warehousing, data management, and mining capabilities of the organization.

Vendor management: Manage contacts and contracts with development partners. Ensure vendor delivery aligns with needs and contracts. Anticipate potential changes and maintain good relationships with partners.

Governance: Create and maintain a structure for IT governance, security, and control frameworks for the group of companies.



Qualifications and Competencies:

Proven experience in IT with at least a bachelor's degree, preferably with a specialization in IT.
At least 5 years' experience in a comparable role.
In-depth knowledge and experience of (AWS-based) IT-architecture solutions, including integration, security, and performance aspects.
Knowledge of and experience with insurance platforms such as Guidewire, Duck Creek, and Applied Systems.
Experience with the following Technology Stack:

o Angular,React,Vue,Java o Sitecore
o SQL,Postgres,MongoDB o Salesforce o Mulesoft
o AzureDataWarehouse o AWSEC2andLambda
Ability to translate business requirements into IT solutions that fit the target architecture and infrastructure setup.
Provide leadership, direction, and definition for the development and analytics teams and the IT Operations Manager, including planning, scheduling, test coordination, and implementation.
Manage risks and resolve issues affecting release scope, schedule, and quality.
Work with QA, Development, DevOps, and Product teams to ensure development projects adhere to release processes and change procedure guidelines.
Design, establish, and maintain a departmental structure to accomplish organizational goals and objectives effectively and efficiently.
Collaborate with decision-makers in other departments to identify, recommend, develop, implement, and support cost-effective technology solutions for all aspects of the organization.
Hands-on approach.
Ability to work independently and collaborate with various roles and disciplines within the organization.","{""role_summary"":""The Director of IT will lead and manage the IT department, responsible for Development, Operations, Security, and creating an IT roadmap to achieve the company's business plan."",""key_terms"":[{""term"":""AWS stack"",""explanation"":""A set of cloud computing services offered by Amazon Web Services, used for building and deploying applications.""},{""term"":""Agile development"",""explanation"":""An iterative approach to project management that focuses on flexibility and continuous improvement.""},{""term"":""Cross-platform web applications"",""explanation"":""Web applications that can run on multiple operating systems and devices.""},{""term"":""Security guidelines and frameworks"",""explanation"":""Standards and best practices for ensuring the security of web applications and data.""},{""term"":""IT governance, security, and control frameworks"",""explanation"":""Policies and procedures for managing and protecting an organization's IT systems and data.""}],""skill_priorities"":{""must_have"":[""Experience in developing and building application platforms"",""Knowledge of IT-architecture solutions"",""Experience with insurance platforms"",""Ability to translate business requirements into IT solutions""],""nice_to_have"":[""Knowledge of AWS-based IT-architecture solutions"",""Experience with Angular, React, Vue, Java"",""Experience with SQL, Postgres, MongoDB, Salesforce, Mulesoft""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with building and managing application platforms?"",""example_answer"":""I have built and managed multiple application platforms using AWS and have experience with insurance platforms such as Guidewire, Duck Creek, and Applied Systems.""},{""question"":""How do you ensure the security and compliance of IT systems and data?"",""example_answer"":""I ensure security and compliance by implementing security guidelines and frameworks, and maintaining a structure for IT governance, security, and control frameworks.""}],""red_flags"":[""Lack of experience in building and managing application platforms"",""Inability to translate business requirements into IT solutions"",""No experience with insurance platforms""],""confidence_score"":90.0}"
IT Help Desk Administrator,Eastlink,"Halifax, Nova Scotia, Canada",June,2024,"Designated Office

Young Tower

6080 Young Street

This Position Is

Hybrid, at least 3 days per week in office

Eastlink is a family owned, entrepreneurial and innovative company headquartered in Halifax, Nova Scotia. We take great pride in being a leader in delivering creative competitive, customer focused telecommunications solutions, and connecting our customers to the things and people that matter most. Serving a customer base across seven provinces, our advanced solutions include Internet, Mobile, TV, Telephone, Security and Automation, Data Communications, and exclusive locally produced programming on Eastlink Community TV.

We embrace diversity, inclusion, equity, and accessibility throughout all levels of the organization and encourage members of equity groups to self-identify during the application process.

The IT Helpdesk Administrator will be a key member of the Information Technology team. Reporting to the Manager of Desktop Support, the IT Helpdesk Administrator will act as the central point of contact for our Internal IT Support Helpdesk, performing Tier 1 support of mobile and desktop computing technologies, trouble ticket creation and assignment. The customers that the IT helpdesk Administrator will support are all Eastlink employees and Contractors hired by Eastlink to perform tasks on Eastlink’s behalf. This position is a hybrid role which will allow working from home and our office location at 6080 Young St, Halifax, NS

Responsibilities

Specific responsibilities will include, but are not limited to the following:

Respond to telephone calls, email, and personnel requests for technical support from our internal Eastlink employee.
Perform high level problem determination, information gathering by asking probing questions and triaging calls to assess the urgency and impact to the employee or business.
Install applications and drivers, password resets, as well as fix minor issues.
Trouble ticket creation & assignment to our IT Operations team


The successful candidate will be customer focused, have exceptional leadership, communication and troubleshooting ability, and thrives in a fast paced, dynamic work environment.

Qualifications

The IT Helpdesk Administrator should have completed or be in the process of completing a related technical diploma, university degree or equivalent program.
Strong customer service skills, with the ability to make the customer their priority, determine their needs, and set realistic expectations. Previous experience in a customer service focused role with be an asset.
Solid written and verbal communication skills
Able to work effectively in a busy, interrupt driven environment, while maintaining a friendly and professional manner
A good sense of responsibility and commitment
Takes pride in their work, with the goal of producing error free work the majority of the time
Interest and ability to look for new and innovative ways of improving efficiency
Strong interest in and demonstrated aptitude for troubleshooting PC hardware and software related problems with the ability to learn new skills quickly.
Able to stay highly organized with their work area, equipment, and assigned tasks.
Has a good sense of integrity and treats others with respect.
Ability to work overtime as required.


Why Choose Eastlink?

Eastlink operates in a culture of continuous improvement through listening, learning and adapting, which enables us to respond quickly to the evolving needs of both employees and customers. We recognize that our truly greatest competitive edge is our people and that delivering a great customer experience begins with a great employee experience. Our philosophy of developing and training our team “on the ground” not only helps to create a strong onboarding experience but also readies employees for future growth opportunities within the organization.

We are extremely proud of our employees and believe the best people make the best companies. As we continue to grow, our goal is to continue to attract the best people.

Ready to explore an exciting career at Eastlink? Your journey begins here.

Apply Now","{""role_summary"":""The IT Helpdesk Administrator provides technical support to internal Eastlink employees and contractors, resolving technical issues and ensuring efficient operations."",""key_terms"":[{""term"":""Tier 1 support"",""explanation"":""Basic technical support provided to customers, typically involving troubleshooting and resolving simple issues.""},{""term"":""Trouble ticket creation"",""explanation"":""The process of documenting and tracking technical issues reported by customers, ensuring efficient resolution and follow-up.""}],""skill_priorities"":{""must_have"":[""Customer service skills"",""Troubleshooting ability"",""Communication skills"",""Technical diploma or degree""],""nice_to_have"":[""Previous experience in a customer service focused role"",""Interest in improving efficiency"",""Ability to work overtime""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach resolving a technical issue reported by an internal employee?"",""example_answer"":""I would first ask probing questions to understand the issue, then assess the urgency and impact to the employee or business, and finally, provide a clear explanation of the solution and next steps.""},{""question"":""Can you give an example of a time when you had to troubleshoot a technical problem?"",""example_answer"":""In my previous role, I had to troubleshoot a printer issue by identifying the root cause, researching solutions, and implementing a fix, resulting in minimal downtime for the user.""}],""red_flags"":[""Lack of customer service experience"",""Inability to work in a fast-paced environment"",""Poor communication skills""],""confidence_score"":90.0}"
Information Technology Manager -18921,The Headhunters Recruitment,"Winnipeg, Manitoba, Canada",June,2024,"The Information Technology Managers responsibly is to oversee, coordinate, and manage the information systems, data, and infrastructure both on and offsite.

Role Overview

The Manager of Information Technology role ensures the effective and efficient implementation, maintenance, and support of cross-organization technology systems and projects, including optimizing the technical infrastructure. They will coordinate information activities with other departments and directly advise the Executive leadership team on the implications of proposed actions and decisions taken by the IT and Security Departments.

Key Responsibilities

Create and maintain a preventive maintenance schedule for equipment and facilities.
Project Management
Train new hires and other team members.
Lead the process to oversee the IT requirements and guide the team to adhere to required company standards.
Prepare documentation of the inspection process, which includes detailed reports and performance records.
Coordinate with vendors to schedule IT visits and ensure timely completion of outsourced tasks.
Ensure accurate documentation of work order details, including scope, time estimates, and materials required.
Monitor work order progress and update stakeholders on the status of ongoing IT tasks.
Review completed IT work orders/invoices for accuracy, completeness, and quality of work.
Assist with the identification and evaluation of potential vendors for IT services and assist with the negotiation of contracts.
Actively search for and recommend improvements to the system and processes.
Perform other duties as assigned or needed.
Utilize CMMS system and other required software and applications, review, enter, schedule based on priority, and track work orders for IT requests.
Schedule maintenance tasks and allocate appropriate resources to complete them.

Qualifications:

Bachelors degree in computer science, Information Technology, or a related field (Master's degree preferred).
Project Management experience an asset
Excellent communication and interpersonal skills
Proficiency in using IT Service Management Systems (ITSM).
Ability to prioritize tasks and manage multiple projects simultaneously.
Clear criminal record is required.
Proficient in an array of software, including, SAP and other ERP/MRP systems, SQL, Application Programming Interface (API), Microsoft office programs (MSSE would be an asset), Power BI, etc.
Customer service experience required.
Strong organizational and time management skills.
Knowledge of IT best practices and security, privacy, and confidentiality standards.
Strong leadership and team management skills, with the ability to inspire and motivate a diverse team.
In-depth knowledge of IT infrastructure, networking, cybersecurity, and cloud technologies.
Experience in developing and implementing IT strategies aligned with business objectives.
Strong problem-solving and decision-making abilities, with a focus on innovation and continuous improvement.
Knowledge of ITIL (Information Technology Infrastructure Library) and other industry frameworks.

What You Will Receive:

Annual salary range: $110,000-$120,000
Paid annual vacation
Extended medical benefits

Only candidates already eligible to work in Canada will be reviewed. Only qualified candidates will be contacted.","{""role_summary"":""The Information Technology Manager oversees and manages information systems, data, and infrastructure, ensuring effective implementation, maintenance, and support of technology systems and projects."",""key_terms"":[{""term"":""ITSM"",""explanation"":""Information Technology Service Management, a framework for managing IT services.""},{""term"":""ERP/MRP"",""explanation"":""Enterprise Resource Planning and Manufacturing Resource Planning, software systems for managing business operations.""},{""term"":""API"",""explanation"":""Application Programming Interface, a set of rules for building software applications.""},{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a framework for IT service management.""},{""term"":""Cloud technologies"",""explanation"":""On-demand computing resources and services over the internet.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in computer science or related field"",""Proficiency in ITSM"",""Excellent communication and interpersonal skills"",""Ability to prioritize tasks and manage multiple projects"",""Clear criminal record"",""Knowledge of IT best practices and security standards"",""Strong leadership and team management skills""],""nice_to_have"":[""Master's degree"",""Project Management experience"",""Proficiency in SAP and other ERP/MRP systems"",""Knowledge of SQL"",""Experience with Microsoft office programs"",""Power BI skills"",""Customer service experience"",""Strong organizational and time management skills"",""Knowledge of IT infrastructure, networking, cybersecurity, and cloud technologies"",""Experience in developing and implementing IT strategies""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you prioritize tasks and manage multiple projects simultaneously?"",""example_answer"":""I use project management tools to prioritize tasks and allocate resources effectively, ensuring timely completion of projects.""},{""question"":""Can you explain your experience with ITSM and how you've utilized them in previous roles?"",""example_answer"":""I've used ITSM to manage service requests, incidents, and problems, ensuring efficient resolution and minimizing downtime.""}],""red_flags"":[""Lack of experience with ITSM or ERP/MRP systems"",""Inability to prioritize tasks and manage multiple projects"",""Poor communication and interpersonal skills""],""confidence_score"":90.0}"
"Manager, IT Client Services - (01074.13)",Thompson Rivers University,"Kamloops, British Columbia, Canada",June,2024,"Summary:

The Manager of IT Client Services holds a pivotal role in ensuring the efficient and effective delivery of IT services to the university support and timely resolution of IT-related issues. Additionally, the manager fosters a culture of customer-centric support within the IT department and ensures team readiness for agile service delivery in a rapidly evolving digital environment.

Major Responsibilities:

Provides leadership, direction, and guidance to the Client Services team
Oversees recruitment, selection and deployment, training, development and review of staff performance.
Establishes clear performance objectives and expectations by conducting regular evaluations and providing feedback
Ensures compliance with occupational health and safety standards.
Fosters a collaborative and inclusive work environment, promoting teamwork and professional development opportunities
Manages day-to-day operations of Client Services Teams to ensure timely and effective response to IT support requests
Develops and implements Service Level Agreements (SLAs) and standard operating procedures for consistency and quality in service delivery
Monitors metrics and key performance indicators to identify trends, areas for improvement and opportunities for enhanced service delivery
Administers the TRU Technology Leasing by collaborating with IT Asset administration to review equipment specifications and coordinate with external contractors. Program
Co-ordinates the development of university-wide IT support policies, standards and procedures
Undertakes projects involving supplier selection and evaluation of IT equipment and services
Organizes and co-ordinates technology education and awareness training programs within the University
Monitors software licenses, maintenance, and support arrangements for University Site Licensed Software
Oversees the change management processes for systems and services
Initiates client surveys and other procedures to measure service quality;
Co-ordinates critical incident activities by coordinating between Client Services and other relevant stakeholders to resolve the issues
Serves as an escalation point for complex or high-priority IT support issues, collaborating with technical specialists and other IT teams for resolution
Oversees IT Service Management system
Coordinates the Active Directory Integration within Client Services
Builds and maintains strong relationships with University Stakeholders, including faculty, staff, students, and academic departments
Acts as a liaison between the IT department and campus community, soliciting feedback, addressing concerns, and advocating for user needs.
Communicates IT Service updates, initiatives, and best practices to stakeholders through various channels and committees
Manages departmental resources effectively, including staffing levels, equipment and budget allocations
Identifies opportunities for cost optimization and efficiency improvements, prioritizing investments to enhance service quality and user experience

Qualifications:

Bachelor's Degree with at least 5 years of relevant experience
Certifications in ITIL and/or project service management (PMP) are considered an asset
Strong technical background with expertise in IT support methodologies, tools and best practices
Excellent communication and interpersonal skills, with the ability to interact effectively with diverse stakeholders
Working knowledge of relevant programs such as Microsoft Intune/Azure

Pay Band:
$96,263.00 - $108,131.00

Location: Kamloops, BC

Diversity and Inclusion Commitment:
Thompson Rivers University is strongly committed to hiring based on merit with a focus on fostering diversity of thought within our community. We welcome those who would contribute to the further diversification of our staff, our faculty and its scholarship including, but not limited to, women, Indigenous, Black and People of Colour, persons with disabilities and persons of any sexual orientation or gender identity. Please note that all qualified candidates are encouraged to apply, however applications from Canadians and permanent residents will be given priority.","{""role_summary"":""The Manager of IT Client Services leads the delivery of IT services, resolves IT issues, and fosters a customer-centric culture within the department."",""key_terms"":[{""term"":""ITIL"",""explanation"":""A framework for IT service management that focuses on aligning IT services with business needs.""},{""term"":""PMP"",""explanation"":""A certification for project management professionals, demonstrating expertise in planning, executing, and delivering projects.""},{""term"":""Microsoft Intune/Azure"",""explanation"":""Cloud-based services for managing and securing devices, applications, and data, with Azure being a cloud computing platform.""}],""skill_priorities"":{""must_have"":[""Strong technical background"",""Excellent communication and interpersonal skills"",""Working knowledge of relevant programs such as Microsoft Intune/Azure""],""nice_to_have"":[""Certifications in ITIL and/or project service management (PMP)""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you ensure timely and effective response to IT support requests?"",""example_answer"":""I would prioritize tasks, allocate resources efficiently, and establish clear performance objectives for the Client Services team.""},{""question"":""Can you describe a situation where you had to foster a collaborative and inclusive work environment?"",""example_answer"":""In my previous role, I promoted teamwork by conducting regular team-building activities and providing opportunities for professional development.""}],""red_flags"":[""Lack of experience in IT service management frameworks like ITIL"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":85.0}"
IT Team Lead,Cloud9 Solutions,"Langley, British Columbia, Canada",June,2024,"Job Description

Cloud9 Solutions is a rapidly growing Managed Services Provider that offers a broad range of IT Consulting, Managed IT, and Cloud services for organizations looking to source and implement IT solutions and IT services in their businesses or in the cloud.

At Cloud9 Solutions, our mission is to provide our clients with solutions that help them address the technology challenges in meeting their business objectives. In addition to a vast range of Private Cloud, Hybrid Cloud and Public Cloud offerings customized to suit any business, big or small, we offer a range of solutions for Connectivity, Unified Communications, and VoIP. This positions Cloud9 Solutions as your true one-stop-shop for any business's IT and Communications needs.

About the job:

We are looking for a highly motivated, hands-on, experienced IT Team Lead to join our business. The candidate will collaborate with all levels of technical resources as well as the leadership team and oversee the company's service delivery to its existing and new clients. This role will also be the base of our new client onboardings, from creating the project to assigning the tasks and resources to the follow-up process to ensure they are completed on schedule.

Job Duties:

Oversee the service delivery to our clients
Ensure client tickets and calls are getting addressed in a timely fashion
Be well versed in the ITIL foundation and ensure these best practices are being followed
Meet with clients to discuss system requirements, specifications, costs and timelines
Lead a team of technicians and allocate resources to facilitate escalations
Work with client contacts and team resources to schedule task
Supervise, hire, train and provide direction for Tier1 and Tier2 staff
Work side by side with the leadership team to implement policies and procedures
Work with shipping/receiving staff to organize hardware setup and delivery
Oversee projects for our client's onboarding and offboarding
Perform other duties and special projects as assigned

Skills And Qualifications

1+ years in IT manager or relevant experience
1+ years in MSP experience
Excellent communication, interpersonal and organization skills
Demonstrated good business judgement and decision-making skills
Creative thinker and problem solver with hands-on troubleshooting skills, attention to detail, thoroughness and follow-through

Job Type: Full-time

Pay: $25.00-$35.00 per hour

Expected hours: 40 per week

Benefits:

Casual dress
Dental care
Extended health care
Vision care

Flexible Language Requirement:

French not required

Schedule:

8 hour shift
Monday to Friday

Licence/Certification: BC Driver's License and reliable vehicle (required)

Work Location: In person

Company Description

Cloud9 Solutions is a rapidly growing Managed Services Provider that offers a broad range of IT Consulting, Managed IT, and Cloud services for organizations looking to source and implement IT solutions and services in their businesses or in the cloud.

Cloud9 Solutions is a rapidly growing Managed Services Provider that offers a broad range of IT Consulting, Managed IT, and Cloud services for organizations looking to source and implement IT solutions and services in their businesses or in the cloud.","{""role_summary"":""Lead a team of IT technicians to deliver services to clients, ensuring timely resolution of client issues and overseeing project onboarding and offboarding."",""key_terms"":[{""term"":""ITIL foundation"",""explanation"":""A set of best practices for IT service management, ensuring efficient and effective delivery of IT services.""},{""term"":""MSP experience"",""explanation"":""Experience working with a Managed Services Provider, offering a range of IT services to clients.""},{""term"":""Tier1 and Tier2 staff"",""explanation"":""Levels of technical support, with Tier1 being the initial point of contact and Tier2 providing more advanced technical support.""}],""skill_priorities"":{""must_have"":[""1+ years in IT manager or relevant experience"",""1+ years in MSP experience"",""Excellent communication, interpersonal and organization skills""],""nice_to_have"":[""Creative thinker and problem solver with hands-on troubleshooting skills""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with IT service management frameworks like ITIL?"",""example_answer"":""I have worked with ITIL foundation principles to ensure efficient delivery of IT services to clients.""},{""question"":""How do you prioritize and allocate resources for project onboarding and offboarding?"",""example_answer"":""I assess project requirements, identify necessary resources, and allocate them accordingly to ensure timely completion.""}],""red_flags"":[""Lack of experience in IT service management or MSP environment"",""Poor communication or organizational skills""],""confidence_score"":85.0}"
"IT Manager, Service & Support - Americas","Novocol Pharma, a Septodont company","Cambridge, Ontario, Canada",June,2024,"Company Details

Novocol Pharma is a growing contract development and manufacturing organization (CDMO), specialized in sterile injectable cartridges and combination product manufacturing. We strive for excellence and customer-centricity to deliver value to global pharmaceutical clients through contract services for drug development and commercial manufacturing. With over 40 years in operation, our team of 600 employees and modern facilities, located in Cambridge, Ontario provide a personalized and responsive experience for our customers. We are focused on serving our strategic partners and patients with quality, integrity, and value.

Our employees are our number one asset! We offer developmental opportunities, excellent compensation and benefit programs, discounted gym memberships, work/life balance programs, employee recognition, social events and spirit days.

We are a proud member of the Septodont group of companies. Septodont is a pharmaceutical and medical device company with a global leadership position in dental pain management. The group counts over 2000+ employees worldwide and has remained a 100% family owned company for over 90 years. Our Cambridge facility serves as a significant manufacturing site within the Septodont group with high volume dental anesthetic production for a global customer base.

We have an opportunity for an IT Manager, Service & Support – Americas.

Job Summary

The IT Manager, Service & Support – Americas reports to the Senior IT Manager, Operations and manages all areas of IT Service and Support in the region. Acting as the management level contact for local needs including for the Cambridge site. This includes managing and mentoring the IT staff responsible for service delivery, help desk, and end user computing. This leadership role is a champion of customer centric behaviours, focusing the IT Service and Support team on achieving service levels and enhancing end user computing through customer centric service delivery.

Responsibilities

Delivers cost-effective operations that fully support and enable strategic objectives for the region.

Leads by example, reinforcing expected behaviours within the team, driving a service excellence culture:

Seeing everything through the lens of the customer.
Paying attention to the physical environment because everything speaks.
Providing service delivery that will create service wows.
Developing processes that make employees service heroes for doing an outstanding job.

Champions ongoing improvement, and markets I&O to the organization by:

Focusing on customer-facing activities.
Acts as the local business partner for the region ensuring customer requirements are understood and facilitating communication with local management teams with specific focus as the first point of contact for the Cambridge site.
Managing from a customer value creation perspective using:
Customer value creation metrics (what is important to the business).
An emphasis on customer-focused problem solving workflows (agile, lean).
All staff empowered to take proactive action to prevent performance issues.
Prioritizing customer-centric behavioural competencies and technical skills for developing and hiring staff:
Developing behavioural competencies, as well as new technical skills.
Protecting staff time for development.

Leads the local Service Support function with a mission focused on:

Champion service excellence in:
The onboarding of new employees ensuring all tools and technologies are properly prepared and trained.
The management of service delivery ensuring the support team and end users are properly prepared for delivery of new or updated services / applications.
Support help desk (including Incident, Problem, Change, and reporting)
Deployment and support of employee devices including management of the hardware lifecycle
Follow up on end user device metrics including hardware, software (i.e. Windows Updates), and security deployments (i.e. disk encryption, endpoint protection) to ensure devices maintain a high level of security and capabilities

Manages help desk and support service levels, including for on-call support outside of regular business hours, to ensure: availability of resources according to business needs (internal and external); and timely escalation of requests/issues.

Leads continuous improvement activities related to service delivery and end user experience liasing with the appropriate I&O teams.

Ensure IT Security playbooks are followed and security incidents are properly prioritized and escalated.

Contributes to the preparation and management of staffing, capital and operations spending plans.

Manages the performance and development of all direct reports.

Responsible for hiring, identifying skill gaps, and appropriate training/development.

Ensures hardware and software assets are tracked and software license compliance is maintained.

Responsible for compliance to GxP guidelines

Qualifications

Education:

Bachelor’s degree in Computer Science or Information Systems, or IT diploma with relevant certification (i.e. ITIL, Lean IT, Microsoft Expert or Architect level).

Experience:

Minimum of 5 years of progressive IT experience with diverse enterprise environments including 2 years of experience supervising teams in a technical support/customer service environment.
Pharmaceutical, food, or cosmetic industry experience is considered an asset.
Demonstrated track record of providing great customer service.
Strong team player with the ability to lead and mentor staff, including remotely, as well as within cross-cultural teams.
Excellent written and verbal communication skills with diverse teams.
Proficiency Portuguese (Brazilian) is an asset.
Agile in thought and action with the ability to tackle difficult problems analytically and to make well-reasoned business decisions (business acumen).
Demonstrated experience guiding conflict resolution and facilitating employee relations activities.
Experience in planning and execution of multi-location projects utilizing formal project management methodology.
Proven knowledge of Health and Safety legislation and other Employment related legislation such as the Employment Standards Act.
Valid Driver’s license and passport (i.e. eligible to travel Internationally up to 10% of the time).
Must be available to work on all shifts.
This is a Hybrid role - 3 days office and 2 days WFH

What we offer

Excellent compensation/benefits package.
Bonus and reward programs
Discounted gym memberships
Programs supporting work life balance
Employee recognition program
Professional and personal development programs
Social events and spirit days

We are committed to diversity and inclusion, and thank all applicants in advance; however, we will be corresponding only with those selected for an interview.

In accordance with the Ontario Human Rights Code and the Accessibility for Ontarians with Disabilities Act, we are committed to providing an inclusive and barrier free recruitment and selection process.

Recruitment Fraud – please be aware of recruitment fraud. Novocol Pharmaceutical of Canada Inc. will never ask for banking information, money or any personal information up front. We will only respond to official applications submitted through our careers site. In addition, we will only use official corporate e-mail addresses (septodont.com or novocolpharma.com) to communicate with applicants. Should you be contacted without submitting an application, please delete the message and advise your e-mail provider.

For Internal

Internal Job Posting Grade 12. The due date for internal applicants to apply for this role is April 1, 2024.

Contract type

Permanent","{""role_summary"":""The IT Manager, Service & Support – Americas leads the IT Service and Support team in the region, focusing on customer-centric service delivery, managing and mentoring staff, and ensuring cost-effective operations that support strategic objectives."",""key_terms"":[{""term"":""ITIL"",""explanation"":""A set of best practices for IT service management that focuses on aligning IT services with business needs.""},{""term"":""Lean IT"",""explanation"":""An adaptation of lean principles to IT, aiming to eliminate waste, reduce variability, and improve flow in IT services and processes.""},{""term"":""GxP"",""explanation"":""Good practices for ensuring the quality of pharmaceutical products, including guidelines for manufacturing, testing, and distribution.""},{""term"":""Agile"",""explanation"":""An iterative approach to project management that emphasizes flexibility, customer satisfaction, and team collaboration.""}],""skill_priorities"":{""must_have"":[""ITIL certification"",""Lean IT certification"",""2 years of experience supervising teams in a technical support/customer service environment"",""Strong team player with the ability to lead and mentor staff"",""Excellent written and verbal communication skills with diverse teams""],""nice_to_have"":[""Pharmaceutical, food, or cosmetic industry experience"",""Proficiency in Brazilian"",""Experience in planning and execution of multi-location projects utilizing formal project management methodology"",""Proven knowledge of Health and Safety legislation and other Employment related legislation""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach ensuring customer-centric service delivery in a technical support environment?"",""example_answer"":""I would focus on developing processes that make employees service heroes for doing an outstanding job, and prioritize customer-centric behavioral competencies and technical skills for developing and hiring staff.""},{""question"":""Can you give an example of how you would champion service excellence in the onboarding of new employees?"",""example_answer"":""I would ensure all tools and technologies are properly prepared and trained, and manage the support team and end users are properly prepared for delivery of new or updated services / applications.""}],""red_flags"":[""Lack of experience in supervising teams in a technical support/customer service environment"",""Inability to prioritize customer-centric behavioral competencies and technical skills for developing and hiring staff""],""confidence_score"":90.0}"
Director of Security and IT,honeycomb.io,Canada,June,2024,"What We’re Building

Honeycomb is built to help engineering teams deeply explore and understand their own production systems — in real time. It's a service for the near future and present, where distributed systems are the new default, every service is a platform, and empowered generalist software engineers are the new ops. We believe in the dream of consumer-quality developer tools and are excited to be building a product that raises our industry's expectations of what our tools can do for us. It enables engineers to answer novel questions about their ever-evolving cloud applications, so they can deploy confidently, resolve incidents faster and focus on high-value work that drives innovation. We’re working with well known companies like HelloFresh, Slack, LaunchDarkly, and Vanguard and more across a range of industries. This is an exciting time in our trajectory, we’ve closed Series D funding, scaled past the 150-person mark, and were named to Forbes’ America’s Best Startups of 2022 and 2023!

In this role, you’ll bring together two functions, our information security team and IT team, building a unified strategy and outlook across both teams to help us better serve our internal partners and customers. Key aspects of the role will involve managing our IT and security leaders and helping us plan for a future where security, compliance, and IT best practices grow increasingly central to our business as we scale and go upmarket. You’ll also support aspects of our compliance and privacy programs, in coordination with our GRC program manager.

We are open to hiring a Senior Manager or Director level for this role.

We can hire this role in the United States and Canada.

What you’ll do:

Help define and unify our strategy for IT, Security, and compliance, and expand our planning horizon. Look ahead and help us understand how we need to mature these functions as we scale
Help us build a data-driven and outcome-oriented culture within IT & Security
Lead our IT and Security functions, including growing and mentoring the leaders and ICs on those teams
Seek balance across investment streams, and help us assess and codify our appetite for risk . IT and Security aren’t just about putting more and more locks and controls on every source of risk; as a growing business, we have to balance security against other goals like employee productivity, user experience, etc.
Assist with keeping our compliance and privacy programs running smoothly, by partnering closely with our GRC manager and supervising the aspects of those programs owned by Security and IT


About You:

You have experience managing an information security function and an IT team, an internal tooling team, a platform team, or other team with internal customers. We don’t necessarily need you to be a deep subject matter expert in every area of security and IT, but we’re looking for someone who is fluent in the concerns of both domains and has some experience leading the unique activities these teams may take on. Experience with compliance and privacy programs, including SOC 2 Type II or ISO 27001 certification and GDPR compliance, will also be helpful
You have experience with B2B SaaS software as well as startups/scale-ups. While all software has security and compliance needs, the world of a cloud-based software startup is a little different; and the security and compliance needs of businesses aren’t the same as those of consumers. Having experience in these domain areas, as well as experience with scaling teams, will be helpful
You know how to be a great manager and leader first, and a technologist second. While this domain will bring together two teams with exciting technical charters, we’re looking for a people-first leader. You should be excited to help these teams thrive through supporting and mentoring their respective leaders and team members, rather than getting hands-on with every technical decision yourself.
You know how to define, communicate, and execute against a strategy — and is excited to help others learn these skills too. As we scale our team, we’re working on shifting more of our strategy from implicit to explicit, and from short-term to long-term. We want to clarify and expand how our team members can contribute to this work and help them level up their strategic thinking in the process
You understand the value of automation and great tools. We have a strong engineering culture and love to find places where technology can help us work smarter. It’ll be helpful if you have experience investing in automation and tooling, and can help guide our security and IT strategy in these areas
You understand the value of a diverse, equitable, and inclusive team — and has some experience building them. Scaling a team always brings both opportunities and growing pains. We’re looking for a leader who can help us capitalize on the former and minimize the latter, while continuing to diversify on key axes. We are trying to raise the standards for developer tools, and we know that a diverse, inclusive team will help us build better products for a larger swath of the industry.
You have management experience. We’re looking for at least three years of people management experience and a year of experience managing managers, with demonstrated success in the role.


What You Get When You Join The Hive!

Base pay (range) of $200,000 - $260,000 USD (range is for Senior Manager up through Director)
A stake in our success - generous equity with employee-friendly stock program
It’s not about how strong of a negotiator you are - our pay is based on transparent levels relative to experience
Compensation benchmarked to San Francisco market - no matter where you live (or move)!
401k plan to help you plan for your future
A remote-first mindset and culture (really!)
100% employee coverage for Health, Dental, Vision, Life and Disability insurance and 75% for dependents
Time to Recharge - In addition to our Unlimited PTO policy, we provide :23 days off through out the year. This includes a company wide break at the end of the year, and we honor having at least one three day weekend a month (if there is not already a locally observed holiday that month, we add one!)
Pick Your Perk - $600 a year to spend on the perks that you care about most
Work Life Balance and Flexible Schedule options
The tech you need AND a $500 Home Setup Stipend
$200 Reimbursement for Cell/Wifi/CoWorking
$1500+ Annual Professional Development Allowance
Up to 16 weeks of paid parental leave, regardless of path to parenthood
Maven Inclusive Family-Building benefit including unlimited virtual appointments, coaches & counselors, and $10K ‘wallet’ to support adoption, surrogacy, IVF, and egg/sperm freezing
Modern Health well-being benefit including self guided resources and access to 12 mental health and 8 coaching sessions - at no additional cost to you
Semi-annual performance conversations (we call them Review & Rewards conversations) - so you know where you stand, and how you’ll be rewarded for your impact
Annual compensation review, benchmarking to industry and inflation changes


Please note we cannot currently sponsor or do visa transfers at this time.

Diversity & Accommodations:

We're building a diverse and inclusive workplace where we learn from each other, and welcome nontraditional candidates, and people of all backgrounds, experiences, abilities and perspectives. You don't need to be a millennial to join us, all gens are welcome! Further, we (of course) follow federal and state disability laws and are happy to provide reasonable accommodations during the application phase, interview process, and employment. Please email Talent@honeycomb.io to discuss accessible formats or accommodations. As an equal opportunity employer our hiring process is designed to put you at ease and help you show your best work; if we can do better - we want to know!","{""role_summary"":""Lead the IT and Security teams to develop a unified approach, ensuring compliance, security, and IT best practices are central to the company's growth."",""key_terms"":[{""term"":""SOC 2 Type II"",""explanation"":""A compliance certification that ensures a company's systems and services meet specific security and compliance standards.""},{""term"":""ISO 27001"",""explanation"":""An international standard for information security management systems that helps organizations manage and protect their information assets.""},{""term"":""GDPR compliance"",""explanation"":""A regulation that ensures companies protect the personal data and privacy of EU citizens.""},{""term"":""B2B SaaS software"",""explanation"":""Software as a Service provided to businesses, typically through cloud-based platforms.""}],""skill_priorities"":{""must_have"":[""Experience managing IT and Security teams"",""Experience with compliance and privacy programs"",""Experience with B2B SaaS software and startups/scale-ups""],""nice_to_have"":[""Deep subject matter expertise in security and IT"",""Experience with automation and tooling""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you balance security and compliance with other business goals, such as employee productivity and user experience?"",""example_answer"":""I would prioritize risk management and develop a data-driven approach to assess and codify our appetite for risk, ensuring that security and compliance are integrated into our overall business strategy.""},{""question"":""How would you lead and mentor the IT and Security teams, and what strategies would you use to grow and develop these teams?"",""example_answer"":""I would focus on building a people-first culture, providing guidance on strategic planning, and empowering team members to take on new challenges and develop their skills.""}],""red_flags"":[""Lack of experience managing IT and Security teams"",""Inability to balance security and compliance with other business goals""],""confidence_score"":90.0}"
"Manager, IT Portfolio Management",Toronto Hydro,"Toronto, Ontario, Canada",June,2024,"Work Illustration

The incumbent is accountable for delivering and supporting mid-to-large scale Information Technology (IT) enabled projects and programs. In addition, s/he delivers and supports application support services for the assigned business unit partner and works with stakeholders to elicit, analyze, communicate and validate requirements for changes to business processes, policies and information systems. This role includes direct interaction and collaboration with a broad range of senior, technical and functional management and subject matter experts throughout the organization.

The role is focused on managing a portfolio of projects ranging in size, budget and complexity. The portfolio may have both IT projects as well as pure process improvement projects. Projects vary depending on size and scope and will require flexibility and may require tailored project management solutions. This position requires day to day management of project team personnel (including full time employees and contractors), management of vendors, communication with key stakeholders, working with business subject management experts to ensure successful project execution. This role will also include direct interaction with the senior management team and subject matter experts throughout the organization.

Key Responsibilities

Leads a team of designated and technical professionals and support staff (internal and external resources and vendors) to manage the day-to-day operational delivery, support, performance monitoring, and reporting for information technology systems and applications for the designated business unit, to ensure client systems are secure and reliable
In alignment with organizational programs, practices and collective agreements, manages employee performance, attendance and training and development. Motivates and engages employees in the attainment of departmental goals and objectives and acts to address gaps in performance which may impact outcomes
Collaborates with business units for the execution of divisional projects, support of software applications, management of incidents and service requests for the designated portfolio
Educates and supports business unit users in the use of information technology securely, providing or arranging for end-user training as required
Provides coaching and feedback to team (internal and external) to reduce and/or eliminate environment, health and safety (EHS) hazards and risks, and introduce controls to maintain EHS performance
Identifies opportunities for continuous improvement in the day-to-day operational support and IT software implementation lifecycle
Responsible to respond and resolve real-time incidents in alignment with the divisional service level agreements. Performs post-incident root cause analysis and creates long term mitigation plans

Requirements

Bachelor’s Degree (Computer Science/Engineering preferred)
Ten (10) years of progressively more senior technical experience
Five (5) years IT project management or IT operations experience
Post-Graduate degree (preferred)
Experience in utility environment with union involvement and management experience (preferred)
Experience in business system analysis and development of functional and systems specifications
Project Management certifications e.g. PMP (preferred)
Knowledge of business and technology domains, such as products, processes, markets sand systems (specific to work stream being supported)
Good understanding of systems delivery, project management, Software Development Life Cycle (SDLC), and ITIL methodologies
Basic knowledge of standard programming and data modeling methodologies
Proficient with structured methods for process and organizational analysis requirements elicitation techniques (e.g. requirement workshops, focus groups, interviews)
Experience in successfully managing multi-million dollar project or portfolio of multiple projects
Program management experience including program management, resource load and capacity management and supervision of staff
Excellent analytical and organizational skills
Ability to manage stakeholder expectations and time conflicting priorities/business interests
Skilled in managing contractors and third-party vendors
Ability to communicate (verbal and written) effectively with clients, stakeholders, senior leadership
Fully proficient in use of MS Office, MS Project, Visio and other PM tools

Toronto Hydro has introduced a Hybrid Work Arrangement. This position allows for remote work up to three days per week, based on business needs. Employees will be required to come onsite on those days when they are involved in activities that they or their leader feel are better conducted in person. You are expected to live in Ontario and within reasonable commuting distance of the office.","{""role_summary"":""The role is responsible for managing a portfolio of IT projects and programs, collaborating with stakeholders to deliver and support application services, and ensuring successful project execution."",""key_terms"":[{""term"":""IT enabled projects"",""explanation"":""Projects that use technology to achieve business objectives.""},{""term"":""Application support services"",""explanation"":""Services that ensure software applications are running smoothly and efficiently.""},{""term"":""ITIL methodologies"",""explanation"":""A set of best practices for delivering high-quality IT services.""},{""term"":""SDLC"",""explanation"":""A framework for developing software applications.""},{""term"":""Program management"",""explanation"":""Overseeing multiple projects to achieve strategic objectives.""}],""skill_priorities"":{""must_have"":[""IT project management experience"",""Experience in business system analysis"",""Knowledge of business and technology domains"",""Good understanding of systems delivery and project management methodologies"",""Excellent analytical and organizational skills"",""Ability to manage stakeholder expectations and conflicting priorities""],""nice_to_have"":[""Post-Graduate degree"",""Experience in utility environment with union involvement and management experience"",""Project Management certifications (e.g. PMP)"",""Experience in successfully managing multi-million dollar project or portfolio of multiple projects"",""Program management experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience in managing a portfolio of IT projects?"",""example_answer"":""I have managed multiple projects with varying sizes and complexities, and have experience in developing tailored project management solutions.""},{""question"":""How do you ensure successful project execution?"",""example_answer"":""I work closely with stakeholders to elicit, analyze, communicate and validate requirements for changes to business processes, policies and information systems.""},{""question"":""How do you manage stakeholder expectations and conflicting priorities?"",""example_answer"":""I prioritize tasks based on business needs, and communicate effectively to manage expectations and resolve conflicts.""}],""red_flags"":[""Lack of experience in IT project management or IT operations"",""Inability to manage stakeholder expectations and conflicting priorities"",""Limited knowledge of business and technology domains""],""confidence_score"":90.0}"
IT Administrator II,Mustang Survival,"Burnaby, British Columbia, Canada",June,2024,"Who We Are

At Mustang Survival, our vision is to enable the ultimate on-water experience. We seek to become the pinnacle waterlife brand by offering authentic, innovative product solutions that instill confidence and trust in our consumers. We require talented, motivated, inspired individuals at all levels of the organization to ensure that we remain true to what we stand for. If you are someone who has curiosity, passion for excellence, and a desire to drive innovative product solutions, come and join us to push the boundaries of what’s possible in delivering the ultimate water life user experience.

What We Offer

Mustang Survival offers a competitive wage of $71,000-85,000. Note: the posted salary ranges are estimates and actual salary may vary depending on the experience of the candidate. As part of our total rewards package, we offer: group RRSP matching, comprehensive health and wellness benefits such as Vacation and Wellness days, Employee Family Assistance Programs, and a Healthcare Spending Account.

Job Purpose

Responsible for responding to tickets from users both locally and at remote offices. This will involve setting up new software and hardware, performing system upgrades and training users. You will work remotely with staff and IT Administrators at other Wing Group Locations around the world, but you’ll be the one covering the needs of the local office and factory.

STRUCTURE

This position reports to the Manager, IT Applications & Infrastructure. This position does not have direct reports.

RESPONSIBILITY

Provide help desk support and specialized technical assistance to system users, escalating issues, as necessary.
Perform hardware, software and peripheral equipment improvements and upgrades to ensure all systems are up to date.
Monitor system performance to ensure that operations are within established standards and develop recommendations for enhancements to improve operations and increase system capabilities.
Administer IT onboarding of new employees, including collecting requirements, setup, and deployment.
Maintain inventory of IT equipment, such as desktops, laptops, mobility devices, etc.
Creates and update documentation of IT processes, policies, licensing, and systems.
Present equipment and policy training to staff and end users.
Plans, develops and implements recovery and backup procedures.
Communicate IT plans, tasks and modifications to relevant stakeholders and employees.
Assist with research and evaluation of new technology, techniques, threats, and industry best practices to optimize efficiency and usability and minimize vulnerabilities.

Requirements

1-2 years experience with M365, Entra and Federated identity concepts
1-2 years' experience with Windows in an Enterprise environment
1-2 years' experience with MacOS and iOS devices in an enterprise environment preferred
Relevant 2-year diploma or greater, or equivalent industry experience
Ability to work independently with minimal supervision
Excellent interpersonal skills with a customer service mindset
1-2 years' experience with Virtualization platforms such as VMWare or Hyper-V
The ability to travel to all the locations that we operate in
Ability to be an authorized individual for controlled goods
Criminal Record Check

ASSETS

Microsoft Certified Azure, CCNA, or other relevant certifications
Cybersecurity certifications","{""role_summary"":""Provide technical support and assistance to system users, perform hardware and software upgrades, and train users."",""key_terms"":[{""term"":""M365"",""explanation"":""Microsoft 365, a suite of cloud-based productivity and collaboration tools.""},{""term"":""Entra"",""explanation"":""A cloud-based identity and access management platform.""},{""term"":""Federated identity"",""explanation"":""A system that allows users to access multiple systems with a single set of login credentials.""},{""term"":""Virtualization platforms"",""explanation"":""Software that creates a virtual environment for running multiple operating systems.""}],""skill_priorities"":{""must_have"":[""1-2 years experience with M365"",""1-2 years experience with Windows in an Enterprise environment"",""Ability to work independently with minimal supervision"",""Excellent interpersonal skills with a customer service mindset""],""nice_to_have"":[""1-2 years experience with MacOS and iOS devices in an enterprise environment"",""1-2 years experience with Virtualization platforms"",""Microsoft Certified Azure, CCNA, or other relevant certifications"",""Cybersecurity certifications""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would troubleshoot a user's issue with M365?"",""example_answer"":""I would first try to reproduce the issue, then check the system logs for any errors, and finally escalate the issue to the IT Administrator if necessary.""},{""question"":""How do you stay up-to-date with the latest developments in Windows and MacOS?"",""example_answer"":""I follow industry blogs and forums, attend webinars, and participate in online training sessions to stay current.""}],""red_flags"":[""Lack of experience with M365 or Windows in an Enterprise environment"",""Inability to work independently with minimal supervision"",""Poor interpersonal skills or lack of customer service mindset""],""confidence_score"":85.0}"
"Regional IT Manager, Ontario and Atlantic Canada",MNP,"Mississauga, Ontario, Canada",June,2024,"Inspirational, innovative and entrepreneurial - this is how we describe our empowered teams. Combine your passion with purpose and join a culture that is thriving in the face of change.

Make an impact with our Technology – Support Services team as a Manager, Regional Technology. This diverse team of tech-savvy problem solvers embraces digital transformation and the possibilities technology brings to the future of our industry. As a trusted advisor, you’ll support, utilize and maintain MNP’s technology to ensure smooth IT operations, enabling team members to work efficiently and effectively.

MNP is proudly Canadian. Providing business strategies and solutions, we are a leading national accounting, tax and business advisory firm in Canada. Entrepreneurial to our core, our talented team members transcend obstacles into opportunities and are successfully transforming mid-market business practices.

Responsibilities

Manage all aspects of IT support delivery for your region
Develop and foster business relationships with regional business leaders, gaining an understanding of the unique business requirements of your assigned regions and ensure appropriate IT service offerings are being delivered
Ensure asset management and equipment provisioning processes are being followed, and participate in annual IT equipment budgeting for offices within your region
Lead a team of IT Coordinators and work closely with other groups in the IT department to ensure delivery of high-quality IT services, support, and excellent customer service
Conduct regular team meetings to ensure alignment and collaboration
Develop team members' skills and career paths through comprehensive IT career development initiatives and to align their behaviors with the IT strategic plan, mission, and firm’s values
Foster team growth and expertise in customer service etiquette, support best practices, technical knowledge, and SLA adherence
Ensure the appropriate resourcing and technical capabilities of the support team to deliver IT service to the business, ensuring customer service is the forefront of our service offering
Act as the hiring manager for open positions in your region
Manage the lifecycle of all incidents/requests within the region and serve as the escalation point for the business as it relates to incidents, requests, or unresolved issues
Prepare and present metrics, activity reports, and progress updates on projects and support delivery
Perform trend analysis of services and historical incidents to improve overall performance.
Maintain flexibility to travel, as necessary


Skills And Experience

At least 3 years in an IT Manager role leading successful IT support teams
Knowledge of ITSM/ITIL framework and best practices
Strong people management skills
Proven experience in incident management
Capacity to succeed in a changing, rapid growing business that fosters entrepreneurial values


MyRewards@MNP

With a focus on high-potential earnings, MNP is proud to offer customized rewards that support our unique culture and a balanced lifestyle to thrive at work and outside of the office. You will be rewarded with generous base pay, vacation time, 4 paid personal days, a group pension plan with 4% matching, voluntary savings products, bonus programs, flexible benefits, mental health resources, exclusive access to perks and discounts, professional development assistance, MNP University, a flexible ‘Dress For Your Day’ environment, firm sponsored social events and more

Diversity@MNP

We embrace diversity as a core value and celebrate our differences. We believe each team member contributes unique gifts and amplifying their potential makes our business stronger. We encourage people with disabilities to apply!","{""role_summary"":""Manage IT support delivery for a region, leading a team of IT Coordinators and ensuring high-quality IT services, support, and customer service."",""key_terms"":[{""term"":""ITIL"",""explanation"":""A framework for IT service management lifecycle, focusing on aligning IT services with business needs.""},{""term"":""ITSM"",""explanation"":""A set of policies, procedures, and processes for managing IT services, ensuring quality and efficiency.""}],""skill_priorities"":{""must_have"":[""At least 3 years in an IT Manager role leading successful IT support teams"",""Knowledge of ITSM/ITIL framework and best practices"",""Strong people management skills"",""Proven experience in incident management""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with ITSM/ITIL framework and how you've applied it in previous roles?"",""example_answer"":""I've worked with ITSM/ITIL for 5 years, implementing incident management processes that improved resolution times by 30%.""},{""question"":""How do you approach team management and development of IT Coordinators?"",""example_answer"":""I prioritize regular team meetings, provide constructive feedback, and create career development plans to align with the IT strategic plan.""}],""red_flags"":[""Lack of experience with ITSM/ITIL framework"",""Inability to manage a team of IT Coordinators""],""confidence_score"":90.0}"
"Senior Manager, IT Infrastructure and Security",Sterling Crane,"Edmonton, Alberta, Canada",March,2024,"Sterling Crane Canada

Come join a team where People make the difference! As a part of Marmon Holdings, Inc., a highly decentralized organization, we rely heavily on people with the aptitude, attitude, and entrepreneurial spirit to drive our success, and we're committed to attracting and retaining top talent.

We are seeking a Senior IT Infrastructure and Security Manager to oversee service delivery for companies in the US, Canada, and Australia. This is a technical working lead position that requires an individual with experience in managing global infrastructure and security programs. Reporting to the Vice President of Information Technology, a successful candidate in this role will be responsible for overseeing global delivery for the portfolio.

The Senior Manager, IT Infrastructure and Security - Global will play a critical role in ensuring the stability, security, and scalability of the infrastructure and security environment for the organization, while providing technical leadership, people management, and strategic guidance to a global team.

Senior Manager, IT Infrastructure and Security - Global

Edmonton, AB

We are seeking a Senior IT Infrastructure and Security Manager to oversee service delivery for companies in the US, Canada, and Australia. This is a technical working lead position that requires an individual with experience in managing global infrastructure and security programs. Reporting to the Vice President of Information Technology, a successful candidate in this role will be responsible for overseeing global delivery for the portfolio.

The Senior Manager, IT Infrastructure and Security - Global will play a critical role in ensuring the stability, security, and scalability of the infrastructure and security environment for the organization, while providing technical leadership, people management, and strategic guidance to a global team.

Responsibilities:

Provide technical leadership to a global team responsible for infrastructure and security service delivery across multiple countries.
Collaborate and communicate with stakeholders, developers, and technical team members to deliver on business objectives, ensuring that project goals are met within scope, time, and budget.
Develop and maintain documentation for business processes, operational procedures, technical design, solution structure, and functional know-how.
Collaborate with other teams that are often geographically dispersed, to define, plan and oversee projects that your team will own or participate in.
Manage team projects and deliverables utilizing common project management frameworks and delivery methods, while ensuring team collaboration.
Provide 24X7 escalation support to cross-functional teams for critical incidents.
Lead, mentor, and manage a team of technical experts, providing guidance and coaching to ensure their growth and success.
Develop and maintain relationships with key stakeholders, including vendors, partners, and clients.
Manage the technical scope of infrastructure and security service delivery, ensuring that solutions are scalable, secure, and aligned with industry standards.
Develop and maintain a technology roadmap for the infrastructure and security portfolio, ensuring that it aligns with business objectives and is updated on an ongoing basis.
Provide thought leadership on emerging technologies, industry trends, and best practices related to infrastructure and security service delivery.
Lead the design, development, and implementation of complex technical solutions, ensuring that they are robust, scalable, and secure.
Develop and manage budgets for infrastructure and security service delivery, ensuring that resources are allocated appropriately and that expenditures are in line with business objectives.
Ensure that infrastructure and security service delivery comply with relevant legal, regulatory, and industry standards
Manage all infrastructure and monitoring tools to enable ideal performance and ensure that components of the disaster recovery infrastructure and technical plans are maintained.
Foster a culture of innovation and continuous improvement, encouraging team members to experiment, take risks, and challenge the status quo.
Develop and maintain strong working relationships with other teams and departments, including development, operations, and business stakeholders.
Provide expert knowledge and direction in IT infrastructure operations and controls, ensuring reliability of the servers and data storage.
Perform system administration for on-prem and cloud infrastructure resources – AD, Databases, IIS servers, Azure, Hyper-V, and VMware.
Forecast and manage budgets for the portfolio and ensure delivery within budgetary constraints.
Provide regular reporting to senior management on portfolio performance, risks, and opportunities.

Qualifications:

Bachelor's degree in Computer Science or related field; Master's degree is a plus.
Minimum 10 years of experience in IT infrastructure and security.
5+ years of experience in a management position with people leadership responsibilities.
Experience working with managed service providers, SaaS services, and hosted solutions.
Solid analytical skills, experience solving practical issues and engaging cross-functional teams.
Ability to effectively prioritize and execute tasks while handling time-sensitive competing priorities.
Demonstrated analytical, problem-solving, organizational, interpersonal, communication skills.
Ability to lead discussion with business stakeholders and suggest holistic solutions/improvements for both technical strategy and business processes.
Exhibits strong initiative; self-starter that can lead others in ambiguous situations.
Ability to influence and drive others toward common goals.
Leads by example creative and innovative idea generation and influences decisions across different teams.
Experience with leading or participating in the gathering and documenting of business processes and requirements for the system with key business users.
Ability to manage multiple initiatives of innovation and converge them all into common strategic objectives.
Understanding of holistic infrastructure and security designs, including being able to provide consult to how those could apply to application design requirements.

We offer competitive compensation packages, flexible work arrangements, health and wellness benefits, retirement benefits, professional development opportunities, paid time off, and a fantastic work environment that promotes teamwork, safety, and a sense of community. If you are passionate about leading people with integrity and developing a career with an enterprise scale organization, we encourage you to apply for this exciting opportunity. Please submit your resume and cover letter for consideration.

Location:

Canada (Hybrid Role)
The ideal candidate will be based out of Edmonton or willing to relocate to Edmonton for a period of 2 years.

IMPORTANT:

We thank all applicants for their interest; however, only those candidates who are shortlisted will be contacted:

CLOSING DATE: Until Filled

Following receipt of a conditional offer of employment, candidates will be required to complete additional job-related screening processes as permitted or required by applicable law.

If you would like to apply for this position, please submit your resume online via our Applicant Tracking System https://marmon.wd5.myworkdayjobs.com/Marmon_Careers or drop your resume at any of our office locations.

Following receipt of a conditional offer of employment, candidates will be required to complete additional job-related screening processes as permitted or required by applicable law.","{""role_summary"":""Oversee global IT infrastructure and security service delivery, providing technical leadership, people management, and strategic guidance to a global team."",""key_terms"":[{""term"":""IT Infrastructure"",""explanation"":""The underlying systems and technology that enable an organization's IT capabilities.""},{""term"":""Security Programs"",""explanation"":""Initiatives and measures taken to protect an organization's IT systems and data from unauthorized access, use, disclosure, disruption, modification, or destruction.""},{""term"":""Global Delivery"",""explanation"":""The process of planning, designing, and executing IT projects and services across multiple regions and countries.""},{""term"":""Technical Leadership"",""explanation"":""Guiding and directing technical teams to achieve business objectives and technical goals.""}],""skill_priorities"":{""must_have"":[""Experience in managing global infrastructure and security programs"",""Technical leadership and people management skills"",""Strong analytical and problem-solving skills"",""Ability to lead cross-functional teams and projects""],""nice_to_have"":[""Master's degree in Computer Science or related field"",""Experience with managed service providers, hosted solutions, and SaaS services"",""Knowledge of industry standards and best practices in IT infrastructure and operations""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with global infrastructure and security programs?"",""example_answer"":""I have managed global infrastructure and security programs for multiple organizations, ensuring compliance with industry standards and best practices.""},{""question"":""How do you approach technical leadership and people management?"",""example_answer"":""I believe in leading by example, empowering team members to take ownership of their work, while providing coaching and guidance to ensure their growth and success.""}],""red_flags"":[""Lack of experience in managing global infrastructure and security programs"",""Inability to provide technical leadership and people management"",""Poor analytical and problem-solving skills""],""confidence_score"":90.0}"
Helpdesk Manager,Hollingsgate Recruitment,"Ottawa, Ontario, Canada",June,2024,"Hollingsgate Recruitment is partnering with a leading IT Network Management company in Ottawa that specializes in the financial sector. We are on the lookout for a dynamic Helpdesk Manager who is eager to advance their career in a supportive and stimulating environment.

Position: Helpdesk Manager

Location: Ottawa, ON

What You ll Do

Lead and Oversee Projects: Manage and guide various IT projects, ensuring they are completed on time while supervising a dedicated team of service desk professionals.
Hands-On Project Involvement: Play a proactive role in executing IT projects, working alongside your team to implement solutions and achieve project goals.
Mentor and Support Technicians: Provide guidance, training, and support to both junior and senior techs, creating a collaborative and productive team atmosphere.
Manage Schedules and Coverage: Develop effective scheduling practices to ensure the service desk is always adequately staffed, balancing workloads, and minimizing downtime.
Assist with Calls and Tickets: Act as an escalation point for complex technical issues, helping team members troubleshoot and resolve customer inquiries efficiently.
Review Timesheets and Task Progress: Monitor timesheets for accuracy, ensuring compliance with company policies, and track task progress to maintain project timelines.

What We re Looking For

Leadership Skills: Proven ability to lead, inspire, and motivate a team, focusing on high performance and exceptional customer service.
Helpdesk Management Experience: Demonstrated experience managing a helpdesk environment with a deep understanding of IT support processes and best practices.
Multitasking Abilities: Excellent organizational skills and the capability to juggle multiple responsibilities and projects simultaneously, maintaining high efficiency.
Communication Skills: Strong verbal and written communication skills, able to clearly convey technical information to both technical and non-technical audiences.

If you're passionate about leading a team and thriving in a fast-paced environment, we want to hear from you! This role offers a unique chance to make a significant impact within a forward-thinking organization.

Apply Now!","{""role_summary"":""Manage and lead a team of IT professionals in a helpdesk environment, ensuring timely project completion, and providing exceptional customer service."",""key_terms"":[{""term"":""Helpdesk Management"",""explanation"":""Overseeing and coordinating IT support processes to ensure efficient issue resolution.""},{""term"":""IT Projects"",""explanation"":""Initiatives aimed at implementing solutions and achieving specific technical goals.""}],""skill_priorities"":{""must_have"":[""Leadership Skills"",""Helpdesk Management Experience"",""Multitasking Abilities"",""Communication Skills""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to lead a team to resolve a complex technical issue?"",""example_answer"":""In my previous role, I led a team to troubleshoot a network outage, ensuring minimal downtime and effective communication with stakeholders.""},{""question"":""How do you prioritize tasks and manage multiple projects simultaneously?"",""example_answer"":""I use project management tools to track progress, and delegate tasks to team members based on their strengths and workload balance.""}],""red_flags"":[""Lack of experience in a helpdesk management role"",""Inability to effectively communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
IT Manager & Infrastructure Architect,Compassion Canada,"London, Ontario, Canada",June,2024,"IT Manager & Infrastructure Architect

Department: Technology (within Marketing & Digital Growth division)
Location: Telecommuting between home office in Ontario, and 985 Adelaide Street S, London, Ontario
Salary: TBD + Benefits
Application Submission: July 3, 2024

SUMMARY
The Information Technology (IT) Manager & Infrastructure Architect will lead Compassion’s informational technology department efforts and drive the development and implementation of innovative technology solutions. Positioned within our Marketing & Digital Growth team, this position is well situated in our on-going digital transformation (developing an agile and learning mindset) pursuit.

Working alongside members of the Marketing & Digital Growth division, and reporting to the Director of Technology, this role will be a key leader in the overall direction of the Information Technology portfolio.

MINISTRY FOCUS
Compassion Canada is a Christian organization, committed to being child-focused, Christ-centered, and church driven. As such, each employee of Compassion Canada shall:
Agree with Compassion Canada’s core documents, including a Statement of Faith.
Conduct themselves in a Christ-like manner at work and outside the workplace.
Participate in regular Staff Gatherings which include spiritual practices like worship, Scripture reading, and prayer.
Pray with staff or supporters when requested or deemed appropriate.

TASKS & RESPONSIBILITIES: WHAT YOU DO MATTERS
Provide leadership oversight to IT department ensuring efficiency, effectiveness, and provision of support and resource allocation to meet the needs of the organization.
Support the Director of Technology in organizational strategy development for Compassion Canada’s multi-year technology plans.
Collaborate with stakeholders to understand business requirements and develop technology strategies aligned with organizational goals and Epic priorities.
Design and architect end-to-end infrastructure solutions that meet business needs, considering factors such as scalability, security, and performance.
Lead the migration of on-premises infrastructure to the cloud, ensuring a seamless transition and optimal utilization of cloud services and cost.
Manage hybrid infrastructure environments, effectively integrating on-premises and cloud resources to maximize efficiency and flexibility.
Develop and implement cyber security strategy, policies, and procedures to protect organizational assets and mitigate cyber security risks.
Mentor and coach team members, fostering a culture of continuous learning and professional development.
Foster a creative and focused environment that models innovation, boldness and ideation.
Provide technical guidance and mentor the IT department ensuring infrastructure cloud solutions are implemented according to best practices and standards.
Manage all infrastructure and monitoring tools to enable ideal performance and ensure that components of the disaster recovery infrastructure and technical plans are maintained.
Manage vendor relationships and third-party service providers, ensuring adherence to service level agreements and quality standards.
Stay informed about industry trends, regulations, and best practices related to IT management, infrastructure cloud architecture, and cyber security, incorporating relevant insights into decision-making processes.
Manage all infrastructure and monitoring tools to enable ideal performance and ensure that components of the disaster recovery infrastructure and technical plans are maintained.
Evaluate emerging technologies and trends, recommending innovative infrastructure cloud solutions to enhance efficiency, effectiveness, and competitiveness.
Collaborate closely with Compassion International to ensure alignment on strategies and explore joint initiatives opportunities.
Support division outcomes and department/team with other duties as requested.

KNOWLEDGE, SKILLS & ABILITIES: WHO YOU ARE MATTERS
Experience working in AWS (Amazon Web Services) and Okta.
Senior level experience with IT infrastructure both on premise and cloud.
Strong background in infrastructure cloud architecture, with expertise in designing and implementing complex, enterprise-level infrastructure cloud solutions.
Experience in migrating on-premises infrastructure to the cloud, end user computing and managing hybrid infrastructure environments.
Demonstrated expertise in developing and implementing disaster recovery, cyber security strategy, policies, and procedures.
Experienced in the implementation of standardized processes, reports, and procedures across large organizations,
Skilled in balancing a long-term project & data roadmap with the real-time needs of an agile and innovative organization,
Demonstrated capacity to collaborate with cross functional teams on multiple projects simultaneously.
Possess strong analytical and problem-solving abilities, with a keen attention to detail.
Excellent written, verbal, and visual presentation skills with capability to interact with all levels within the organization and for multiple external audiences.

EDUCATION & EXPERIENCE REQUIRED: WHAT YOU BRING MATTERS
Post-secondary education or credential in Computer Science, Information Technology or related discipline required or minimum of five (5) years leadership experience in direct or related area.
Experienced ITIL framework
Cloud computing certification (AWS Certified Solutions Architect), continuous learning credentials or education in area of expertise is an asset.

The foregoing statements are intended to describe the general nature and level of work being performed by people assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills.

We appreciate all applications for employment; however, we will only contact those applicants invited for an interview.

Please note, we will accommodate the needs of persons with disabilities in our hiring process. Should you require an accommodation during the hiring process or for this application, please contact Compassion Canada via email at accessibility@compassion.ca or call People & Culture Resources at (519) 668-0224.","{""role_summary"":""The IT Manager & Infrastructure Architect leads Compassion's IT department, driving innovative technology solutions, and collaborating with the Marketing & Digital Growth team to achieve digital transformation."",""key_terms"":[{""term"":""Infrastructure Architecture"",""explanation"":""Designing and implementing complex, enterprise-level infrastructure cloud solutions.""},{""term"":""Cyber Security Strategy"",""explanation"":""Developing and implementing policies and procedures to protect organizational assets and mitigate cyber security risks.""},{""term"":""Cloud Computing"",""explanation"":""Migrating on-premises infrastructure to the cloud, ensuring a seamless transition and optimal utilization of cloud services and cost.""},{""term"":""Hybrid Infrastructure Environment"",""explanation"":""Effectively integrating on-premises and cloud resources to maximize efficiency and flexibility.""}],""skill_priorities"":{""must_have"":[""Experience working in AWS (Amazon Web Services) and Okta"",""Senior level experience with IT infrastructure both on premise and cloud"",""Strong background in infrastructure cloud architecture"",""Experience in migrating on-premises infrastructure to the cloud, end user computing and managing hybrid infrastructure environments""],""nice_to_have"":[""Cloud computing certification (AWS Certified Solutions Architect)"",""Experienced ITIL framework"",""Continuous learning credentials or education in area of expertise""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with infrastructure cloud architecture and how you've implemented complex, enterprise-level infrastructure cloud solutions in the past?"",""example_answer"":""I have experience working with AWS and Okta, and have successfully implemented infrastructure cloud solutions that meet business needs, considering factors such as scalability, security, and performance.""},{""question"":""How do you stay informed about industry trends, regulations, and best practices related to IT management, infrastructure cloud architecture, and cyber security?"",""example_answer"":""I regularly read industry publications, attend conferences, and participate in online forums to stay current on the latest developments and incorporate relevant insights into my decision-making processes.""}],""red_flags"":[""Lack of experience with AWS and Okta"",""Inability to demonstrate expertise in designing and implementing complex, enterprise-level infrastructure cloud solutions""],""confidence_score"":90.0}"
National IT Manager,Kuehne+Nagel,"Mississauga, Ontario, Canada",June,2024,"Are you ready for a new and exciting leadership opportunity with one of the most successful logistics organizations worldwide? Here at Kuehne+Nagel, our Toronto office is looking for a new National IT Manager to join our IT team.

Your Role

As the National IT Manager, your primary objective will be to support the National Management team while ensuring global IT standards and policies are maintained and implemented. You will oversee a team of local IT Specialists with the goal of representing our Canada team, while focusing on our US objectives. You will report directly to the National Finance Manager

Your Responsibilities

To lead a team of IT support engineers through various projects + daily tasks.
To be responsible for all local IT activities within your cluster/country
To take charge as the primary IT contact within area of responsibility supporting all IT demands + engaging with the appropriate supply teams
To ensure that all IT infrastructure is supported + managed appropriately to deliver a highly resilience working platform
To manage + review all local supplier contracts + negotiations
To take responsibility for all IT security + data protection + ensure compliance to the global standards
To manage the budget if local IT as approved by the local, NAM and global management
To identify cost savings, as well as process improvements + best practices on a continuous basis

If you require an accommodation for the recruitment /interview process (including alternate formats of materials, or accessible meeting rooms or other accommodation), please let us know and we will work with you to meet your needs.

Your Skills And Experiences

Bachelor's Degree in Computer Science or similar
5+ Years of experience in similar role with strong leadership experience
Strong knowledge and background in IT Management with stakeholder management experience
Great project management skills, including organization, planning, time management and prioritization
IT Certifications (CCNA,PMP, MSCE, TIA A+) would be an asset

Good Reasons to Join

There has never been a better time to work in logistics. Bring your skills to an industry that offers stability and international career growth. We offer a great compensation and medical/dental benefits package, employee discounts, tuition reimbursement, excellent training programs, and a fun, and interesting global work environment.","{""role_summary"":""Lead a team of IT support engineers, manage local IT activities, and ensure IT infrastructure is supported and managed to deliver a highly resilient working platform."",""key_terms"":[{""term"":""IT infrastructure"",""explanation"":""The combination of hardware, software, and network resources required to operate and manage an organization's IT systems.""},{""term"":""Stakeholder management"",""explanation"":""The process of identifying, analyzing, and prioritizing the needs of an organization to ensure their expectations are met.""},{""term"":""CCNA"",""explanation"":""Cisco Certified Network Associate, a certification that validates an individual's skills in installing, configuring, and troubleshooting medium-sized networks.""}],""skill_priorities"":{""must_have"":[""Bachelor's Degree in Computer Science or similar"",""5+ Years of experience in similar role with strong leadership experience"",""Strong knowledge and background in IT Management with stakeholder management experience""],""nice_to_have"":[""IT Certifications (CCNA,PMP, MSCE, TIA A+)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience in managing a team of IT support engineers?"",""example_answer"":""I have managed a team of 5 IT support engineers in my previous role, where we worked on multiple projects and ensured timely delivery of IT services.""},{""question"":""How do you ensure IT infrastructure is supported and managed to deliver a highly resilient working platform?"",""example_answer"":""I ensure regular maintenance, monitoring, and upgrading of IT systems, and also have a contingency plan in case of any system failures.""}],""red_flags"":[""Lack of experience in managing a team of IT support engineers"",""Inability to ensure IT infrastructure is supported and managed to deliver a highly resilient working platform""],""confidence_score"":90.0}"
Delivery Manager IT - Permanent Role,Procom,"Guelph, Ontario, Canada",June,2024,"Delivery Manager – IT – Permanent Role On behalf of our client in the Professional Services Sector, PROCOM is looking for a Delivery Manager - IT.
Delivery Manager - IT - Job Description

Our client in Guelph, Ontario is seeking a highly skilled IT Delivery Manager to lead the implementation of IT projects with a focus on cloud migration and on-premises solution delivery
This senior role requires a candidate with a deep understanding of application support management, strong IT service management, and exceptional people management skills
The ideal candidate will have proven experience in migrating legacy applications to modern cloud-based solutions, particularly on the Azure platform


Delivery Manager - IT - Mandatory Skills

4-5 years of experience as a Scrum Master/Delivery Manager
5+ years in software development, project management, or business analysis
Proven experience with cloud platforms, particularly Azure
Expertise in migrating on-premises solutions and legacy applications to modern platforms
Excellent communication skills, both verbal and written, including presentation and facilitation skills
Proficiency in Project Management and team collaboration tools (e.g., JIRA, Confluence, Figma)
Certified Advanced Scrum Master/PMP Certification or equivalent
Ability to adapt quickly to changing priorities and influence others without authority
Outcomes-focused mindset


Delivery Manager - IT- Preferred Skills

Experience with Agile UX Management Framework and Agile techniques (e.g., User Stories, Burndown techniques, A/B Testing, Lean Startup)
UX certifications (e.g., Certified UX Professional, Nielsen Norman Group UX Certification)
Proficiency in cloud infrastructure as code (IaC) tools (Terraform, CloudFormation)
Experience with DevOps tools and practices, including CI/CD pipelines, automation tools (Jenkins, GitLab CI), and containerization (Docker, Kubernetes)
Knowledge of security best practices and compliance standards (ISO 27001, NIST, GDPR)
Strong background in IT Service Management frameworks (ITIL 4, SIAM)
Ability to leverage analytics tools (Power BI, Tableau) for reporting and decision-making


Delivery Manager - IT - Assignment Start Date ASAP – Permanent Role
Delivery Manager - IT - Assignment Location Guelph, ON – Work Hybrid","{""role_summary"":""Lead IT projects, focusing on cloud migration and on-premises solution delivery, requiring strong IT service management, people management, and cloud migration skills."",""key_terms"":[{""term"":""Cloud migration"",""explanation"":""Moving applications and data from on-premises infrastructure to cloud-based infrastructure.""},{""term"":""On-premises solution delivery"",""explanation"":""Implementing and managing IT solutions within an organization's own infrastructure.""},{""term"":""Azure platform"",""explanation"":""A cloud computing platform and set of services offered by Microsoft.""},{""term"":""Scrum Master"",""explanation"":""A facilitator of Scrum framework, responsible for ensuring the team follows Scrum principles and practices.""},{""term"":""IT service management"",""explanation"":""A set of practices and policies for managing IT services, focusing on customer needs and IT services lifecycle.""},{""term"":""Agile UX Management Framework"",""explanation"":""A framework for managing user experience in Agile development, focusing on iterative and incremental delivery.""},{""term"":""Cloud infrastructure as code (IaC) tools"",""explanation"":""Tools for managing and provisioning cloud infrastructure through code and configuration files.""},{""term"":""DevOps tools and practices"",""explanation"":""A set of practices for collaboration and communication between development and operations teams, focusing on automation and continuous delivery.""},{""term"":""ITIL 4"",""explanation"":""A framework for IT service management, focusing on service lifecycle, from strategy to continual improvement.""}],""skill_priorities"":{""must_have"":[""4-5 years of experience as a Scrum Master/Delivery Manager"",""5+ years in software development, project management, or business analysis"",""Proven experience with cloud platforms, particularly Azure"",""Expertise in migrating on-premises solutions and legacy applications to modern platforms"",""Excellent communication skills, both verbal and written, including presentation and facilitation skills"",""Proficiency in Project Management and team collaboration tools (e.g., JIRA, Confluence, Figma)"",""Certified Advanced Scrum Master/PMP Certification or equivalent"",""Ability to adapt quickly to changing priorities and influence others without authority"",""Outcomes-focused mindset""],""nice_to_have"":[""Experience with Agile UX Management Framework and Agile techniques (e.g., User Stories, Burndown techniques, A/B Testing, Lean Startup)"",""UX certifications (e.g., Certified UX Professional, Nielsen Norman Group UX Certification)"",""Proficiency in cloud infrastructure as code (IaC) tools (Terraform, CloudFormation)"",""Experience with DevOps tools and practices, including CI/CD pipelines, automation tools (Jenkins, GitLab CI), and containerization (Docker, Kubernetes)"",""Knowledge of security best practices and compliance standards (ISO 27001, NIST, GDPR)"",""Strong background in IT Service Management frameworks (ITIL 4, SIAM)"",""Ability to leverage analytics tools (Power BI, Tableau) for reporting and decision-making""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with cloud migration projects, particularly on the Azure platform?"",""example_answer"":""I led a team that migrated a legacy application to Azure, resulting in a 30% reduction in costs and a 25% increase in application performance.""},{""question"":""How do you ensure effective communication and collaboration between development and operations teams?"",""example_answer"":""I use Agile frameworks and tools like JIRA and Confluence to facilitate collaboration and ensure that all stakeholders are aligned on project goals and objectives.""},{""question"":""Can you give an example of a time when you had to adapt quickly to changing priorities and influence others without authority?"",""example_answer"":""In my previous role, I had to pivot a project scope due to changing business requirements. I worked closely with stakeholders to communicate the changes and ensure a smooth transition, resulting in a successful project delivery.""}],""red_flags"":[""Avoid candidates without cloud experience, particularly Azure."",""Be cautious of candidates with limited experience in IT service management and Agile frameworks.""],""confidence_score"":90.0}"
"Manager, Systems Administration",Ontario Medical Supply,"Ottawa, Ontario, Canada",June,2024,"Ontario Medical Supply is a Leading Distributor of medical equipment, supplies, and services for healthcare organizations and home healthcare clients across Ontario. Specializing in long term care, assisted living, retirement and home health care. Ontario Medical Supply is partnered for success with Royal Drugs. Royal Drugs is a healthcare company providing specialty pharmacy, infusion therapy, and retail pharmacy services. Together, we work towards supporting optimal health outcomes and better quality of life.

Come Join Our Team!

Purpose:
The primary goal of the Manager, Systems Administration is to ensure the company’s IT infrastructure meets the needs of the organization, is secure and dependable. The Manager, Systems Administration plays a critical role, in cooperation with other members of the IT team, in maintaining and constantly improving systems and technologies that support business operations.
The organization’s IT infrastructure currently supports more than 10 locations with additional locations being added due to growth. Our main location in Ottawa includes an on-premises server room.

Location: Ontario Medical Supply (OMS) – Ottawa, ON or Markham, ON
Reports to: Senior Director, Information Technology
No. of Positions: 1
ATR: 4550
Type: Full time, Permanent
Salary: Salary, commensurate with experience
Benefits: Yes

Job Responsibilities:
Define, manage, maintain, and implement IT infrastructure including servers and networks
Manage physical servers and server virtualization (VMWare and Hyper-V)
Server operating systems (primarily Windows, some Linux)
Manage server storage systems
Manage networks including LAN/WAN, firewalls, routers, switches, Wi-Fi, cabling
Configure and administer Active Directory in an M365 environment
Configure and maintain the M365 email system
Work with external vendors and internal IT staff to manage and improve IT security
Manage and implement phone systems across all locations
Participate in various IT projects
Evaluate and recommend hardware and software upgrades, as well as plan and design future infrastructure growth
Backups and disaster recovery solutions
Create and maintain system and network documentation
Ensure standards and procedures are up to date and enforced to support management of IT assets and adhering to compliance requirements
Vendor and contract management

Qualifications:
Minimum 5 years’ experience in IT infrastructure management
An in-depth understanding of a variety of IT systems, hardware, and software is essential
Experience managing IT infrastructure projects
Experience managing and mentoring technical staff
Planning and organizational skills including the ability to plan, coordinate, prioritize and monitor projects and day to day maintenance and support activities
Solid understanding of virtualization technology (VMWare and Hyper-V)
Solid understanding of network and security monitoring tools
Experience working with a SAN (iSCSI and Fiber Channel)
Understanding of network protocols, including TCP/IP, DHCP, DNS, VPN
Excellent problem solving, analytical skills, technical skills and attention to detail
Excellent interpersonal skills working with business team leaders and business users at all levels of the organization
Communicates effectively verbally and in written form
A passion to learn the business and use their skills to improve business outcomes
Understand the business goals and objectives to ensure alignment of IT priorities with business priorities
A desire to make a difference in the growth and success of the organization
A belief in continuous learning and an interest in new technologies

Other:
Must be available for on-call support during evenings and weekends on a rotating schedule
Travel to our various locations will be required

While we thank you for your interest, only select applicants will be contacted regarding the position.

Ontario Medical Supply is an inclusive and equal opportunity employer committed to providing diversity and accommodations for applicants upon request at any stage of the recruitment process in accordance with the Accessibility for Ontarians with Disabilities Act (AODA) and the Ontario Human Rights Code. All applicants must make their requirements known when contacted.","{""role_summary"":""The Manager, Systems Administration ensures the company's IT infrastructure meets the organization's requirements, is secure, and dependable, supporting business operations."",""key_terms"":[{""term"":""VMWare"",""explanation"":""A virtualization technology used to manage and allocate computing resources.""},{""term"":""Hyper-V"",""explanation"":""A virtualization technology used to manage and allocate computing resources.""},{""term"":""M365"",""explanation"":""A suite of Microsoft products including email, office applications, and other productivity tools.""},{""term"":""SAN"",""explanation"":""A storage area network used to connect storage devices to servers.""},{""term"":""TCP/IP"",""explanation"":""Protocols used to manage communication between devices on a network.""},{""term"":""DHCP"",""explanation"":""A protocol used to assign IP addresses to devices on a network.""},{""term"":""DNS"",""explanation"":""A system used to translate domain names to IP addresses.""},{""term"":""VPN"",""explanation"":""A virtual private network used to securely connect devices to a network.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in IT infrastructure management"",""In-depth understanding of IT systems, hardware, and software"",""Experience managing IT infrastructure projects"",""Experience managing and mentoring technical staff"",""Solid understanding of virtualization technology (VMWare and Hyper-V)"",""Solid understanding of network and security monitoring tools"",""Experience working with a SAN (iSCSI and Fiber Channel)""],""nice_to_have"":[""Planning and organizational skills"",""Excellent problem-solving, analytical skills, and attention to detail"",""Communicates effectively verbally and in written form"",""A passion to learn the business and use their skills to improve business outcomes"",""Understand the business goals and objectives to ensure alignment of IT priorities with business priorities""]},""proposed_screening_questions_with_answers"":[{""question"":""What experience do you have with virtualization technology, specifically VMWare and Hyper-V?"",""example_answer"":""I have implemented and managed virtualization solutions using VMWare and Hyper-V in my previous role, ensuring efficient resource allocation and improved system performance.""},{""question"":""How do you stay current with new technologies and advancements in IT infrastructure management?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and engage with peers to stay informed about the latest developments in IT infrastructure management.""}],""red_flags"":[""Lack of experience with virtualization technology (VMWare and Hyper-V)"",""Inability to manage and mentor technical staff"",""Limited understanding of network and security monitoring tools""],""confidence_score"":90.0}"
"IT Service Delivery Manager, NA",Valmet,"Montreal, Quebec, Canada",June,2024,"Please scroll down for the English version***

Si vous êtes un professionnel de l'informatique possédant de vastes compétences en gestion de projet, ceci est votre opportunité de rejoindre un leader mondial de l’industrie

La décision entourant le choix de votre prochain employeur ne doit pas être prise à la légère. Si vous désirez travailler aux premières lignes du développement de nouveaux procédés et produits qui permettront de façonner diverses industries, continuez votre lecture pour voir ce que nous vous offrons!

Nous avons bâti notre équipe gagnante en investissant continuellement dans le perfectionnement des compétences, le leadership et le mieux-être. Appliquez votre expertise pour faire avancer votre carrière en tant que responsable de la livraison des technologies de l'information (TI) chez Valmet.

Le responsable de la livraison des TI est responsable de la mise en œuvre, de la livraison et du support des solutions informatiques qui font progresser Valmet Business. Vous superviserez la conception, le développement et les tests des systèmes informatiques afin qu'ils répondent aux besoins commerciaux actifs et futurs de l'organisation. Vos responsabilités consisteront notamment à diriger des initiatives stratégiques et à assurer le bon fonctionnement des fonctions quotidiennes. Les responsabilités incluent également l'audit de qualité de ces services et solutions dans la zone Amérique du Nord tout en collaborant étroitement avec l'entreprise et l'équipe informatique mondiale dans le monde entier.

Attentes

Les candidats bien qualifiés posséderont un baccalauréat en informatique ou un diplôme technique connexe combiné à des diplômes et certifications professionnels liés à l’informatique. Solide compétences in leadership et un minimum de 5 ans d'expérience professionnelle dans la fourniture de solutions informatiques grâce à des initiatives d'amélioration continue efficaces avec une expérience avérée dans la mise en œuvre du changement.

La gestion de projet avec les certifications associées, les politiques de pointe et la formation d'un large éventail de publics seront considérées comme un atout majeur.

Ce poste nécessite une excellente maîtrise de la langue anglaise puisqu’il s’agit de notre langue commerciale commune utilisée dans le monde entier. Ce poste nécessite la capacité d'apporter un support à nos clients, tant virtuellement qu'en se déplaçant occasionnellement sur nos sites situés en Amérique du Nord. Il sera nécessaire pour certains projets de s'adapter à la disponibilité de nos collègues situés dans d'autres fuseaux horaires.

Nous offrons

Nous offrons un milieu de travail stimulant valorisant l’innovation, adapté aux personnes avides de perfectionnement, qui aiment travailler dans un environnement rapide et dynamique. Le poste inclut une généreuse rémunération et un ensemble d’avantages sociaux, y compris un Régime de Pension Agréé financé par la Compagnie.

Veuillez noter que toute offre d’emploi est conditionnelle à une vérification des antécédents.

Renseignements supplémentaires

Livrer des technologies et des services compétitifs, c’est ce que nous faisons de mieux. Chez Valmet, nous continuons à avancer et à nous perfectionner, tout en nous concentrant sur la technologie, les services, des pratiques durables, notre présence locale et nos gens.

Pour être inclus dans le processus de recrutement, veuillez nous présenter votre demande directement en ligne. Pour de plus amples renseignements, veuillez contacter Agda Feio par courriel au agda.feio@valmet.com

Veuillez noter que Valmet ne demandera jamais d'informations financières personnelles pendant le processus d'entrevue. Si vous pensez avoir été victime d'une escroquerie en matière d'offre d'emploi en ligne, veuillez en informer la Federal Trade Commission des États-Unis ou le Centre Ant-Fraude du Canda.

Quand tout fonctionne harmonieusement

Valmet est l’endroit où se réunissent les meilleurs talents d’un grand nombre de disciplines. Avec nos 19 000 professionnels partout dans le monde, nous sommes le chef de file mondial des développeurs et fournisseurs de technologies, d’automation et de services pour les industries des pâtes et papiers et de l’énergie. Notre engagement à faire avancer le rendement de nos clients exige de la créativité, des innovations technologiques, du savoir-faire dans le service et, surtout, du travail d’équipe. Joignez-vous à l’équipe!  https://www.valmet.com/fr

Veuillez défiler vers le haut pour la version française***

If you are an IT professional with extensive project management skills, this is your opportunity to join a global industry leader.

Deciding on a new career within Valmet can be an exciting prospect. Every day there are teams of Valmet employees around the world who share the feeling of achieving something great – that feeling when everything works together.

Our winning team is built by continuous investment in skills development, leadership, and well-being. As a global company, we offer many career paths to suit individual needs and aspirations. Apply your expertise to further your career as an Information Technology (IT) Delivery Manager at Valmet.

The IT Service Delivery Manager is responsible for the implementation, delivery and support of IT solutions that drive Valmet Business forward. You will oversee the design, development, and testing of IT systems so that they meet the organization's active and future business needs. Your responsibilities will include leading strategic initiatives and ensuring the smooth operation of daily functions. Responsibilities also include the quality audit of these services and solutions in the North America Area while collaboration closely with the business and the Global IT Team worldwide.

Expectations

Well qualified candidates will possess a Bachelor’s Degree in Computer Science or a related technical degree combined with IT business-related professional degrees and certifications. You have strong leadership skills with minimum of 5 years of work experience in delivering IT solutions through effective continuous improvement initiatives with a proven track record in implementing change.

Project Management with related certifications, leading policies and training a diverse range of audiences will be considered as a strong asset.

This position requires excellent command of the English language since it is our common business language used worldwide. This position requires the ability to provide support to our customers, both virtually and by occasionally traveling to our sites located in North America. It will be necessary for certain projects to accommodate the availability of our colleagues located in other time zones.

Please note that any offer of employment is contingent upon a background check.

We offer

We offer a challenging work environment that values innovation and suits development-minded people who enjoy working in a fast-paced and dynamic setting. Includes a generous wage and benefits package that includes a company-funded pension plan.

Please note that any offer of employment is contingent upon a background check.

Additional Information

Delivering competitive technologies and services is what we do best. At Valmet, we continue to push forward and develop ourselves, concentrating on technology, services, sustainability, local presence, and our people.

To be included in the recruiting process, please apply directly with us online. For more information please reach out to Agda Feio at agda.feio@valmet.com

Please note that Valmet will never ask for personal financial information during the interview process. If you feel you have been a victim of an online job posting scam, please notify the US Federal Trade Commission or the Canadian Anti-Fraud Centre.

When everything works together

Valmet is where the best talent from a wide variety of backgrounds comes together. With 19,000 professionals around the world, we are the leading global developer and supplier of technologies, automation and services for the pulp, paper, and energy industries. Our commitment to moving our customer’s performance forward requires creativity, technological innovations, service know-how – and above all, teamwork. Join the team! www.valmet.com/careers","{""role_summary"":""The IT Delivery Manager is responsible for implementing, delivering, and supporting IT solutions that drive business forward, overseeing design, development, and quality audit of services and solutions in North America."",""key_terms"":[{""term"":""IT solutions"",""explanation"":""Technical systems and services that support organizational goals.""},{""term"":""Project Management"",""explanation"":""The process of planning, organizing, and controlling resources to achieve specific objectives.""},{""term"":""Continuous Improvement"",""explanation"":""A systematic process to identify and implement changes to improve efficiency and effectiveness.""}],""skill_priorities"":{""must_have"":[""Bachelor's Degree in Computer Science or related technical degree"",""Minimum 5 years of work experience in delivering IT solutions"",""Strong leadership skills"",""Excellent command of the English language""],""nice_to_have"":[""Project Management certifications"",""Leading policies and training a diverse range of audiences""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience in implementing IT solutions that drive business forward?"",""example_answer"":""In my previous role, I successfully implemented a new IT system that increased efficiency by 20%.""},{""question"":""How do you ensure the smooth operation of daily functions in an IT team?"",""example_answer"":""I prioritize tasks, delegate responsibilities, and conduct regular team meetings to ensure everyone is aligned.""}],""red_flags"":[""Lack of experience in delivering IT solutions"",""Poor command of the English language""],""confidence_score"":90.0}"
Senior IT Systems Administrator,WorkatHome-JobBoard,"Richmond, British Columbia, Canada",July,2024,"Saltworks Technologies (Richmond, BC) is a global technology leader in advanced industrial wastewater treatment and lithium refining. Our innovative machines produce clean water from high-strength industrial discharges and refine lithium to support the energy transition. We offer meaningful and exciting work in a collaborative environment, driven by innovation and problem-solving. We're a fast-growing cleantech company offering exceptional career opportunities, driven by major global trends.

The Role

We have an immediate opening for a Senior IT Systems Administrator. In this role, you will be instrumental in ensuring the seamless operation of our IT infrastructure. You will be responsible for managing and maintaining our network, servers, and client systems, while also helping ensure network security to protect our data and operations.

This is an onsite role at our office in Richmond, BC, with limited opportunity for remote work. You must be located in or be willing to relocate to the Lower Mainland.

System Administration

Your primary areas of responsibility are:

Install, configure, deploy, and maintain Windows and Linux client/server systems and virtual machines.

Configure and maintain Microsoft 365 environment.

Administer various software and hardware assets, including on-premise, cloud and hybrid, as well as enterprise software systems.

Install, configure, repair, upgrade, and maintain networking and end-user devices.

Network Security

Ensure network security and stability across local and cloud-based environments.

Implement and oversee security protocols to safeguard data and network operations.

Conduct regular system audits to detect vulnerabilities and mitigate risks.

Maintain data backups to ensure data integrity and availability.

Technical Support

Provide direct technical support for IT infrastructure, ongoing and new projects, and end-user issues.

Resolve technical challenges promptly and efficiently in compliance with company policies.

Project Management

Collaborate with IT Manager and project stakeholders to plan and execute system upgrades, migrations, and new technology deployments.

Coordinate with vendors and service providers to ensure timely delivery of products and services as needed.

You Will Be a Great Fit If You Have

A degree, diploma, or certificate in Information Technology or related field.

Minimum of 5 years of experience in system and network administration on-premise and in the cloud, including but not limited to Microsoft 365, Microsoft VMs, Cloud Services, Hybrid Environments, MDM, Entra, Intune, Web Servers, Clusters, Storage Management, AD, Remote Access, ZTNA, and Linux systems.

Proven experience supporting IT systems in a corporate or other business environment with 50+ users is a must.

Experienced in automating day-to-day IT administration related tasks.

Experience With PowerShell, Bash, And Other Scripting Languages.

Proven hands-on experience in deploying Networks, Equipment, Servers, VMs, Access Control Solutions, GP, device mass deployment and configuration, RMM (Remote Management and Monitoring) systems, Backup Solutions, Ticketing Systems, managing users in Hybrid Environment, SharePoint, etc.

Excellent troubleshooting skills, ability to manage multiple projects simultaneously, exercise critical thinking, and preventative damage control.

Excellent verbal and written communication skills in English.

Ability to lead and deploy assigned projects or tasks independently.

The Following Qualifications Are Preferred But Not Required

Experience with database administration tasks for SQL Server and other databases.

Proficiency in coding and dev-ops tools, especially PHP, Python, SQL, Git, and Docker.

Why join Saltworks?

We have an outstanding team that is passionate about innovation and solving key environmental challenges facing our planet.

Join a team pioneering the future of water. Some of our customers include world-leading electric vehicle makers, semiconductor firms, mining companies, agriculture firms, and more!

We Offer

A collaborative and rewarding work environment.

Opportunities to advance technically or in leadership roles.

A competitive compensation package that includes medical, dental, vision, RRSP matching, life insurance, AD&D coverage, and an education allowance.

A culture that supports safety, innovation, learning, diversity, and teamwork.

Fun social activities and company events.

How To Apply

If you would like to be a part of a globally recognized team, please submit your resume (cover letters are not required).

While we sincerely appreciate all applications, only those candidates selected for an interview will be contacted. All applications are considered confidential.

Kindly, no recruiters.

INDS

0SpDUpKvUI","{""role_summary"":""The Senior IT Systems Administrator is responsible for ensuring the seamless operation of our IT infrastructure, including network, servers, and client systems, while maintaining network security and providing technical support."",""key_terms"":[{""term"":""Microsoft 365"",""explanation"":""A cloud-based suite of productivity applications, including email, word processing, and collaboration tools.""},{""term"":""Virtual Machines (VMs)"",""explanation"":""Software-based computers that run operating systems and applications, often used for testing, development, and deployment.""},{""term"":""Cloud Services"",""explanation"":""On-demand computing resources and applications provided over the internet, often used for scalability and flexibility.""},{""term"":""Hybrid Environments"",""explanation"":""Combination of on-premise and cloud-based infrastructure, often used for data storage, processing, and security.""},{""term"":""MDM (Mobile Device Management)"",""explanation"":""Software used to manage, monitor, and secure mobile devices, often used for remote access and data protection.""},{""term"":""Entra"",""explanation"":""A cloud-based identity and access management platform, often used for secure access to applications and resources.""},{""term"":""Intune"",""explanation"":""A cloud-based endpoint management platform, often used for device management, security, and compliance.""},{""term"":""Web Servers"",""explanation"":""Software that hosts and serves websites, applications, and data, often used for online presence and communication.""},{""term"":""Clusters"",""explanation"":""Groups of computers or servers that work together to provide high availability, scalability, and performance, often used for critical applications and data processing.""},{""term"":""Storage Management"",""explanation"":""The process of storing, retrieving, and managing data, often used for data protection, recovery, and compliance.""},{""term"":""AD (Active Directory)"",""explanation"":""A directory service that manages access, authentication, and authorization for users, computers, and resources.""},{""term"":""Remote Access"",""explanation"":""The ability to access and control computers, servers, or networks remotely, often used for technical support, maintenance, and management.""},{""term"":""ZTNA (Zero Trust Network Access)"",""explanation"":""A security approach that assumes no user or device is trusted, often used for secure access to applications and resources.""},{""term"":""Linux systems"",""explanation"":""An open-source operating system, often used for servers, supercomputers, and embedded devices.""},{""term"":""PowerShell"",""explanation"":""A task automation and configuration management framework, often used for scripting and automation.""},{""term"":""Bash"",""explanation"":""A Unix shell and command-line interpreter, often used for scripting and automation.""}],""skill_priorities"":{""must_have"":[""System and network administration experience"",""Microsoft 365 experience"",""Cloud and hybrid infrastructure experience"",""Scripting languages (PowerShell, Bash)"",""IT infrastructure technical support experience""],""nice_to_have"":[""Database administration experience (SQL Server)"",""Coding and dev-ops experience (Python, SQL, Git, Docker)""]},""proposed_screening_questions_with_answers"":[{""question"":""What experience do you have with Microsoft 365 and cloud-based infrastructure?"",""example_answer"":""I have 3+ years of experience with Microsoft 365, including deployment, configuration, and security.""},{""question"":""How do you approach network security and vulnerability management?"",""example_answer"":""I use a layered security approach, including firewalls, intrusion prevention systems, and regular vulnerability scans and penetration testing.""}],""red_flags"":[""Lack of experience with Microsoft 365 and cloud-based infrastructure"",""Inability to work in an onsite role with limited remote work opportunities""],""confidence_score"":95.0}"
"Associate Manager, IT - Release Management",Kraft Heinz,"Toronto, Ontario, Canada",June,2024,"Job Description

The Associate Manager Release Management will be a key component of the IT ERP Capabilities Team. The role will implement and report against KHC Release Management principles.

Primary Responsibilities

Develop and maintain release management standards and documentation.
Ensure adherence to Kraft Heinz global IT standards and procedures while employing continuous improvement of Release Management processes, tools and repositories
Manage SAP outages with cross functional global teams and provide appropriate communication including associated impacts
Coordinate cutover through SAP landscape (F/D->Prod)
Facilitate Hypercare for major releases, implementations, and other projects
Leads monthly releases including coordination with Change Management and Test Hub
Perform routine transport management activities including guidance and approvals
Contribute to development of annual and forward planning release calendars including publication and communication of changes
Participate in CAB, GCC, etc. to provide input and guidance as pertains to Release Management, including presentations as applicable.
Maintain relationships and orchestrate work between different teams at different locations during cutover and project release activities.
Provide release reporting metrics and follow-up of over-due / abandoned items.
Maintain release repositories including associated documentation (timelines, build metrics, testing, status reporting, etc.)


Additional contributions, with possibilities to lead, include

Present release status at weekly Leadership meetings
Identifying and reporting upon release risks/issues identified from Release perspective
Identify and define release scope with IT leads and Project Managers
Communicate all key project plans, commitments, and changes including requirements, QA plans, schedule, and scope changes
Report upon and conduct Release Readiness reviews, Milestone Reviews, and Business Go/No-Go reviews
Define, coordinate and facilitate Technical Go-live activities per plans and checklists


Appetite for Success

Project & Process Management
Vendor Relationship Management
Influencing and Negotiating
Acting as an Owner
Problem solving and Critical thinking
Thrive in a results-driven environment
Effective communication and troubleshooting skills, relationship building skills, and work effectively in a team environment with both local and remote teams
Advanced interpersonal, oral, and written communication skills, and able to multitask effectively


Qualifications

Team Leadership and management of cross functional teams
Experiences working in multinational companies operating in the consumer goods environment
Proven track record of successful assignments and positive results
Support through different time zones with geographically dispersed teams and clients
Experience with testing methodology, subject areas and activities, including test planning, preparation, execution and reporting
Strong leadership capabilities and excellent interpersonal, verbal and written communication skills
Experience in handling and leading escalations and managing resolution of critical issues
Experience in coordination with PMO and aligning on methodology and process
Experience in HP Quality Center is highly preferred
SAP S4 and Legacy application knowledge a plus.


Location(s)

Toronto - Queen's Quay - Headquarters

Kraft Heinz is an Equal Opportunity Employer – Underrepresented Ethnic Minority Groups/Women/Veterans/Individuals with Disabilities/Sexual Orientation/Gender Identity and other protected classes. In order to ensure reasonable accommodation for protected individuals, applicants that require accommodation in the job application process may contact NATAI@kraftheinz.com for assistance.","{""role_summary"":""The Associate Manager Release Management is responsible for implementing and reporting against KHC Release Management principles, ensuring adherence to global IT standards and procedures, and managing SAP outages and releases."",""key_terms"":[{""term"":""Release Management"",""explanation"":""The process of planning, coordinating, and controlling the movement of releases to production.""},{""term"":""SAP"",""explanation"":""A popular enterprise resource planning (ERP) software used to manage business operations and customer relations.""},{""term"":""Hypercare"",""explanation"":""A period of intense support and monitoring after a major release or implementation to ensure stability and resolve any issues quickly.""}],""skill_priorities"":{""must_have"":[""Project & Process Management"",""Vendor Relationship Management"",""Influencing and Negotiating"",""Acting as an Owner"",""Problem solving and Critical thinking"",""Effective communication and troubleshooting skills"",""Relationship building skills"",""Work effectively in a team environment with both local and remote teams""],""nice_to_have"":[""Experience with testing methodology"",""Experience in handling and leading escalations"",""Experience in coordination with PMO"",""Experience in HP Quality Center"",""SAP S4 and Legacy application knowledge""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with Release Management principles and how you've applied them in previous roles?"",""example_answer"":""In my previous role, I developed and maintained release management standards and documentation, ensuring adherence to global IT standards and procedures.""},{""question"":""How do you coordinate with cross-functional teams during cutover and project release activities?"",""example_answer"":""I maintain relationships and orchestrate work between different teams at different locations during cutover and project release activities, ensuring effective communication and collaboration.""}],""red_flags"":[""Lack of experience in Release Management principles and practices"",""Inability to work effectively in a team environment with both local and remote teams""],""confidence_score"":80.0}"
Information Manager,"Ontario Transit Group - Ontario Line - Southern Civil, Stations & Tunnel","Toronto, Ontario, Canada",June,2024,"Company Description

Ferrovial Construction Canada Inc. and VINCI Construction Grands Projects are undertaking the design, build, and finance the Ontario Line Southern Civil, Stations, and Tunnel (South Civil) package.

As Ontario Transit Group, we are now mobilizing our design and construction crews, with major works. The South Civil contract is anticipated to be completed in 2030.

The project will strengthen Ontario’s economy by supporting an estimated 1,500 jobs at the peak of construction.

What is the project?

A six-kilometer tunnel and associated tunnelling works from Exhibition to Don Yard portal (west of the Don River).
Stations:
One above-ground station to be integrated with the existing GO Transit Exhibition Station.
Two underground stations to be integrated with the existing TTC Osgoode and Queen subway stations.
Four new underground stations (King/Bathurst, Queen/Spadina, Moss Park, Corktown).
The benefits to Ontario!

Faster, more frequent, and reliable access to rapid transit with more than 227,500 people will live within a 10-minute walk of an Ontario Line station.

Improve the quality of life for commuters by reducing daily travel time.
Reduce crowding on the existing Line 1 (Yonge-University) subway.
Up to 57,000 more jobs accessible by transit (in 45 minutes or less) for Toronto residents.
Economic and community growth along the future transit line and thousands of job opportunities annually during construction.
Reduction in traffic congestion, greenhouse gases, and fuel consumption by providing an alternative transportation option.

Job Description

Ontario Line South Design & Construction project is a massive project happening in the heart of Toronto for the following 7 years. Along the project duration, large number of processes are happening in parallel, and several digital tools and platforms would be used in the design and construction of the project.

The Information Manager, reporting directly to the Digital Delivery Manager, will lead the information management requirements and processes implementation throughout all the project departments. Among other duties, with a internal strategic consultant approach, the Information Manager will lead a 3 key-steps process:

Identify: work jointly with department managers to detect processes that can be improved in the project
Simplify: work together with them to reduce to the minimum steps and propose a clear flowchart for bringing the process to the rest of the teams
Digitalize: prioritizing the project platforms and solutions, proposed the best approach to bring it into a digital process. From this point, the Information Manager should work together with the Data Management team to propose the best data models and data structure for reporting and data analytics processes.

Asite and Dalux Field are the official EDMS and Operational and Construction Management platforms across the project. The Information Manager will need to get familiar with these platforms and lead the implementation and deployment of the processes happening in them.

Additional Information Manager duties include:

Analyze and document using visual flowcharts for the different processes of the project
Definition of information standards and data models applicable to design and construction projects. Development of use cases and POCs for validating the schemas.
Creation of templates for different design and construction tools, for input and output data schemas, to link information from different processes and tools.
Development of logic schemas linked to existing standards and data ontologies, specially linked to 3D (BIM) and 2D (GIS) geometric references.
Being capable of standardizing initiatives approach, with strategic and analytic vision to understand project needs and providing value from the data that they or other departments generate.
Developing training content, both basic and more advanced levels for different adoption users.

Establish and prepare clear and concise documentation for the different standardized processes

Qualifications

Basic Qualifications

At least 5 years of experience in design and construction of big projects
Civil or Industrial engineering bachelor, or equivalent studies with real experience in design and construction projects
High Analytical Thinking and mindset, Problem Solving and Strategic Vision skills
High communication and meeting leadership skills
High experience with some flowchart, diagram and process visualization (MS Visio, Edraw, Miro)
High experience with Microsoft Office (Office 365, SharePoint, Power Platform)
Experience in EDMS systems administration such as SharePoint, Asite, Aconex, ACC
Experience in Power BI, PowerQuery, DAX and/or SQL
Experience in analysing BIM and GIS requirements of design and construction projects

Preferred Certifications

Any official Certification in any Microsoft Office 365 tools

Additional Information

We Offer:

Competitive Salary
Comprehensive Benefits Package:
Disability Insurance
Dental Insurance
Extended medical insurance
(Optional) RRSP matching
Discretionary Bonus

Why OTG?

Welcome to Ontario Transit Group (OTG), located in the heart of Downtown Toronto, where diversity and passion collide. As we work on the groundbreaking Ontario Line project, we prioritize fostering a positive culture. Join us and be part of a team that celebrates our employees, organizes family events, and promotes health and wellness initiatives. Our commitment to personal and professional growth means annual performance reviews, salary increases, comprehensive health benefits, generous RRSP matching, industry education support, and career development opportunities.

At OTG, we embrace diversity, recognizing that it strengthens us as a team and as a company. We are an equal-opportunity employer, encouraging applications from all interested candidates. We value Indigenous people, racialized people, neurodivergent people, people with disabilities, and individuals from gender and sexually diverse communities with intersectional identities. Reasonable accommodations are available upon request for people with disabilities. If you're ready to be part of our dynamic team in one of the world's most diverse cities, don't wait any longer—apply now!



While we appreciate your interest, only selected candidates will be contacted for interviews. Please note that we do not accept agency submissions.","{""role_summary"":""The Information Manager will lead the information management requirements and processes implementation throughout all project departments, working closely with department managers to identify, digitalize, and simplify processes, and ensure data models and structures are in place for reporting and data analytics."",""key_terms"":[{""term"":""EDMS"",""explanation"":""Electronic Document Management System, used for managing and storing project documents and data.""},{""term"":""BIM"",""explanation"":""Building Information Modelling, a digital representation of the physical and functional characteristics of a building or infrastructure project.""},{""term"":""GIS"",""explanation"":""Geographic Information System, a system for capturing, storing, analyzing, and displaying geographically referenced data.""},{""term"":""Asite"",""explanation"":""A cloud-based construction collaboration platform used for managing and sharing information.""}],""skill_priorities"":{""must_have"":[""At least 5 years of experience in design and construction of big projects"",""Civil or Industrial engineering bachelor, or equivalent studies with real experience in design and construction projects"",""High Analytical Thinking and mindset, Problem Solving and Strategic Vision skills"",""High communication and meeting leadership skills"",""High experience with some flowchart, diagram and process visualization (MS Visio, Edraw, Miro)"",""High experience with Microsoft Office (Office 365, SharePoint, Power Platform)""],""nice_to_have"":[""Any official Certification in any Microsoft Office 365 tools""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with EDMS systems administration, such as SharePoint, Asite, Aconex, ACC?"",""example_answer"":""I have worked with SharePoint for 3 years, and have experience with Asite, Aconex, and ACC. I have administered these systems for multiple projects, ensuring data accuracy and accessibility.""},{""question"":""How do you approach process simplification and digitalization in a construction project?"",""example_answer"":""I work closely with department managers to identify areas for improvement, and then develop clear flowcharts to simplify and digitalize processes, ensuring data models and structures are in place for reporting and data analytics.""}],""red_flags"":[""Lack of experience with EDMS systems administration"",""Inability to simplify and digitalize complex processes""],""confidence_score"":90.0}"
Information systems Technical Advisor,Mindtris,"Halifax, Nova Scotia, Canada",March,2024,"Job title: Information systems Technical Advisor

Duration:1 year, extendable up to 3 years

Location: Halifax, Nova Scotia (Onsite)

Responsibilities

Analyze intricate technical challenges and recommend solutions
Provide technical guidance and best practices around solution implementations, upgrades, etc.
Design technical solutions and assist with the development of Detailed Architecture Design Documents
Plan and create the structure for technical solutions
Assist with evaluation and selection of software and hardware solutions
Suggest integration methods with other internal IT systems
Supervise the execution of projects/programs, including conducting code reviews
Gain an understanding of systems and interfaces in place at the client's organization and be able to identify cross impacts.
Lead resolution of technical issues - lead discussion with technical resources, drive to solution, engage project manager as needed, defect resolution, etc.
Guide software development teams and address technical concerns
Translate complex requirements into functional architecture
Offer guidance to technical team members
Ensure the implementation of agreed-upon architecture and infrastructure
Lead development of work effort estimates and plans for technical work (application and infrastructure) in collaboration with project manager
Play lead role in setting up development and test environments
Identify technical cross impacts with other projects or operational work
Identify any technical risks and contribution to risk response strategy
Review vendor engagements (SOW for technical aspects)
Engaged in all phases of the Software Development Life Cycle (SDLC) including client interactions, requirements gathering, application design, development, testing, debugging, deployment, maintenance, and enhancements
Participate in the investigation of opportunities for improvement and make recommendations. May consult technical equipment/software vendors and current users in these evaluations
Stay up-to-date with the latest technology trends and developments
Conduct transition to operations with operational teams
Other duties as required.

Qualifications

Minimum education level of a University Degree or equivalent College diploma with combined work experience
Previous work as a technical architect
Familiarity with coding languages
Understanding of various operating systems
Familiarity with Cloud technologies
Strong leadership and team building skills
Strong decision making and conflict management skills. Ability to coach, motivate, build trust, negotiate and communicate

Whopper Technologies, a minority women-owned enterprise, is at the forefront of digital transformation, technology excellence, and business growth solutions. Specializing in talent mobilization and innovation, we are dedicated to enhancing customer experiences across diverse sectors such as Information Technology, Telecommunications, Healthcare, Engineering, and the Public sector. With a focus on deploying top-tier talent and fostering innovation, we empower businesses to thrive and excel in a rapidly evolving digital landscape, helping them reach new heights of success.

Whopper Technologies is committed to fostering workforce diversity and is proud to be an equal opportunity employer.","{""role_summary"":""The Information Systems Technical Advisor analyzes technical challenges, recommends solutions, and provides technical guidance to ensure the implementation of agreed-upon architecture and infrastructure."",""key_terms"":[{""term"":""Technical Architecture Design Documents"",""explanation"":""Detailed documents outlining the design of technical solutions.""},{""term"":""Cloud technologies"",""explanation"":""Cloud-based computing and storage solutions.""},{""term"":""Software Development Life Cycle (SDLC)"",""explanation"":""The process of designing, developing, testing, and maintaining software applications.""}],""skill_priorities"":{""must_have"":[""Technical architecture experience"",""Familiarity with coding languages"",""Strong leadership and team building skills""],""nice_to_have"":[""Familiarity with Cloud technologies"",""Understanding of various operating systems""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a complex technical challenge you've faced and how you addressed it?"",""example_answer"":""In my previous role, I identified a technical issue with our cloud-based infrastructure. I worked with the development team to design a solution, and we were able to implement it within a tight deadline.""},{""question"":""How do you stay current with the latest technology developments?"",""example_answer"":""I regularly read industry publications, participate in online forums to stay informed about the latest trends and advancements in technical architecture and software development.""}],""red_flags"":[""Lack of technical architecture experience"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
"Systems Manager, WMS and Integration",Radiant Global Logistics (Canada) Inc.,"Mississauga, Ontario, Canada",June,2024,"Radiant offers a complete range of industry-leading transportation and warehousing solutions to businesses around the globe by leveraging our extensive network of carrier partners across all modes. Radiant provides customized logistics solutions that create value and increase profitability for our customers. 

Radiant Canada is a learning environment in which passion, dedication and a commitment to getting the job done are valued. That’s what being on our team is all about. It’s where you can gain valuable skills and experience, which also helps Radiant grow. If this sounds like the kind of company you are looking for, we would love to hear from you!

We are currently looking for a Manager, WMS and Integration Systems to join Radiant and be part of our dynamic team.
4 DAY ONSITE, 1 DAY REMOTE:  Work in the office at 1280 Courtneypark Drive E, Mississauga Monday to Thursday.  Work from home Fridays.  

What You’ll Do:  
Maintain a productive, high performing team through recruiting, selecting, orienting and training. Develop personal growth opportunities for team members. 
Manage all contractual relationships i.e. source / vet appropriate WMS application and system vendor partners, request and review contracts, approve invoices, etc. 
Lead / coordinate WMS application and integration design for projects. Provide detailed cost estimates, resource plans and schedules to project management teams. 
Engage and ensure effective and timely delivery of deliverables and tasks.
Handle all escalated matters related to the delivery of IT solutions. 
Ensure IT solutions comply with architectural standards. 
Organize and maintain the performance of WMS application issues in accordance with agreed SLA’s.
Determine the operational objectives by studying business functions, gathering information and evaluating outputs.
Design and improve systems by analyzing current practices and suggesting improvements.
Monitor project progress by tracking activity; resolving problems; publishing progress reports and recommending actions.
Maintain system-enforced processes by writing and updating procedures.
Provide references for users by writing and maintaining user documentation and providing support and training for users.
Test and support the QA process.
Document process and system procedures.
Other duties and assignments as required.

What You Bring to the Role:
College or University Degree in Computer Science, Engineering, or related field.
Minimum of 5 years’ experience with WMS in the position of applications support, project management and/or development of which a minimum 2 years’ experience must be in a management / leadership role.
Strong working knowledge of EDI systems and their specifications.
Complete working knowledge of warehouse business processes.
Experience delivering business critical software functionality.
Experience with 3PL distribution customer onboarding
3PL Distribution Supply chain / logistics experience is required. 
Must have the following technical skills:
5 years’ experience using WMS Systems and EDI Integration specifically:
Business analysis and systems analysis in support of technology solutions,
Project co-ordination, Documentation and End-user support,
Report Design,
Integration,
Quality Assurance and Testing,
Customer relationship management,
Distribution management,
Financial management,
Reporting and analytics
Experience with Kober High Jump Advantage System is preferred.
Experience with Biz Talk EDI is preferred.
Dedicated project commitment to providing acceptable and timely deliveries.
Ability to communicate effectively with all levels of the Company inside and outside of IT
Strong interpersonal skills to successfully communicate and collaborate with users, other technical teams, and internal stakeholders to collect requirements and articulate technical strategies. 
Highly organized with the ability to multi-task and prioritize.
High tolerance for stress. 
Strong problem-solving skills and decision-making skills in a team environment.
Team cooperation and respect is required. 
Strong analytical and reasoning skills with attention to detail.
After hours and weekend work as required.  
10% Travel Required

Perks You’ll Get:
·      Health, Dental, Vision, Life and Disability insurance
·      RRSP Contribution Matching
·      Birthday Day Off
·      Paid Sick Days
·      Learning & Development Opportunities
·      Employee Discounts
·      Access to an Employee Assistance Program for services including counseling, financial and legal consultation
·      Wellness Program
·      Safety Shoe Allowance
·      A Supportive and Positive Work Environment

The Fine Print:
Radiant is committed to providing accessible employment practices that are in compliance with the Accessibility for Ontarians with Disabilities Act (AODA). Accommodations are available on request for candidates taking part in all aspects of the recruitment and selection process.

We thank all candidates for applying, however, only those candidates selected for an interview will be contacted.","{""role_summary"":""Manage and lead the Warehouse Management System (WMS) and Integration Systems team, ensuring high-performing team, effective project delivery, and compliance with architectural standards."",""key_terms"":[{""term"":""WMS"",""explanation"":""Warehouse Management System, a software solution that manages and controls warehouse activities.""},{""term"":""EDI"",""explanation"":""Electronic Data Interchange, a standard for exchanging business documents between organizations.""},{""term"":""3PL"",""explanation"":""Third-Party Logistics, a service that outsources logistics and distribution operations to a third-party provider.""}],""skill_priorities"":{""must_have"":[""5 years' experience with WMS"",""Minimum 2 years' experience in a management/leadership role"",""Strong working knowledge of EDI systems and warehouse business processes"",""3PL Distribution Supply chain/logistics experience"",""Technical skills: WMS Systems, EDI Integration, Business analysis, Project co-ordination, Report Design, Integration, Quality Assurance, Testing, Customer relationship management, Distribution management, Financial management, Reporting and analytics""],""nice_to_have"":[""Experience with Kober High Jump Advantage System"",""Experience with Biz Talk EDI""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with WMS systems and EDI integration?"",""example_answer"":""I have 5 years of experience, including 2 years in a management role, and have successfully implemented WMS systems and EDI solutions in previous roles.""},{""question"":""How do you ensure effective project delivery and compliance with architectural standards?"",""example_answer"":""I prioritize tasks, set clear goals, and establish open communication channels with stakeholders to ensure timely delivery and compliance with standards.""}],""red_flags"":[""Lack of experience with WMS systems and EDI integration"",""Inability to communicate effectively with technical and non-technical stakeholders""],""confidence_score"":90.0}"
Senior Manager IT,Resonaite,"Toronto, Ontario, Canada",March,2025,"Our client in the non-profit sector is seeking a Deputy Director, IT to lead IT operations, security, strategy, and infrastructure. This role ensures technology supports organizational goals efficiently and securely.

Location: Hybrid 3d/week Toronto

Key Responsibilities:
• Assist in IT strategy development and implementation.
• Oversee IT budget, policies, and vendor management.
• Lead IT team, fostering innovation and professional growth.
• Manage IT projects using Agile methodologies.
• Maintain and secure IT infrastructure, networks, and cloud services.
• Ensure cybersecurity best practices and conduct security assessments.
• Provide IT support and optimize Microsoft 365 services.

Qualifications:
5+ years experience in IT management
Strong expertise in IT infrastructure, security, and cloud technologies.
Advanced knowledge of Microsoft 365 (Exchange, SharePoint, Teams, Azure AD).
Experience in IT leadership, project management, and team development.","{""role_summary"":""Lead IT operations, security, strategy, and infrastructure to support organizational goals efficiently and securely."",""key_terms"":[{""term"":""Agile methodologies"",""explanation"":""An iterative approach to managing projects, focusing on flexibility and collaboration.""},{""term"":""Cloud services"",""explanation"":""On-demand access to computing resources, and applications over the internet.""},{""term"":""Cybersecurity best practices"",""explanation"":""Established guidelines for protecting computer systems and sensitive data from unauthorized access.""},{""term"":""Microsoft 365"",""explanation"":""A suite of productivity applications, including Exchange, SharePoint, Teams, and Azure AD.""}],""skill_priorities"":{""must_have"":[""IT management experience"",""IT infrastructure expertise"",""Microsoft 365 knowledge""],""nice_to_have"":[""Project management skills"",""Team development experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure cybersecurity best practices in your IT operations?"",""example_answer"":""I conduct regular security assessments, implement robust access controls, and stay updated on emerging threats.""},{""question"":""Can you describe your experience with Microsoft 365, specifically with Exchange and SharePoint?"",""example_answer"":""I've implemented and managed Microsoft 365 for my previous organization, ensuring seamless integration of Exchange, SharePoint, and Teams.""}],""red_flags"":[""Lack of experience with Agile methodologies"",""Inadequate knowledge of cloud technologies""],""confidence_score"":90.0}"
"Manager, IT Service Manager",Akkodis,"Toronto, Ontario, Canada",March,2025,"Akkodis is seeking a Manager, IT Service Manager for a full-time position with a client in Toronto, ON and ideally looking for experience with ITSM management, ITIL certifications, Management experience, ITSM processes, incidents Management
Position: Manager, IT Service Manager
Location: Toronto, On - Hybrid
Full Time

Key skills:
Extensive experience in introducing, managing, and improving ITSM processes, specifically in Incident, Major Incident, Problem, and Change Management (not looking for configuration management as that will be someone else’s responsibility). Hands-on incident management experience is needed, including at least some major incidents. Will be coaching their direct reports, including the major incident manager.

Have a roadmap in place and need help with tactical work like introducing CAB workbench, and introducing training to support the rollout but want someone who comes with their own experience and ideas and suggestions of how to do things better. They are working on maturing their ITSM processes.
Not looking for any particular industry experience but has to come from a sizeable organization as they are the only ones with formalized ITSM processes.
Needs to have excellent communication skills and will be presenting to the CTO and SVPs every week.
Description,
We are embarking on an important and exciting journey to transform our IT Service Management practices to support the growing services delivered by Moneris that benefit millions of Canadians each day!
As IT Service Management leader, you will oversee the execution of the IT Service Management roadmap and lead the daily operations and execution of all processes within the ITSM program.
Location: You will be based in our Toronto office and will work in a hybrid model.
Reporting Relationship: You will report to the Director, of Production Support and Service Management.

What you'll do
Led IT service management teams responsible for the daily operations of Moneris’ IT Service Management processes including incident management, major incident management, problem management, change management, and configuration management.
Manage the IT service management processes for Incident, Major Incident, Problem, Change, and Configuration management which includes tracking and enforcing any daily process compliance issues with stakeholders.
Support all technology team members on ITSM process and procedural questions and lead training and communication activities.
Take a lead role for the most critical of major incidents, in a 24x7 environment, where senior ITSM leadership is imperative for the successful resolution. Moreover, uses sound judgment and decision-making skills to lead senior technology practitioners and leaders towards the most effective recovery and resolution.
Key contributor to the success of the service improvement process by identifying process deficiencies and recommendations for improvement.
Review operational metrics with senior management to drive awareness, support, and compliance.
Chairs regular operational meetings with stakeholders to review operational KPI’s, and trends and identify improvement opportunities to drive ITSM across the Technology Organization.
Seen as the trusted ITSM expert and partner at Moneris and levers industry and ITSM framework knowledge to improve ITSM processes delivered at Moneris.
Maintain a diverse peer group of other ITSM professionals to share ideas and challenges to the benefit of Moneris’ IT Service Management

What you bring
Bachelor’s degree in information technology, system administration, information systems management, or similar disciplines. A Master’s degree is considered an asset.
Minimum 10 years of experience working in developing, administering, or conducting IT service management work processes and managing senior technical resources.
Minimum 3 years’ experience managing IT service management teams
Expert and experienced in supporting and administering IT service management responsibilities such as incident, problem, and IT change and configuration management.
ITIL V3 or ITIL V4 Intermediate certification, Expert level (considered an asset)
Experience supporting payment systems within a merchant-acquiring business (considered an asset)

What you get
Comprehensive Total Rewards Program including bonuses, flexible benefits starting from day 1, and your choice of either a health spending account (HSA) or personal spending account (PSA)
RRSP matching & defined contribution pension plan
Learning & development programs and resources including unlimited free access to Coursera and an Educational Assistance Program
Holistic approach to your well-being, with an Employee Assistance Program for you and your family, access to 24/7 virtual health care, wellness events, and a supportive workplace culture
A workplace committed to investing in Diversity, Equity, and Inclusion (DEI) through various initiatives including, employee inclusion groups (EIGs), mentorship, DEI learning and workshops, educational events, and various resources including an internal DEI website and newsletter
Company-wide paid year-end closure & personal time off (including religious, personal, and volunteer days)","{""role_summary"":""Manage IT service management teams, and processes, including incident, major incident, problem, and change management, and enforce process compliance, and lead training and communication activities."",""key_terms"":[{""term"":""ITSM"",""explanation"":""IT Service Management, a set of policies, procedures, and processes to manage IT services.""},{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a set of best practices for IT service management.""},{""term"":""CAB"",""explanation"":""Change Advisory Board, a group that assesses, and approves changes to IT services.""}],""skill_priorities"":{""must_have"":[""Extensive experience in ITSM processes"",""Hands-on incident management experience"",""ITIL certification"",""Management experience"",""Excellent communication skills""],""nice_to_have"":[""Experience supporting payment systems"",""Master's degree"",""ITIL Expert level certification""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with ITSM processes, specifically in Incident, Major Incident Management?"",""example_answer"":""I have managed ITSM processes for over 5 years, including incident and major incident management, and have implemented process improvements that resulted in a 30% reduction in incident resolution time.""},{""question"":""How do you stay current with industry trends and best practices in ITSM?"",""example_answer"":""I regularly attend industry conferences, participate in ITSM professional networks, and engage with peers to share knowledge and best practices.""}],""red_flags"":[""Lack of experience with ITSM processes"",""No ITIL certification"",""Poor communication skills""],""confidence_score"":90.0}"
"Manager, IT Service Management (ITSM)",eHealth Saskatchewan,"Saskatchewan, Canada",March,2025,"Why eHealth?

We may be biased, but eHealth Saskatchewan is the place to be right now! As the result of a province wide consolidation of IT services in the health care sector, we have seen substantial growth in our organization that is only going to increase as we aim to meet our expanded mandate and the immense need for our support. This gives our people a unique and rare opportunity to truly create, build, improve, and leave their mark on a growing organization.

We are a Treasury Board Crown Corporation that focuses on digital technologies to enable, support, and enhance high quality health services across the entire province. There is no greater job satisfaction than knowing the work you do is directly related to saving a life or bringing a new one into the world. Although we may not be front facing with patient care, we have a huge role in maintaining and improving IT systems and supporting health care providers and teams throughout Saskatchewan in delivering the best possible care to patients, citizens, and health system users. Programs range from primary care to acute care, and includes laboratories, pharmaceuticals and diagnostics. Additional programs and services that support patient care and information include Virtual Care, MySaskHealthRecord, the Provincial Electronic Health Record, Health Registries (eligibility for health services/distribution of health cards) and vital event records.

Our vision is “Connected healthcare, accessible to everyone, everywhere” with a mission to “Collaborate to transform healthcare through the use of information and innovative technology”. It is a complex environment, constantly evolving and quick to change as we live our values of excellence, integrity, teamwork, courage, resilience and collaboration.

About the Role:

Reporting to the Director, Operational Support Services, the Manager, IT Service Management (ITSM) will oversee day-to-day service management, operational support, quality and standards, and recruitment for Operational Support Services. This includes leading the development of an ITIL Centre of Excellence and maintaining and communicating ITIL processes and standards. This role is responsible for ensuring high-quality IT service management across multiple teams, with a focus on service excellence, ITIL standards, and customer experience.

The individual is part of a management team who collaboratively manages the first point of contact and customer support for critical applications within the Saskatchewan health sector and for MySaskHealthRecord services for Saskatchewan citizens. This position will facilitate communication among health sector stakeholders, including executive management, end users and the public as required, while working collaboratively with technical experts and vendors. With patients and the public at the forefront, the Manager will ensure that eHealth’s programs, technology, and tools remain a top priority and functional for those who need them most.

Key Responsibilities

Manage the requirements, tracking, maintenance, and continual improvement of ITSM tools, ensuring alignment with organizational objectives.
Lead decommissioning tasks of legacy ITSM applications, and work with technical teams to ensuring smooth transition to modern solutions.
Oversee Service Desk standards, ensuring the highest level of customer experience and service delivery.
Develop and lead an ITIL Centre of Excellence, establishing and ensuring ITIL best practices and continuous service improvement.
Lead ITIL process adoption and improvement initiatives in alignment with the organization’s ITSM transformation strategy.
Establish, implement, and communicate quality assurance frameworks, ITIL processes, and governance structures across all teams.
Drive the standardization and optimization of ITSM processes across Service Desk, Knowledge Management, and the IT Operations Centre (ITOC).
Work collaboratively with healthcare stakeholders, end users, and technical experts to ensure seamless IT service management and manage escalations, confidential IT requests, audits and reviews.
Enhance ServiceNow capabilities, leveraging its full potential for automation, reporting, and service improvement.
Establish and monitor service quality metrics, SLAs, and KPIs to ensure performance targets are met.
Advocate and work collaboratively on ITSM process improvements by partnering with IT leadership and business stakeholders.

The ideal candidate will be a resilient leader who demonstrates:

Progressive experience in linking strategy and operations, IT polices, framework and practices;
Superior communication, problem-solving, accountability, systems management skills, and a solid track record in initiating and supporting collaborative work and innovation solutions;
Knowledge of public sector budgeting, forecasting, accountability, and decision-making processes;
Understanding how to advance the strategic and corporate work of the organization and the goals of government overall;
Change agent with a proven track record in leading dynamic and diverse teams through provincial wide changes and times of uncertainty;
Ability to navigate and build strong relationships in a large, complex multi-enterprise environment;
Extensive leadership experience that enables you to lead, direct and manage a team of professionals;
Ability to think critically and view issues and challenges from multiple perspectives; and,
Reputation for integrity and a focus on service excellence.

Experience & Qualifications:

Demonstrated experience managing ITSM tool requirements, tracking, maintenance, development, and continuous improvement tasks and initiatives.
Proven ability to manage decommissioning tasks for legacy ITSM applications.
At least five (5) years of experience in IT services field.
Knowledge of ITIL principles, processes, and frameworks.
Advanced computer skills and knowledge of systems and applications, such as ServiceNow administrator functions, Active Directory and account management systems, and interdependencies of accounts.
Advanced computer skills in Microsoft Office Suite (Word, Excel, PowerPoint, etc.)
Strong leadership skills, writing and presentational skills.

The successful applicant will have a mix of a strategic mindset, relatable educational and/or experienced background in IT Services and knowledge of service level agreements, queue management, and continuous improvement. They will need to be able to paint the strategic picture for those around them, while understanding the operational nuances that drive the business. Curiosity, innovation, and the ability to learn new subjects and apply them into practice, will also be critical.

We offer:

Dynamic work environment with opportunities to create and build;
A competitive salary;
A physical wellness flex benefit program;
A comprehensive benefits package, including pension; and
Paid vacation, scheduled days off and other types of leaves. (maternity/paternity/adoption/family/personal leave, sick leave)

If this role sounds like the opportunity you have been looking for to challenge yourself, make a difference in people’s lives, and display your abilities – we would love to hear from you.

Employment Type

Permanent Full-time

Location(s)

SK

Salary Range

$48.255 - $61.691

We are committed to workplace diversity.

Number of Openings

1

Mar 18, 2025, 11:59:00 PM","{""role_summary"":""Manage IT service management, operational support, quality, and standards, ensuring high-quality IT service management across multiple teams, focusing on service excellence, ITIL standards, and customer experience."",""key_terms"":[{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a set of best practices for IT service management.""},{""term"":""ITSM"",""explanation"":""IT Service Management, a set of policies, processes, and procedures for managing IT services.""},{""term"":""ServiceNow"",""explanation"":""A cloud-based IT service management platform for automating and managing IT services.""}],""skill_priorities"":{""must_have"":[""ITIL principles, processes, and frameworks"",""Advanced computer skills in Microsoft Office Suite"",""Strong leadership skills, writing, and presentational skills""],""nice_to_have"":[""Knowledge of public sector budgeting, forecasting, accountability, and decision-making processes"",""Ability to think critically and view issues and challenges from multiple perspectives""]},""proposed_screening_questions_with_answers"":[{""question"":""What experience do you have with ITSM tool requirements, tracking, maintenance, development, and continuous improvement tasks and initiatives?"",""example_answer"":""I have managed ITSM tool requirements, tracking, maintenance, development, and continuous improvement tasks and initiatives in my previous role.""},{""question"":""How do you ensure high-quality IT service management across multiple teams?"",""example_answer"":""I ensure high-quality IT service management by focusing on service excellence, ITIL standards, and customer experience, and by leading the development of an ITIL Centre of Excellence.""}],""red_flags"":[""Lack of experience in managing ITSM tool requirements, tracking, maintenance, development, and continuous improvement tasks and initiatives"",""Inability to think critically and view issues and challenges from multiple perspectives""],""confidence_score"":90.0}"
"Senior Manager, IT Operations and Improvements",Metergy Solutions,"Markham, Ontario, Canada",March,2025,"About Metergy Solutions Inc. (“Metergy”)
As one of North America’s most experienced submetering providers, Metergy Solutions has brought turnkey solutions to clients for over 20 years. Metergy supplies, installs and remotely reads meters to measure individual suite consumption of electricity, water, gas, and thermal energy in multifamily and commercial buildings, and bills and collects the utility consumption.

Our innovative Submetering as a Service (SaaS) model generates long-term recurring revenue and has been proven to reduce in-suite energy consumption by an impressive 40%, significantly advancing our clients' decarbonization efforts. This outstanding performance has enabled Metergy to issue green bonds and secure green financing, fueling our sustained growth and creating extraordinary career opportunities for our team.

As the #1 submeter provider in the New York and Canadian markets, and one of the largest in North America, Metergy boasts over 850,000 contracted meters, issues more than 2 million utility invoices annually, and employs over 400 dedicated team members. Our successful acquisitions have consistently exceeded expectations, unlocking immense growth potential.

Metergy is proudly a portfolio company of Brookfield Infrastructure Partners, one of the world’s largest investors, owners, and operators of infrastructure assets across the utilities, transport, energy, data, and sustainable resources sectors. This partnership provides Metergy with access to substantial capital, infrastructure investment expertise, and a global reach, positioning us for continued success and innovation

Our Mission

Provide building owners and occupants with accurate and reliable utility consumption data through market-leading expertise in turnkey submetering and billing, while fostering a workplace with inspired team members empowered to do more good.

Role Overview
Are you passionate about driving IT excellence and continuous improvement? Do you thrive on analyzing metrics and leading impactful initiatives? Is your IT career pushing you to become a leader? If so, we have an exciting opportunity for you! As the Manager, IT Operations and Improvements at Metergy Solutions, you will play a pivotal role in optimizing our IT operations, ensuring robust reporting, and spearheading improvement projects that drive efficiency and innovation.

Responsibilities

Lead IT Improvement Initiatives: Identify areas for improvement within IT operations, develop strategic plans, and lead initiatives to enhance efficiency, reduce costs, and improve service delivery
Drive Process Optimization: Analyze existing IT processes, identify bottlenecks, and implement best practices to streamline workflows and improve overall performance
Develop and Implement IT Metrics Reporting: Design and maintain comprehensive IT metrics dashboards to track performance, identify trends, and support data-driven decision-making
Financial Analysis and Cost Management: Conduct financial analysis to ensure cost-effective IT operations, manage budgets, and optimize resource allocation
AI and Automation Opportunities: Explore and implement AI and automation solutions to enhance IT operations and drive innovation
Collaboration and Communication: Foster strong collaboration with other departments, ensuring IT initiatives align with business goals and support overall organizational success
Team Development and Leadership: Mentor and develop IT staff, fostering a culture of continuous learning and improvement
Lead the Development of Delivery Models: Spearhead the creation and implementation of IT delivery models based on ITIL, MOE, and DevOps best practices, ensuring they are fit for purpose and aligned with organizational goals
Intranet Ownership and Management: Oversee the management and continuous improvement of the company's intranet, ensuring it meets organizational needs and enhances internal communication



Qualifications

Bachelor's degree in Computer Science, Computer/Electrical Engineering, Information Technology, or a related field
Proven experience in IT operations, process improvements, and financial analysis
Strong knowledge of ITIL, MOE, and DevOps best practices
Excellent analytical and reporting skills
Experience with AI technologies and their application in IT operations
Strong project management and leadership skills
Excellent communication and collaboration abilities
Ability to manage multiple priorities and work effectively in a fast-paced environment



Metergy’s recruitment process includes accommodation for applicants with disabilities. All accommodations will consider the applicant’s accessibility needs due to disability and are available upon request.","{""role_summary"":""The Manager, IT Operations and Improvements will lead IT operations, drive process optimization, and develop and implement IT metrics reporting to enhance efficiency and innovation."",""key_terms"":[{""term"":""ITIL"",""explanation"":""A set of best practices for IT service management that focuses on aligning IT services with business needs.""},{""term"":""MOE"",""explanation"":""A framework for managing and operating IT services, focusing on efficiency, effectiveness, and excellence.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and speed up the release of new features.""},{""term"":""AI"",""explanation"":""Artificial intelligence, which is used to automate and enhance IT operations in this role.""}],""skill_priorities"":{""must_have"":[""Proven experience in IT operations"",""Strong knowledge of ITIL, MOE, and DevOps best practices"",""Excellent analytical and reporting skills"",""Strong project management and leadership skills""],""nice_to_have"":[""Experience with AI technologies and their application in IT operations""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you optimized IT processes to improve efficiency and what steps you took?"",""example_answer"":""I analyzed the current process, identified bottlenecks, and implemented automation using DevOps best practices, resulting in a 30% reduction in processing time.""},{""question"":""How do you stay current with the latest developments in IT operations and process improvements?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and read relevant publications to stay informed about best practices and new technologies.""}],""red_flags"":[""Lack of experience with ITIL, MOE, or DevOps best practices"",""Inability to manage multiple priorities in a fast-paced environment""],""confidence_score"":90.0}"
"Manager, IT Service Management",Akkodis,"Toronto, Ontario, Canada",March,2025,"Manager, IT Service Management

The Opportunity
We are embarking on an important and exciting journey to transform our IT Service Management practices to support the growing services delivered by us that benefit millions of Canadians each day!

As IT Service Management leader, you will oversee executing the IT Service Management roadmap and for leading the daily operations and execution of all processes within the ITSM program.

Location: You will be based in our Toronto office and will work in a hybrid model.

Reporting Relationship: You will report to Director, Production Support and Service Management.
What you'll do
Lead IT service management teams responsible for the daily operations for our IT Service Management processes including incident management, major incident management, problem management, change management and configuration management.
Manage the IT service management processes for Incident, Major incident, Problem, Change and Configuration management which includes tracking and enforcing any daily process compliance issues with stakeholders.
Support all technology team members on ITSM process and procedural questions and leads training and communication activities.
Take a lead role for the most critical of major incidents, in a 24x7 environment, where senior ITSM leadership is imperative for the successful resolution. Moreover, uses sound judgement and decision-making skills to lead senior technology practitioners and leaders towards the most effective recovery and resolution.
Key contributor to the success of service improvement process by identifying process deficiencies and recommendations for improvement.
Review operational metrics with senior management to drive awareness, support and compliance.
Chairs regular operational meetings with stakeholders to review operational KPI’s, trends and identify improvement opportunities to drive ITSM across the Technology Organization.
Maintain diverse peer group of other ITSM professionals to share ideas and challenges to the benefit of our IT Service Management

Your Career - What you bring
Bachelor’s degree in information technology, system administration, information systems management or similar disciplines. Master’s degree considered an asset.
Minimum 10 years of experience working in developing, administering, or conducting IT service management work processes and managing senior technical resources.
Minimum 3 years' experience managing IT service management teams
Expert and experienced in supporting and administering IT service management responsibilities such as incident, problem and IT change and configuration management.
ITIL V3 or ITIL V4 Intermediate certification, Expert level (considered an asset)
Experience supporting payment systems within a merchant acquiring business (considered an asset)","{""role_summary"":""Oversee the execution of IT Service Management roadmap, leading daily operations, and ensuring process compliance. Provide technical guidance, identify areas for improvement, and drive service excellence."",""key_terms"":[{""term"":""IT Service Management"",""explanation"":""A set of practices that ensure IT services are delivered efficiently and effectively, covering incident, problem, change, and configuration management.""},{""term"":""ITIL"",""explanation"":""A widely adopted framework for IT service management, providing best practices and guidelines for IT service delivery.""}],""skill_priorities"":{""must_have"":[""10+ years of experience in IT service management"",""3+ years of experience managing IT service management teams"",""Expertise in IT service management processes (incident, problem, change, and configuration management)""],""nice_to_have"":[""Master's degree in a related field"",""ITIL V3 or ITIL V4 Intermediate certification"",""Experience supporting payment systems within a merchant acquiring business""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with IT service management processes, including incident, problem, and change management?"",""example_answer"":""I have over 10 years of experience in IT service management, with a focus on process improvement and team leadership.""},{""question"":""How would you approach leading a critical major incident resolution in a 24x7 environment?"",""example_answer"":""I would leverage my experience in IT service management and sound judgment to lead senior technology practitioners towards effective recovery and resolution.""}],""red_flags"":[""Lack of experience in IT service management team leadership"",""Inability to demonstrate expertise in IT service management processes""],""confidence_score"":90.0}"
"Manager, Infrastructure and Cloud Operations",PointClickCare,"Toronto, Ontario, Canada",March,2025,"PointClickCare is a leading North American healthcare technology platform enabling meaningful care collaboration and real‐time patient insights. For over 20 years, the company has been focused on realizing its vision: to help create a world in which providers and plans can confidently deliver frictionless care. Since its inception, PointClickCare has grown exponentially, with over 2,200 employees working to impact millions across North America. Recognized by Forbes as one of the top 100 private cloud companies and acknowledged by Waterstone Human Capital as Canada’s Most Admired Corporate Cultures, PointClickCare leads the way in creating cloud-based healthcare software.

At PointClickCare, we offer a wealth of opportunities and a vibrant culture that empowers our employees. Our dynamic environment is the perfect place to advance your career while engaging in meaningful work alongside incredible colleagues. Here, you’ll discover a space where your talents can thrive, your career can grow, and your work will have a lasting impact on healthcare across North America. We believe that work becomes profoundly fulfilling when driven by a higher purpose.

Join us and be part of a team that is making a real impact.

To learn more about us, check out Life at PointClickCare and connect with us on Glassdoor and LinkedIn.

The Manager, Infrastructure and Cloud Operations develops and maintains the design and integrity of all corporate infrastructure and cloud systems/services. This role requires a people leader with extensive knowledge in Azure cloud technology and financial operations, infrastructure management, and demonstrated experience in team management. This manager will have experience successfully finding ways to improve the quality of IT service delivery, focusing on quality, efficiency, productivity, and agility.

This role oversees delivering operational support for all infrastructure services brokered, and managing internal corporate infrastructure and applications that support the organization’s business processes across the enterprise. As a people leader, the role will be to guide and direct the TSS Infrastructure and Operations group including performance reviews and goal setting. As a skilled and experienced technician and infrastructure specialist, this working manager role will manage incidents and request escalations from other groups at PointClickCare for resolution, documentation, and knowledge transfer (where required).

This role will also coordinate and sustain relationships with OCIO counterpart groups and vendors/partners, assist in contract negotiations, take part in operational and security scorecard reviews and budget monitoring

Key Responsibilities

Supervise, guide and collaborate with a diverse technical team of Architects, Analysts, Administrators, DBA’s, and App Admins to comprehend the needs of the workload, design, develop, evaluate, and deploy cloud services that are efficient, cost-effective, and adaptable for architectural flexibility.
Keep the systems secure by following the best guidelines for security and compliance. Maintain clear and detailed system documentation, including infrastructure setup based on observations and modifications.
Regularly enhance and revise Standard Operating Procedures (SOPs) for all operational processes and ensure that all services related to infrastructure function properly and are always available for business use. Work with and maintain good contacts of external vendors and service providers to make sure incidents and problems are addressed quickly and professionally.
Manage the IT roadmap for short-term goals to align with the current needs of the business and security. Take part in planning, implementing, and overseeing projects and budgets related to infrastructure.
Responsible for providing support for infrastructure services, such as LAN/WAN/WLAN, Windows, VMWare, A/D, and services from external partners, in a large-scale network environment. Manage Azure IaaS/PaaS/MI environments and some Microsoft 365 micro-services as listed in the service catalog.
Other duties as assigned.

Qualifications And Skills

At least 5 years of experience managing infrastructure, with 3 or more years in a leading or supervising position that involves cloud-based solutions.
In-depth understanding of cloud platforms, infrastructure technologies, networking, virtualization, and storage solutions.
Demonstrated skill in examining complex problems, designing solutions, and making decisions based on data to optimize service performance.
Strong ability to communicate and collaborate well with teams and stakeholders from diverse backgrounds and functions.
Effective leadership skills with a history of leading and growing successful teams, promoting a culture of teamwork and creativity.
Bachelor’s degree in information technology or computer science; or equivalent experience.

PointClickCare Benefits & Perks

Benefits starting from Day 1!

Retirement Plan Matching

Flexible Paid Time Off

Wellness Support Programs and Resources

Parental & Caregiver Leaves

Fertility & Adoption Support

Continuous Development Support Program

Employee Assistance Program

Allyship and Inclusion Communities

Employee Recognition … and more!

It is the policy of PointClickCare to ensure equal employment opportunity without discrimination or harassment on the basis of race, religion, national origin, status, age, sex, sexual orientation, gender identity or expression, marital or domestic/civil partnership status, disability, veteran status, genetic information, or any other basis protected by law. PointClickCare welcomes and encourages applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process. Please contact recruitment@pointclickcare.com should you require any accommodations.

When you apply for a position, your information is processed and stored with Lever, in accordance with Lever’s Privacy Policy. We use this information to evaluate your candidacy for the posted position. We also store this information, and may use it in relation to future positions to which you apply, or which we believe may be relevant to you given your background. When we have no ongoing legitimate business need to process your information, we will either delete or anonymize it. If you have any questions about how PointClickCare uses or processes your information, or if you would like to ask to access, correct, or delete your information, please contact PointClickCare’s human resources team: recruitment@pointclickcare.com

PointClickCare is committed to Information Security. By applying to this position, if hired, you commit to following our information security policies and procedures and making every effort to secure confidential and/or sensitive information.","{""role_summary"":""The Manager, Infrastructure and Cloud Operations is responsible for developing and maintaining the design and integrity of all corporate infrastructure and cloud systems/services, overseeing operational support, and managing internal corporate infrastructure and applications."",""key_terms"":[{""term"":""Azure cloud technology"",""explanation"":""A cloud computing platform used for infrastructure management and financial operations.""},{""term"":""Infrastructure management"",""explanation"":""The process of maintaining and overseeing the design and integrity of corporate infrastructure and cloud systems.""},{""term"":""Financial operations"",""explanation"":""The management of financial resources and budgeting for infrastructure and cloud services.""}],""skill_priorities"":{""must_have"":[""Extensive knowledge in Azure cloud technology"",""Experience in team management and leadership"",""Infrastructure management and financial operations skills"",""Bachelor's degree in information technology or computer science""],""nice_to_have"":[""Experience in contract negotiations"",""Familiarity with operational and security scorecard reviews""]},""proposed_screening_questions_with_answers"":[{""question"":""What experience do you have with Azure cloud technology, and how have you utilized it in previous roles?"",""example_answer"":""I have 5 years of experience working on Azure cloud technology, and in my previous role, I successfully implemented a cloud-based solution that improved efficiency by 30%.""},{""question"":""Can you describe your experience with infrastructure management and financial operations?"",""example_answer"":""I have 3 years of experience managing teams and overseeing infrastructure projects, and I have a strong understanding of financial operations and budgeting for infrastructure and cloud services.""}],""red_flags"":[""Lack of experience with Azure cloud technology"",""Inability to demonstrate leadership and team management skills""],""confidence_score"":90.0}"
Information Technology Service Management Specialist,LeverageTek Staffing Solutions,Greater Ottawa Metropolitan Area,March,2025,"LeverageTek is actively seeking an ITSM Specialist for a 4-month contract with it’s Ottawa based customer.


Work Location
Hybrid – 3/days week onsite at Ottawa HQ


Key Tasks
• Responsible for leading and driving best practices, innovation, and efficiency within the clients IT Service Delivery environment.
• This role requires deep expertise in ITIL frameworks, ITSM tools, and service strategy to enhance IT operations and ensure alignment with business goals.
• Provide expert guidance on ITSM best practices, processes, and frameworks (e.g., ITIL, COBIT, ISO 20000).
• Lead ITSM strategy development and implementation to optimize service delivery.
• Assess current ITSM capabilities and recommend improvements in processes, automation, and tools.
• Support the selection, configuration, and optimization of a new ITSM platform.
• Develop and refine incident, problem, change, and service request management processes.
• Define key performance indicators (KPIs) and service level agreements (SLAs) to measure and improve service performance.
• Collaborate with cross-functional teams, including IT operations, security, and development, to ensure seamless service integration.
• Provide training and mentorship to IT teams to enhance ITSM capabilities and adoption.
• Stay up to date with industry trends, emerging technologies, and ITSM advancements.


Key Qualifications
• Minimum 3-5+ years of experience in ITSM consulting, advisory roles, or IT operations management.
• Hands-on experience with ITSM tools like ServiceNow, BMC Remedy, Cherwell, Zendesk, ServicePRO etc.
• Experience providing advisory/strategic support and guidance within ITSM environments where the organization is considering consolidating from multiple ITSM tools to one common ITSM platform.


Other Qualifications
• Experience participating in and contributing to the Procurement process for new ITSM software.
• ITIL Certification.
• Additional certifications such as COBIT, ISO 20000, PMP, or Agile methodologies.


Assets
• Experience in cloud-based ITSM implementations.
• Knowledge of enterprise architecture frameworks and IT governance.
• Experience in implementing automation and AI-driven ITSM solutions is a plus.
• Hands-on knowledge and experience with Zendesk and ServicePRO ITSM software.


About LeverageTek Staffing Solutions
Founded in 2003, LeverageTek provides end-to-end, cross-functional staffing solutions throughout North America. We are a trusted partner to leading private and public sector organizations and experts in talent solutions that create optimal business outcomes.
Don’t let our name fool you. Our roots are in technology, but we are also a proven leader in accounting and finance, sales and marketing, human resources, supply chain, and legal talent acquisition. We offer contract and permanent staffing, executive search, talent mapping, management consultancy, and contractor payroll management.

LeverageTek is an equal opportunity employer. We offer a welcoming and inclusive environment in service to one another, our customers, the candidates we represent, and the diverse communities we call home. We do all of this with kindness, empathy, and respect for each other. LeverageTek is committed to employment equity and creating a diverse and inclusive workplace. We welcome applications from all qualified individuals regardless of race, religion, gender, national origin, age, disability, and marital status.
Accessibility accommodations are available upon request","{""role_summary"":""Lead and drive best practices, innovation, and efficiency within the client's IT Service Delivery environment, ensuring alignment with business goals."",""key_terms"":[{""term"":""ITIL"",""explanation"":""A framework for IT service management that provides best practices for delivering IT services.""},{""term"":""ITSM"",""explanation"":""IT Service Management, a set of policies, procedures, and processes for managing IT services.""},{""term"":""COBIT"",""explanation"":""A framework for IT governance and management that provides best practices for IT control and assurance.""},{""term"":""ISO 20000"",""explanation"":""An international standard for IT service management that provides guidelines for IT service providers.""}],""skill_priorities"":{""must_have"":[""ITIL frameworks"",""ITSM tools"",""service strategy"",""ITSM consulting"",""IT operations management""],""nice_to_have"":[""COBIT"",""ISO 20000"",""PMP"",""Agile methodologies"",""cloud-based ITSM implementations"",""enterprise architecture frameworks"",""IT governance"",""automation and AI-driven ITSM solutions""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with ITSM strategy development and implementation?"",""example_answer"":""I have led ITSM strategy development and implementation projects, resulting in improved service delivery and alignment with business goals.""},{""question"":""How do you stay up to date with industry trends and emerging technologies?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and read relevant publications to stay current with industry trends and emerging technologies.""}],""red_flags"":[""Lack of experience with ITSM tools like ServiceNow, BMC Remedy, Cherwell, Zendesk, ServicePRO."",""No experience providing advisory/strategic support and guidance within ITSM environments.""],""confidence_score"":90.0}"
Information Technology Infrastructure Manager,Keilhauer,"Scarborough, Ontario, Canada",March,2025,"Job Title: IT Infrastructure Manager

Note: This position was previously posted but was placed on hold due to business priorities. We are now actively hiring and encourage previous applicants to reapply.

Starting Salary Range: $90k - $115k (based on experience)

About the Company: Keilhauer

Founded in 1981, Keilhauer is a privately owned, design-focused contract furniture manufacturer. The company produces seating and tables that enhance communication and engagement in various spaces such as meeting rooms, collaboration areas, lobbies, and lunchrooms. Keilhauer is internationally recognized for award-winning design and high environmental standards.

About the Role: We are seeking a proactive and hands-on IT Infrastructure Manager to lead our infrastructure and support team. This role is crucial in ensuring the stability, security, and scalability of our IT systems while overseeing help desk operations. The IT Infrastructure Manager will work closely with the Head of Technology to develop and implement infrastructure strategies, manage a team of skilled professionals, and maintain high availability of systems. The role also includes overseeing IT projects, managing vendor relationships, and ensuring financial accountability within the department. This position requires flexibility to be available during off-hours for system maintenance and emergency support.

Primary Responsibilities:

Business Continuity & Critical Systems

Ensure the availability, performance, and security of business-critical systems (Syteline, Windchill, SQL, O365).
Develop and maintain backup, disaster recovery, and incident response plans (Veeam, Commvault).
Oversee help desk operations, ensuring timely issue resolution and continuous improvement of support processes.
Monitor and refine ticketing system performance to enhance user satisfaction.
Maintain an on-call rotation for critical system support.

Strategic Technology Leadership & Innovation

Assess emerging technologies, industry solutions, and vendor offerings to enhance infrastructure, security, and business operations.
Proactively recommend tools, platforms, and automation strategies to optimize efficiency.
Lead IT infrastructure projects, ensuring they align with business goals, are delivered on time, and within budget.
Provide insights to leadership on infrastructure performance, trends, and investment opportunities.
Manage software licensing and vendor compliance, ensuring adherence to EULA requirements.

Infrastructure Management & Security

Design, implement, and maintain IT infrastructure, including servers, storage, networking, and cloud services.
Optimize system performance and reliability through proactive monitoring and automation.
Lead network security, ensuring protection from internal/external threats, including firewall (FortiGate, Cisco) and security best practices.
Regularly assess vulnerabilities and implement risk mitigation strategies.
Ensure wired/wireless networks and converged infrastructure are secure and scalable.

Team Leadership & Growth Mindset

Manage a team of three, setting expectations, mentoring, and conducting performance reviews.
Foster a culture of continuous learning, innovation, and personal development.
Encourage a proactive mindset, empowering the team to suggest and implement improvements.
Lead by example, providing hands-on support when necessary while developing the team’s technical capabilities.

Qualifications:

2+ years of experience as an IT specialist or in a similar leadership role.
Post-secondary degree or diploma.
PMP certification or equivalent project management experience.
Advanced technical knowledge in server infrastructure, networks, scripting/automation, and cloud systems.
Proven experience with disaster recovery, backup solutions, and incident response.
Familiarity with ERP systems, product lifecycle management tools, and databases.
Certifications such as ITIL, CISSP, or other relevant credentials preferred.
Excellent interpersonal and communication skills in both written and spoken English.
Valid driver’s license, own vehicle, and valid insurance.


Working Conditions: This role is primarily performed in an office environment, with some functions conducted in manufacturing facilities. The position requires frequent interaction through face-to-face contact, email, and phone communications. The candidate must be available during off-hours for urgent system maintenance, upgrades, and incident response.


How to Apply: If this role sounds like a fit for you, please send your resume to careers@keilhauer.com and tell us why you would be a great addition to our team! Please note that only those selected for further consideration will be contacted.","{""role_summary"":""The IT Infrastructure Manager leads the infrastructure and support team, ensuring the stability, security, and scalability of IT systems, overseeing help desk operations, and maintaining high availability of systems."",""key_terms"":[{""term"":""Syteline"",""explanation"":""An enterprise resource planning (ERP) system used for managing business operations.""},{""term"":""Windchill"",""explanation"":""A product lifecycle management (PLM) tool used for managing product data and processes.""},{""term"":""Veeam"",""explanation"":""A backup and disaster recovery software used for ensuring business continuity.""},{""term"":""Commvault"",""explanation"":""A data protection and information management software used for backup and disaster recovery.""},{""term"":""FortiGate"",""explanation"":""A network security system used for protecting against internal and external threats.""},{""term"":""CISSP"",""explanation"":""A certification for information security professionals, demonstrating expertise in security best practices.""}],""skill_priorities"":{""must_have"":[""2+ years of experience as an IT specialist or in a similar leadership role"",""Advanced technical knowledge in server infrastructure, networks, scripting/automation, and cloud systems"",""Proven experience with disaster recovery, backup solutions, and incident response"",""Excellent interpersonal and communication skills in both written and spoken English""],""nice_to_have"":[""PMP certification or equivalent project management experience"",""Certifications such as ITIL, CISSP, or other relevant credentials"",""Familiarity with ERP systems, product lifecycle management tools, and databases""]},""proposed_screening_questions_with_answers"":[{""question"":""What strategies would you implement to ensure the availability, performance, and security of business-critical systems?"",""example_answer"":""I would develop and maintain backup, disaster recovery, and incident response plans, and oversee help desk operations to ensure timely issue resolution.""},{""question"":""How would you assess emerging technologies to enhance infrastructure, security, and business operations?"",""example_answer"":""I would research industry solutions, assess vendor offerings, and proactively recommend tools and platforms to optimize efficiency.""}],""red_flags"":[""Lack of experience in a similar leadership role"",""Inability to work during off-hours for system maintenance and emergency support""],""confidence_score"":90.0}"
Information Technology Administrator,Applus+ Laboratories,"Toronto, Ontario, Canada",March,2025,"NATURE OF WORK

Provide technical and administrative support for LAN, using Windows and a variety of application software. Maintain adequate knowledge of existing hardware and software in use to maximize efficiency of the network and users' utilization of them. Uses knowledge of operating system and application software to provide high levels of support to users. Assist in server and infrastructure upgrades and expansions.

REPORTING STRUCTURE

The position reports to the Director of IT North America.

EXAMPLES OF WORK

Listed examples are illustrative and representative of the tasks required for this position, and are not intended to be complete or exclusive.

Perform general network maintenance on LAN relating to users, contexts, and network devices.
Monitor cables and ensure reliable connectivity to the network.
Assist with network troubleshooting and maintaining data integrity.
Assist in providing computer/network support relating to software and hardware problems reported by users.
Assist with on-boarding and off-boarding users and sites.
Assist with maintenance of multiple systems and databases.
Assist with developing SQL/Crystal Reports for manager’s staff.
Monitor and evaluate efficiency of software/hardware usage, providing items to be covered in training of users, making them more efficient.
Install new software applications or hardware on the LAN, coordinating assistance from third parties when necessary.
Add and maintain users on the network; assigning application access, ensuring security, and maintaining their configurations are within standards.
Assist in installation of workstations and printers on the LAN.
Participate in team meetings, providing input and suggestions, and prepare minutes of discussion items when necessary.
Assist in gathering bid prices on equipment and supplies as needed.
Provide written document on a monthly basis which defines upcoming needs of network which would require purchase of additional hardware or software.
Monitor and report licenses on applications to ensure compliance on a monthly basis.
Other duties may be assigned.

REQUIRED QUALIFICATIONS

General understanding of the company business. Ability to build and maintain professional employee relations. Excellent oral/written communication skills. Knowledge of MS Office, Windows operating systems, Active Directory, PowerShell, Crystal Reports. Excellent phone etiquette. Able to multi-task. Employee service driven, teamwork and detail orientated, professional, upbeat, energetic, takes initiative, dependable, takes pride in work.
To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Bachelor's degree in computer science, information technology or a related field as well as at least 3+ years of experience in networking or equivalent

PHYSICAL REQUIREMENTS

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The employee is regularly required to stand, walk, sit, talk, listen and hear. The employee is occasionally required to reach with hands and arms, lift, and stoop, kneel or crouch. The employee must occasionally lift, carry and/or move up to 20 pounds.

Specific vision abilities required by this job include close vision, peripheral vision, depth perception, and ability to adjust focus.

Mental Requirements: Ability to read and interpret documents such as safety rules, operating and maintenance instructions, and procedure manuals. Ability to write routine reports and correspondence. Ability to speak effectively before groups of customers or employees of organization. Ability to add, subtract, multiply, and divide in all units of measure, using whole numbers, common fractions, and decimals.

Ability to compute rate, ratio, and percent and to draw and interpret bar graphs. Ability to apply common sense understanding to carry out instructions furnished in written, oral, or diagram form. Ability to deal with problems involving several concrete variables in standardized
situations.","{""role_summary"":""Provide technical and administrative support for LAN, ensuring efficient network and user utilization, and assist in server and infrastructure upgrades and expansions."",""key_terms"":[{""term"":""LAN"",""explanation"":""Local Area Network, a computer network that connects devices in a limited geographical area.""},{""term"":""Active Directory"",""explanation"":""A directory service developed by Microsoft that stores information about objects on a network.""},{""term"":""PowerShell"",""explanation"":""A task automation and configuration management framework from Microsoft, consisting of a command-line shell and scripting language built on .NET.""},{""term"":""Crystal Reports"",""explanation"":""A business intelligence application used to design and generate reports from a wide range of data sources.""}],""skill_priorities"":{""must_have"":[""MS Office"",""Windows operating systems"",""Active Directory"",""PowerShell"",""Crystal Reports""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you troubleshoot a network connectivity issue?"",""example_answer"":""I would first check the physical connections, then use tools like ping and tracert to identify the problem, and finally, if necessary, use PowerShell to investigate further.""},{""question"":""Can you explain the importance of maintaining data integrity in a network?"",""example_answer"":""Data integrity is crucial because it directly affects the reliability of the data used by users, and any corruption or loss can have significant consequences.""}],""red_flags"":[""Lack of experience with MS Office and Active Directory"",""Inability to multi-task and prioritize tasks efficiently""],""confidence_score"":90.0}"
IT Manager - Hotel,COREcruitment Ltd,"Vancouver, British Columbia, Canada",March,2025,"Salary: $90,000
Location: Vancouver, BC

A prestigious hotel in Vancouver is seeking a dedicated IT Manager to oversee all aspects of its information technology infrastructure. The ideal candidate will ensure seamless operations, manage system upgrades, and provide technical support to staff and guests. This role offers an opportunity to maintain and enhance the hotel's IT systems, ensuring exceptional service and security. The IT Manager will play a crucial role in customer service, needing to interact directly with guests to resolve technical issues and enhance their overall experience.

Skills and Experience:
• Proven experience managing IT systems within a hotel or hospitality environment
• Strong technical proficiency with various systems
• Excellent problem-solving skills and ability to manage multiple projects simultaneously
• Effective communication and interpersonal skills to communicate technical information to non-technical staff
• Bachelor’s degree in Information Technology, Computer Science, or related field is a plus but not essential
• Capacity to work independently

If you are keen to discuss the details further, please apply today or send your cv to Nastasija
Note that candidates must have the right to live and work in the USA to be considered. Only shortlisted candidates will be contacted.
COREcruitment are experts in recruiting for the service sector. We currently have live roles across the UK, Middle East, Europe, North America, Southeast Asia, Africa and Australia. To view other great opportunities please check out our website at www.corecruitment.com
Follow COREcruitment on your favorite social networks - Facebook, Twitter, LinkedIn and Instagram","{""role_summary"":""Oversee hotel IT infrastructure, ensuring seamless operations, managing system upgrades, and providing technical assistance to staff and guests."",""key_terms"":[{""term"":""IT infrastructure"",""explanation"":""The underlying technology systems and networks that enable hotel operations.""},{""term"":""System upgrades"",""explanation"":""Regular updates to ensure hotel technology remains secure, efficient, and effective.""}],""skill_priorities"":{""must_have"":[""Proven experience managing hotel/hospitality IT systems"",""Strong problem-solving skills"",""Effective communication and interpersonal skills""],""nice_to_have"":[""Bachelor's degree in IT, Computer Science, or related field""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to troubleshoot a technical issue for a non-technical staff member?"",""example_answer"":""In my previous role, I helped a colleague resolve a printer issue by explaining the problem in simple terms and providing a step-by-step solution.""},{""question"":""How do you prioritize multiple IT projects simultaneously?"",""example_answer"":""I use project management software to track progress, set deadlines, and delegate tasks to ensure timely completion.""}],""red_flags"":[""Lack of experience in hotel/hospitality IT management"",""Inability to communicate technical information to non-technical staff""],""confidence_score"":85.0}"
"Director of IT & Digital Transformation - Edmonton or Calgary, AB",MKL BAU,Greater Edmonton Metropolitan Area,March,2025,"Edmonton, Alberta, Canada .

full-time . March 17, 2025

Description

Director of IT & Digital Transformation (Player-Coach Role)

Reports To: President

About Inline

Inline is a Civil Engineering Field Services firm. With a team of 250+ team members across various departments (Finance, Operations, HR, Sales) and significant field-to-office operations, we are on a journey to modernize and automate our processes using the Microsoft 365 platform and other leading technologies. We’re looking for a hands-on Director of IT & Digital Transformation who can set the strategic technology vision while actively driving day-to-day execution.

Position Overview

As the Director of IT & Digital Transformation at Inline, you will wear multiple hats: you’ll work strategically to align IT initiatives with the company’s long-term goals, but you’ll also be hands-on-rolling up your sleeves to build solutions, troubleshoot issues, and mentor your small IT team (currently one direct report). This is a player-coach role, ideal for someone who loves leading digital transformation but isn’t afraid to dive into technical details.

Core Responsibilities

Strategic Planning & Vision

Develop and execute a multi-year IT roadmap, ensuring alignment with Inline’s growth objectives.
Evaluate emerging technologies (e.g., advanced field data capture tools, AI, IoT) for potential business value.

Hands-On Microsoft 365 & Power Platform Development

Oversee (and, when needed, personally handle) the configuration and administration of Microsoft 365, including SharePoint, Teams, OneDrive, and license management.
Lead the design and implementation of Power Apps, Power Automate (Flow), and Power BI solutions that streamline field-to-office data flows and enhance productivity.

IT Operations & Support

Directly manage day-to-day IT operations, ensuring minimal downtime and prompt resolution of technical issues.
Oversee hardware and software updates, manage user accounts, and maintain system security across the organization.
When necessary, provide hands-on support to fill gaps and address urgent technical needs.

Cybersecurity & Compliance

Develop and enforce company-wide security policies, best practices, and data protection standards.
Conduct regular risk assessments and collaborate with external security partners (if needed) for specialized tasks (e.g., penetration testing).

Team Leadership & Development

Serve as a mentor and coach for your direct report(s), providing guidance on technical tasks, professional growth, and cross-functional collaboration.
Cultivate a learning culture: encourage continuous improvement and upskilling to keep pace with evolving technologies.

Business Analysis & Cross-Functional Collaboration

Partner with key stakeholders in Finance, HR, Sales, and Field Ops to understand process pain points and propose technology solutions.
Lead or support software evaluations, vendor negotiations, and implementation projects, ensuring alignment with business objectives.

Budget & Vendor Management

Own the IT budget, forecast technology expenses, and ensure ROI on major initiatives.
Manage relationships with key vendors and service providers, holding them accountable for deliverables and service quality.

Change Management & Adoption

Develop clear communication plans, training programs, and stakeholder engagement strategies for all IT initiatives.
Champion user adoption, ensuring that new tools and processes deliver measurable productivity gains.

Metrics & Continuous Improvement

Track and report on key performance indicators (KPIs), such as system uptime, support ticket resolution, and user adoption rates.
Use data and user feedback to refine processes, optimize workflows, and prioritize future projects.

What Success Looks Like

Immediate Impact: You seamlessly blend strategic oversight with day-to-day operations. Team members see you as both a leader and a reliable go-to resource for solving complex tech challenges.

Mid-Term (6–12 Months): Key digital transformation projects (e.g., new Power Apps for field data collection, improved SharePoint-based intranet) are successfully implemented, and end-users embrace the new tools.

Long-Term: Inline has a robust, secure, and scalable IT environment that supports growth, efficiency, and innovation; your team expands responsibly as the company’s needs evolve.

Ideal Candidate Profile

Experience

7+ years in IT leadership or management roles (Manager, Senior Manager, or Director) within mid-sized organizations.
Proven track record in player-coach positions where you’ve successfully balanced strategic responsibilities with hands-on tasks.

Technical Proficiency

Expertise in Microsoft 365 administration (SharePoint, Teams, Power Platform).
Familiarity with IT security best practices, network fundamentals, and data protection.
Comfortable with common business applications (ERP, CRM, HRIS, etc.)—experience with field service solutions is a plus.

Leadership & Communication

Strong ability to mentor and motivate a small team, fostering growth and collaboration.
Excellent interpersonal and stakeholder management skills, able to translate complex technical concepts for non-technical audiences.

Strategic & Hands-On Balance

Demonstrable history of crafting IT strategies aligned with business objectives, while staying connected to the “nuts and bolts” of technology.
Ability to shift between executive-level discussions and rolling up your sleeves for direct problem-solving or development.

Education

Bachelor’s degree in Computer Science, Information Systems, or related field (Master’s or MBA a plus, but not mandatory).
Relevant certifications (e.g., Microsoft certifications, PMP, ITIL) are beneficial.

#INDHP2025","{""role_summary"":""The Director of IT & Digital Transformation is a hands-on leader who sets strategic technology vision, drives day-to-day execution, and mentors a small IT team to modernize and automate processes using Microsoft 365 and other leading technologies."",""key_terms"":[{""term"":""Microsoft 365"",""explanation"":""A suite of cloud-based productivity and collaboration tools, including SharePoint, OneDrive, and Teams.""},{""term"":""Power Platform"",""explanation"":""A low-code development environment for building custom business solutions, including Power Apps, Power Automate (Flow), and Power BI.""},{""term"":""IT roadmap"",""explanation"":""A strategic plan outlining the organization's technology goals, objectives, and timelines for achieving them.""},{""term"":""Player-coach role"",""explanation"":""A leadership position that combines strategic oversight with hands-on technical responsibilities, requiring the ability to both lead and execute.""}],""skill_priorities"":{""must_have"":[""Microsoft 365 administration (SharePoint, Teams, Power Platform)"",""IT security best practices and data protection"",""Leadership and team management experience""],""nice_to_have"":[""Field service solution experience"",""Microsoft certifications, PMP, ITIL"",""Master's or MBA degree""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you developed and executed a multi-year IT roadmap, ensuring alignment with the company's growth strategy?"",""example_answer"":""In my previous role, I created a 3-year IT roadmap that aligned with the company's growth objectives, resulting in a 25% increase in productivity.""},{""question"":""How do you balance strategic oversight with hands-on technical responsibilities in a player-coach role?"",""example_answer"":""I prioritize tasks based on urgency and delegate tasks to my team, while maintaining visibility into day-to-day operations to ensure alignment with strategic objectives.""}],""red_flags"":[""Lack of experience in Microsoft 365 administration"",""Inability to balance strategic oversight with hands-on technical responsibilities"",""Poor leadership and team management experience""],""confidence_score"":95.0}"
"Manager, IT Infrastructure",Bosa Properties,"Vancouver, British Columbia, Canada",March,2025,"About The Company

Bosa Properties Inc. (""BPI"") is an end-to-end real estate company offering human-centered solutions for property development and management. Based out of Vancouver, Canada, our team of in-house experts work across residential, commercial and master-planned projects, with a growing residential portfolio that includes more than 22,000 homes that are built or under development, and an income portfolio that includes 5.5 million square feet of retail, industrial, office and rental properties under management.

We are an organization of high achievers and believe what is created in community is always better than what is created in isolation. We set high expectations and support you in achieving excellence. We are building a trusted community to collaborate, learn from each other and deliver results.

About The Role



Reporting to the Director, IT Operations, the IT Infrastructure Manager is responsible for overseeing infrastructure operations and ensuring the availability and security of services across the organization. The IT Infrastructure Manager is responsible for training, managing, and mentoring a team of specialist and generalist IT professionals and will work closely with other IT leaders to define and prioritize projects to enhance and secure the technologies we rely on every day.

The Manager, IT Infrastructure possesses a combination of advanced technical skills and incredible managerial abilities. They are naturally service oriented, passionate about problem solving, and can motivate a team of hybrid/remote work IT professionals. The Manager, IT Infrastructure, will contribute a deep understanding of the continuously changing IT landscape and is a valued partner in the day-to-day operation of a high performing business.

Supporting a user base of 350 hybrid-work users, the Infrastructure Team is a critical component of the overall support structure within Bosa Properties Inc. This is an excellent opportunity for an IT professional to truly take ownership of the IT Infrastructure function at one of the top property developers in the country.

What You'll Do

Manage the Infrastructure team, evaluate performance, and address performance issues
Recruit, train and support multiple roles (e.g. Network/System Administrator, DevOps Engineer)
Establish, measure, and track KPI's for system health and support escalations
Develop weekly and monthly reports on the team's productivity
Work with business units to understand and provide expected service levels
Manage technology projects start to finish
Act as an escalation contact for incidents and manage the escalation process where required
Monitor ticket queues, assign issues, and identify opportunities for improvements and automation
Work with stakeholders on technology adoption, training, and optimizing technology usage
Create training material and conduct training sessions
Utilize contract/consultant resources for specialized skillsets we do not have internally

What You Bring

You are a customer-centric individual with a keen desire to standardize and automate.  Your experience allows you to respond appropriately to critical incidents, and you thrive in an environment that is evolving how technology is used in the business.  Most notably, you enjoy training and developing others - from your own team to technology champions in each department that you partner with.

Our Must Haves:

Diploma in Computer Information Systems Administration or equivalent work experience
Minimum four (4) years of experience leading a team of 3+ direct reports
Minimum eight (8) years of experience with a minimum of four (4) years of experience in a senior IT operational role
A wide breadth of knowledge in the technology space, with direct experience in a Windows-based, M365, AWS/Azure environment
Experience optimizing escalation workflows, and team schedules for both in and after-hours coverage to meet SLA's and KPI's
Experience collecting business and user requirements, and managing technology implementation projects
Experience with event correlation and root cause analysis for infrastructure services and security incidents
Experience managing training schedules and performance of direct reports
Experience with change management and change control processes
Experience with issue tracking systems (e.g. FreshService, JIRA)
Experience working in agile/scrum environments
Excellent communication & documentation skills

Our salary ranges and bonus percentages are determined by job family and level. Base salary is determined by a combination of factors including, but not limited to, education and training, years of relevant experience, and internal equity.

Salary

$134,067—$184,418 CAD

Who You Are

Trustworthy: You lead with trust when interacting with your team and other departments. You proactively build trust by demonstrating credibility, empathy, and sincerity.
Humble: Unpretentious and self-aware, you take responsibility for your mistakes. You know that egos are barriers to doing our best work and always learning.
Community focused: You believe what is created in community is always better than what is created in isolation and excellence is created through collaboration.

How To Apply

We value your interest in Bosa Properties. While we can only respond to shortlisted applicants, we will keep your information on file and consider you for future opportunities as they come available.

You belong here! If your experience and interests match with some of the above, we want you to apply. We are dedicated to building a diverse community, where everyone belongs.

Accommodations will be provided as requested by candidates taking part in all aspects of the selection process.","{""role_summary"":""The IT Infrastructure Manager oversees infrastructure operations, ensuring service availability and security across the organization, while leading and mentoring a team of IT professionals."",""key_terms"":[{""term"":""M365"",""explanation"":""Microsoft 365, a cloud-based suite of productivity and collaboration tools.""},{""term"":""AWS/Azure"",""explanation"":""Cloud computing platforms provided by Amazon Web Services (AWS) and Microsoft Azure, used for infrastructure and application hosting.""},{""term"":""DevOps Engineer"",""explanation"":""A professional responsible for ensuring the smooth operation of software systems, bridging development and operations teams.""},{""term"":""KPI's"",""explanation"":""Key Performance Indicators, used to measure and track system health and support escalations.""},{""term"":""SLA's"",""explanation"":""Service Level Agreements, outlining the expected service quality and responsiveness for IT services.""},{""term"":""Agile/Scrum"",""explanation"":""Iterative project management methodologies, emphasizing collaboration, flexibility, and continuous improvement.""}],""skill_priorities"":{""must_have"":[""Diploma in Computer Information Systems Administration or equivalent work experience"",""Minimum four (4) years of experience leading a team of 3+ direct reports"",""Minimum eight (8) years of experience with a minimum of four (4) years of experience in a senior IT operational role"",""A wide breadth of knowledge in the technology space, with direct experience in a Windows-based, M365, AWS/Azure environment"",""Experience optimizing escalation workflows, and team schedules for both in and after-hours coverage to meet SLA's and KPI's"",""Experience collecting business and user requirements, and managing technology implementation projects"",""Experience with event correlation and root cause analysis for infrastructure services and security incidents"",""Experience managing training schedules and performance of direct reports"",""Experience with change management and change control processes"",""Experience with issue tracking systems (e.g. FreshService, JIRA)""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with managing a team of IT professionals, including training and mentoring?"",""example_answer"":""I have led teams of up to 10 IT professionals, providing training and mentorship to ensure their growth and success.""},{""question"":""How do you approach problem-solving in a fast-paced IT operations setting?"",""example_answer"":""I prioritize critical incidents, leveraging my technical expertise and experience to respond effectively and efficiently.""},{""question"":""Can you walk me through your experience with technology adoption and training?"",""example_answer"":""I have developed and delivered training programs for IT teams, ensuring successful technology adoption and optimal usage.""}],""red_flags"":[""Lack of experience in a senior IT operational role"",""Inability to manage and prioritize multiple projects simultaneously""],""confidence_score"":95.0}"
IT Help Desk Manager,Fastco Canada,"Vaudreuil-Dorion, Quebec, Canada",March,2025,"Status: Full-time, Permanent Position | Location: Vaudreuil-Dorion, QC

Report To: Director of Information Systems | Service: Information Systems

Overview

Reporting to the Director of Information Systems, the IT Help Desk Manager will oversee the daily operations of our help desk, manage escalations, ensure compliance with service-level agreements (SLAs), and continuously improve processes to enhance end-user support. This role requires a strong leader with a strategic mindset to guide the team, optimize workflows, and implement best practices in IT service management.

In a smaller team environment, this role may also involve hands-on technical work.

Responsibilities

Help Desk Operations & Team Management

Oversee the help desk function, ensuring timely and effective resolution of IT support tickets.
Manage and mentor Help Desk Technicians, providing guidance and professional development opportunities.
Ownership and administration of Fastco’s ITSM platform to streamline ticket management and reporting.
Ensure adequate staffing coverage for IT support during both regular and off-hours using HCM software and other scheduling tools.
Establish and enforce Standard Operating Procedures (SOPs) for help desk workflows, security protocols, and troubleshooting guides.
Analyze ticket data and user feedback to identify areas for service improvement and training opportunities.


IT Service Management & Escalations

Participate in the evaluation of new and existing products/vendors, with the collaboration of the Product Development, Technical Services & Sales departments.
Work with the planning department to identify opportunities to improve forecasting models for better product availability.
Work with Marketing to stay informed of ongoing sales initiatives that could lead to demand peaks and/or stock depletion.
Work with Product Managers and the Master Planner to review the Management forecast on new items.
Provide support in the S&OP cycle.


Security & Compliance

Ensure that all help desk procedures align with company security policies, especially when handling sensitive user data.
Enforce security best practices, including password management, user authentication policies, and access control procedures.
Stay informed about cybersecurity threats and ensure the team follows best practices for data privacy and confidentiality.
Conduct post-incident reviews for major issues and work towards long-term preventative solutions.


Process Improvement & Reporting

Continuously review and refine help desk processes to improve response times, efficiency, and user satisfaction.
Monitor key performance metrics (e.g., ticket resolution time, user satisfaction scores, firstcall resolution rate) and provide reports to senior management.
Provide insights and recommendations for IT budgeting, including technology investments, staff training, and resource allocation.


End-User Support & Training

Ensure end-users receive high-quality technical support and customer service.
Develop user guides, knowledge base articles, and training sessions to empower employees to resolve common IT issues independently.
Gather and analyze user feedback to drive improvements in IT support services.


Required Skills & Qualifications

5+ years of experience in IT support, with at least 2+ years in a leadership or management role.
Strong expertise in IT service management (ITSM) tools like Freshdesk, SeviceNow, or similar platforms.
Experience working in Active Directory, M365, Windows, Linux, and cloud environments.
Hands-on experience in troubleshooting network, hardware, and software issues.
Strong understanding of IT security best practices, compliance standards, and access control policies.
Experience with help desk performance metrics, reporting, and continuous improvement initiatives.
Excellent leadership, strategic planning, and process improvement skills.
Excellent communication and interpersonal skills in French, with a good command of English to facilitate collaboration between teams.
Ability to manage and prioritize multiple tasks, projects, and escalations in a fast-paced environment.


Preferred Qualifications

ITIL certification (or experience with ITIL best practices).
Certifications such as CompTIA, Microsoft, or similar.
Experience with Human Capital Management (HCM) scheduling software or similar workforce management tools.
SAP ByDesign or similar ERP system experience


This position may require minimal travel.","{""role_summary"":""The IT Help Desk Manager oversees daily help desk operations, manages escalations, and ensures service-level agreements are met. They lead the team, optimize workflows, and implement best practices in IT service management."",""key_terms"":[{""term"":""ITSM"",""explanation"":""Information Technology Service Management, a framework for delivering IT services.""},{""term"":""SLAs"",""explanation"":""Service-Level Agreements, which define the expected quality of IT services.""},{""term"":""Fastco's ITSM platform"",""explanation"":""A specific IT service management tool used by the company.""},{""term"":""HCM software"",""explanation"":""Human Capital Management software, used for scheduling and workforce management.""},{""term"":""SOPs"",""explanation"":""Standard Operating Procedures, which outline help desk workflows and security protocols.""},{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a framework for IT service management best practices.""},{""term"":""CompTIA"",""explanation"":""A certification for IT and a provider of IT industry standards.""},{""term"":""SAP ByDesign"",""explanation"":""An Enterprise Resource Planning (ERP) system used for managing business operations.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in IT support"",""Strong expertise in IT service management (ITSM) tools"",""Experience working in Active Directory, M365, Windows, Linux, and cloud environments"",""Strong understanding of IT security best practices, compliance standards, and access control policies"",""Excellent leadership, strategic planning, and process improvement skills"",""Excellent communication and interpersonal skills in French, with a good command of English""],""nice_to_have"":[""ITIL certification (or experience with ITIL best practices)"",""Certifications such as CompTIA, Microsoft, or similar"",""Experience with Human Capital Management (HCM) scheduling software or similar workforce management tools"",""SAP ByDesign or similar ERP system experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach optimizing help desk workflows and improving response times?"",""example_answer"":""I would analyze ticket data, identify bottlenecks, and implement process changes to streamline ticket management and reporting.""},{""question"":""Can you give an example of how you would ensure IT security best practices in a previous role?"",""example_answer"":""I enforced password management policies, ensured user authentication and access control procedures were in place, and conducted regular security audits.""}],""red_flags"":[""Lack of experience in IT service management tools"",""Inability to communicate effectively in French and English"",""No experience in leading a team or managing escalations""],""confidence_score"":90.0}"
"Manager, IT and Facilities",YouthLink,"Toronto, Ontario, Canada",February,2025,"Who we are YouthLink believes in the potential of every youth, and we are dedicated to providing them with the support, guidance and opportunities they need to make positive life choices. We provide youth with brief and ongoing counselling, in-home wraparound support, shelter, housing, educational support, and safe drop-in spaces. Guided by our mission and inspired by the potential to make a profound impact, Youthlink works closely with youth, families and partners in our community. We come together to highlight and develop strengths, aspirations and positive actions that improve the health and well-being of all who live, work, study and play in our community. As a service delivery organization, we leverage data-driven decision-making and grassroots engagement with youth advisory councils to create an inclusive, innovative, and responsive agency that provides the best fit and most needed services for our communities. If you are seeking a meaningful opportunity and want to play a key role in bringing our vision for a stronger Scarborough where all youth and families thrive, join us. (Full-time 35 hours per week) Non-Bargaining Unit Position IT Systems and Operations 45% Plans, manages and evaluates the operations of information systems and electronic devices. With vendors, develops a systems infrastructure plan for networking a wide-area network for the entire agency, ensures UPS back-up, Security monitoring/ cyber security.Develops system requirements, specifications, costs and timelines. Manages Web contractors for the YouthLink Website ensuring updates are added as needed. Ensures technology is accessible and equipped with current hardware and software. Trouble shoots hardware, software and network operating system for Issues. Negotiates the best cost for staff phones, sets them up, trains staff in use of phones, and troubleshoots. On boards staff with fobes, phones, computers, access to buildings. Maintains photocopiers, negotiates contracts with vendors. Hires and manages contractors for system projects regarding network infrastructure, Telecommunications software, and information systems. Provides orientation, training and support to users Supports off-site employees with the use of laptops, email and other forms of online communication. Installs and maintains AV equipment. Facilities 45% Ensures that the buildings meet all health and safety requirements; Ensures compliance with building and safety codes, hazardous waste disposal, handling hazardous materials, fire alarm systems and fire protection equipment. Plans best allocation and utilization of space and resources; investigates availability and suitability of options; evaluates costs for required goods or services to achieve maximum value for money; plans for future development in line with business objectives. Prepares documents to put out to tender for contractors; manages projects and supervises work of contractors; follows up for completion and payment. Manages all contracts for cleaning, landscaping, elevators, HVAC, and electrical. Maintains a key control system for all locations. Budgets and Planning 10% Maintains current and accurate inventory of technologies, facilities, goods, hardware, software and resources. Monitors the help-desk system daily for reported problems with facilities or IT. Assigns priorities to issues reported. Responds to staff and keeps them informed of progress or problem resolution. Provides help desk statistics and reports. In conjunction with the Senior Director of Finance, Administration manages facility and technology budgets and expenditures. Actively contributes to the Agency’s Strategic Plan by participating in initiatives and committees to support the Plan. May be asked to contribute to the development of a funding proposal. Takes all reasonable and necessary precautions to protect his or her own health and safety and that of co-workers by complying and demonstrating knowledge of the policies, procedures and safe practices established by Youthlink. Highlights of What You Bring Education: Undergraduate degree or diploma in Information Technology or a combination of education and experience. Microsoft Certification (MCSE) required. Experience: Five years experience in an IT environment, computer operations, and technical support Five years experience in project management, facilities and maintenance, preparing RFPs and negotiating contracts. Three years of managerial experience. Experience implementing and managing in a Microsoft Windows platform, Virtualization, Clustering technologies, Exchange, personal computer Office Tools, Virus Scanning, Security, Firewalls, SQL databases Experience in cell phones technologies. Proficient knowledge in computer hardware and software systems and programs, network administration and installation, troubleshooting, viruses and security, email and internet programs and protocols. Skills: Demonstrated ability to manage large scale projects in either IT or facilities and manage contractors. Ability to work as a team and understand team building skills. Exceptional analytical and problem solving skills. Decision making skills. Effective verbal, presentation and listening communications skills, and effective written communications skills Ability to work under stress and assign priorities to work Working conditions This position works normal hours but is required to be on-call for emergencies related to the building, security, or equipment, or systems failure. Travelling between agency sites required. Physical Requirements This position has some physical demands, such as lilting, bending and reaching. Working on a computer screen for long periods of time. Join us. YouthLink's core values define what we stand for and how we operate, helping us to work together in the most fulfilling ways. We value leadership , acting in ways that exemplify what we expect of each other and our clients. We work together, bringing out the best in each other and creating strong working relationships. Our professional ethics are evident in all the work we do and the decisions we make. We value humanity and show consideration for people, their abilities, skills, diversity and perspectives. We create an inclusive workplace that celebrates individual differences and, through our actions, demonstrates empathy, goodwill and honesty. We value innovation , demonstrating flexibility and changeability in adapting to our work and community dynamics. We show courage in developing service initiatives that will improve the well-being of our clients and their families. We value respect for people for who they are and for their knowledge, skills and experience as individuals and team members. We treat clients with respect and fairness and encourage the same in return. We value excellence , demonstrating competence and accountability in delivering client services. We display clear judgment and exhibit clear thinking and reasoning in all situations. We continually strive to accomplish all tasks and provide an outstanding service for our clients. Benefits At YouthLink, we understand the nature of our work and the deep commitment every team member offers. We strive to provide a rewarding compensation and benefits package to support our people. This includes: Comprehensive health and dental coverage for you and your family, with 100% of the premiums fully covered. Annual vacation with pay at 1.66 working days for each calendar month to a maximum of 20 working days per year. 5 ‘authorized absence’ days for family illness or emergency circumstances that prohibit employees from reporting to work. 3 paid agency days every calendar year after 3 calendar months service. Maternity / parental /adoption leave top-up payments (to top-up Canadian government unemployment benefit payments). 100% premium cost for long-term disability coverage paid by employee. Eligibility to participate in the pension plan after 2 years of continuous service with a generous matching employer contribution. Apply now. We welcome applications from candidates who reflect the communities we serve, particularly candidates from Black communities, Indigenous communities, racialized people, persons with disabilities, members of diverse gender identities and people with lived experiences. We are seeking candidates who demonstrably operate and practice from an equity and trauma-informed lens.We encourage applications from passionate professionals who will help us dismantle systemic barriers and embrace working outside of Euro-centric practices. If you meet 70% of the qualifications we are looking for and share 100% of our passion and commitment to supporting youth and their families, please submit your application. We can’t promise to hire you; we can promise to review your lived and learned experiences fully. We are committed to providing equitable employment opportunities and a workplace free from discrimination and harassment. We are equally committed to providing an inclusive and accessible workplace. If you require accommodations at any stage of the interview process, please email us at accessibility@youthlink.ca . Powered by JazzHR","{""role_summary"":""The IT Systems and Operations role is responsible for managing and evaluating the operations of information systems, electronic devices, and facilities. The role involves planning, developing, and implementing system requirements, managing web contractors, and providing technical support to staff."",""key_terms"":[{""term"":""Microsoft Certification (MCSE)"",""explanation"":""A certification that demonstrates expertise in Microsoft products and technologies.""},{""term"":""Virtualization, Clustering technologies"",""explanation"":""Technologies that enable multiple virtual machines to run on a single physical machine, improving resource utilization and efficiency.""},{""term"":""SQL databases"",""explanation"":""A type of database management system that uses Structured Query Language (SQL) to manage and manipulate data.""},{""term"":""Firewalls"",""explanation"":""A network security system that monitors and controls incoming and outgoing network traffic based on predetermined security rules.""}],""skill_priorities"":{""must_have"":[""Microsoft Certification (MCSE)"",""Experience in IT environment, computer operations, and technical support"",""Experience in project management, facilities, and maintenance""],""nice_to_have"":[""Experience implementing and managing Microsoft Windows platform"",""Experience with cell phones technologies""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with Microsoft Certification (MCSE)?"",""example_answer"":""I have worked with Microsoft Certification (MCSE) for the past 5 years, and I have successfully implemented and managed Microsoft Windows platforms.""},{""question"":""How do you troubleshoot hardware, software, and network operating system issues?"",""example_answer"":""I use a systematic approach to identify the root cause of the issue, and then I use my knowledge of hardware, software, and network operating systems to resolve the issue.""}],""red_flags"":[""Lack of experience in IT environment, computer operations, and technical support"",""Inability to work under stress and assign priorities to work""],""confidence_score"":90.0}"
"manager, information systems",Holiday Inn Ottawa East,"Ottawa, Ontario, Canada",March,2025,"Overview

Languages

English

Education

Bachelor's degree

Experience

3 years to less than 5 years

On site

Work must be completed at the physical location. There is no option to work remotely.

Work setting

Hotel, motel, resort

Responsibilities

Tasks

Plan and control budget and expenditures
Recruit staff
Supervise staff
Train staff
Establish and implement policies and procedures for information systems
Manage incidents
Plan, organize, direct, control and evaluate daily operations

Additional information

Work conditions and physical capabilities

Fast-paced environment
Work under pressure
Tight deadlines
Attention to detail
Large workload

Personal suitability

Efficient interpersonal skills
Excellent oral communication
Excellent written communication
Flexibility
Initiative
Judgement
Organized
Reliability
Team player
Values and ethics
Proactive

Employment groups

This employer promotes equal employment opportunities for all job applicants, including those self-identifying as a member of these groups:

Support for persons with disabilities

Provides awareness training to employees to create a welcoming work environment for persons with disabilities

Support for newcomers and refugees

Provides diversity and cross-cultural trainings to create a welcoming work environment for newcomers and/or refugees

Support for youths

Provides awareness training to employees to create a welcoming work environment for youth

Support for Veterans

Provides awareness training to employees to create a welcoming work environment for Veterans

Support for Indigenous people

Provides cultural competency training and/or awareness training to all employees to create a welcoming work environment for Indigenous workers

Support for mature workers

Provides staff with awareness training to create a welcoming work environment for mature workers

Supports for visible minorities

Provides diversity and cross-cultural training to create a welcoming work environment for members of visible minorities","{""role_summary"":""Manage daily hotel operations, supervise staff, and implement policies and procedures for information systems."",""key_terms"":[{""term"":""Information systems"",""explanation"":""Computer-based systems that support hotel operations, such as property management systems.""}],""skill_priorities"":{""must_have"":[""Supervisory experience"",""Budgeting skills"",""Excellent communication skills""],""nice_to_have"":[""Experience in the hospitality industry"",""Knowledge of information systems""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you handle a last-minute staff shortage during peak hours?"",""example_answer"":""I would quickly assess the situation, prioritize tasks, and make adjustments to ensure minimal impact on guests.""},{""question"":""Can you give an example of a time when you had to implement a new policy or procedure in a previous role?"",""example_answer"":""In my previous role, I introduced a new customer feedback system, which resulted in a 20% increase in satisfaction.""}],""red_flags"":[""Lack of experience in a fast-paced environment"",""Inability to work under pressure""],""confidence_score"":80.0}"
"Manager, ITSM Process Lead",Akkodis,"Etobicoke, Ontario, Canada",March,2025,"Akkodis is partnered with a leading FinTech who specialize in payment processing to recruit a Manager, ITSM Process Lead to join an IT Service Management team located in Toronto.

In this role, you will be responsible for overseeing a team of 5 direct reports. Outside your people management responsibilities, you'll play a pivotal role in driving ITSM transformation - enhancing processes, implementing improvements, and ensuring ITSM best practices are embedded across the technology environment.

What you'll do:
Lead & Enhance ITSM Processes – Oversee Incident, Major Incident, Problem, and Change Management, ensuring compliance, efficiency, and continuous improvement.
Drive ITSM Transformation – Execute the ITSM roadmap, introduce new tools like CAB Workbench, and implement training programs to support adoption.
Manage a High-Performing Team – Guide and mentor a team of five direct reports, including a Major Incident Manager, fostering best-in-class ITSM capabilities.
Lead High-Stakes Major Incidents – Take command in 24/7 critical situations when needed, making sound decisions under pressure and coordinating with senior technology leaders.
Be the Trusted ITSM Expert – Present regularly to the CTO and SVPs, leveraging industry knowledge to drive strategic ITSM advancements.
Promote Data-Driven Improvement – Analyze key ITSM metrics, identify trends, and spearhead initiatives to enhance overall service quality.

What You Bring
10+ years in IT Service Management (ITSM), with hands-on experience in Incident, Major Incident, Problem, and Change Management
3+ years of leadership experience, managing ITSM teams in enterprise environments
Strong track record of introducing, managing, and optimizing ITSM processes in large, complex organizations
Exceptional communication & stakeholder management skills—confident presenting to executive leadership
Experience with CAB Workbench implementation and ITSM training programs (a plus)
ITIL V3 or V4 Intermediate certification (Expert level is an asset)


If you are interested in learning more or would like to discuss any other ITSM Process & transformation roles, don't hesitate to apply!","{""role_summary"":""Manage a team of ITSM professionals, drive ITSM transformation, and ensure best practices are embedded across the technology environment."",""key_terms"":[{""term"":""ITSM"",""explanation"":""Information Technology Service Management, a framework for delivering high-quality IT services.""},{""term"":""CAB Workbench"",""explanation"":""A tool for managing and implementing ITSM processes.""},{""term"":""Major Incident"",""explanation"":""A critical IT incident that requires immediate attention and resolution.""},{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a framework for IT service management best practices.""}],""skill_priorities"":{""must_have"":[""10+ years in IT Service Management (ITSM)"",""3+ years of leadership experience, managing ITSM teams in enterprise environments"",""Exceptional communication & stakeholder management skills""],""nice_to_have"":[""Experience with CAB Workbench implementation and ITSM training programs"",""ITIL V3 or V4 Intermediate certification""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience in ITSM process transformation?"",""example_answer"":""I led a team to implement new ITSM processes, resulting in a 30% reduction in incident resolution time.""},{""question"":""How do you ensure effective communication with executive leadership?"",""example_answer"":""I prepare regular reports on ITSM metrics and trends, and present them to the CTO and SVPs.""}],""red_flags"":[""Lack of experience in ITSM process transformation"",""Inability to communicate effectively with executive leadership""],""confidence_score"":90.0}"
"Team Lead, End User Computing",Husky Technologies,"Bolton, Ontario, Canada",March,2025,"The Team Lead, End User Computing is accountable for management and operations of all end user devices and peripheral equipment. Responsibilities include design, architecture, sourcing, and management of the end user computing platform, building and maintaining technology standards based on industry best practices, managing a technology roadmap, and proposing/developing new solutions to support the business strategy. The Team Lead, End User Computing will work with the larger IT organization to deliver solutions, serve as a subject matter expert in end user computing technology, manage governance and compliance, and drive the focus to deliver an optimum customer experience.

Identify end user technologies such as desktop workstation hardware, video conferencing technologies, printers and mobile computers which will improve customer satisfaction, reduce cost and improve efficiency.
Architect, design, implement, test and deploy end user technology solutions
Complete research using vendors, interviews and written materials for new and emerging technologies for input into recommendations around potential use within Husky. Research and analysis is also performed in seeking possible solutions for identified issues and problems in major platform changes and functional software deployments.
Work with other team members to develop and test firm images that are used on the majority of our 5,000+ workstation fleet.
Collaborate with Infrastructure, Security and other teams that interface with the end user technology team. Work with Service Desk and regions/offices to provide second level support on hardware and software environments.
Create/test packages and scripts to be distributed through software distribution systems including SCCM and InTune.
Collaborate with vendors and other staff to troubleshoot issues, identify platforms that meet requirements, and ensure regions/offices receive required support and services to provide end users with a stable, consistent platform.
Create and maintain a standards catalog which lists all core end user device platform standards and/or services provided by the End User Computing team.
Assign personnel to various projects, direct their activities, and evaluate their work to ensure timelines and service levels are met
Monitor ongoing staff performance, identify and communicate opportunities for improvement.
Proactively seek and communicate opportunities for improvement in both the operational and customer satisfaction aspects IT
Establish metrics to measure efficient use of existing systems and resources
Promote a professional environment at all times, acting as a point of escalation for staff and internal teams
Manage the lifecycle of all endpoint devices by establishing duty cycles and coordinating ongoing refresh initiatives
Ensure assigned IT support tickets are triaged and resolved within agreed-to SLAs
Other duties assigned.
Requirements
Comprehensive understanding of, but not limited to, PC hardware, meeting room kits, scan guns, printers, mobile devices, software, operating systems, directory services, etc.
Experience with software distribution systems
Experience with device and asset management required
Experience in hardware and software design, installation, configuration, maintenance, and troubleshooting required
Problem solving skills and ability to work under pressure
10+ years of professional IT experience with increasing supervisory experience.","{""role_summary"":""The Team Lead, End User Computing is responsible for managing and operating end user computing platforms, building technology standards, and proposing new solutions to support business strategy."",""key_terms"":[{""term"":""End User Computing"",""explanation"":""Refers to the management and operation of devices and peripheral equipment used by employees.""},{""term"":""Technology Roadmap"",""explanation"":""A plan outlining the development and implementation of technology solutions over time.""},{""term"":""Governance and Compliance"",""explanation"":""Ensuring that technology solutions meet regulatory and organizational standards.""},{""term"":""SCCM and InTune"",""explanation"":""Software distribution systems used to manage and deploy technology solutions.""}],""skill_priorities"":{""must_have"":[""Comprehensive understanding of PC hardware, software, operating systems, directory services, etc."",""Experience with software distribution systems"",""Experience with device and asset management"",""Problem solving skills and ability to work under pressure""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""What experience do you have with end user computing platforms?"",""example_answer"":""I have 10+ years of experience managing and operating end user computing platforms, including designing and implementing technology solutions.""},{""question"":""How do you stay current with emerging technologies and industry best practices?"",""example_answer"":""I regularly research vendors, attend industry conferences, and participate in online forums to stay current with emerging technologies and industry best practices.""}],""red_flags"":[""Lack of experience with software distribution systems"",""Inability to work under pressure""],""confidence_score"":90.0}"
IT Technical Manager,MSP Corp Prairies,"London, Ontario, Canada",February,2025,"Ready to take your career to the next level? Invest in yourself! MSP Corp is a dynamic and evolving organization. Our team is energetic and multidisciplinary, performing at the highest levels.  We thrive on the diversity of our team and believe that any candidate could be the talent to take us to the next level. We drive technology and performance by providing powerful toolsets, business support and professional services. Our team provides complete, turn-key solutions with one goal in mind — to ensure that we can deliver 100% any day, any time.

As we continue to grow, we are seeking a Technical Services Coordinator at MSP Corp to support one of our clients.

About The Role

The Technical Services Coordinator is responsible for managing client-facing IT staff, ensuring efficient handling of escalated technical issues, and maintaining smooth collaboration with both internal and outsourced resources. This role also involves providing leadership, coaching, and development to team members while working closely with the MSP (Managed Service Provider) to support ongoing IT projects and ensure the security and compliance of the organization’s IT infrastructure.

Role title: Technical Services Coordinator
Location: London
Salary: 80,000$ - 95,000 based on experience
Schedule: Monday to Friday (8-hours) 100% onsite

What You’ll Do

Supervise and guide front-line IT staff, providing mentorship and ensuring smooth operations.
Manage escalated technical issues, collaborating with internal and outsourced resources to determine the best course of action.
Deliver hands-on assistance to resolve complex issues, driving timely resolutions and ensuring high-quality outcomes.
Coach, mentor, and motivate team members, fostering a supportive and productive environment.
Oversee the delegation of tasks, ensuring that the team remains aligned with organizational goals and customer needs.

In collaboration with MSP

Partner with IT staff and MSP team members to support ongoing projects, coordinating efforts with assigned project staff.
Work with the MSP to implement disaster recovery, backup procedures, and ensure information security and control measures are in place.
Ensure compliance with relevant IT legislation, including copyright and privacy regulations, in partnership with the MSP.
Collaborate with vendors and the MSP to negotiate project schedules, deadlines, and deliverables. Ensure all escalated issues are documented, tracked, and resolved efficiently.

What We’re Looking For

Proven experience in IT support and team management, particularly in a technical services or IT coordination role Min.5 years.
Strong problem-solving skills with the ability to handle escalations and complex technical challenges.
Effective communicator with the ability to work cross-functionally with internal teams, vendors, and external partners.
Proficient in Microsoft 365 Administration, including Conditional Access Policies and Intune management.
Experience in Windows 10/11 Deployment and Management.
Strong knowledge of Windows Server Administration.
Familiarity with SQL Server Administration.
Expertise in Virtualization Platforms (VMware, Hyper-V).
Hands-on experience with Hosted Server Environments, Clusters, and SANs.
Proficient in managing Multisite Networks.

Why work at MSP Corp.?

Dental care
Extended health care
Life insurance
On-site parking
Paid time off
Vision care

Ready to make a difference? Join us and shape the future. Apply today!

Diversity, Equity & Inclusion at MSP Corp, we believe that diversity, equity, and inclusion are essential for fostering a healthy and innovative work environment. We are committed to creating a workplace where everyone, regardless of age, gender, ethnicity, sexual orientation, ability, or any other characteristic, feels valued and respected. We encourage applications from individuals of diverse backgrounds and perspectives and ensure a fair and inclusive recruitment process.

Thank you for your interest in this opportunity. We will only contact candidates whose profile closely matches the job requirements.","{""role_summary"":""The Technical Services Coordinator is responsible for managing client-facing IT staff, ensuring efficient handling of escalated technical issues, and maintaining smooth collaboration with internal and outsourced resources."",""key_terms"":[{""term"":""Managed Service Provider (MSP)"",""explanation"":""A company that provides IT services and support to clients.""},{""term"":""Conditional Access Policies"",""explanation"":""Security policies that control access to resources based on user identity, location, and device factors.""},{""term"":""Intune management"",""explanation"":""A cloud-based endpoint management solution that helps manage and secure devices.""},{""term"":""Virtualization Platforms (VMware, Hyper-V)"",""explanation"":""Software that creates and manages virtual machines, allowing multiple OS to run on a single physical machine.""},{""term"":""Hosted Server Environments, Clusters, and SANs"",""explanation"":""Server environments that are hosted remotely, clusters of servers that work together, and Storage Area Networks that provide shared storage.""}],""skill_priorities"":{""must_have"":[""Proven experience in IT support and team management"",""Strong problem-solving skills"",""Effective communication skills"",""Proficient in Microsoft 365 Administration"",""Experience in Windows 10/11 Deployment and Management"",""Strong knowledge of Windows Server Administration"",""Familiarity with SQL Server Administration"",""Expertise in Virtualization Platforms (VMware, Hyper-V)""],""nice_to_have"":[""Hands-on experience with Hosted Server Environments, Clusters, and SANs"",""Proficient in managing Multisite Networks""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to handle a complex technical issue and how you resolved it?"",""example_answer"":""I once had to troubleshoot a network issue that was causing downtime for our clients. I worked with the internal team and external partners to identify the root cause and implemented a solution that minimized downtime and ensured a smooth recovery.""},{""question"":""How do you approach team management and mentorship, and can you give an example?"",""example_answer"":""I believe in leading by example and providing regular feedback. I once had a team member who was struggling with a technical skill, and I provided one-on-one coaching and guidance until they felt confident in their abilities.""}],""red_flags"":[""Lack of experience in IT support and team management"",""Inability to work cross-functionally with internal teams, vendors, and external partners""],""confidence_score"":90.0}"
Technology Strategy Manager,AutoTrader.ca,"Greater Toronto Area, Canada",February,2025,"TRADER Corporation is a trusted Canadian leader in online media, dealer and lender services. The company is comprised of AutoTrader.ca, AutoSync and Dealertrack Canada. AutoTrader.ca (AutoHebdo.net in Quebec) offers the largest inventory of new cars and used cars in Canada, receiving over 25 million monthly visits to its marketplace. With over 3,500 subscribers and counting, AutoSync is the largest and fastest growing dealer and OEM software provider in Canada. The platform's suite of connected automotive software solutions brings advertising, conversion and operational support together, synchronizing the entire retail process. AutoSync's diverse range of offerings includes: vAuto, EasyDeal, xtime, Motoinsight, Activix, TAdvantage and TRFFK. Dealertrack is Canada’s largest automotive financing portal, enhancing efficiency and profitability for all major segments of the automotive, marine, recreational vehicle, motorcycle and powersport retail industries. Over 6.5 million credit applications are submitted via the Dealertrack Canada portal each year. Collateral Management is a national, end-to-end, managed technology solution that offers industry insight and multi-channel collection strategies to maximize funds recovered. Collateral Management helps you remain compliant in all jurisdictions, alleviating your exposure to reputational and financial risks. Visit tradercorporation.com to learn more.

TRADER Corporation's parent company AutoScout24 is the largest pan-European online car market with over 2 million listings and more than 43,000 dealer customers. With AutoScout24, users can find, finance, buy, subscribe for and sell used and new cars. The marketplace provides inspiration on cars and other vehicles and makes hard decisions easy.

Since 1998 AutoScout24 has been offering private users, car dealers and other cooperation partners from the automotive, financial and insurance services sector a comprehensive digital platform for car trading. The online marketplace includes used and new cars, motorcycles as well as commercial vehicles. AutoScout24 has over 30 million users per month, more than 43,000 dealers and around 500 employees. In addition to Germany, AutoScout24 is also represented in the European core markets of Belgium, Luxembourg, the Netherlands, Italy, France and Austria.

More information on www.autoscout24.de

Experience leveraging AI, Generative AI (GenAI) to enhance engineering productivity, automate repetitive tasks, and optimize workflows. Candidates should demonstrate the ability to integrate AI-driven solutions into their daily work — such as code generation, debugging, reviews, documentation, and decision support—to improve efficiency for themselves and their teams. A proactive approach to exploring and implementing AI tools that drive innovation and streamline development processes is highly valued

We are a leading international tech company with operations across Europe and Canada, seeking a dynamic and strategic Technology Strategy Manager to support our Chief Technology Officer (CTO). This pivotal role is designed for an individual who excels in strategic planning, communication, and program management, and who can drive the effectiveness of our global technology organization. The Technology Strategy Manager will act as a trusted advisor to the CTO, ensuring that strategic initiatives are well-communicated, resources are optimally allocated, and programs are executed efficiently across all locations. The successful candidate will embody a mindset akin to a special operations team, diving into complex topics and providing comprehensive support to ensure the success of our strategic technology initiatives.

Key Responsibilities:

Strategic Planning and Execution:
Collaborate with the CTO and technology leadership to formulate and communicate strategic directions for the technology function.Assist in setting priorities, aligning initiatives with overall business objectives, and monitoring execution.Facilitate strategic planning sessions and workshops.
Strategic Communication and Stakeholder Management:
Develop and produce high-quality communication materials (presentations, emails, reports) for internal stakeholders, technology teams, and external parties, including the supervisory board.
Craft clear and compelling messages that articulate the technology vision, strategy, and progress to diverse audiences.
Program and Project Management:
Ensure global technology programs are delivered on time, effectively communicated, and in alignment with technology leadership expectations.
Monitor program progress, identify risks, and implement mitigation strategies.
Lead or support strategic projects as assigned by the CTO, ensuring they are delivered on time, within scope, and meet quality standards.
Analytical Support:
Provide in-depth analysis of technology function metrics, including employee engagement scores, productivity measures, and operational efficiency indicators. Generate comprehensive reports that highlight trends, successes, and areas for improvement within the technology organization.
Budget, Capacity and Resource Planning:
Oversee technology functional capacity and budget planning.
Work closely with HR and finance teams to align staffing and resources with strategic needs and budget constraints.
Analyze workforce data to forecast future staffing requirements.
Operational Efficiency and Change Management:
Identify opportunities to improve processes within the technology organization to enhance efficiency and effectiveness.
Drive and support change management initiatives, ensuring successful adoption of new technologies and processes.
Implement best practices and ensure compliance with organizational policies.

Qualifications:
Bachelor's degree in Computer Science, Information Technology, Business Administration, or a related field; MBA or advanced degree preferred.
Experience in technology (leadership) roles.
Proven experience in strategic planning, program management, and operational leadership within a global organization.
Exceptional communication and presentation skills, with the ability to convey complex technical concepts to non-technical audiences.
Strong analytical and problem-solving abilities, with a data-driven approach to decision-making.
Experience in change management and driving organizational transformation.
Demonstrated ability to manage multiple priorities in a fast-paced, dynamic environment.
Excellent interpersonal skills and the ability to build relationships across diverse teams and cultures.
Knowledge of current technology trends and their potential impact on business strategies.
Familiarity with risk management and compliance in a technology context.

What We Offer:
A leadership role in a forward-thinking, international tech company.
Opportunity to influence the strategic direction and success of our global technology organization.
A collaborative and innovative work environment that values diversity and inclusion.
Competitive salary and comprehensive benefits package.
Professional development opportunities and support for continuous learning.

What’s in it for you…
-We understand that there is life at work and life outside of work. Here are a few benefits we all benefit from that support us to be our creative best.
Fitness and wellness
-We provide discounts to nation-wide gyms, onsite gyms (when we’re in the office), an Employee and Family Assistance Program, as well as a virtual wellness program.
Benefits from Day 1
-Gym discounts
-Local in-office free gyms
-Employee and Family Assistance program
-Weekly virtual wellness events
-Conferences & training budget
-Regular internal training programs
Financial planning
-Let us help you invest in your future with 3% matching towards your pension and multiple forms of income protection.
Competitive salary
-Annual bonus structure
-3% CPP matching","{""role_summary"":""The Technology Strategy Manager will support the Chief Technology Officer (CTO) in strategic planning, communication, and program management, driving the effectiveness of the global technology organization."",""key_terms"":[{""term"":""AI-driven solutions"",""explanation"":""Integrating artificial intelligence into daily work to improve efficiency and automate tasks.""},{""term"":""Generative AI (GenAI)"",""explanation"":""A type of AI that can generate code, debug, and optimize workflows.""},{""term"":""Strategic planning"",""explanation"":""Formulating and communicating strategic directions for the technology function.""}],""skill_priorities"":{""must_have"":[""Strategic planning"",""Communication"",""Program management""],""nice_to_have"":[""AI experience"",""MBA or advanced degree""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you give an example of a strategic planning session you led and the outcome?"",""example_answer"":""I led a strategic planning session to align our technology initiatives with business objectives, resulting in a 20% increase in productivity.""},{""question"":""How do you stay current with technology trends and their potential impact on business strategies?"",""example_answer"":""I regularly read industry publications, attend conferences, and network with peers to stay informed.""}],""red_flags"":[""Lack of experience in strategic planning and program management"",""Inability to communicate complex technical concepts to non-technical audiences""],""confidence_score"":90.0}"
"Senior Manager, IT Service Management",LifeLabs Medical Laboratory Services,"Etobicoke, Ontario, Canada",March,2025,"For over 50 years, LifeLabs has been Canada’s leading provider of laboratory diagnostic information and digital health connectivity systems, enabling patients and healthcare practitioners to diagnose, treat, monitor and prevent disease. We are passionate about empowering healthier Canadians through accessible, accurate, and innovative diagnostic services.

We are committed innovators, operating Canada's first commercial genetics lab, and the country's largest online patient portal, with more than 8 million Canadians receiving their results online. More than 112 million laboratory tests come through LifeLabs’ laboratories annually, and our team of more than 6,000 passionate, caring, and diverse professionals works together as one to provide high quality testing and results that Canadians can trust.

We know that behind every lab requisition, sample being tested, or investment in technology is an individual and their family counting on us. At LifeLabs, you can make a meaningful impact on Canadians’ lives every day.

Our teams are at the heart of everything we do. We are proud to be recognized as one of Canada’s Best Employers, reflecting our deep commitment to our core values of caring, agility, teamwork, and a customer-centered approach. As part of this commitment, LifeLabs prioritizes the ongoing development of our diversity, equity, and inclusion (DEI) program to better serve the needs of our diverse workforce and the communities we serve. We continue to take steps to challenge ourselves to act with courage and integrity, and to create an environment where people can be their true selves.

These values are not just words on a page, they guide our actions and decisions every day and have come to define our team culture.

Reports to: Vice President, Technology Infrastructure & CISO

Status: Full Time

Schedule: Monday-Friday

Additional Requirements: N/A

Number of Positions: 1

Start Date: ASAP

Internal Application Deadline: March 21, 2025

LifeLabs operates under a Hybrid workforce model. Further details will be provided during the interview stage.

This vacancy is for an existing position.

Purpose of the Role

The Senior Manager, IT Service Management is an essential member of the IT Technology Shared Services leadership team and will define, implement, and maintain the IT Service Management portfolio, processes and procedures across internal organization and external suppliers leveraging the Information Technology Infrastructure Library (ITIL) framework. The ideal candidate will oversee the full scope of IT Service Management (ITSM) delivery across IT and to the business. This person will be responsible for the deployment of IT Service Management and its related processes: Incident management, Request Fulfillment, Problem Management, Configuration Management, Change Management, and Knowledge Management.

This person will lead the IT Service Management vision, strategy, goals, and priorities to achieve best-in-class service delivery. This will include designing service management operations in lockstep with cloud architecture to ensure ITIL objectives continue to be met while progressively pursuing new, modern practices. This role will require a senior leader with broad working knowledge of infrastructure technologies (legacy and modern), operations, architecture, platform delivery, vendor management and partnerships, cloud technologies, hybrid cloud operating models, and Agile infrastructure. Since this function services the broader enterprise, this leader will also need to have a strong background in applications support and operations, particularly the ITSM tool set (BMC Helix). There will be a heightened focus towards process simplification/engineering, automation, self-service capabilities, and advancements in AI operations. This role is also expected to have a significant matrix management responsibility and will be required to manage incident, problem and change across stakeholder organizations (technology & business groups).

They will also follow up and report on the adherence to the ITSM processes in the department and work with IT leadership to ensure coherence. The Senior Manager will lead the design and implementation of projects, policies and processes aimed at improving IT services, systems, and operations. They will lead a small team on strategies for improved services, performance, and reliability.

Your Responsibilities Will Include

Responsible for providing oversight and leadership of ITIL-based IT Service Management processes and policies for Incident, Problem, Change, and Asset management
Develop and maintain documentation and training materials around ITSM policies, processes and standards within the knowledge bases and other collaboration portals
Develop business cases to propose and implement additional ITSM processes and functions to further improve service – Knowledge Management, Release Management, Event Management, Request Management (with self-service capabilities)
Ensure services and tools are consistently deployed, executed, measured, monitored, and improved for Incident Management, Problem Management, Change Management, Asset Management, Configuration Management (CMDB), Capacity Management, Service Catalog, ServiceNow ITSM Platform, etc.
Partner with business stakeholders and transformation office leads to deliver initiatives on target and on budget
Serve as a senior expert on service management to educate, enable, and promote awareness to the Technology organization, service providers and business partners
Drive production stability, performance, and automation
Evaluate new information systems products or services and suggest improvements to existing products or services
Develop and oversee metrics and reporting capabilities
Provide leadership to staff and cross-functional teams to ensure deliverables are met
Develops strategic direction for ITIL based process improvement initiatives
Support increased project and milestone delivery through repeatable and consistent execution of ITIL process
Identify, analyze, and mitigate risk and issues across LifeLabs IT landscape
Own and govern the BMC Helix ITSM development lifecycle
People management duties, such as hiring, performance management, mentoring, running team meetings, timesheet approvals etc.
Annual budgeting, ensuring budget tracking through projections and actuals
Ensure continuity of the team through cross-training and succession planning
Set goals and delivery results – set annual goals for team members using the SMART framework – identity action steps and timelines needed to reach objectives and communicate plans to staff including delegation of work – Track progress to ensure completion of work and set priorities, manage workload for self and staff
Plan and facilitate effective meetings, implement changes and new systems or programs within the department
Conduct performance reviews on a regular basis, deliver ongoing feedback and address performance issues – recognize training needs – collaborate with team members to create and implement development plans – embrace continuous learning and self-development

What You Bring To The Role

Expert knowledge of IT Service Management concepts
7+ years of experience with various technologies relevant to IT Service Management (BMC, Service Now)
7+ years of experience managing and leading teams of technical staff
5+ years of experience with BMC Helix ITSM (Remedy)
Proven ability to effectively collaborate and engage with internal and external business partners at all levels on projects from conceptualization to execution, and plan for short and long-term goals
High attention to details, motivation and commitment to quality and customer service
7+ years of experience coordinating cross-functional work teams toward task completion
5+ years of experience overseeing vendor partners with a proven track record of building, developing, and managing service delivery and support teams
Bachelors degree in information technology, system administration, information systems management or a related discipline
ITIL v4.0 or DevOps Certification an asset
Proven ability to act with a sense of urgency and accountability while achieving quality results and identifying and resolving problems and issues in a context that requires assuming responsibility for decisions which have an impact on people, costs, and the delivery of services
Understanding of all aspects of software development and implementation
Proven ability to act as a thought leader in researching and presenting innovative ways to solve complex infrastructure related issues, including working with Managed Service Providers and other vendor partners with root cause analysis, SLA adherence and outcomes-based results
Proven ability to work in an Agile environment

LifeLabs’ compensation programs are commensurate based on the role, skill, effort, responsibility and working conditions, irrespective of gender, race, ethnicity, beliefs, age or any other personal characteristics. Pay programs are communicated regularly in an accessible and transparent manner.

LifeLabs is also proud to offer resources, opportunities, as well as a collaborative and supportive environment that enables our team members to thrive.

In Addition To a Competitive Compensation Package, LifeLabs Provides a Comprehensive Total Rewards Program, Specific To The Job Position. Your Package May Include

Employee Group Benefits: Competitive coverage for employees and their families to support their overall health and wellness needs, including Extended Health Care, Dental Care, and Life Insurance.
Retirement Savings Plan
Vacation and Wellness Days
Employee Wellness and Giving Programs: Our award winning mental, physical and financial wellness programs aim to address the comprehensive well-being of our team members, including resources like the Employee & Family Assistance Program, financial planning tools, and employee recognition initiatives.
Professional development and membership reimbursement, access to preferred rates and discount programs, including WorkPerks, Home and Auto Insurance, Costco Membership, etc., and optional health-related benefits.

In accordance with LifeLabs’ Accessibility Policy , and the applicable Accessibility Acts within the provinces we operate in, accommodations are available by request for candidates taking part in all aspects of the recruitment and selection process. For a confidential inquiry or to request an accommodation, please contact your recruiter or email careers@lifelabs.com .

Vaccinations are highly encouraged at LifeLabs’. Vaccinations and/or immunization screening may be mandatory for selected employees if regulated by provincial or regional governments, or through employer-led vaccination policies in the facilities we service. Please ensure you ask if this position requires the successful candidate to be vaccinated or undergo immunization screening.

Ready to empower healthier Canadians? Apply today!

Apply Now","{""role_summary"":""The Senior Manager, IT Service Management portfolio, processes, and procedures across internal organization and external suppliers, ensuring best-in-class service delivery and ITIL objectives."",""key_terms"":[{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a set of practices for IT service management""},{""term"":""BMC Helix"",""explanation"":""A software tool for IT service management""},{""term"":""Agile"",""explanation"":""An iterative approach to project management and software development""},{""term"":""Cloud Architecture"",""explanation"":""A model for delivering computing services over the cloud""}],""skill_priorities"":{""must_have"":[""Expert knowledge of IT Service Management concepts"",""7+ years of experience with various technologies relevant to IT Service Management"",""7+ years of experience managing and leading teams of technical staff"",""5+ years of experience with BMC Helix ITSM""],""nice_to_have"":[""ITIL v4.0 or DevOps Certification"",""Proven ability to act as a thought leader in researching and presenting innovative ways to solve complex infrastructure related issues""]},""proposed_screening_questions_with_answers"":[{""question"":""What is your experience with ITIL-based IT Service Management processes and policies?"",""example_answer"":""I have 7+ years of experience with ITIL-based IT Service Management processes and policies, including Incident, Problem, Change, and Asset management.""},{""question"":""How do you ensure services and tools are consistently deployed, executed, measured, monitored, and improved?"",""example_answer"":""I develop and maintain documentation and training materials around ITSM policies, processes, and standards within knowledge bases and other collaboration portals.""}],""red_flags"":[""Lack of experience with ITIL-based IT Service Management processes and policies"",""Inability to manage and lead teams of technical staff""],""confidence_score"":90.0}"
IT Site Manager,Aversan Inc.,"Victoria, British Columbia, Canada",March,2025,"Aversan Inc. (www.aversan.com) is a trusted multi-service engineering and electronics manufacturing company. Aversan delivers leading-edge and reliable safety-critical electronics and software systems to the aerospace, defence, and space industries.

We are currently seeking a qualified IT Site Manager to join our team.

Location: Victory, BC

Work Arrangement: Hybrid

Responsibilities

Infrastucture Functions
Process assigned tickets in ServiceNow through multiple assignment groups, read architecture diagrams, and construct rules based on those diagrams.
Firewalls and network filters, in both Enterprise, Stores, and cloud networks
Intrusion Prevention policies
Networking Protocols/Concepts (Routing (OSPF, BGP), VLAN, Sub-netting, Load balancing, TCP/IP, DNS, HTTP, TLS, SSH)
Site-to-site and remote-access VPN connectivity
Network Access Control
Authentication, Authorization and Accounting (to include multi-factor authentication)
Web access proxy servers and URL filtering
Network Security policy creation, exception documentation and approval
Provide suggestions to team lead/manager in creating your professional development and training plan.
Work on projects assigned to you, in effort to advance partnership opportunities between Network Security team and other business areas.
Work with senior engineers to define network security requirements for current and future state end-to-end architectures and platforms to advance security controls and the security posture of the business.
Assist senior engineers in collaborating with development and engineering teams to prioritize security risks, provide mitigation or remediation recommendations, and implement compensating controls.
Assist in performing proof-of-concept testing for network security solutions under consideration for purchase and implementation.
Provide 7/24 On-Call support for infrastructure related service incidents and follow internal management escalation procedures when necessary (team rotation).
Assist in developing and maintaining network security policies, standards, processes and workflows.


End User Support Functions
Provide Level 2 customer facing support.
Image, deploy and support all desktop and laptops
Support users by regularly monitoring the ticket queue and executing tickets that are assigned to you.
Instruct users as well as troubleshoot basic and advanced software/hardware issues with internal and external customers via phone, email, chat, and remote control/assist software.
Troubleshoot all inquiries regarding systems, hardware, software, and operator problems.
Work with Workplace team to support necessary tickets.
Route or escalate requests to appropriate functional teams beyond Service Desk Team.
Ability to setup, support and troubleshoot VTC (Video Teleconference) and VOL (Video Online)
Create and maintain knowledge base documents
Collaborate with Engineering and all other supportive roles within the campus. May also require interaction with external vendors and /or customers.
Basic Qualifications

Degree in Computer Science, Computer Engineer or a relevant field
Strong relevant managerial experience in IT domain
Experience in network security policy creation
Experience with ServiceNow
Networking Protocols/Concepts (Routing (OSPF, BGP), VLAN, Sub-netting, Load balancing, TCP/IP, DNS, HTTP, TLS, SSH)
Firewalls and network filters, in both Enterprise, Stores, and cloud networks
Able to setup, support and troubleshoot VTC (Video Teleconference) and VOL (Video Online)","{""role_summary"":""Manage IT infrastructure and provide end-user support, ensuring the security and reliability of systems and networks."",""key_terms"":[{""term"":""ServiceNow"",""explanation"":""A cloud-based IT service management platform used for ticketing and workflow management.""},{""term"":""OSPF"",""explanation"":""An open-standard routing protocol used for routing decisions in computer networks.""},{""term"":""BGP"",""explanation"":""A routing protocol used for exchanging routing and reachability information among autonomous systems on the internet.""},{""term"":""VLAN"",""explanation"":""A virtual local area network that allows multiple virtual LANs to share the same physical network infrastructure.""},{""term"":""Sub-netting"",""explanation"":""The process of dividing a larger network into smaller sub-networks to improve organization and security.""},{""term"":""Load balancing"",""explanation"":""A technique used to distribute network traffic across multiple servers to improve responsiveness and availability.""},{""term"":""TCP/IP"",""explanation"":""A set of communication protocols used to interconnect devices on the internet.""},{""term"":""DNS"",""explanation"":""A system that translates human-readable domain names into IP addresses.""},{""term"":""HTTP"",""explanation"":""A protocol used for transferring data, including web pages, over the internet.""},{""term"":""TLS"",""explanation"":""A cryptographic protocol used to provide secure communication over a network.""},{""term"":""SSH"",""explanation"":""A secure protocol used for remote access and management of network devices.""},{""term"":""VPN"",""explanation"":""A virtual private network that allows secure, encrypted connections between devices over the internet.""}],""skill_priorities"":{""must_have"":[""Experience in network security policy creation"",""Experience with ServiceNow"",""Networking Protocols/Concepts (Routing (OSPF, BGP), VLAN, Sub-netting, Load balancing, TCP/IP, DNS, HTTP, TLS, SSH)"",""Firewalls and network filters, in both Enterprise, Stores, and cloud networks""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the importance of network security policy creation in an organization?"",""example_answer"":""Network security policy creation is crucial as it outlines the rules and guidelines for securing an organization's network infrastructure, ensuring the confidentiality, integrity, and availability of sensitive data.""},{""question"":""How do you troubleshoot basic and advanced software/hardware issues with internal and external customers via phone, email, chat, and remote control/assist software?"",""example_answer"":""I use a structured approach to identify the root cause of the issue, and then utilize my technical knowledge to resolve the problem, while maintaining effective communication with the customer throughout the process.""}],""red_flags"":[""Lack of experience in network security policy creation"",""Inability to setup, support, and troubleshoot VTC (Video Teleconference) and VOL (Video Online)""],""confidence_score"":90.0}"
Application Technology Manager,emergiTEL,"Toronto, Ontario, Canada",March,2025,"My client is looking for a Manager Application Technology to lead the development, configuration, and support of enterprise applications, ensuring seamless operations for staff and members. You'll manage vendor relationships, oversee system health, and drive continuous improvement in financial and content management applications.

🔹 Key Responsibilities:
✅ Lead the development & optimization of ECM and finance applications.
✅ Collaborate with teams to enhance system performance & user experience.
✅ Manage vendors & IT change requests, ensuring compliance & efficiency.
✅ Monitor application health, analyze performance, & provide 24/7 support.
✅ Drive digital transformation in banking & financial services.

🔹 What You Bring:
💡 5+ years managing ECM & finance applications (Captiva, Doxim, SharePoint, Sage 500).
🏦 5+ years in technology leadership within banking/financial services.
🔹 Expertise in integrated application ecosystems & digital transformation.
🛠 Strong knowledge of SDLC, Azure DevOps, and financial compliance.
📊 Strategic thinker with risk management & decision-making expertise.
📍 Location: Canada (Remote/Hybrid options)
🚫 No sponsorship – candidates must be eligible to work in Canada.

📩 Interested? Let’s connect! #Hiring #ECM #TechnologyLeadership #BankingTech #DigitalTransformation","{""role_summary"":""Lead the development and support of enterprise applications, ensuring seamless operations for staff and members."",""key_terms"":[{""term"":""ECM"",""explanation"":""Enterprise Content Management, a system for managing and storing documents and content.""},{""term"":""SDLC"",""explanation"":""Software Development Life Cycle, a process for planning, designing, building, testing, and deploying software.""},{""term"":""Azure DevOps"",""explanation"":""A cloud-based platform for collaborative software development, delivery, and deployment.""},{""term"":""Digital Transformation"",""explanation"":""The integration of digital technology into all areas of business, changing how companies operate and deliver value to customers.""}],""skill_priorities"":{""must_have"":[""ECM and finance applications management"",""Technology leadership in banking/financial services"",""SDLC and Azure DevOps knowledge"",""Financial compliance expertise""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with ECM and finance applications management?"",""example_answer"":""I have managed ECM and finance applications for 5+ years, including Captiva, Doxim, SharePoint, and Sage 500.""},{""question"":""How do you stay current with digital transformation trends in banking and financial services?"",""example_answer"":""I regularly read industry publications, attend conferences, and participate in online forums to stay informed about the latest developments.""}],""red_flags"":[""Lack of experience with ECM and finance applications management"",""No experience in technology leadership within banking/financial services""],""confidence_score"":90.0}"
"Manager, IT Contracts",Recipe Unlimited Corporation,"Vaughan, Ontario, Canada",February,2025,"Recipe Unlimited Corporation is Canada’s leading full service restaurant company. Home to such iconic brands as Swiss Chalet, Harvey’s, St.Hubert, The Keg, Montana’s, Kelseys, Bier Markt, East Side Mario’s, Landing Group, New York Fries, The Pickle Barrell & Catering, State and Main, Elephant and Castle, Original Joe’s, Fresh Kitchen + Juice Bar, and The Burger Priest. With this diverse portfolio of restaurants our Home Office Teammates have the opportunity to work on a wide variety of some of the most popular, well-loved brands in Canada. Variety isn’t the only thing we offer – we are passionate about our industry, we celebrate and support diversity of thought, we are innately curious and encourage our Teammates to take ownership. Above all else, we believe in doing the right thing for our people, our communities and our planet.

The Manager, IT Contracts role encompasses overseeing the entire lifecycle of IT contracts, ensuring compliance, and tracking performance. It involves precise management of purchase orders, resolving discrepancies, and adhering to policies. The role requires meticulous asset tracking and document management for easy access and organization. As a central communication hub, it necessitates addressing contract-related queries and maintaining strong vendor and stakeholder relationships. Additionally, it entails monitoring vendor performance, analyzing data for improvement opportunities, and coordinating business reviews with cross-functional teams to ensure continuous alignment and efficiency.

What you will do in this role:

IT Contract administration: Overseeing the entire lifecycle of contracts specific to our information technology departments, including tracking deadlines, monitoring performance, and ensuring compliance with terms and conditions
Apply basic financial knowledge, including invoice processing and an understanding of financial statements, to support contract administration and vendor payment accuracy. Including processing of purchase orders and invoices in JD Edwards
Purchase Order Management: Responsible for the accurate and timely processing of invoices against purchase orders, including verifying pricing, quantities, and delivery dates. Working with Recipe Stakeholders and vendors to resolve any discrepancies. Following Recipe's purchase order policy, escalate when appropriate purchase orders have not been created
Asset Tracking: Track and maintain accurate records of IT Assets, including their location, condition, purchase and maintenance history
Document and record management: Organizing and maintaining contract files, correspondence, amendments, and other related documents in a systematic and accessible manner
Communication: Serving as the main point of contact for contract-related queries, documenting and reaching out to the appropriate parties for resolution. Building and maintaining positive relationships with vendors and internal business stakeholders
Vendor performance monitoring: Monitor vendor performance, tracking progress against agreed-upon action plans and performance metrics. Analyzing data to identify trends, areas for improvement, and cost-saving opportunities. Regularly update stakeholders, progress and address emerging issues or challenges
Business review: Collaborate with cross-functional teams to gather relevant data, reports, and insights. Schedule and lead business review meetings with vendors and internal stakeholders. Ensure all participants are invited and resources, such as meeting rooms, technology, and materials, are prepared in advance
Contract renewal and termination: Managing contract renewal or termination processes, working with various business partners, providing notice of renewals

What we are looking for from you:

A University Degree or College Diploma in Finance is preferred
3 years of experience as a Contract Analyst, preferably in the IT Industry
Strong analytical skills with the ability to interpret data and identify trends
Excellent communication and interpersonal skills to effectively collaborate with internal teams and vendor representatives
Strong organizational skills to manage multiple business reviews simultaneously and ensure all necessary preparations are made
Ability to facilitate meetings, manage conflicts, and drive productive discussions
Proven experience in vendor management, performance analysis, or related roles
Proficient in G SUITE for Microsoft Office Products

What’s in it for you?

Flexible/Hybrid work environment
You’d be joining a close-knit, innovative team of creative and energetic go-getters
You’d be a part of Canada’s largest full-service restaurant company that leads the industry in size and innovation
20% associate discount dining card and monthly dining allowance valid at participating Recipe brands
A welcoming, fun and safe work environment founded on respect
Career advancement opportunities with a company that owns some of Canada’s most iconic restaurant brands
Industry-leading benefits, wellness programs, and total rewards programs

Recipe is committed to providing a diverse, equitable and inclusive workplace. Celebrating people, being passionate and curious, owning it, and doing the right thing are the values that guide how we build our teams, support our franchisees and create a company that unlocks the full potential of everyone.

Recipe is dedicated to providing accommodations in accordance with applicable human rights and accommodation legislation. For individuals that require accommodations please contact recruit@recipeunlimited.com.","{""role_summary"":""Oversee the entire lifecycle of IT contracts, ensuring compliance, tracking performance, and maintaining strong vendor and stakeholder relationships."",""key_terms"":[{""term"":""IT Contracts"",""explanation"":""Overseeing the entire lifecycle of contracts specific to information technology departments.""},{""term"":""Invoice Processing"",""explanation"":""Supporting contract administration and vendor payment accuracy.""},{""term"":""Purchase Order Management"",""explanation"":""Accurate and timely processing of invoices against purchase orders.""},{""term"":""Asset Tracking"",""explanation"":""Tracking and maintaining accurate records of IT Assets.""},{""term"":""Vendor Performance Monitoring"",""explanation"":""Monitoring vendor performance, tracking progress against agreed-upon action plans and performance metrics.""}],""skill_priorities"":{""must_have"":[""Contract administration"",""Financial knowledge"",""Invoice processing"",""Purchase Order Management"",""Asset Tracking"",""Vendor Performance Monitoring""],""nice_to_have"":[""G SUITE for Microsoft Office Products""]},""proposed_screening_questions_with_answers"":[{""question"":""What experience do you have with contract administration, and how have you ensured compliance in the past?"",""example_answer"":""I have 3 years of experience as a Contract Analyst, and I have developed a thorough understanding of contract terms and conditions. I ensure compliance by tracking deadlines, monitoring performance, and verifying pricing, quantities, and delivery dates.""},{""question"":""How do you stay organized when managing multiple business reviews simultaneously?"",""example_answer"":""I prioritize tasks, create to-do lists, and set reminders to ensure I meet deadlines. I also maintain accurate records of IT Assets, including their location, condition, purchase, and maintenance history.""}],""red_flags"":[""Lack of experience in contract administration or vendor performance monitoring."",""Inability to interpret data and identify trends.""],""confidence_score"":90.0}"
End User Computing Operations Lead,Government of Alberta,"Alberta Beach, Alberta, Canada",March,2025,"Job Information

Job Title: End User Computing Operations Lead

Job Requisition ID: 67980

Ministry: Technology and Innovation

Location: Remote across Alberta

Full or Part-Time: Full Time

Hours of Work: 36.25 hours per week

Permanent/Temporary: Ongoing

Scope: Open Competition

Closing Date: March 21, 2025

Classification: Systems Analyst 3

Salary: $3,199.50 - $4,237.85/ Bi-weekly ($83,506 - $110,607/year)

The Government of Alberta is committed to a diverse and inclusive public service that reflects the population we serve to best meet the needs of Albertans. Consider joining a team where diversity, inclusion and innovation are valued and supported. For more information on diversity and inclusion, please visit: https://www.alberta.ca/diversity-inclusion-policy.aspx .

The Ministry of Technology and Innovation is responsible for making innovation and technology the driving force behind Alberta’s economic growth and diversification. To learn more about us, please visit: https://www.alberta.ca/technology-and-innovation.aspx .

The Technology Support and Operations Division uses a one-government approach to Information Management and Technology (IMT) governance, decision-making and service delivery across the Government of Alberta (GoA) balanced with individual business partner needs. This broader lens facilitates enhanced data sharing, collaboration, reduction in data duplication and innovation support to ensure effective IMT solutions and service delivery across the government to provide better services to Albertans.

Role Responsibilities

Reporting to the End User Computing (EUC) Manager, the Operations Lead is a critical role in leading the way in how End User Computing services are managed and improved, as a core service, within the GoA. This position plays a critical role in shifting EUC services from a technical service offering to user-centric service offering that provides high-business value and increases user performance within the workplace to enable business partner outcomes.

The Operations Lead provides oversight and guidance to the End User Computing team; works with other Information Management and Technology (IMT) and business teams; provides leadership and direction to cross- functional project teams and contributes in the review, development and implementation of divisional service management processes that ensure consistent service management practices are utilized across government.

Responsibilities

The Operations Lead is responsible for day to day planning, coordination, and prioritization of work assignments within the Operations Team. The Operations Lead has a broad scope of services that reaches across all GoA Users and has a significant impact to government ministries at all levels. The End User Computing Service is comprised of a portfolio of components and supporting services including, but not limited to, desktop hardware, software management, desktop imaging and core application packaging and deployments, VIP support services, mobile computing IT bars, mobile device management, network print support and boardroom support services.

Some of the role’s responsibilities include, but are not limited to:

Staff Leadership
Service Operations Ownership
Service Evolution
Service Level Management
Financial Management

To be successful in this role, you must demonstrate excellent:

Problem/Incident Management skills
Supervisory/leadership/coaching skills
Communication skills
Change Management skills
Attention to Detail/Organizational skills
Enterprise Service Management skills
Relationship/Rapport building skills

Please click on this link to view the job description for this position.

APS Competencies

Competencies are behaviors that are essential to reach our goals in serving Albertans. We encourage you to have an in depth understanding of the competencies that are required for this opportunity and to be prepared to demonstrate them during the recruitment process.

This Link Will Assist You With Understanding Competencies

https://www.alberta.ca/system/files/custom_downloaded_images/psc-alberta-public-service-competency-model.pdf .

Agility: Ability to anticipate, assess, and readily adapt to changing priorities, manage resilience in times of uncertainty and effectively work in a changing environment.
Develop self and others: A commitment to lifelong learning and the desire to invest in the development of the long-term capability of yourself and others.
Build Collaborative Environments: Leads and contributes to the conditions and environments that allow people to work collaboratively and productively to achieve outcomes.
Develop Networks: Proactively building networks, connecting, and building trust in relationships with different stakeholders.
Systems Thinking: The work done within the APS is part of a larger integrated and inter-related environment. It is important to know that work done in one part of the APS impacts a variety of other groups/projects inside and outside the APS. Systems thinking allows us to keep broader impacts and connections in mind.
Creative Problem Solving: Ability to assess options and implications in new ways to achieve outcomes and solutions.

Qualifications

Required:

University degree in Computer Sciences or a related field.
Four (4) years of progressive leadership and technical experience in the IT field, specifically related to the technologies and responsibilities of this position:
Enterprise Service Management
Incident/Problem Management
Leadership/Supervisory/Coaching
Change Management
Equivalencies

Equivalencies are considered on the basis of:

A related two-year diploma in computer technology or a related discipline from a recognized postsecondary institution and six (6) years related experience; or
A related one-year certificate from a recognized post-secondary institution and seven (7) years related experience.

Assets

ITIL Certification.
Service Level/KPI Management experience.
Vendor/Contract Management experience.
Continuous Improvement/Service Evolution experience.
Experience in assessing new opportunities and performing necessary due-diligence around technical, operational and financial impacts.
Superior IT technical aptitude to guide the operations and to define road maps for in scope EUC services.
Experience with Enterprise Service Management.
Experience collaborating with the technical project teams and business partners to collect, clarify, and translate technical details into practical, informative messages and forward direction.

Minimum recruitment standards outline the minimum education and experience required for appointment to a job classification.

Refer to https://www.alberta.ca/alberta-public-service-minimum-recruitment-standards

Notes

Term of Employment: Permanent, Full-time position.

Hours of Work: 36.25 hrs./week - Monday to Friday

Location: Remote across Alberta.

You must reside in Alberta to work remotely.

This competition may be used to fill future vacancies, across the Government of Alberta, at the same or lower classification level.

Final candidate will be required to undergo security screening.

Cover Letter: Applicants are advised to provide a cover letter summarizing information that clearly and concisely demonstrates how their qualifications meet the advertised requirements, including education, experience, and relevant examples of required competencies.

Resume: For Employment Experience, please indicate duration of employment (month, year). Please specify employment status (i.e., Casual, part-time, or full-time)

Ex: Youth Worker, Jan 2006 - June 2009, Part-time (three 8 hr. shifts/week)

For Any Post-Secondary Education

Please specify your major and length of program and the year you graduated.

Ex: Bachelor of Social Work, 4-year Degree (Graduated 2017)

Any costs associated with obtaining the required documents/checks as noted or interview travel expenses, will be the responsibility of the candidate. Out-of-province applicants can obtain the required documents/checks from the province they currently reside in.

Links and information on what the GoA have to offer to prospective employees.

Working for the Alberta Public Service - https://www.alberta.ca/advantages-working-for-alberta-public-service.aspx
Public Service Pension Plan (PSPP) - https://www.pspp.ca
Alberta Public Service Benefit Information - https://www.alberta.ca/alberta-public-service-benefits
Professional learning and development - https://www.alberta.ca/professional-development-support-directive
Research Alberta Public Service Careers tool – https://researchapscareers.alberta.ca
Positive workplace culture and work-life balance
Opportunity to participate in flexible work arrangements such as working from home up to two days per week and modified work schedule agreement
Leadership and mentorship programs

How To Apply

Applicants are advised to provide information that clearly and concisely demonstrates how their qualifications meet the advertised requirements, including education, experience, and relevant examples of required competencies.

Candidates are required to apply for a job online. Please visit https://www.alberta.ca/job-application-resources#before for more information. Please visit Recruitment Principles , for more information.

It is recommended applicants who have completed post-secondary studies from outside of Canada obtain an evaluation of their credentials from the International Qualifications Assessment Service (IQAS)( https://www.alberta.ca/international-qualifications-assessment.aspx ) or from a recognized Canadian Credential Evaluator; please visit the Alliance of Credential Evaluation Services of Canada for more information ( https://canalliance.org/en/default.html ).

It is recommended that applicants include the assessment certificate from IQAS or any other educational assessment service as part of their application.

Closing Statement

This competition may be used to fill future vacancies, across the Government of Alberta, at the same or lower classification level.

We thank all applicants for their interest. All applications will be reviewed to determine which candidates' qualifications most closely match the advertised requirements. Only individuals selected for interviews will be contacted.

If you require any further information on this job posting or require an accommodation during the recruitment process, please contact Michelle Elliott at Michelle.Elliott@gov.ab.ca .","{""role_summary"":""The End User Computing Operations Lead is responsible for leading the way in managing and improving End User Computing services, providing high-business value and increasing user performance within the workplace to enable business partner outcomes."",""key_terms"":[{""term"":""End User Computing"",""explanation"":""A service that provides high-business value and user performance within the workplace to enable business partner outcomes.""},{""term"":""Enterprise Service Management"",""explanation"":""A framework for managing IT services across an organization, focusing on customer needs and service quality.""},{""term"":""Service Level Management"",""explanation"":""The process of defining, agreeing, and delivering IT services to meet business requirements, focusing on service quality and customer satisfaction.""}],""skill_priorities"":{""must_have"":[""University degree in Computer Sciences or a related field"",""Four years of progressive leadership and technical experience in the IT field"",""Experience in Enterprise Service Management"",""Incident/Problem Management skills"",""Leadership/Supervisory/Coaching skills"",""Change Management skills""],""nice_to_have"":[""ITIL Certification"",""Service Level/KPI Management experience"",""Vendor/Contract Management experience"",""Continuous Improvement/Service Evolution experience"",""Experience in assessing new opportunities and performing necessary due-diligence around technical, operational and financial impacts""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach incident/problem management in an IT environment?"",""example_answer"":""I prioritize incidents based on business impact and work closely with stakeholders to resolve issues efficiently, ensuring minimal downtime and effective communication.""},{""question"":""Can you describe your experience with Enterprise Service Management?"",""example_answer"":""I have implemented ESM frameworks in previous roles, focusing on service quality, and process efficiency, and have experience with service level management, incident management, and problem management.""}],""red_flags"":[""Lack of experience in leading IT teams"",""Inability to adapt to changing priorities and manage resilience in times of uncertainty"",""Poor communication and relationship-building skills""],""confidence_score"":90.0}"
"Manager, M365 Centre of Excellence (COE)",Metergy Solutions,"Markham, Ontario, Canada",March,2025,"About Metergy Solutions Inc. (“Metergy”)
As one of North America’s most experienced submetering providers, Metergy Solutions has brought turnkey solutions to clients for over 20 years. Metergy supplies, installs and remotely reads meters to measure individual suite consumption of electricity, water, gas, and thermal energy in multifamily and commercial buildings, and bills and collects the utility consumption.

Our innovative Submetering as a Service (SaaS) model generates long-term recurring revenue and has been proven to reduce in-suite energy consumption by an impressive 40%, significantly advancing our clients' decarbonization efforts. This outstanding performance has enabled Metergy to issue green bonds and secure green financing, fueling our sustained growth and creating extraordinary career opportunities for our team.

As the #1 submeter provider in the New York and Canadian markets, and one of the largest in North America, Metergy boasts over 850,000 contracted meters, issues more than 2 million utility invoices annually, and employs over 400 dedicated team members. Our successful acquisitions have consistently exceeded expectations, unlocking immense growth potential.

Metergy is proudly a portfolio company of Brookfield Infrastructure Partners, one of the world’s largest investors, owners, and operators of infrastructure assets across the utilities, transport, energy, data, and sustainable resources sectors. This partnership provides Metergy with access to substantial capital, infrastructure investment expertise, and a global reach, positioning us for continued success and innovation

Our Mission

Provide building owners and occupants with accurate and reliable utility consumption data through market-leading expertise in turnkey submetering and billing, while fostering a workplace with inspired team members empowered to do more good.

Role Overview
Are you a Microsoft evangelist and passionate about their M365 products? Can you see yourself leading a COE, helping the business maximize the investment in Microsoft products? Do you see limitless potential with MS CoPilot and want to champion its adoption? If so, we have a fantastic role for you!

The Manager of the Microsoft Center of Excellence (COE) at Metergy will lead the development and implementation of innovative solutions using Microsoft Power Platform. This role is pivotal in driving digital transformation and enhancing business processes across the organization. The Manager will act as a Microsoft evangelist, promoting the effective use of Microsoft 365 tools and staying updated on the latest products. They will oversee a team of professionals, including citizen developers, and ensure the effective use of Microsoft tools to improve efficiency, collaboration, and data governance.

Responsibilities

Lead Power Platform Development: Oversee the agile development of automation solutions using Microsoft Power Platform, including Power Apps, Power BI, and Power Automate
Microsoft Evangelism: Promote the effective use of Microsoft 365 tools across the organization and stay updated on the latest Microsoft products
Training and Development: Develop and implement training programs to enhance the skills of power users and ensure the effective use of Microsoft applications
Data Governance: Ensure data integrity and manage API connections across platforms
Chair AI Committee: Promote proper usage of CoPilot throughout organization with Citizen developers
Collaboration and Communication: Foster a culture of continuous improvement and knowledge sharing among team members and across departments
Innovation and Adoption: Drive the adoption of new Microsoft applications and technologies, including AI and machine learning tools
Performance Monitoring: Monitor and optimize the performance of applications and processes, ensuring alignment with organizational goals



Qualifications

Education: Bachelor's degree in Information Technology, Computer Science, or a related field. Advanced degrees or certifications in Microsoft technologies are a plus
Experience: Minimum of 5 years of experience in managing IT projects and teams, with a focus on Microsoft Power Platform and related technologies
Skills: Strong leadership and project management skills, excellent communication and collaboration abilities, and a deep understanding of Microsoft tools and data governance practices
Certifications: Relevant Microsoft certifications (e.g., Power Platform, Azure) are highly desirable



Metergy’s recruitment process includes accommodation for applicants with disabilities. All accommodations will consider the applicant’s accessibility needs due to disability and are available upon request.","{""role_summary"":""Lead the development and implementation of innovative solutions using Microsoft Power Platform, driving digital transformation and enhancing business processes across the organization."",""key_terms"":[{""term"":""Microsoft Power Platform"",""explanation"":""A suite of low-code, no-code tools for automating business processes, including Power Apps, Power BI, and Power Automate.""},{""term"":""Microsoft 365"",""explanation"":""A bundle of Microsoft productivity applications, including Word, Excel, and Outlook, used for collaboration and data governance.""},{""term"":""CoPilot"",""explanation"":""An AI-powered tool for automating business processes and enhancing decision-making.""},{""term"":""Citizen developers"",""explanation"":""Non-technical users who create and deploy business applications using low-code, no-code tools.""}],""skill_priorities"":{""must_have"":[""Strong leadership and project management skills"",""Excellent communication and collaboration abilities"",""Deep understanding of Microsoft tools and data governance practices""],""nice_to_have"":[""Advanced degrees or certifications in Microsoft technologies"",""Relevant Microsoft certifications (e.g., Power Platform, Azure)""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you promote the effective use of Microsoft 365 tools across the organization?"",""example_answer"":""I would develop a training program to enhance the skills of power users and ensure the effective use of Microsoft applications.""},{""question"":""How would you ensure data integrity and manage API connections across platforms?"",""example_answer"":""I would implement data governance practices, monitor API connections, and ensure alignment with organizational goals.""}],""red_flags"":[""Lack of experience in managing IT projects and teams, with a focus on Microsoft Power Platform and related technologies.""],""confidence_score"":90.0}"
Manager of IT Clinic and Corporate Applications,Medcan,"Toronto, Ontario, Canada",March,2025,"Are you passionate about helping people live their healthiest lives? Do you thrive in a dynamic, supportive environment where your contributions truly matter? If so, Medcan is the place for you!

About Us:

Founded in 1987, Medcan is a leader in transformational proactive and primary care dedicated to helping patients and team members live well, for life. We offer a comprehensive range of services including preventative health assessments, wellness programs, and specialized medical care.

Our core values of excellence, drive, respect and integrity guide everything we do. We’re committed to creating a workplace where everyone can thrive, and we’re proud to support over 1,500 businesses across Canada with our health and wellness solutions.

Medcan is seeking an experienced Manager of IT Clinic and Corporate Applications to provide leadership for planning, implementation, and maintenance of solutions including application support. This individual is responsible for all aspects of the organization's Clinic and Corporate Application portfolio, including an application integration platform. The Manager will collaborate directly with business stakeholders to identify, recommend, develop, implement, and support cost-effective technology solutions to support our business.

Why You’ll Love Working Here:

Hybrid Office Policy: Flexible work-from-home and office options.
Coffee and Snacks: Keep your energy up with our delicious onsite offerings.
Employee Perks: Access to wellness programs like fitness training and other discounted Medcan services and products.
Benefits: Comprehensive health plans, retirement saving matches, educational reimbursement, and so much more!
Engaging Work Environment: Join a team that values collaboration, creativity, and continuous improvement.
Recognition: We celebrate our employees’ contributions through manager recognition and AwardCo prizes.
Career Growth Opportunities: We believe in nurturing talent and providing opportunities for professional development and career advancement.

Key Responsibilities:

Stakeholder Collaboration: Manage application support and delivery while prioritizing team workload and capacity. Partner with the business to continuously improve, optimize, and enhance processes and their use of applications. Continuously assess business needs and opportunities for improvements to leverage existing technology. Be a trusted advisor to business partners and IT colleagues on best practices and application of technology. Work closely with other IT management personnel in identifying, evaluating, selecting, and implementing information technologies that support corporate and IT strategies. Provide and own inputs to financial and capital planning processes.
Team Leadership: Foster a collaborative environment, encourage professional growth, and ensure team members are aligned with the organization’s goals. Delegate responsibilities effectively, ensuring each team member understands their role and contributes to project success. Develop and maintain an effective organizational structure that supports the needs of the business and optimizes the pool of talent. Support and nurture staff, build paths to develop and grow the team, and set and measure performance objectives while providing regular one-on-one feedback to all team members.
Data Accuracy and Reporting: Manage the enterprise application integration platform including governance, development practices, maintenance, and support. Regularly audit data sources, validate data quality, and address any discrepancies promptly. Create clear documentation for application support procedures and data definitions.
Efficiency and Quality: Optimize application support processes by leveraging automation tools and best practices. Implement data validation checks to ensure high-quality application data. Continuously monitor performance metrics and identify areas for improvement. Balance efficiency with data accuracy to drive meaningful insights.
Prioritization: Collaborate with senior management to align application initiatives with overall business priorities. Assess the impact and urgency of different projects and allocate resources accordingly. Communicate trade-offs and make informed decisions based on business value.
Process Improvement: Regularly evaluate existing application processes and identify bottlenecks or inefficiencies. Propose enhancements, such as streamlining workflows, adopting new tools, or refining data models. Encourage a culture of continuous improvement within the team. Manage the application support and maintenance operations for the portfolio, along with other IT operational teams (Service Desk and Infrastructure Services). Ensure the continuous delivery of IT services through oversight of service level agreements with end users and monitoring of systems performance. Review software acquisition and maintenance contracts and assist with establishing master agreements to capitalize on economies of scale.

Qualifications:

Experience: 5+ years managing people, including building and leading teams of high-performing IT professionals.
Education: Post-secondary degree/diploma in Human Resources or a related discipline. Some experience in strategic planning and execution.
Technical Requirements: Experience managing external IT service providers and assessing the risk and cost implications of IT contracts and contract negotiations. Experience with onshore, nearshore, and offshore development and support processes. Experience in designing, building, transforming, and managing applications in cloud and application modernization strategies. Sound knowledge of systems architecture, technical design principles, and software development and integration technology.
Strategic Thinking: Proven ability to design and implement innovative application strategies and build a strong technology portfolio.
Intellectual Curiosity: Consistently seek clarity and ask “How” and “Why” questions to fully acquire necessary knowledge.
Leadership: Exceptional leadership skills to build enthusiastic, high-performing teams while focusing on strategic goals. Strong organizational skills, the ability to perform under pressure, and manage multiple priorities with competing demands for resources. Strong understanding of human resource management principles, practices, and procedures.
Performance Management: Experience designing effective application support and maintenance processes and advanced technology solutions for driving business outcomes.
Analytical Acumen: Strong skills in collecting, organizing, analyzing, and disseminating information with precision. Experience with systems design and development from business requirements analysis through to day-to-day management.
Communication: Excellent verbal, written, and presentation skills, engaging stakeholders across the enterprise with clarity. Strong negotiating skills (internally and externally). Ability to present ideas in a business-friendly and user-friendly language.

Reporting to: Vice President, Information Technology

Work Schedule: Full-time position working 40 hours per week based on business needs between regular office hours Monday to Friday 9-5 PM. Hybrid, with two days in the office per week.

Location: Our downtown Toronto clinic is conveniently located at 150 York Street, nearby St. Andrew station or a 10-minute walk from Union Station!

Ready to Apply? If you’re ready to make a difference and be part of a company that truly cares about its people, we’d love to hear from you! Apply today and let’s inspire wellness together.

Ready to Apply?

If you’re ready to make a difference and be part of a company that truly cares about its people, we’d love to hear from you! Apply today and let’s inspire wellness together.

Diversity, Equity and Accessibility:

Medcan is dedicated to employment equity, diversity and inclusion. We strive to ensure all staff have a fair opportunity to participate and success at work. If contacted for an employment opportunity, please advise your Talent Acquisition Specialist if you require accommodation.","{""role_summary"":""The Manager of IT Clinic and Corporate Applications leads the planning, implementation, and maintenance of IT solutions, collaborating with business stakeholders to identify cost-effective technology solutions."",""key_terms"":[{""term"":""Application Integration Platform"",""explanation"":""A platform that integrates multiple applications to improve efficiency and reduce costs.""},{""term"":""Cloud and Application Modernization Strategies"",""explanation"":""Approaches to migrate applications to the cloud and modernize them to improve scalability and efficiency.""},{""term"":""Onshore, Nearshore, and Offshore Development and Support Processes"",""explanation"":""Different models for outsourcing software development and support to optimize costs and efficiency.""}],""skill_priorities"":{""must_have"":[""5+ years of experience managing people, including building and leading teams of high-performing IT professionals"",""Post-secondary degree/diploma in Human Resources or a related discipline"",""Experience managing external IT service providers and assessing the risk and cost implications of IT contracts and contract negotiations"",""Experience with onshore, nearshore, and offshore development and support processes"",""Experience in designing, building, transforming, and managing applications in cloud and application modernization strategies""],""nice_to_have"":[""Some experience in strategic planning and execution""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience in managing external IT service providers and assessing the risk and cost implications of IT contracts and contract negotiations?"",""example_answer"":""In my previous role, I managed a team of IT professionals who worked with external service providers. I assessed the risk and cost implications of IT contracts and negotiations, which resulted in a 20% reduction in costs.""},{""question"":""How do you stay current with the latest developments in cloud and application modernization strategies?"",""example_answer"":""I regularly attend industry conferences and read industry publications to stay current with the latest developments in cloud and application modernization strategies.""}],""red_flags"":[""Lack of experience in managing external IT service providers and assessing the risk and cost implications of IT contracts and contract negotiations"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Technical Lead,Randstad Digital,"Mississauga, Ontario, Canada",March,2025,"Technology Lead - ERP /SAP, IAM, Infrastructure (Contract Position)
Number of Positions: 1 Filled: 0 Duration: 15 months
Location: Mississauga, ON, CA
Must be eligible to work in Canada
Hybrid position, 1-2d/w in Mississauga, ON office mandatory

Roles and responsibilities:
Technical Expertise -Serve as a technology expert in the product area and maintains a depth of knowledge in current industry trends for the respective Product business functional area. Guides the team with its technical
deliverables.

Operations & People Management - Manage the day-to-day product activities of the team and integrates work into product backlogs. Ensure proactive and reactive problem management is driven across all the delivery teams. Provide advice and lessons learned, and proactively helps teams improve their ways of working and supporting tools (e.g., Jira). May lead teams in Daily Scrums.

Delivery - Advice and lead product teams on Agile practices, processes, and overall approach to executing product delivery quickly and with quality. Also, leads and coaches the team in DevOps methods and delivery. Raise the performance of product teams through continuous improvement and meeting facilitation.

Design - Advice the team in the development of the solution design based on the business and technology requirements.

Continuous Improvement - Drive improvement using a hypothesis; experimentation; measure; knowledge sharing; and ensure teams are actively seeking out opportunities for improvement. Contribute technical expertise in service of continuously improving applications across their lifecycle and provide ongoing maintenance and support to adapt to changing business requirements. Involved in Release planning &Management.

Stakeholder Engagement & Support - Engage with relevant stakeholders in end-to-end service delivery lifecycle. Ensure the appropriate signoffs are obtained at the correct stage (e.g., Architecture, IT security, infrastructure and Product teams etc.), appropriate operational and support requirements are maintained.

Maintenance & Testing - Ensure the completion of business, technology and operational testing and the definition and optimization of appropriate service maintenance models.

Must skills and experience:
Minimum 10 years of IT experience.
Minimum 5+yrs of technical lead role
Good experience with SAP CDC / Gigya preferred.
Good experience with Identity and Access Management required.
Strong leadership and people management skills.
Solid understanding of the infrastructure and application landscape.
Proven track record in Service, Demand, Change and Release Management.
Excellent understanding and awareness of ITIL processes and tools.
Expert knowledge of concepts and tools behind the design of the relevant area of expertise e.g., business
processes or systems and underlying information technologies.
Business acumen coupled with good understanding and awareness of the technology enabling the Team’s
business functional area.
Negotiation Skills.
Agile or Scrum certification (nice to have).","{""role_summary"":""Lead a team of technical experts in the ERP/SAP, IAM, and Infrastructure domain, ensuring the delivery of high-quality products and services while maintaining a deep understanding of industry trends."",""key_terms"":[{""term"":""ERP"",""explanation"":""Enterprise Resource Planning, a software system that manages and integrates business operations.""},{""term"":""SAP"",""explanation"":""Systems, Applications, and Products in Data Processing, a popular ERP software.""},{""term"":""IAM"",""explanation"":""Identity and Access Management, a system that manages user identities and access to resources.""},{""term"":""DevOps"",""explanation"":""Development and Operations, a set of practices that aims to improve collaboration and efficiency between development and operations teams.""},{""term"":""Agile"",""explanation"":""An iterative approach to project management that emphasizes continuous improvement and flexibility.""},{""term"":""Scrum"",""explanation"":""A framework for implementing Agile principles in project management.""},{""term"":""ITIL"",""explanation"":""Information Technology Infrastructure Library, a set of best practices for IT service management.""}],""skill_priorities"":{""must_have"":[""10+ years of IT experience"",""5+ years of technical lead experience"",""Experience with Identity and Access Management"",""Solid understanding of infrastructure and application landscape"",""Proven track record in Service, Demand, Change and Release Management"",""Excellent understanding and awareness of ITIL processes and tools"",""Expert knowledge of concepts and tools behind the design of the relevant area of expertise"",""Business acumen coupled with good understanding and awareness of the technology enabling the Team's business functional area"",""Negotiation Skills"",""Strong leadership and people management skills""],""nice_to_have"":[""Agile or Scrum certification"",""Experience with SAP CDC / Gigya""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with Identity and Access Management systems?"",""example_answer"":""I have implemented IAM solutions for multiple clients, ensuring secure authentication and authorization processes.""},{""question"":""How do you stay current with industry developments in ERP and SAP?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and engage with peers to stay informed about the latest trends and best practices.""}],""red_flags"":[""Lack of experience with Identity and Access Management"",""Inability to demonstrate strong leadership and people management skills""],""confidence_score"":90.0}"
"Manager, Cloud Technology and Systems",BCIT Computing,"Burnaby, British Columbia, Canada",February,2025,"Bookmark this Posting Print Preview | Apply for this Job

Position Details

Position Information

Position Title Manager, Cloud Technology and Systems Who We Are

At BCIT, putting people at the core of everything we do is paramount. This idea is the foundation of BCIT’s People Vision, which describes the Institute’s goals and priorities in respect to our people. In a complex and uncertain world, it’s vital our people feel valued, supported and connected. BCIT champions a culture of innovation and global progress through people’s imagination and creativity. With a competitive compensation package, great work-life balance, and career advancement opportunities, see why we’ve earned the title of one of BC’s Top Employers for over ten years running.

Position Summary

BCIT’s Information Technology Services department is seeking a regular, full-time (1.0 FTE) Manager, Cloud Technology and Systems. This position participates as a member of the ITS management team, and contributes as a senior member of the Cloud Technology & Infrastructure Services team, assisting in development of strategies, plans and policies. Leads Enterprise Cloud Technology and Enterprise Systems teams in delivery of industry-leading foundation services across the Institute, including cloud technology and architecture, enterprise systems, IaaS management, integration services and identity and access management. Leads cross-functional teams in delivery of user services such as security operations, integration services and monitoring. Provides strategic contribution aimed at driving optimized and secure connectivity and systems for the campus community.

Duties & Responsibilities

Key Accountabilities

Participates as a member of the ITS management team, and contributes as a senior member of the Cloud Technology & Infrastructure Services team, assisting in development of strategies, plans and policies to support the service delivery model and the Institute’s current and future business needs. Develops and implements standards, processes, procedures, tools and metrics.
Develops high performance IT operations teams with capacity to provide state-of-the art support across the Institute. Ensures teams are utilizing optimal techniques, tools and practices to operate technology and software. Fosters an environment of learning, balanced with rapid delivery of quality solutions.
Leads Enterprise Cloud Technology and Enterprise Systems teams in delivery of industry-leading foundation services across the Institute, including cloud technology and architecture, integration services, enterprise systems, and identity and access management.
Manages the delivery of user services such as cloud security operations, linux systems, identity and access management, integration services and monitoring of services. Supports various cross-functional teams across IT services including cyber security operations (SecOps) and their requirements.
Leads the planning and implementation of the enterprise cloud technology and systems roadmap and plans, ensuring the required budget support, associated resources and service ownership. Incorporates improvements, ongoing updates, lifecycle management into roadmaps to ensure currency of plans.
Keeps the Director apprised of relevant issues as they arise and ensures adequate closure in a timely fashion. Collaborates across ITS management to support strategic priorities for BCIT, IT Services and Cloud Technology & Infrastructure Services.
Participates in managing the Institute’s IT infrastructure lifecycle. Develops resource allocation plans and supports project managers by ensuring projects are optimally resourced for success.
Leads support and operations of key ITS service environments, including disaster recovery and high availability. Implements, supports and maintains monitoring capabilities, ensuring computer, storage and cloud service availability, system performance, and intrusion detection.
Collaborates with the other ITS departments to ensure work is aligned with division and Institute objectives, and to foster practices for optimal support of service requests. Delivers project communications and facilitates meetings/workshops to advance technology operations.
Represents the Institute on Provincial committees/initiatives. Undertakes special and ad hoc projects for the advancement of ITS Enterprise Technology portfolio.
Manages staff, overseeing and participating in selection, coaching, mentoring, development, performance management and other people-management practices. Promotes an environment of growth by working with staff to create learning plans, identify training and development opportunities, and ensure the team receives support for growth.

Qualifications

Qualifications & Requirements

Bachelor’s degree in computer science, information systems, business administration or a related field.
Eight years of experience in Enterprise Architecture, System Environment management, software development, network maintenance, technology infrastructure, continuous improvement and leading matrix organizations at progressive levels of responsibility.
An equivalent combination of education and experience may be considered.
Broad knowledge of current and emerging technologies, technology directions and strategic application to business needs; cloud technology adoption, includes familiarity with traditional IT practices, as well as emerging methods such as DevOps and Agile.
Exceptional people management and coaching skills with excellent oral and written communication skills, including the ability to explain technology solutions in business terms, establish rapport and persuade others.
Strong progressive leader and change agent; passionate about delivering high quality projects for ITS clients, with a sharp focus on user impact.
Excellent business acumen and planning skills, with ability to establish processes and manage achievements against key metrics.
Experience working in an Information Technology environment within a large, complex and unionized environment will be preferred.

Additional Information

Benefits – Why You’d Love Working With Us

Competitive pay
Minimum of twenty-five days of vacation
Competitive employer-paid extended health and dental plan including access to a Health Care Spending Account of up to $500 if eligible!
Defined benefit pension plan with employer contributions
Flexible hybrid work arrangements available
Professional Development funds and resources
Access to most BCIT Flexible Learning courses free of charge
Wellness and Employee Assistance programs
Complimentary membership with free access to the Fitness Centre, Gymnasium, and more
For more information on our generous benefits, click here!

BCIT is committed to the principles of equity, diversity & inclusion and to promoting opportunities in hiring for systemically oppressed groups who have been excluded from full participation at BCIT and the larger community. This includes Indigenous Peoples, women, racialized persons, persons with disabilities and those who identify as 2S/LGBTQIA+. All qualified candidates are encouraged to apply; however, Canadian citizens and permanent residents will be given priority.

Persons with disabilities who require accommodation for any part of the application or hiring process should contact RecruitmentAssistant@bcit.ca. Please note that all applications must be submitted via the careers page portal. Email applications will not be accepted.

The British Columbia Institute of Technology acknowledges that our campuses are located on the unceded traditional territories of the Coast Salish Nations of xwməθkwəy̓əm (Musqueam), Sḵwx̱wú7mesh (Squamish), and səl̓ilwətaɁɬ (Tsleil-Waututh).

Position Details

Posting Category Management Salary Range $123,820-$177,992, with a control point of $154,775 per annum Additional Salary Information

The Compensation Range is the span between the minimum and the maximum base salary for a position. The control point of the range represents an employee that possesses full job knowledge, qualifications, and experience for the position. In the normal course, employees will be hired, transferred, or promoted between the minimum and the control point of the salary range for a job, taking internal equity into account. Salaries above the control point may be considered for extenuating circumstances and must be approved by an external governing body.

Department 2 Cloud Tech & Infrastructure Serv Campus Location Burnaby campus Bargaining Unit Management Job Status Regular Full-Time/Part-Time Full-Time Number of Vacancies 1 Anticipated Start Date 04/07/2025 Anticipated End Date

Competition Information

Competition Number 25M191 Competition Open Date 02/05/2025 Competition Close Date Open Until Filled? Yes Quicklink for Posting https://careers.bcit.ca/postings/9258

Supplemental Questions

Required fields are indicated with an asterisk (*).

* What is the highest level of education attained?
GED
High School Diploma
Certificate
Diploma
Associates Degree
Bachelors Degree
Masters Degree
PHD
* How many years of experience do you have in this type of position?
0-1
1-2
3-5
6-9
10+
* All positions at BCIT require on campus presence at the applicable campus location(s). This means the successful candidate must be able to and willing to relocate to the Lower Mainland. Please select from the following that best describes your situation:
I currently reside in the Lower Mainland
I do not currently reside in the Lower Mainland, however I am willing and able to relocate if found to be the successful candidate
I do not currently reside in the Lower Mainland and I am unwilling to relocate
* Given the posted salary range for this position, please indicate your salary expectation should you be the successful candidate for this position. (Open Ended Question)
Documents Needed to Apply

Required Documents

Resume
Cover Letter

Optional Documents","{""role_summary"":""The Manager, Cloud Technology and Systems leads the development of strategies, plans, and policies for cloud technology and systems, and manages the delivery of user services across the Institute."",""key_terms"":[{""term"":""Cloud Technology"",""explanation"":""The use of cloud computing to deliver scalable and on-demand access to a shared pool of computing resources.""},{""term"":""Enterprise Systems"",""explanation"":""Large-scale computer systems that support the operations and management of an organization.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""Agile"",""explanation"":""An iterative approach to project management that emphasizes flexibility and rapid delivery.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in computer science, information systems, or a related field"",""Eight years of experience in Enterprise Architecture, System Environment management, software development, network maintenance, technology infrastructure, continuous improvement and leading matrix organizations"",""Broad knowledge of current and emerging technologies, technology directions and strategic application to business needs""],""nice_to_have"":[""Experience working in an Information Technology environment within a large, complex and unionized environment""]},""proposed_screening_questions_with_answers"":[{""question"":""What experience do you have in leading cross-functional teams in the delivery of user services such as security operations, integration services, and monitoring?"",""example_answer"":""I have led teams in delivering user services such as security operations, integration services, and have experience in monitoring service delivery to ensure high-quality services.""},{""question"":""How do you stay current with emerging technologies and their strategic application to business needs?"",""example_answer"":""I participate in training and development opportunities, attend industry conferences, and network with peers to stay informed about emerging trends and technologies.""}],""red_flags"":[""Lack of experience in leading matrix organizations"",""Inability to explain technology solutions in business terms""],""confidence_score"":90.0}"
"Manager, Technical Operations",Jolera,"Toronto, Ontario, Canada",March,2025,"Who We Are

Jolera offers MSPs & IT solution providers next-generation managed services, enabling them to create world-class experiences for their clients. Our clients receive award-winning solutions built on over 25 years of experience servicing businesses worldwide.

We’ve helped transform hundreds of MSPs & solution providers worldwide! With our collection of tenured experts, we provide an elevated managed service experience for a variety of clients. At Jolera, we treat each MSP partner with specialized care and uniquely organize our products for your individual business needs.

Who You Are

Jolera seeks an energetic and experienced Technical Operations Manager to join our team in a full-time, permanent capacity.

What You Will Do

Provide leadership and oversight to a team of technical resources delivering infrastructure and service delivery projects.
Liaise with clients and internal leadership to manage daily operational aspects and lead high-priority projects.
Ensure all initiatives are effectively managed to guarantee program success.
Maintain the overall health of the program by working with the IT Service Management (ITSM) team for quick and efficient incident resolution.
Improve process performance, efficiency, and productivity to meet business and client needs.
Manage, develop, motivate, and coach technical staff.
Take ownership of outstanding issues and drive them to resolution.
Produce SLA and KPI metrics and reports.
Serve as the point of contact or escalation for support teams regarding client services.
Collaborate with the ITSM team to identify opportunities for improvement based on metrics and data.
Be flexible and willing to take on challenges beyond the job description.
Identify and address potential concerns to maintain a strong environment.


Qualifications

Bachelor’s degree in information technology or a recognized equivalent.
5-10 years of related work experience in a similar role.
Comprehensive knowledge of a broad range of IT services, including Service Desk, NOC, Field Services, and Systems Engineering.
Strong knowledge and experience with system and network architectures.
Ability to make tough decisions confidently.
Strong project management and leadership skills.
Excellent prioritization abilities.
Experience in process development and improvement with a growth mindset.
Experience in a Service Delivery function, dealing with clients, internal teams, and vendors.
Ability to maintain a high level of confidentiality.
Strong interpersonal skills.
Capability to work independently on simple to moderately complex tasks.
Knowledge of IT Infrastructure projects and strategies, preferably gained through various project roles.
Flexibility to work overtime when required.


Preferred Hands-On Experience:

Windows Administration
Linux/UNIX Systems Administration
Network Engineering
Storage Management
Backup & Recovery
Virtualization
ServiceNow


What We Offer

Competitive compensation package
Competitive benefits package
Company Perks, and various brand discounts
Company events, recognitions, and celebrations
Career development and growth opportunities","{""role_summary"":""Lead a team of technical resources to deliver infrastructure and service delivery projects, ensuring program success and improving process performance, efficiency, and productivity."",""key_terms"":[{""term"":""ITSM"",""explanation"":""IT Service Management, a framework for managing IT services to meet business needs.""},{""term"":""NOC"",""explanation"":""Network Operations Center, a central location for monitoring and managing IT networks.""},{""term"":""Service Desk"",""explanation"":""A single point of contact for IT support, managing incidents and service requests.""},{""term"":""SLA"",""explanation"":""Service Level Agreement, a contract defining service quality and responsiveness.""},{""term"":""KPI"",""explanation"":""Key Performance Indicator, a metric measuring business or process performance.""},{""term"":""Virtualization"",""explanation"":""Creating virtual versions of IT resources, such as servers or storage, to improve efficiency.""}],""skill_priorities"":{""must_have"":[""5-10 years of related work experience in a similar role"",""Comprehensive knowledge of a broad range of IT services"",""Strong knowledge and experience with system and network architectures"",""Ability to make tough decisions confidently"",""Strong project management and leadership skills""],""nice_to_have"":[""Windows Administration"",""Linux/UNIX Systems Administration"",""Network Engineering"",""Storage Management"",""Backup & Recovery"",""Virtualization"",""ServiceNow""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with IT service management and how you've improved process performance in previous roles?"",""example_answer"":""In my previous role, I implemented a new ITSM framework, which resulted in a 25% reduction in incident resolution time and a 30% increase in client satisfaction.""},{""question"":""How do you approach project management and leadership, and what strategies do you use to ensure program success?"",""example_answer"":""I use a collaborative approach, working closely with team members and stakeholders to set clear goals and objectives. I also prioritize regular progress updates and adjust plans as needed to ensure successful project delivery.""}],""red_flags"":[""Lack of experience in IT service management or leadership roles"",""Inability to prioritize tasks effectively"",""Poor communication or interpersonal skills""],""confidence_score"":85.0}"
IT Infrastructure Manager,Pollard Banknote Limited,"Winnipeg, Manitoba, Canada",March,2025,"We’re looking for a strategic and proactive IT Infrastructure Manager to join our IT Infrastructure team in Winnipeg.

As the IT Infrastructure Manager, you will lead a team of 12 experts managing a complex, multi-site infrastructure across North America. Overseeing Windows, Linux, networking, and virtualization, you’ll ensure system resilience, security, and high performance. Collaborating with European counterparts, you’ll guide cross-functional teams and maintain strong communication. Success in this role requires strategic leadership, hands-on expertise, and proficiency in budgeting and vendor management, particularly with Microsoft 0365, Palo Alto Networks, and Dell equipment.

Who We Are

At Pollard Banknote Limited, we've been a leader in instant lottery ticket manufacturing and services for over a century, delivering innovation and quality. Our diverse, talented team drives creativity and collaboration. Alongside our traditional products, we lead in digital lottery solutions, enhancing player engagement with cutting-edge technology. Join us in impacting millions of lives with exciting lottery experiences and help shape the future of gaming!

What We Offer

Competitive compensation
Profit sharing program – every role plays a part in our success!
Company Pension
Health & Extended Benefits
Opportunities for professional development
Tuition Reimbursement
On-Site Cafeteria & Outdoor Patio
On Site Gym
A variety of committee-driven employee engagement activities
Free Parking
Hybrid Work Environment

What You'll Do

Lead and manage a team of 12 IT professionals, providing direction, mentorship, and support.
Take ownership of the organization’s IT infrastructure, focusing on Windows, Linux, networking, and virtualization technologies.
Ensure the infrastructure is properly maintained, patched, and aligned with security standards.
Manage vendor relationships and contracts, specifically for Microsoft 0365, Palo Alto Networks, and Dell hardware.
Oversee and manage the IT infrastructure budget, ensuring efficient resource allocation and cost management.
Collaborate with teams across North America and Europe to ensure consistency and best practices in infrastructure management.
Oversee and maintain network security in alignment with industry standards and organizational security policies.
Manage data center operations across multiple North American locations, ensuring uptime, efficiency, and security.
Take a proactive role in monitoring systems, identifying potential issues before they escalate.
Collaborate with development teams in a large-scale development shop to ensure infrastructure needs are met, and the systems can support ongoing projects.
Plan and implement infrastructure projects, upgrades, and migrations with minimal disruption to business operations.
Maintain compliance with industry regulations and best practices for IT infrastructure and security.
Support the organization's long-term IT strategy by researching and recommending new technologies to enhance infrastructure capabilities.

Who You Are

Strategic and hands-on individual who thrives in complex, multi-site IT environments.
Skilled in collaboration and communication, working effectively across teams and geographies.
Proactive in identifying and solving infrastructure challenges while ensuring security and performance.
A supportive leader who mentors and empowers teams to deliver results.

What You'll Bring

Bachelor's degree in Information Technology, Computer Science, or a related field.
5+ years of experience in IT infrastructure management, including Windows, Linux, networking, and virtualization.
Proven experience leading teams and managing large-scale infrastructure environments.
Strong communication skills, with the ability to collaborate effectively with both technical and non-technical stakeholders.
Experience working in or managing large development environments.
In-depth knowledge of security standards and practices.
Experience in multi-site infrastructure management and data center operations.
Proficiency in budgeting and vendor management, particularly with Microsoft 0365, Palo Alto Networks, and Dell equipment.
Ability to take ownership of systems, ensuring they are well-maintained and secure.
Strong problem-solving skills with a proactive approach to identifying and resolving infrastructure issues.

Pollard Banknote Limited is an equal opportunity employer, committed to promoting and maintaining a diverse and inclusive workforce. Reasonable accommodations are available upon request.

Employment is contingent upon a satisfactory response from a Criminal Record Search.","{""role_summary"":""Lead a team of 12 experts to manage a complex, multi-site IT infrastructure across North America, ensuring system resilience, security, and high performance."",""key_terms"":[{""term"":""0365"",""explanation"":""A Microsoft product used for infrastructure management.""},{""term"":""Palo Alto Networks"",""explanation"":""A network security provider used in the organization's infrastructure.""},{""term"":""Dell equipment"",""explanation"":""Hardware used in the organization's infrastructure.""},{""term"":""Virtualization"",""explanation"":""A technology used to manage multiple operating systems on a single physical machine.""},{""term"":""Linux"",""explanation"":""An operating system used in the organization's infrastructure.""},{""term"":""Windows"",""explanation"":""An operating system used in the organization's infrastructure.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in IT infrastructure management"",""Proven experience leading teams and managing large-scale infrastructure environments"",""Strong communication skills"",""In-depth knowledge of security standards and practices"",""Experience in Information Technology, Computer Science, or a related field""],""nice_to_have"":[""Experience working in or managing large development environments"",""Proficiency in budgeting and vendor management""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience in managing a complex, multi-site IT infrastructure?"",""example_answer"":""I have managed a team of 12 experts to ensure system resilience, security, and high performance across North America.""},{""question"":""How do you ensure infrastructure security and compliance with industry regulations?"",""example_answer"":""I maintain compliance with industry regulations and best practices for IT infrastructure and security, and ensure the infrastructure is properly maintained, patched, and aligned with security standards.""}],""red_flags"":[""Lack of experience in IT infrastructure management"",""Inability to lead a team of 12 experts"",""No experience with Microsoft 0365, Palo Alto Networks, and Dell hardware""],""confidence_score"":90.0}"
Manager of Information Technology,Windsor Regional Hospital,"Windsor, Ontario, Canada",February,2025,"VACANCY STATUS: FULL TIME

Position Purpose

The Manager of Information Technology is responsible for overseeing the implementation, integration, and ongoing management of Windsor Regional Hospital’s Information Systems. This role ensures that these systems meet the needs of WRH, improve patient care, and ensures adherence to governance and security standards. The Manager will work closely with TransForm, a shared service organization, to align strategies and operations across five hospitals in the region. Collaboration with these hospitals is essential to improve system issues, policies and procedures.

There are no direct reports

Duties And Responsibilities

Represent WRM in all respects with TransForm (TSSO) account management to ensure the Information Technology needs of WRH are delivered in a timely manner within established budgeted Capital and Expense limits.
Identify and coordinate via hospital leadership all WRH IT ongoing and new project and service needs including provincially mandated requirements.
Within WRH, Implement security frameworks, conduct risk assessments, vulnerability assessments and incident response planning.
Development of internal information security polices, with
Ensure training and compliance of all security polices and governance. Coordinate and implement WRH wide audit requirements
Provide TransForm with updates on key hospital led initiatives and their status changes, through regular scheduled meetings with the account manager.
Participation in regional committees such as Regional Intake Committee (RIC), Regional Change Management and Adoption Team (RCMAT), and Regional Data Governance. This would include bringing any TransForm produced materials, requests for action, dissemination, or request for decision, and follow up within the hospital to achieve the necessary response back to TransForm.
Coordinate the prioritization, awareness, identification of accountability and responsibility for all Intake requests and/or Projects.
Responsible for monitoring all initiatives, engagement for intake submission process and reporting internally to key stakeholders and executives within WRH.
Serve as the site operational lead for all IS projects working in partnership with TransForm Shared Service Organization (TransForm), Mohawk Medbuy (MMC), hospitals in Erie St. Clair (ESC), provincial partners, and vendors. The role provides collaborative oversight for the coordination of digital services, including systems and infrastructure at WRH.
Other duties as assigned.

Skills/Capabilities

Strong knowledge of clinical workflows and healthcare regulations.

Proven experience in project management and stakeholder engagement.

Experience in establishing and maintaining relationships with technology vendors, ensuring service level agreements are met and managing vendor performance

In-depth understanding of cloud computing concepts and technologies

French Language proficiency an asset

Qualifications

Bachelor’s degree in Information Technology with a preference in Health Informatics, Information Technology, Healthcare Management, or a related field.

Minimum of 10 years Leadership comprising of Service Desk, Networking/Infrastructure and Security/GRC (Governance Risk and Compliance)

Cybersecurity experience implementing

Certified Professional in Healthcare Information and Management Systems – Canada (CPHIMS-CA) preferred

#yqg

Windsor Regional Hospital is an equal opportunity employer. In accordance with the Accessibility for Ontarians with Disabilities Act, 2005, upon request, accommodation will be provided by WRH throughout the recruitment, selection and/or assessment process to applicants with disabilities.","{""role_summary"":""The Manager of Information Technology oversees the implementation, integration, and ongoing management of Windsor Regional Hospital's Information Systems, ensuring they meet the hospital's needs, improve patient care, and adhere to governance and security standards."",""key_terms"":[{""term"":""Governance Risk and Compliance (GRC)"",""explanation"":""A framework for managing an organization's overall governance, risk, and compliance with regulations and standards.""},{""term"":""Cloud computing concepts and technologies"",""explanation"":""The use of remote servers accessed over the internet to store, manage, and process data, rather than local computers or servers.""},{""term"":""Cybersecurity experience implementing"",""explanation"":""Practical knowledge of protecting computer systems, networks, and sensitive information from unauthorized access, use, disclosure, disruption, modification, or exploitation.""},{""term"":""Certified Professional in Healthcare Information and Management Systems – Canada (CPHIMS-CA)"",""explanation"":""A professional certification demonstrating expertise in healthcare information and management systems in Canada.""}],""skill_priorities"":{""must_have"":[""Strong knowledge of clinical workflows and healthcare regulations"",""Proven experience in project management and stakeholder engagement"",""Experience in establishing and maintaining relationships with technology vendors"",""In-depth understanding of cloud computing concepts and technologies""],""nice_to_have"":[""French Language proficiency"",""Certified Professional in Healthcare Information and Management Systems – Canada (CPHIMS-CA)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with project management and stakeholder engagement in a healthcare setting?"",""example_answer"":""I have managed multiple projects in healthcare, ensuring effective communication with stakeholders, including clinicians, vendors, and hospital leadership.""},{""question"":""How do you stay current with healthcare regulations and clinical workflows?"",""example_answer"":""I regularly review industry publications, attend conferences, and participate in professional organizations to stay informed about regulatory changes and best practices in healthcare.""}],""red_flags"":[""Lack of experience in healthcare IT project management"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Incident Manager,Hatched Recruitment Group,"Montreal, Quebec, Canada",March,2025,"Incident Manager (3 Positions) – Montreal Airport
Location: Montreal, QC (On-site)
Language Requirement: French
Citizenship: Must be a Canadian Citizen
Availability: On-call required

Role Overview:
We are seeking three experienced Incident Managers to oversee and coordinate critical Networking/Server/Storage incident management at Montreal-Trudeau International Airport (YUL). The role involves managing and monitoring IT infrastructure incidents, ensuring efficient resolution, and maintaining service level commitments across multiple business processes and vendor applications.

Key Responsibilities:
Incident Coordination: Oversee all activities related to critical incidents, ensuring swift and effective resolution.
Process Management: Manage, coordinate, and monitor daily activities related to the Incident Management process within the assigned service domain.
Workload Balancing: Assign resources efficiently to meet service level agreements.
Escalation & Resolution: Identify incidents at risk of missing SLAs, escalate as needed, and drive resolution efforts.
Stakeholder Liaison: Act as the primary interface for the Process Account Lead and High Priority Incident Manager.
Performance Management: Monitor and evaluate team performance to ensure adherence to incident management processes.
Service Delivery Oversight: Track service performance for all customers supported within the environment.
Data Analysis: Analyze process efficiency and delivery metrics to drive improvements.

Environment & Scope:
The role involves supporting critical IT infrastructure and business processes, including:
Server management, storage, backup/recovery, disaster recovery, Active Directory, database management, and web servers.
Over 100 vendor applications used within the airport environment.
Coordination with SITA Global Services (SGS) for the management of SITA kiosks at YUL, ensuring communication with key stakeholders.

Qualifications & Requirements:
Prior experience in major incident management and IT service delivery.
Strong understanding of IT infrastructure and airport technology environments.
Ability to work on-call and respond to high-priority incidents as needed.
Fluency in French is required.
Must be a Canadian Citizen due to security and compliance requirements.","{""role_summary"":""Oversee and coordinate critical Networking/Server/Storage incident management at Montreal-Trudeau International Airport, ensuring efficient resolution and maintaining service level agreements."",""key_terms"":[{""term"":""Incident Management"",""explanation"":""The process of identifying, containing, and resolving IT incidents to minimize business impact.""},{""term"":""SLA (Service Level Agreement)"",""explanation"":""A formal agreement between IT and its customers that define the service quality, responsiveness, and resolution targets.""},{""term"":""SITA kiosks"",""explanation"":""Self-service kiosks used at airports for check-in, baggage tagging, and other passenger services.""}],""skill_priorities"":{""must_have"":[""Prior experience in major incident management and IT service delivery"",""Strong understanding of IT infrastructure and airport technology environments"",""Fluency in French"",""Ability to work on-call and respond to high-priority incidents as needed""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with incident management in a critical IT infrastructure environment?"",""example_answer"":""In my previous role, I managed a team that resolved critical incidents within 2 hours, resulting in a 30% reduction in downtime.""},{""question"":""How do you ensure effective communication with stakeholders during high-priority incidents?"",""example_answer"":""I prioritize clear and concise communication, ensuring that stakeholders are informed of incident status and resolution timelines.""}],""red_flags"":[""Lack of experience in airport technology environments"",""Inability to work on-call and respond to high-priority incidents as needed""],""confidence_score"":90.0}"
IT Applications Manager,Visier Inc.,"Vancouver, British Columbia, Canada",March,2025,"Visier is the leader in people analytics and we believe in a 'people-first' approach to business strategy. Our innovative technology transforms the way that organisations make decisions, allowing them to elevate their employees and drive better business outcomes. Embarking on an exciting new chapter in our growth story, we are looking for talented individuals who can help both Visier and our customers grow, evolve and win!

Visier Inc. is seeking a highly motivated and strategic IT Applications Manager to lead the architecture, development, and execution of our application enablement roadmap. This role is crucial in ensuring Visier's internal use of cloud applications are robust, scalable, and aligned with our evolving business needs. You will be a key driver in shaping the future of our internal application ecosystem, fostering innovation, and maximizing the value derived from our technology investments.

What You’ll Be Doing…

Strategic Roadmap Development:

Develop and maintain a comprehensive, multi-year strategic roadmap for application enablement, aligned with Visier's overall business objectives.
Conduct thorough assessments of current application landscape, identifying gaps, opportunities, and areas for improvement.
Collaborate with stakeholders across departments (e.g., Engineering, Product, Finance, HR) to understand their application needs and translate them into actionable plans.
Research and evaluate emerging technologies and industry best practices to inform roadmap development.

Application Architecture & Design:

Define and enforce application architecture standards, ensuring scalability, security, and maintainability.
Lead the design and implementation of application integrations and data flows.
Evaluate and select appropriate application platforms and technologies.
Ensure applications are designed to support business continuity and disaster recovery requirements.

Team Leadership & Collaboration:

Provide technical leadership and mentorship to application development and support teams.
Foster a collaborative and innovative work environment.
Communicate effectively with stakeholders at all levels of the organization.
Manage projects, budgets and timelines.

Security and Compliance:

Ensure all applications adhere to security and compliance standards, including data privacy regulations.
Implement and maintain security best practices for application development and deployment.
Participate in security audits and risk assessments.

What You’ll Bring To The Table…

Bachelor's degree in Computer Science, Information Technology, or a related field.
Proven experience (5+ years) as an IT Applications Manager or similar role.
Strong understanding of application architecture, design, and development principles.
Experience with a variety of application technologies, including cloud-based solutions, SaaS, and on-premise systems.
Excellent analytical, problem-solving, and decision-making skills.
Strong communication, interpersonal, and leadership skills.
Experience managing IT projects and budgets.
Relevant certifications (e.g., ITIL, PMP) are a plus.
The ideal candidate will have significant experience with ServiceNow.

Most importantly, you share our values...

You roll up your sleeves
You make it easy
You are proud
You never stop learning
You play to win

The base pay range for this position in Canada is $93k - 139k / year + commission/bonus

The compensation offered will be determined by factors such as relevant qualifications, experience, knowledge and skills. Many of our positions are eligible for additional types of compensation (e.g., commission plans, bonus, etc.) which our Talent Acquisition team will share with you if you interview for the role.

See the #VisierLife in action

Instagram - @visierlife

Linkedin - https://www.linkedin.com/company/visier-analytics/

Visier Candidate Privacy Notice and Recruiter Policy","{""role_summary"":""Lead the architecture, development, and execution of application enablement roadmap, ensuring Visier's internal use of cloud applications are robust, scalable, and aligned with evolving business needs."",""key_terms"":[{""term"":""Application Enablement"",""explanation"":""The process of developing and implementing applications to support business needs.""},{""term"":""Cloud Applications"",""explanation"":""Software applications that are hosted and delivered over the internet.""},{""term"":""Scalability"",""explanation"":""The ability of an application to handle increased workload or user demand without compromising performance.""},{""term"":""Security and Compliance"",""explanation"":""The process of ensuring applications adhere to security standards, data privacy laws, and industry regulations.""}],""skill_priorities"":{""must_have"":[""Proven experience as an IT Applications Manager or similar role"",""Strong understanding of application architecture, design, and development principles"",""Experience with a variety of application technologies, including cloud-based solutions, SaaS, and on-premise systems"",""Excellent analytical, problem-solving, and decision-making skills"",""Strong communication, interpersonal, and leadership skills""],""nice_to_have"":[""Relevant certifications (e.g., ITIL, PMP)"",""Significant experience with ServiceNow""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with application architecture and design?"",""example_answer"":""I have designed and implemented multiple application integrations, ensuring scalability and security.""},{""question"":""How do you stay current with emerging technologies and industry best practices in application development?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and conduct research to stay informed.""}],""red_flags"":[""Lack of experience with cloud-based solutions"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Information Technology Audit Manager,Akkodis,"Toronto, Ontario, Canada",March,2025,"Job Title: IT Audit Manager
Candidate Summary:
We are seeking an experienced IT Audit Manager with over 15 years of expertise in IT governance, data governance, and internal audit within the financial services industry. This candidate has a proven track record of delivering independent assurance on the design and operation of IT systems, internal controls, and data governance practices, ensuring compliance with evolving regulatory frameworks.

Key Responsibilities:
Provide senior-level support for IT governance and data governance audits, collaborating with senior leaders to ensure effective audit planning, reporting, and issue remediation.
Engage with key stakeholders including Director, US Functions IT, Managing Director US IT, and Deputy US CAE to provide updates on audit findings and track open audit issues.
Coordinate responses to US regulatory examinations, working with external auditors and regulators such as FRBNY, OCC, SEC, and FINRA to address and verify regulatory issues.
Develop and implement audit approaches for IT and data governance, ensuring adequate coverage of emerging risks, proprietary technologies, and compliance needs.
Collaborate with Risk Management and Compliance teams to assess and enhance risk management strategies across platforms.
Lead efforts to shift the organization toward a predictive insights-driven approach, enhancing the data analysis capabilities and tools within the audit function.

Qualifications:
Bachelor’s Degree in a relevant field.
Over 15 years of experience in IT governance, data governance, and internal audit, with a strong focus on financial services.
In-depth understanding of IT risks, audit methodologies, and regulatory compliance across Capital Markets, Retail/Commercial Banking, and Enterprise Applications.
Proven ability to engage with senior stakeholders, influence audit strategy, and drive successful issue remediation.
Extensive experience with regulatory bodies such as FRBNY, OCC, SEC, and FINRA.
Excellent communication skills with a focus on relationship-building, problem-solving, and delivering impactful insights.

Preferred Qualifications:
5+ years of experience in IT Internal Audit.
Professional certifications in audit or technology (e.g., CISA, CISSP).

Why Join Us?
As an IT Audit Manager, you will play a critical role in shaping and executing the audit strategy for IT and data governance, ensuring compliance with regulatory standards and strengthening internal controls. This position offers the opportunity to work with senior leaders and make a tangible impact on the organization’s risk management strategies, driving security, productivity, and competitive advantage through data-driven insights.","{""role_summary"":""Lead IT audit and governance efforts, ensuring regulatory compliance and driving data-driven insights to strengthen internal controls and risk management strategies."",""key_terms"":[{""term"":""IT governance"",""explanation"":""The process of overseeing and managing an organization's IT systems, policies, and procedures to ensure effective use of IT resources.""},{""term"":""Data governance"",""explanation"":""The process of managing and overseeing an organization's data assets to ensure quality, security, and compliance requirements.""},{""term"":""Internal audit"",""explanation"":""An independent evaluation of an organization's internal controls, risk management, and governance processes to ensure compliance with laws and regulations.""},{""term"":""Regulatory frameworks"",""explanation"":""A set of rules, laws, and guidelines that govern an industry or sector, such as financial services.""}],""skill_priorities"":{""must_have"":[""15+ years of experience in IT governance, data governance, and internal audit"",""In-depth understanding of IT risks, audit methodologies, and regulatory compliance"",""Proven ability to engage with senior stakeholders, influence audit strategy, and drive successful issue remediation""],""nice_to_have"":[""5+ years of experience in IT Internal Audit"",""Professional certifications in audit or technology (e.g., CISA, CISSP)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience in developing and implementing audit approaches for IT and data governance?"",""example_answer"":""I have developed and implemented audit approaches for IT and data governance in my previous role, ensuring adequate coverage of emerging risks and compliance needs.""},{""question"":""How do you stay current with evolving regulatory frameworks and ensure compliance in your audit work?"",""example_answer"":""I regularly review regulatory updates and attend industry conferences to stay current, and I ensure compliance by collaborating with senior stakeholders and regulators.""}],""red_flags"":[""Lack of experience in IT internal audit"",""Inability to engage with senior stakeholders""],""confidence_score"":90.0}"
Technology Lead,MSZ Systems,"Toronto, Ontario, Canada",March,2025,"Location:- Montreal OR Toronto, Canada

Relevant:
5+ years of experience in pipeline design and development (Batch and Streaming) using Azure/snowflake cloud services, primarily on Azure Datalake Gen2, Azure Data Factory, Azure Event Hub, Databricks, and Snowflake.
 Must Skills:
Databricks, Snowflake, Pyspark, SQL, Data Modeling
 Responsibilities:
Excellent communication, work closely with Customer
Expertise in above skills
Complete the user stories in the assigned sprint, highlight the risks at right time
 JD:
Collaborate with stakeholders to understand requirements, data solutions, data models and mapping documents.
Lead the design, development, and implementation of data solutions using Azure Data Lake Storage (ADLS), Azure Data Factory, Event Hub, Databricks, and Snowflake.
Oversee the end-to-end data pipeline, ensuring data quality, integrity, and security.
Lead the deployment activities including the Dev test approval, PR approval, Collaboration with DevOps team, Release mgmt. for deployment into all environments including production and provide knowledge sharing to Data operations team
Assist data analysts with technical input.
Provide data engineering inputs to the data solution architect.
Lead the effort estimates/story point estimates for the sprint.
Mentor and guide a team of data engineers.
Foster a collaborative environment to encourage knowledge sharing and continuous improvement.
Conduct code reviews and ensure adherence to coding standards and best practices.","{""role_summary"":""Lead the design, development, and implementation of data solutions using Azure cloud services, ensuring data quality, and collaborating with stakeholders."",""key_terms"":[{""term"":""Azure Datalake Gen2"",""explanation"":""A cloud-based data storage solution for storing and processing large amounts of data.""},{""term"":""Azure Data Factory"",""explanation"":""A cloud-based data integration service for creating, scheduling, and managing data pipelines.""},{""term"":""Azure Event Hub"",""explanation"":""A cloud-based event streaming service for ingesting and processing large volumes of events.""},{""term"":""Databricks"",""explanation"":""A cloud-based Apache Spark platform for data engineering, data science, and data analytics.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and analyzing large amounts of data.""},{""term"":""Pyspark"",""explanation"":""A Python library for Apache Spark, used for data processing and analytics.""},{""term"":""Data Modeling"",""explanation"":""The process of creating conceptual representations of data structures and relationships.""}],""skill_priorities"":{""must_have"":[""Databricks"",""Snowflake"",""Pyspark"",""SQL"",""Data Modeling""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design a data pipeline using Azure Data Factory and Azure Datalake Gen2?"",""example_answer"":""I would start by understanding the business requirements and then design a pipeline that leverages Azure Data Factory for data integration and Azure Datalake Gen2 for data storage and processing.""},{""question"":""How do you ensure data quality and integrity in a data pipeline?"",""example_answer"":""I would implement data validation and data quality checks at each stage of the pipeline, and also perform regular data audits to ensure data accuracy and completeness.""}],""red_flags"":[""Lack of experience with Azure cloud services"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Senior Manager - IT /Cloud FinOps and Governance,Kaleris,"British Columbia, Canada",March,2025,"Job Description

Senior Manager - IT /Cloud FinOps and Governance – Job Description

Job Title: Senior Manager - IT /Cloud FinOps and Governance

Location: Canada

Company: Kaleris

About Us: Kaleris is a leading provider of transportation and asset management software for accelerated supply chain execution. Kaleris delivers leading cloud-based transportation and asset management solutions to accelerate supply chain execution for industrial and finished goods shippers and carriers to connect logistics and inventory at yards, terminals, and distribution centers and manage shipments via rail, truck, and multi-mode transportation.

Job Summary: We are seeking a highly skilled and experienced Senior Manager to lead our IT and Cloud FinOps and Governance team. The ideal candidate will have a strong background in financial operations, cloud cost management, and IT governance. This role is critical in ensuring the efficient and effective use of cloud resources, optimizing costs, and maintaining robust governance frameworks.

Key Responsibilities

Lead and manage the IT/Cloud FinOps and Governance team.
Develop and implement strategies for cloud cost optimization and financial management.
Establish and maintain governance frameworks to ensure compliance with industry standards and best practices.
Collaborate with cross-functional teams to align cloud financial operations with business objectives.
Monitor and analyze cloud spending, identifying opportunities for cost savings and efficiency improvements.
Provide regular reports and insights to senior leadership on cloud financial performance and governance.
Drive continuous improvement initiatives in cloud financial operations and governance processes.
Stay up-to-date with industry trends and advancements in cloud technology and financial operations.

Qualifications

Bachelor's degree in Finance, Information Technology, or a related field. A Master's degree or relevant certifications (e.g., FinOps Certified Practitioner, AWS Certified Solution Architect - Associate) is a plus.
Minimum of 7-10 years of experience in IT operations, cloud operations/management, and governance.
Strong understanding of cloud platforms (e.g., AWS, Azure, Google Cloud) and their financial management tools.
Proven track record of leading and managing teams.
Excellent analytical, problem-solving, and decision-making skills.
Strong communication and interpersonal skills, with the ability to collaborate effectively with stakeholders at all levels.
Experience with financial reporting and analysis tools.

Knowledge of industry standards and best practices in IT governance

Kaleris is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.","{""role_summary"":""Lead and manage the IT/Cloud FinOps and Governance team, ensuring efficient and effective use of cloud resources, optimizing costs, and maintaining robust governance frameworks."",""key_terms"":[{""term"":""FinOps"",""explanation"":""Financial Operations, focusing on cloud cost management.""},{""term"":""Cloud Governance"",""explanation"":""Establishing and maintaining frameworks to ensure compliance with industry standards and best practices.""},{""term"":""Cloud Cost Optimization"",""explanation"":""Identifying opportunities for cost savings and efficiency improvements in cloud spending.""}],""skill_priorities"":{""must_have"":[""Strong background in financial operations"",""Cloud cost management"",""IT governance""],""nice_to_have"":[""Master's degree or relevant certifications (e.g., FinOps Certified Practitioner, AWS Certified Solution Architect - Associate)"",""Experience with financial reporting and analysis tools""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with cloud cost optimization and financial management?"",""example_answer"":""I have successfully implemented strategies for cloud cost optimization, resulting in significant cost savings and efficiency improvements.""},{""question"":""How do you stay up-to-date with industry trends and advancements in cloud technology and financial operations?"",""example_answer"":""I regularly attend industry conferences, and participate in online forums and training sessions to stay current with the latest developments.""}],""red_flags"":[""Lack of experience in leading and managing teams"",""Inability to communicate effectively with stakeholders at all levels""],""confidence_score"":90.0}"
Cloud DevOps Engineer,Techedin,Canada,March,2025,"We are seeking a talented and experienced Cloud DevOps Engineer with a strong background in cloud technologies, particularly AWS/GCP, to join our dynamic and innovative team. The ideal candidate will play a critical role in designing, developing, and maintaining scalable, secure, and highly reliable cloud-based solutions. This role offers the opportunity to collaborate with cross-functional teams, mentor peers, and make impactful decisions in a fast-paced, customer-oriented environment.

Responsibilities

Work with the Infrastructure and Engineering teams to maintain products, keeping them secure, bug-free and compliant with platform policies
Support our Customer Success team to troubleshoot customer issues and fix/patch software as needed
Familiarize yourself with end-to-end architecture for both products. Reverse engineer and document system architecture which can be shared across the team
Manage cloud infrastructure and drive DevOps best practices for maintaining our CI/CD pipeline for these products
Perform regular patching, security updates and performance tuning of software products

Minimum Qualifications

BS Degree in Computer Science or similar
5+ years' experience in software development
Experience with full stack models, services, and cloud deployment
Comfortable with GCP or AWS, and proficient in either one
Comfortable with understanding full stack software using Go, JavaScript, and React
Proficiency in Databases, specifically NoSQL like DynamoDB and MongoDB
Comfortable with C# for desktop applications
Experience with either Jenkins or BuildKite
Experience with DevOps tools like – Docker, Terraform, Linux
Proficient in Git and GitHub knowledge
Excellent communication skills
Ability to be a self-starter

Preferred Qualifications

Proficiency in gRPC and Protobuf
Basic game engine experience with Unity
Experience with TestFlight
Knowledge of installers
Knowledge of Electron","{""role_summary"":""Design, develop, and maintain scalable, secure, and highly reliable cloud-based solutions, collaborating with cross-functional teams and mentoring peers."",""key_terms"":[{""term"":""Cloud technologies"",""explanation"":""Refers to the use of cloud-based services and infrastructure to build and deploy applications.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""CI/CD pipeline"",""explanation"":""A set of automated processes that integrate code changes into a larger system, ensuring continuous integration and delivery.""},{""term"":""Full stack"",""explanation"":""Refers to the development of all layers of an application, from the front-end user interface to the back-end server-side logic and database integration.""},{""term"":""gRPC"",""explanation"":""A high-performance RPC framework for building scalable and efficient APIs.""},{""term"":""Protobuf"",""explanation"":""A data serialization format used for communication between services and APIs.""}],""skill_priorities"":{""must_have"":[""Experience with cloud technologies (AWS/GCP)"",""Proficiency in DevOps tools (Docker, Terraform, Linux)"",""Experience with full stack development (Go, JavaScript, React)"",""Proficiency in Databases (NoSQL, DynamoDB, MongoDB)""],""nice_to_have"":[""Proficiency in gRPC and Protobuf"",""Basic game engine experience with Unity"",""Experience with TestFlight"",""Knowledge of installers"",""Knowledge of Electron""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing and implementing a scalable cloud-based solution?"",""example_answer"":""I would start by assessing the requirements and identifying the most suitable cloud provider, then design a scalable architecture, and finally implement it using DevOps best practices.""},{""question"":""Can you explain the importance in a CI/CD pipeline?"",""example_answer"":""A CI/CD pipeline ensures that code changes are automatically built, tested, and deployed to production, reducing errors and improving efficiency.""}],""red_flags"":[""Lack of experience with cloud technologies (AWS/GCP)"",""Inability to work with full stack development""],""confidence_score"":90.0}"
DevOps Infrastructure Engineer,Techedin,"Calgary, Alberta, Canada",March,2025,"We are seeking a talented and experienced DevOps Infrastructure Engineer with a strong background in cloud technologies, particularly AWS/GCP, to join our dynamic and innovative team. The ideal candidate will play a critical role in designing, developing, and maintaining scalable, secure, and highly reliable cloud-based solutions. This role offers the opportunity to collaborate with cross-functional teams, mentor peers, and make impactful decisions in a fast-paced, customer-oriented environment.

Responsibilities

Work with the Infrastructure and Engineering teams to maintain products, keeping them secure, bug-free and compliant with platform policies
Support our Customer Success team to troubleshoot customer issues and fix/patch software as needed
Familiarize yourself with end-to-end architecture for both products. Reverse engineer and document system architecture which can be shared across the team
Manage cloud infrastructure and drive DevOps best practices for maintaining our CI/CD pipeline for these products
Perform regular patching, security updates and performance tuning of software products

Minimum Qualifications

BS Degree in Computer Science or similar
5+ years' experience in software development
Experience with full stack models, services, and cloud deployment
Comfortable with GCP or AWS, and proficient in either one
Comfortable with understanding full stack software using Go, JavaScript, and React
Proficiency in Databases, specifically NoSQL like DynamoDB and MongoDB
Comfortable with C# for desktop applications
Experience with either Jenkins or BuildKite
Experience with DevOps tools like – Docker, Terraform, Linux
Proficient in Git and GitHub knowledge
Excellent communication skills
Ability to be a self-starter

Preferred Qualifications

Proficiency in gRPC and Protobuf
Basic game engine experience with Unity
Experience with TestFlight
Knowledge of installers
Knowledge of Electron","{""role_summary"":""Design, develop, and maintain scalable, secure, and highly reliable cloud-based solutions, collaborating with cross-functional teams and making impactful decisions in a fast-paced, customer-oriented environment."",""key_terms"":[{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and speed up the release of new software features.""},{""term"":""Cloud technologies"",""explanation"":""On-demand access to a shared pool of computing resources, such as servers, storage, and applications, over the internet.""},{""term"":""CI/CD pipeline"",""explanation"":""A series of automated processes that integrate code changes from development to deployment, ensuring faster and more reliable delivery of software applications.""},{""term"":""Full stack"",""explanation"":""A comprehensive understanding of all layers of a technology stack, including front-end, back-end, and database.""},{""term"":""NoSQL"",""explanation"":""A type of database that does not use the structured query language (SQL) to manage and store data, often used for handling large amounts of unstructured or semi-structured data.""}],""skill_priorities"":{""must_have"":[""Experience with full stack models, services, and cloud deployment"",""Proficiency in either GCP or AWS"",""Experience with DevOps tools like Docker, Terraform, Linux"",""Proficiency in Git and GitHub knowledge"",""Excellent communication skills""],""nice_to_have"":[""Proficiency in gRPC and Protobuf"",""Basic game engine experience with Unity"",""Experience with TestFlight"",""Knowledge of installers"",""Knowledge of Electron""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach designing a scalable and secure cloud-based architecture?"",""example_answer"":""I would start by identifying the requirements of the application and then design a multi-layered architecture that incorporates load balancing, auto-scaling, and security best practices.""},{""question"":""How do you stay up-to-date with the latest developments in cloud technologies and DevOps tools?"",""example_answer"":""I regularly follow industry blogs and attend webinars to stay current with the latest trends and advancements in cloud technologies and DevOps tools.""}],""red_flags"":[""Lack of experience with cloud technologies, particularly GCP or AWS"",""Inability to communicate technical concepts effectively""],""confidence_score"":90.0}"
Cloud Operations Engineer,iTmethods,"Toronto, Ontario, Canada",March,2025,"Who we are
iTMethods has grown to become a market leader in enabling Enterprise DevOps. Our&#8239;Managed DevOps&#8239;SaaS Platform enables global enterprises to securely integrate, migrate, and modernize their complex, multi-cloud, multi-vendor DevOps environments leveraging our partnerships with industry leaders like: Atlassian, CloudBees, GitHub, GitLab, Sonatype and Jenkins. iTMethods helps companies build better software, faster and more securely. We play a critical role in helping organizations capitalize on their growth opportunities by using DevOps to accelerate their pace of innovation.
We're a Canadian company with headquartersin Toronto and havea flexible work policy that willallowus to grow our team remotely. We offer the excitement and agility of a start-up and the security of a profitable, well-established company serving fortune 500 clients.Every day, everyone at iTMstrives to be an active part of the best DevOps platform and delivery teams our clients have ever worked with. We ask for your ideas, expertise, and commitment. In return, we give you access to intelligent people, an opportunity to further your knowledge, and the chance to build innovation for the real world.
The Opportunity
Reporting to the Director of Platform Operations, we are adding a Cloud Operations Engineer to the team. In this position, you will play a critical role in eliminating vulnerabilities and optimizing uptime for our enterprise clients by implementing resilient and robust solutions leveraging automation for fault detection and a laser focus on automatically recovering when a fault is detected and continuously looking to deploy solutions which avoid previously identified faults from being generated.
Responsibilities
Address root causes and identify solutions. You will focus on problem-solving, automation, and ensuring a sustained focus on engineering. You will:
Architect and implement monitoring alarms and logging solutions
Identify issues proactively, and mitigate them to improve the customer experience
Audit, test, and review solutions to ensure we deliver a resilient, monitored, highly secure, and complete solution
Demand forecasting and capacity planning. You will create and maintain good visibility of the demand for AWS resources, planning, and usage. You will plan and execute efficient use of resources
Optimize through automation. You will eliminate manual, repetitive, tactical solutions with no enduring value. You will implement automation for a more sustained and scalable solution, services, and processes, contributing to the continuous improvement of all operations to efficiently manage and maintain deployments
Plan and deploy upgrade, configuration changes and security patches
Drive continuous improvement. You will research and implement best practices in DevOps. You will explore and evaluate new and emerging software tools and technologies
Be on call on a rotation basis
Take ownership of not only your deliverables but the platform and drive resiliency on the platform as per an SRE mindset
Be hands-on. You will:
Assist in the configuration and support of customer environments
Code deployments, optimization, and various tools
Troubleshoot and resolve escalated software and infrastructure-related issues and challenges, acting as a customer-facing escalation point
Review new tools and software prior to implementation
Qualifications
Education/qualifications and experience You have a Bachelor's Degree in Computer Science, Computer Engineering, Software Engineering, and preferably certification in AWS, Ansible and Terraform and have worked on DevOps tools Git and Jenkins
Exceptional communication and problem solving skills
Have worked with collaboration tools like Jira, Confluence and Jira ServiceDesk
You’re driven, collaborative and motivated.You thrive on developing solutions to open-ended business problems
Ability to write code
Passion for automation and efficiency
Ability to work autonomously and as part of a team
Our Commitment to You
Flexible work environment
Competitive compensation and benefits package
Learning and Development
Career Progression
Culture – One team environment founded on respect and collaboration where we do not take shortcuts and are customer obsessed
Join us
Apply here or learn more on ourwebsite,MediumorLinkedIn.
iTMethods is committed to fostering an inclusive and accessible environment where employees feel valued and respected, and where every employee has the opportunity to realize their potential. We are committed to providing reasonable accommodations, if required, and will work with you to meet your needs.
Powered by JazzHR
f1Au1Ufnr4","{""role_summary"":""Cloud Operations Engineer responsible for ensuring uptime and eliminating vulnerabilities for clients by implementing resilient solutions, automating fault detection, and continuously improving solutions."",""key_terms"":[{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and speed up the pace of innovation.""},{""term"":""SRE mindset"",""explanation"":""A way of thinking that focuses on building and maintaining scalable, reliable, and resilient systems, taking ownership of the platform and driving resiliency.""},{""term"":""Automation"",""explanation"":""The use of technology to perform tasks without human intervention, improving efficiency and reducing manual errors.""}],""skill_priorities"":{""must_have"":[""AWS"",""Ansible"",""Terraform"",""Git"",""Jenkins"",""Jira"",""Confluence"",""Jira ServiceDesk"",""Problem-solving skills"",""Communication skills"",""Automation""],""nice_to_have"":[""Certification in AWS, Ansible, and Terraform"",""Experience with DevOps tools""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach automating fault detection and recovery in a cloud-based environment?"",""example_answer"":""I would use tools like Ansible and Terraform to automate the deployment of monitoring alarms and logging solutions, and implement automation for fault detection and recovery.""},{""question"":""How do you stay up-to-date with the latest developments in DevOps and cloud computing?"",""example_answer"":""I regularly research and evaluate new and emerging software tools and technologies, and participate in online communities and forums to stay informed.""}],""red_flags"":[""Lack of experience with AWS, Ansible, and Terraform"",""Inability to write code"",""Poor problem-solving skills""],""confidence_score"":90.0}"
DevOps Engineer,stakefish,Canada,February,2025,"As our DevOps Engineer, you will be helping us build and maintain blockchain networks and protocols. You will work on improving our current infrastructure including security, automation, and monitoring among other things. You will also have the chance to dive deep into new blockchain protocols, run testnets, build secure and scalable infra and maintain it.

What will you do?

Build secure and reliable infrastructure to monitor, detect and mitigate performance and security issues
System administration activities for Linux servers, which includes routine, proactive daily management of the health, stability, and availability of system infrastructure
Create and maintain system procedural and technical documentation
Stay up to date and build on peer-to-peer networking security best practices
Create, maintain and communicate threat models + risk assessments for all systems we operate

What excites us about you?

You have experience as DevOps/SRE/Infrastructure engineer
You have the ability to program in one or more languages like Python, GoLang, Bash or Javascript
You have experience managing server infrastructures with high availability requirements
You had designed secure networks, systems, and application architectures
You had set up and maintained software in both data centers and cloud environments
You have a deep understanding of sockets, full networking stack, and Linux security
You possess the knowledge of building automation and CI/CD processes and tools
You are experienced with Docker, Kubernetes, and other cloud deployment technologies
You have flexibility, teamwork, and you are comfortable with ambiguity, able to take charge and get things done despite the unknowns

What will be great to have?

You have an understanding of the blockchain space and blockchain technology
You possess knowledge of cryptography and security best practices
You have contributions to open source communities

If those describe you, this is the right opportunity for you!

Why are we awesome you ask?

We are truly at the forefront of the crypto ecosystem as maintainers of the infrastructure layer of blockchain networks! We practice the crypto team mentality by assembling a truly global and diverse team.

We collectively represent more than 12 different countries and are united in a single mission: building out the future of decentralization. Crypto is here to stay, having introduced novel ideas such as DeFi, NFTs and DAOs. At the core of all this are teams like us working relentlessly to build the necessary tools and applications that help run and secure blockchains.

Here are some other reasons you should join us:

We have employees from over 10 countries across the globe, and you will be able to meet interesting people from different backgrounds and cultures. Distributed and remote work is baked into our culture
We are one of the top staking service providers with over $3B of assets staked across our validators. We actively explore and develop new products related to staking. You will work on high-impact engineering projects building exciting new products in a startup environment
We have a capable and passionate team. You will find teammates who are power DeFi users, intense NFT collectors, Bitcoin & Ethereum knowledge nerds, etc. You can learn and debate everything on crypto with our teammates
We are not backed by VC funding, and we are already profitable. Our financial independence means that we can make decisions independent of VCs, and we prioritize our ideals of decentralization, user sovereignty, and user privacy over simply making a profit. It also means that, unlike most other startups, stakefish can provide you with a stable low-risk employment opportunity without fundraising concerns","{""role_summary"":""As a DevOps Engineer, you will build and maintain blockchain networks and protocols, improving infrastructure, security, automation, and monitoring, and dive into new blockchain protocols."",""key_terms"":[{""term"":""Blockchain protocols"",""explanation"":""A set of rules and standards used to build and operate blockchain networks.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and speed up the release of software applications.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a set of practices that automate the build, test, and deployment of software applications.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating the deployment, scaling, and management of containerized applications.""}],""skill_priorities"":{""must_have"":[""Experience as DevOps/SRE/Infrastructure engineer"",""Ability to program in one or more languages like Python, GoLang, Bash or Javascript"",""Experience managing server infrastructures with high availability requirements"",""Deep understanding of sockets, full networking stack, and Linux security"",""Knowledge of building automation and CI/CD processes and tools""],""nice_to_have"":[""Understanding of the blockchain space and blockchain technology"",""Knowledge of cryptography and security best practices"",""Contributions to open source communities""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a secure and scalable infrastructure for a blockchain network?"",""example_answer"":""I would start by identifying the security requirements of the network, then design a scalable infrastructure that meets those requirements, using tools like Kubernetes and Docker to automate deployment and management.""},{""question"":""How do you stay up to date with the latest developments in blockchain technology and security best practices?"",""example_answer"":""I regularly read industry blogs and publications, attend conferences, and participate in open-source communities to stay informed about the latest developments in blockchain technology and security best practices.""}],""red_flags"":[""Lack of experience with blockchain technology and security best practices"",""Inability to work in a fast-paced, ambiguous environment""],""confidence_score"":90.0}"
DevOps Engineer (Entry level),Thomson Reuters,"Toronto, Ontario, Canada",March,2025,"DevOps Engineer

Hybrid Position - Minneapolis or Toronto only!

The DevOps Enablement Team at Thomson Reuters is responsible for delivering comprehensive DevOps solutions to the company's technology teams.

As a DevOps Engineer, you will play a crucial role in advancing infrastructure and processes with a focus on automation, reliability, and efficiency.

This involves working closely with development and operations teams to architect, implement, and maintain scalable and resilient systems, leveraging the latest in cloud technologies and DevOps practices.

About the Role:

In this opportunity, as a DevOps Engineer, you will:

Turn new requirements into code, including unit testing, deployment, and ongoing monitoring.
Work with team members through practices and tools enablement including a focus on automation and defining new ways of working, along with a modern development toolset.
Partner with delivery teams through a DevOps transformation of the product lifecycle from requirements definition, through development, and operations.
Collaborate with peers to identify priorities for enablement measured by an increase in developer efficiency.
Drive innovation with a willingness to explore and learn AI technologies, applying them to enhance DevOps solutions and processes.


About You:

This role is designed for individuals who are passionate about leveraging cutting-edge technologies to drive efficiency and innovation within our DevOps & Cloud automation practices.

If you have a proactive mindset, a passion for learning, and a desire to work in a dynamic, collaborative environment, we encourage you to apply.

Here are the skillsets required:

1-2 years of experience with public cloud (AWS, Azure) and strong Automation experience with Python, Bash, PowerShell etc - Must have
Understand and build automated tests to fit into the bigger picture of software delivery for building CI/CD pipelines, optimizing the execution of tests, and ensuring that the tests are regularly providing fast and reliable feedback.
Demonstrated proficiency in utilizing public cloud platforms (AWS/Azure/OCI)
Experience with Generative AI, AI assisted Developer tools like GitHub CoPilot, AWS Code Whisperer etc.


What’s in it For You?

Join us to inform the way forward with the latest AI solutions and address real-world challenges in legal, tax, compliance, and news. Backed by our commitment to continuous learning and market-leading benefits, you’ll be prepared to grow, lead, and thrive in an AI-enabled future. This includes:

Industry-Leading Benefits: We offer comprehensive benefit plans to include flexible vacation, two company-wide Mental Health Days off, access to the Headspace app, retirement savings, tuition reimbursement, employee incentive programs, and resources for mental, physical, and financial wellbeing.
Flexibility & Work-Life Balance: Flex My Way is a set of supportive workplace policies designed to help manage personal and professional responsibilities, whether caring for family, giving back to the community, or finding time to refresh and reset. This builds upon our flexible work arrangements, including work from anywhere for up to 8 weeks per year, and hybrid model, empowering employees to achieve a better work-life balance.
Career Development and Growth: By fostering a culture of continuous learning and skill development, we prepare our talent to tackle tomorrow’s challenges and deliver real-world solutions. Our skills-first approach ensures you have the tools and knowledge to grow, lead, and thrive in an AI-enabled future.
Culture: Globally recognized and award-winning reputation for inclusion, innovation, and customer-focus. Our eleven business resource groups nurture our culture of belonging across the diverse backgrounds and experiences represented across our global footprint.
Hybrid Work Model: We’ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected.
Social Impact: Make an impact in your community with our Social Impact Institute. We offer employees two paid volunteer days off annually and opportunities to get involved with pro-bono consulting projects and Environmental, Social, and Governance (ESG) initiatives.


In the United States, Thomson Reuters offers a comprehensive benefits package to our employees. Our benefit package includes market competitive health, dental, vision, disability, and life insurance programs, as well as a competitive 401k plan with company match. In addition, Thomson Reuters offers market leading work life benefits with competitive vacation, sick and safe paid time off, paid holidays (including two company mental health days off), parental leave, sabbatical leave. These benefits meet or exceeds the requirements of paid time off in accordance with any applicable state or municipal laws. Finally, Thomson Reuters offers the following additional benefits: optional hospital, accident and sickness insurance paid 100% by the employee; optional life and AD&D insurance paid 100% by the employee; Flexible Spending and Health Savings Accounts; fitness reimbursement; access to Employee Assistance Program; Group Legal Identity Theft Protection benefit paid 100% by employee; access to 529 Plan; commuter benefits; Adoption & Surrogacy Assistance; Tuition Reimbursement; and access to Employee Stock Purchase Plan.

Thomson Reuters complies with local laws that require upfront disclosure of the expected pay range for a position. The base compensation range varies across locations.

For any eligible US locations, unless otherwise noted, the base compensation range for this role is $70,000 - $130,000.

This role may also be eligible for an Annual Bonus based on a combination of enterprise and individual performance.

Base pay is positioned within the range based on several factors including an individual’s knowledge, skills and experience with consideration given to internal equity. Base pay is one part of a comprehensive Total Reward program which also includes flexible and supportive benefits and other wellbeing programs.

Do you want to be part of a team helping re-invent the way knowledge professionals work? How about a team that works every day to create a more transparent, just and inclusive future? At Thomson Reuters, we’ve been doing just that for almost 160 years. Our industry-leading products and services include highly specialized information-enabled software and tools for legal, tax, accounting and compliance professionals combined with the world’s most global news services – Reuters. We help these professionals do their jobs better, creating more time for them to focus on the things that matter most: advising, advocating, negotiating, governing and informing.

We are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments that celebrate diversity and inclusion. At a time when objectivity, accuracy, fairness and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward.

Accessibility

As a global business, we rely on diversity of culture and thought to deliver on our goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity/Affirmative Action Employer providing a drug-free workplace.

We also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law.

Protect yourself from fraudulent job postings click here to know more.

More information about Thomson Reuters can be found on https://thomsonreuters.com.","{""role_summary"":""As a DevOps Engineer, you will advance infrastructure and processes with a focus on automation, reliability, and efficiency, working closely with development and operations teams to architect, implement, and maintain scalable and resilient systems."",""key_terms"":[{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve the speed and quality of delivering software applications and services.""},{""term"":""Cloud Technologies"",""explanation"":""A model of delivering computing services over the internet, allowing users to access and store data, applications, and services on remote servers.""},{""term"":""Automation"",""explanation"":""The use of technology to perform tasks or processes without human intervention, increasing efficiency and reducing errors.""},{""term"":""AI Technologies"",""explanation"":""The development of computer systems that can perform tasks that typically require human intelligence, such as learning, problem-solving.""}],""skill_priorities"":{""must_have"":[""Public cloud (AWS, Python, Bash, PowerShell"",""Automation experience""],""nice_to_have"":[""Generative AI"",""AI assisted Developer tools like GitHub CoPilot, AWS Code Whisperer""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would automate a deployment process using AWS?"",""example_answer"":""I would use AWS CodePipeline to automate the deployment process, leveraging AWS CodeBuild for continuous integration and AWS CodeDeploy for continuous deployment.""},{""question"":""How do you stay current with new developments in AI and machine learning?"",""example_answer"":""I regularly read industry blogs and attend conferences to stay up-to-date, and I'm excited to explore new AI technologies and apply them to enhance DevOps solutions and processes.""}],""red_flags"":[""Lack of experience with public cloud platforms (AWS/Azure/OCI)"",""Inability to work in a dynamic, collaborative environment""],""confidence_score"":90.0}"
SRE / DevOps Engineer,Veracity Software Inc,Canada,February,2025,"Canada / Remote

6+ Months Contract

Position Requirements

Collaborate closely with Development teams to improve services and operational targets.
Implement and maintain CI/CD practices using tools like Sonar.
Manage application integration and monitoring using DataDog, SumoLogic, and alert systems like MS Teams.
Identify vulnerabilities using tools like JFrog Xray and Veracode.
Design infrastructure automation and deployment systems with Docker/Kubernetes.
Improve system reliability through telemetry and security best practices in cloud deployments.

Required Skills & Experience

Overall 8+ years experience in DevOps
2+ years with AWS (EC2, S3, Lambda, etc.).
5+ years with Windows, Linux, IIS/.NET, and Java.
Strong Git, Jenkins/Bamboo, APM, and telemetry knowledge.
Experience with Chef, Puppet, Ansible, and scripting (PowerShell, Python, Bash).
Expertise in cloud security, networking, storage, and DNS.
Excellent communication, problem-solving, and collaboration skills.
Familiarity with Agile methodologies.

Preferred: Bachelor's Degree in Computer Science or equivalent experience.","{""role_summary"":""Work with development teams to improve operational targets, manage application integration, and ensure system reliability through cloud deployments."",""key_terms"":[{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a practice to automate testing and deployment of code changes.""},{""term"":""Sonar"",""explanation"":""A tool for code quality and security analysis.""},{""term"":""DataDog"",""explanation"":""A monitoring and analytics platform for application performance and infrastructure.""},{""term"":""SumoLogic"",""explanation"":""A cloud-based log management and analytics platform.""},{""term"":""JFrog Xray"",""explanation"":""A tool for scanning and identifying vulnerabilities in software components.""},{""term"":""Veracode"",""explanation"":""A platform for identifying and mitigating security risks in software.""},{""term"":""Docker/Kubernetes"",""explanation"":""Containerization tools for automating deployment and management of applications.""},{""term"":""Telemetry"",""explanation"":""The process of collecting and transmitting data from remote sources for monitoring and analysis.""}],""skill_priorities"":{""must_have"":[""DevOps experience"",""AWS experience"",""Windows, Linux, IIS/.NET, and Java experience"",""Git, Jenkins, APM, and telemetry knowledge"",""Cloud security, networking, storage, and DNS expertise"",""Excellent communication, problem-solving, and collaboration skills""],""nice_to_have"":[""Bachelor's Degree in Computer Science or equivalent experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach improving system reliability in cloud deployments?"",""example_answer"":""I focus on implementing telemetry and security best practices to ensure system reliability.""},{""question"":""Can you explain your experience with Docker and Kubernetes?"",""example_answer"":""I have used Docker for containerization and Kubernetes for orchestration in my previous projects.""}],""red_flags"":[""Lack of experience with AWS or cloud security""],""confidence_score"":90.0}"
(f2pool) DevOps Engineer,stakefish,Canada,February,2025,"As our DevOps Engineer, you will be helping us build and maintain blockchain networks and protocols. You will work on improving our current infrastructure including security, automation, and monitoring among other things. You will also have the chance to dive deep into new blockchain protocols, run testnets, build secure and scalable infra and maintain it.

What will you do?

Build secure and reliable infrastructure to monitor, detect and mitigate performance and security issues
System administration activities for Linux servers, which includes routine, proactive daily management of the health, stability, and availability of system infrastructure
Create and maintain system procedural and technical documentation
Stay up to date and build on peer-to-peer networking security best practices
Create, maintain and communicate threat models + risk assessments for all systems we operate

What excites us about you?

You have experience as DevOps/SRE/Infrastructure engineer
You have the ability to program in one or more languages like Python, GoLang, Bash or Javascript
You have experience managing server infrastructures with high availability requirements
You had designed secure networks, systems, and application architectures
You had set up and maintained software in both data centers and cloud environments
You have a deep understanding of sockets, full networking stack, and Linux security
You possess the knowledge of building automation and CI/CD processes and tools
You are experienced with Docker, Kubernetes, and other cloud deployment technologies
You have flexibility, teamwork, and you are comfortable with ambiguity, able to take charge and get things done despite the unknowns

What will be great to have?

You have an understanding of the blockchain space and blockchain technology
You possess knowledge of cryptography and security best practices
You have contributions to open source communities

If those describe you, this is the right opportunity for you!

Why are we awesome you ask?

We are a truly global team! We are digital nomads coming from more than 12 different countries, working from wherever we want. We have a collective mission, to provide meaningful services and bring a unique value to users within the crypto space.

We are looking for fun, curious, and committed individuals to swim with us!

Requirements

A BSc/BA degree in Computer Science or a relevant field","{""role_summary"":""As a DevOps Engineer, you will build and maintain blockchain networks and protocols, improving infrastructure, security, automation, and monitoring."",""key_terms"":[{""term"":""Blockchain"",""explanation"":""A decentralized, distributed ledger technology for secure data storage and transmission.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a set of practices for automating and streamlining software development and delivery.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""}],""skill_priorities"":{""must_have"":[""Experience as DevOps/SRE/Infrastructure engineer"",""Ability to program in one or more languages (Python, GoLang, Bash or Javascript)"",""Experience managing server infrastructures with high availability requirements"",""Deep understanding of sockets, full networking stack, and Linux security"",""Knowledge of building automation and CI/CD processes and tools"",""Experience with Docker, Kubernetes, and other cloud deployment technologies""],""nice_to_have"":[""Understanding of the blockchain space and blockchain technology"",""Knowledge of cryptography and security best practices"",""Contributions to open source communities""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a secure and scalable infrastructure for a blockchain network?"",""example_answer"":""I would start by assessing the network's security requirements and identifying potential vulnerabilities. Then, I would design a scalable infrastructure using containerization and orchestration tools like Docker and Kubernetes, ensuring high availability and fault tolerance.""},{""question"":""How do you stay up-to-date with security best practices in the blockchain space?"",""example_answer"":""I regularly follow industry leaders and researchers on social media, attend webinars and conferences, and participate in online forums to stay current with the latest security best practices and advancements in the blockchain space.""}],""red_flags"":[""Lack of experience with blockchain technology or security best practices"",""Inability to work with ambiguity and uncertainty""],""confidence_score"":90.0}"
DevOps/SecOps Engineer,Ndax,"Calgary, Alberta, Canada",March,2024,"As one of Canada's largest and fastest growing cryptocurrency trading platforms, NDAX has set the bar high for the country's fintech industry and is constantly leading the way in terms of security and innovation. We're on a mission to empower more Canadians to unlock the full potential of digital finance. To address the various needs in the Canadian cryptocurrency space, NDAX has assembled a multidisciplinary team with diverse backgrounds, including finance, technology, engineering, compliance, marketing, and more.

We're proud to have been recognized as one of Canada's Best Workplaces by Great Place to Work®.

NDAX is currently looking to hire a DevOps / SecOps engineer. As a DevOps / SecOps engineer, your responsibilities will include supporting the team in developing current products and in launching products in the pipeline. Using your experience, you will ensure the integrity of our system and support with the developing our technical foundations and system security.

Requirements

Possess extensive knowledge of networking, infrastructure, and applications through a DevOps lens, with a strong emphasis on security
Be a versatile technologist with a knack for swiftly learning and utilizing various technologies, particularly cloud platforms and protective monitoring systems
Demonstrate software development and scripting expertise
Have a comprehensive understanding of security control techniques applicable to both traditional IT environments and cloud-based systems
Have a deep understanding of technical attack methods and their detection in digital landscapes
Be equipped to assess and analyze diverse information to derive conclusions for enhancing system security
Stay informed about information security concepts, along with the latest trends and principles in IT security, data protection, and information risk management.
Posses deep knowledge of security monitoring, prevention and control systems including anti-virus, web proxies and security software


Responsibilities

Execute automation strategies, robust monitoring, and infrastructure-as-code methodologies
Manage and enhance essential applications within a dynamic cloud-native microservices framework
Implement and oversee CI/CD pipelines across diverse environments
Collaborate with a cross-functional engineering team, exploring cutting-edge technologies
Continuously refine best practices to boost deployment quality and speed
Promote and enhance the culture of knowledge sharing within the engineering team
Participate in a rotating on-call schedule with the engineering team
Effectively communicate risks in a nuanced way to support informed business decisions


Benefits

Supercharged Health Plan: Coverage for medical, disability, dental, and vision!
Chill Time: Paid time off plus 2 personal days just for you!
Level Up: Training and development opportunities to boost your skills!
Extra Goodies: Bonuses, awards, and surprise gifts!
Future Investment: Stock option plan to share in the company's success!
Amazing Team: Work with great people and be part of an awesome team!","{""role_summary"":""Support the development of current and pipeline products as a DevOps/SecOps engineer, ensuring system integrity and security foundations."",""key_terms"":[{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""SecOps"",""explanation"":""A practice that integrates security into DevOps to ensure the secure operation of software systems.""},{""term"":""Cloud-native microservices"",""explanation"":""A software architecture that uses cloud-based services to build and deploy small, independent applications (microservices) that work together.""},{""term"":""CI/CD pipelines"",""explanation"":""Automated processes that integrate code changes into a larger system, ensuring continuous integration and delivery.""},{""term"":""Infrastructure-as-code"",""explanation"":""A practice that manages and provisions infrastructure resources through code and configuration files.""}],""skill_priorities"":{""must_have"":[""DevOps knowledge"",""Security expertise"",""Cloud platforms"",""Scripting skills"",""Software development""],""nice_to_have"":[""Knowledge of security monitoring systems"",""Experience in IT security and data protection""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure the integrity of a system in a DevOps environment?"",""example_answer"":""I use automation strategies, robust monitoring, and infrastructure-as-code methodologies to ensure system integrity.""},{""question"":""Can you explain your experience with security control techniques in cloud-based systems?"",""example_answer"":""I have experience implementing security control techniques in cloud-based systems, including anti-virus, web proxies, and security software.""}],""red_flags"":[""Lack of experience with cloud platforms"",""Insufficient knowledge of security control techniques""],""confidence_score"":90.0}"
Cloud Engineer,Scotiabank,"Toronto, Ontario, Canada",March,2025,"Requisition ID: 206977

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture. Scotiabank has embarked on the journey to modernize both development practices and tools. One of the main areas of transformation is the public cloud and the various platform technologies that support both development and operations on the cloud. The aim is to provide a streamlined process and framework which will allow the development teams to focus on building business logic. We are looking to build our development team with influencer, makers, creators, and industry leaders who will drive us forward.

The role of the Cloud Engineer operates within the Cloud File Storage Engineering team. This valuable member of the team will be responsible for creating platform components and services for the broad enterprise use.

Is this role right for you? In this role, you will:

Champions a customer focused culture to deepen client relationships and leverage broader Bank relationships, systems, and knowledge.
Key accountabilities include development and maintenance of cloud platforms, services, and components to enable safe enterprise-wide use of public cloud offerings
Knowledge of a component of a larger product.
Assisting in implementing, and refactoring code.
Assisting in ensuring software, programs and applications are developed and/or configured to meet high availability, integrity and reliability, security, and compliance requirements.
Working with other engineers and architects on breaking-down, scoping and estimating tasks.
Working with application teams for successful onboarding onto the Platform
Participating in planning and retrospective sessions, attending stand-ups, etc.
Be able to build and operate the highly available and scalable software and infrastructure.

Skills

Do you have the skills that will enable you to succeed in this role? We'd love to work with you if you have:

3+ years of experience with Google Cloud Platform (GCP)
3+ years of experience with Cloud Managed Development/Services such as Google Cloud Storage
3+ years of experience in using Infrastructure as Code tooling Like Terraform.
3+ years of experience with development languages (Go, Python, etc)
3+ years of experience with container-based technologies (Docker, Kubernetes)
3+ years of experience in the use of CI/CD Tools
3+ years of experience with config management tools and Scripting Languages (Ansible, Bash, Groovy)
Good oral and written communication skills

Nice To Have

Bachelor (equivalent or higher) degree in computer science or engineering/mathematics discipline.
Understanding of Cloud Native Platforms, particularly Kubernetes, and associated technologies (e.g., Istio, Envoy, Anthos, Kustomize).
Experience working with monitoring tools such as Dynatrace, Prometheus, Grafana, etc.
Understanding of software development lifecycle and release process (container-native workflow for job orchestration, Git/GitOps, CI/CD, environments, code repositories).
Understanding of different database technologies (e.g. CloudSQL, NoSQL, Relational databases)
Focus on scalable, enterprise-level software system design (both on code and infrastructure levels)
Passion for driving teams towards high performance and a deep pride in quality craftsmanship.
Unix administration skills.

What's in it for you?

Diversity, Equity, Inclusion & Allyship - We strive to create an inclusive culture where every employee is empowered to reach their fullest potential, respected for who they are, and are embraced through bias-free practices and inclusive values across Scotiabank. We embrace diversity and provide opportunities for all employee to learn, grow & participate through our various Employee Resource Groups (ERGs) that span across diverse gender identities, ethnicity, race, age, ability & veterans.
Accessibility and Workplace Accommodations - We value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. Scotiabank continues to locate, remove and prevent barriers so that we can build a diverse and inclusive environment while meeting accessibility requirements.
Upskilling through online courses, cross-functional development opportunities, and tuition assistance.
Competitive Rewards program including bonus, flexible vacation, personal, sick days and benefits will start on day one.
Community Engagement - no matter where you choose to work from; we offer opportunities for community engagement & belonging with our various programs such as hackathons, contests, cooking with friends, Humans of Digital and much more!

Work arrangements: Hybrid

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","{""role_summary"":""The Cloud Engineer role is responsible for creating platform components and services for broad enterprise use, focusing on cloud platforms, services, and components to enable safe enterprise-wide use of public cloud offerings."",""key_terms"":[{""term"":""Cloud Native Platforms"",""explanation"":""Refers to cloud-based systems that are designed to take advantage of cloud computing principles, such as scalability and on-demand resources.""},{""term"":""Infrastructure as Code (IaC) tooling"",""explanation"":""A practice that involves managing and provisioning infrastructure resources through code and configuration files, rather than through graphical user interfaces.""},{""term"":""Container-based technologies"",""explanation"":""Technologies that allow multiple isolated applications to run on a single host operating system, improving resource utilization and application portability.""},{""term"":""CI/CD Tools"",""explanation"":""Tools that automate the build, test, and deployment of software applications, ensuring faster and more reliable delivery.""}],""skill_priorities"":{""must_have"":[""3+ years of experience with Google Cloud Platform (GCP)"",""3+ years of experience with Cloud Managed Development/Services such as Google Cloud Storage"",""3+ years of experience in using Infrastructure as Code tooling Like Terraform."",""3+ years of experience with development languages (Go, Python, etc)"",""3+ years of experience with container-based technologies (Docker, Kubernetes)"",""3+ years of experience in the use of CI/CD Tools"",""Good oral and written communication skills""],""nice_to_have"":[""Bachelor (equivalent or higher) degree in computer science or engineering/mathematics discipline."",""Understanding of Cloud Native Platforms, particularly Kubernetes, and associated technologies (e.g., Istio, Envoy, Anthos, Kustomize)."",""Experience working with monitoring tools such as Dynatrace, Prometheus, Grafana, etc."",""Understanding of software development lifecycle and release process (container-native workflow for job orchestration, Git/GitOps, CI/CD, environments, code repositories)."",""Understanding of different database technologies (e.g. CloudSQL, NoSQL, Relational databases)"",""Focus on scalable, enterprise-level software system design (both on code and infrastructure levels)"",""Passion for driving teams towards high performance and a deep pride in quality craftsmanship."",""Unix administration skills.""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with Google Cloud Platform (GCP)?"",""example_answer"":""I have worked with GCP for the past 3 years, and have hands-on experience with its various services such as Google Cloud Storage, Cloud SQL, and Cloud Functions.""},{""question"":""How do you approach infrastructure as code (IaC) in your development workflow?"",""example_answer"":""I use Terraform to manage my infrastructure as code, which allows me to version control my infrastructure and collaborate with my team more effectively.""}],""red_flags"":[""Lack of experience with Google Cloud Platform (GCP)"",""Inability to work with container-based technologies (Docker, Kubernetes)""],""confidence_score"":90.0}"
DevOps and Cloud Engineer,Centrilogic,"Toronto, Ontario, Canada",March,2025,"DevOps and Cloud Engineer

Purpose

Our customers demand the highest quality and reliability for their services and we look for innovative ways to meet that demand through product development and innovation. Our cloud presence and cloud management systems are a key component to providing world-class customer experiences via solution engagements or self-serve portals by conveying the optimal data to feed process automation workflows, and business analytics in the most efficient, resilient and scalable manner. Operational efficiencies are critical to the white-glove treatment CentriLogic strives to maintain. To that end, customer facing and internal systems must offer self-serve capabilities, single pane of glass experiences, optimize transactions and automate repeatable processes.

The ideal candidate will be an experienced cloud DevOps engineer with strong experience on Azure and CI/CD.

This position reports to Head of DevOps practice and it can be based in any one of our GTA locations but is expected to travel as needed.

Primary Responsibilities

• Providing thought leadership on both process and technical matters; become a real champion and trusted advisor to our clients on all facets Continuous Delivery
• Designing and enabling automated delivery strategies for core bet-the-company applications – on premises and in the cloud
• Assisting production teams to understand the new paradigm of infrastructure-as-code
• Mentoring and educating development teams to keep them up to speed with the latest approaches, tools and skills

Skills

• Code and configure CI/CD in public cloud setting
• Firm grasp of internet, cloud and network security concepts
• Containerization and orchestration
• Understanding of distributed systems and microservices architecture
• Extensive experience with infrastructure as code provisioning (PowerShell/Bash Scripting/Terraform/Ansible/Salt)
• Experience with Azure and AWS
• Experience with SCM Tools like GitHub

Qualifications

• Source Control expertise (Git/TFS/Subversion)
• Experience with public cloud (Azure preferred)
• Strict adherence to process and procedures
• Understanding and hands on expertise with the SDLC lifecycle
• Experience with different deployment tools – Azure DevOps, Github, GitLab, Jenkins
• Languages: Terraform, Powershell, Bash, Bicep, Ansible, Salt
• 3+ years of experience with CI/CD Pipelines (Azure DevOps/Github, Jenkins, Git)
• 1+ years of experience with Containers and orchestration (Docker Swarm/Kubernetes) in a production environment
• Experience working in an Agile environment
• Excellent communication skills, both oral and written
• Mastery of design patterns and anti-patterns
• Strong analytical and troubleshooting skills
• Superior oral/written communication and time management skills
• Ability to work in a high growth, fast paced environment

Desirable

• Recent public cloud (Azure and/or AWS) certifications
• Maintenance of Industry certifications
• Skills in Windows and Unix environments a plus","{""role_summary"":""Design and implement automated delivery solutions for core applications, providing thought leadership and mentoring to development teams, and ensuring operational efficiencies in a cloud-based environment."",""key_terms"":[{""term"":""Infrastructure-as-code"",""explanation"":""A practice of managing and provisioning infrastructure through code, rather than manual configuration.""},{""term"":""Containerization"",""explanation"":""A method of packaging applications and their dependencies into a single container, ensuring consistency across environments.""},{""term"":""Microservices architecture"",""explanation"":""A design approach that structures an application as a collection of small, independent services, each responsible for a specific business capability.""}],""skill_priorities"":{""must_have"":[""CI/CD pipeline experience"",""Azure preferred"",""Infrastructure as code provisioning"",""Containerization and orchestration"",""Experience with public cloud""],""nice_to_have"":[""Recent public cloud certifications"",""Maintenance of Industry certifications"",""Skills in Windows and Unix environments""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of infrastructure-as-code and how you've implemented it in a previous role?"",""example_answer"":""In my previous role, I used Terraform to manage our infrastructure, allowing us to version and track changes to our environment.""},{""question"":""How do you approach containerization and what tools have you used for orchestration?"",""example_answer"":""I've used Docker Swarm for container orchestration and Kubernetes for more complex deployments, ensuring consistency across environments.""}],""red_flags"":[""Lack of experience with public cloud providers (Azure or AWS)"",""Inability to explain infrastructure-as-code or containerization concepts""],""confidence_score"":90.0}"
Senior Devops Engineer,EQ Bank | Equitable Bank,"Toronto, Ontario, Canada",March,2025,"Join a Challenger

Being a traditional bank just isn’t our thing. We are big believers in innovating the banking experience because we believe Canadians deserve better options, and we challenge ourselves and our teams to creatively transform what’s possible in banking. Our team is made up of inquisitive and agile minds that find smarter ways of doing things. If you’re not afraid of taking on big challenges and redefining the future, you belong with us. You’ll get to work with people who will encourage you to reach new heights. We like to keep things fun, ask questions and learn together.

We are a big (and growing!) family. Overall we serve more than 670,000 people across Canada through Equitable Bank, Canada's Challenger Bank™, and have been around for more than 50 years. Equitable Bank's wholly-owned subsidiary, Concentra Bank, supports credit unions across Canada that serve more than six million members. Together we have over $125 billion in combined assets under management and administration, with a clear mandate to drive change in Canadian banking to enrich people's lives. Our customers have named our EQ Bank digital platform (eqbank.ca) one of the top banks in Canada on the Forbes World's Best Banks list since 2021.

Purpose of Job

EQ Bank’s IT team is starting to evolve and Needs a talented Senior DevOps Engineer with a solid passion in this space. Experienced and knowledgeable about the end to end software build chain, operations and automated build and release process.

Main Activities

Design, improve and implement build and release pipelines
Provide subject matter expertise to developers and testers on the current and future technology of DevOps tools chain
Work and collaborate with the larger team to exchange knowledge, solutions and practices to build a more consistent, robust approach to development approaches
Research and analyze existing and emerging technologies to identify products, tools to support the DevOps team
Continuously improve performance and proactively identify and resolve bottlenecks that will reduce time to build and deliver our software
Build and Maintain high availability Continuous Integration/Continuous Delivery infrastructure
Engage as a lead in DevOps capacity planning, software performance analysis and system tuning
Review and provide feedback on product functional specifications, design specifications
Perform formal Code Review, static and security analysis, design and implement Unit Tests and perform code coverage analysis



Knowledge/Skill Requirements

Subject Matter expert with minimum 5 years’ experience in Continuous Integration and Continuous Deployment orchestration
Champion cloud deployments to Azure, AWS or GCP - 2 year solid hands-on experience
Expertise in platform as a service using Pivotal CF or IBM Bluemix - 2+ year experience
Good trouble shooting skills and practical usage of various source control systems (Git, SVN) - 5+ years of experience
Solid understanding of Software Delivery Lifecycle
Good to have SecOps experience
Architecture and design understanding behind containers and work with Docker, Kubernetes or similar technologies - 3+ years of experience
Working knowledge of programming/scripting in one or more of the following languages: Java, C, C++, groovy, Python, Shell
Bachelor's degree or equivalent in the field of Computer Science, Systems or Engineering
Five or more years of similar professional experience



Job Complexities / Thinking Challenges:

Strong organizational skills; demonstrated ability to manage time and adhere to tight deadlines
Must be flexible to adapt to a dynamic environment, make quick and sound decisions under pressure
Ability to communicate technical information and ideas effectively
Must be reliable, proactive, results-oriented, and attentive to details
Ability to design high quality, scalable and supportable technology solutions that could be re-used by other areas of the bank
Team player who mentors and helps fellow team members whenever required
Self-starter who is able to work independently and lead a team if required
Ability to prioritize assignments, projects and handle multiple competing priorities (multi-tasking) within restricted time constraints
Problem solver with sound judgment who takes initiative, accepts ownership and accountability
Ability to help the team in interviewing process
Independent, self-motivated and enthusiastic



Accountability

The Senior Dev Ops Engineer will help development teams (in house and external vendor suppliers) build, integrate, manage and deploy releases into all environments using a hybrid methodology (Agile + Waterfall). This role requires collaboration with all participants across the SDLC: software developers, Quality Assurance, Automated Testing, Infrastructure, Production Owners, Operations, Channels, and Business Units representatives as they continuously develop, deploy, test and implement technology changes
The incumbent will be accountable to continuously improve the Software Development processes to drive measurable efficiency and productivity improvements for technology delivery teams
The Senior Dev-Ops Engineer will liaise with Technology and Project leadership teams to ensure project changes, enhancements, fixes, and emergency patches are implemented to production environments using secure and controlled procedures. Responsibilities also include, acting as point of contact for planning and securing lower environments, addressing cross-projects linkages and dependencies, tracking and communicating of changes as they are implemented



What we offer [For full-time permanent roles]

💰 Competitive discretionary bonus

✨ Market leading RRSP match program

🩺 Medical, dental, vision, life, and disability benefits

📝 Employee Share Purchase Plan

👶🏽 Maternity/Parental top-up while you care for your little one

🏝 Generous vacation policy and personal days

🖥 Virtual events to connect with your fellow colleagues

🎓 Annual professional development allowance and a comprehensive Career Development program

💛 A fulfilling opportunity to join one of the top FinTechs and help create a new kind of banking experience

The incumbent will be working hybrid and in office time will be spent working from Equitable Bank’s additional office space located at 351 King Street East, Toronto, ON.

Equitable Bank is deeply committed to inclusion. Our organization is stronger and our employees thrive when we honour and celebrate everyone’s diverse experiences and perspectives. In tandem with that commitment, we support and encourage our staff to grow not just in their career path, but personally as well.

We commit to providing a barrier-free recruitment process and work environment for all applicants. Please let us know of any accommodations needed so that you can bring your best self to the application process and beyond. All candidates considered for hire must successfully pass a criminal background check and credit check to qualify for hire. While we appreciate your interest in applying, an Equitable recruiter will only contact leading candidates whose skills and qualifications closely match the requirements of the position.

We can’t wait to get to know you!","{""role_summary"":""A Senior DevOps Engineer is needed to design, improve, and implement build and release pipelines, and collaborate with the larger team to exchange knowledge and solutions."",""key_terms"":[{""term"":""Integration/Continuous Deployment orchestration"",""explanation"":""Automating the build, test, and release of software to improve efficiency and quality.""},{""term"":""Cloud deployments to Azure, AWS or GCP"",""explanation"":""Moving applications and data to cloud-based services for greater flexibility and scalability.""},{""term"":""Platform as a Service using Pivotal CF or IBM Bluemix"",""explanation"":""Providing a complete platform for developing, running, and managing applications without infrastructure concerns.""},{""term"":""Containers and Docker, Kubernetes or similar technologies"",""explanation"":""Packaging applications and their dependencies into containers to improve deployment and management.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in Continuous Integration and Continuous Deployment orchestration"",""2+ years of experience in Azure, AWS or GCP"",""2+ years of experience in platform as a service using Pivotal CF or IBM Bluemix"",""5+ years of experience in trouble shooting and source control systems (Git, SVN)"",""Solid understanding of Software Delivery Lifecycle"",""Bachelor's degree or equivalent in Computer Science, Systems or Engineering""],""nice_to_have"":[""Good SecOps experience"",""Architecture and design understanding behind containers and work with Docker, Kubernetes or similar technologies"",""Working knowledge of programming/scripting in one or more of the following languages: Java, C, C++, groovy, Python, Shell""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach continuous integration and deployment in a cloud-based environment?"",""example_answer"":""I use tools like Jenkins, Git, and Docker to automate the build, test, and deployment process, ensuring efficient and reliable delivery of software.""},{""question"":""Can you explain your experience with platform as a service using Pivotal CF or IBM Bluemix?"",""example_answer"":""I have used Pivotal CF to deploy and manage applications without worrying about the underlying infrastructure, improving development speed and reducing costs.""}],""red_flags"":[""Lack of experience in cloud deployments"",""Inability to work in a dynamic environment with tight deadlines""],""confidence_score"":90.0}"
Cloud Engineer (AWS),CGS Federal (Contact Government Services),"Yellowstone, Alberta, Canada",January,2025,"Employment Type: Full-Time, Experienced

Department: Information technology

We are seeking a Cloud Engineer (AWS) who will be responsible for supporting the development of all required documentation necessary to support the engineering, security, and operational processes for a large federal agency. The ideal candidate will possess a strong grasp of cloud computing SaaS, PaaS, and IaaS fundamentals.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:


Design solutions that ensure maximum flexibility and scalability, while meeting all required security controls
Support the development of all required documentation necessary to support the engineering, security, and operational processes
Perform business and technical alternative analysis for any/all aspects of the solution, aiding the customer is making decisions along the way
Facilitate the transition of the solution to operations, initially and ongoing ensuring at all times the system is operating within the anticipated operating boundaries
Strong grasp of cloud computing SaaS, PaaS and IaaS fundamentals with experience designing and implementing solutions




Qualifications:


Bachelor's Degree in Computer Science, Engineering, or other Engineering or Technical discipline or equivalent relevant experience
At least four (4-7) years of professional IT experience performing duties in support of federal government agencies
4+ years design, implementation and/or support of highly distributed applications demonstrating strong architectural skills to ensure availability, reliability, etc
Hands-on experience with AWS (Required) or other cloud services reinforced with architectural design experience
Experience designing and delivering large-scale solutions, most of which that have advanced to the production state
Strong grasp of cloud computing SaaS, PaaS and IaaS fundamentals with experience designing and implementing solutions. Develop cloud base solution designs and implementation plans based on customer needs
Familiar with lift-and-shift migrations and migration methodologies for cloud migration
Experience in Cloud computing, Networking, Storage, and Identity Management AWS Certification or Cloud Architect Certification (or desire to obtain certification)




Ideally, you will also have:


Hands-on experience with AWS (required) or other cloud services reinforced with architectural design experience designing and delivering large-scale solutions, most of which that have advanced to the production state
Develop cloud base solution designs and implementation plans based on customer needs
Familiar with lift-and-shift migrations and migration methodologies for cloud migration
Experience in Cloud Compute, Networking, Storage, and Identity Management AWS Certification or Cloud Architect Certification (or desire to obtain certification)




Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package.


Health, Dental, and Vision
Life Insurance
401k
Flexible Spending Account (Health, Dependent Care, and Commuter)
Paid Time Off and Observance of State/Federal Holidays




Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com","{""role_summary"":""Support the development of documentation for engineering, security, and operational processes as a Cloud Engineer (AWS) with a strong grasp of cloud computing fundamentals."",""key_terms"":[{""term"":""SaaS"",""explanation"":""Software as a Service, a cloud computing model where applications are provided over the internet.""},{""term"":""PaaS"",""explanation"":""Platform as a Service, a cloud computing model where a platform for developing and deploying applications is provided.""},{""term"":""IaaS"",""explanation"":""Infrastructure as a Service, a cloud computing model where virtualized computing resources are provided over the internet.""},{""term"":""Lift-and-shift migrations"",""explanation"":""A cloud migration strategy where applications are moved to the cloud without redesign or re-architecture.""}],""skill_priorities"":{""must_have"":[""AWS experience"",""Cloud computing fundamentals"",""Designing and implementing cloud solutions"",""Bachelor's Degree in Computer Science or equivalent""],""nice_to_have"":[""Cloud Architect Certification"",""Experience with lift-and-shift migrations"",""Familiarity with cloud migration methodologies""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the differences between SaaS, PaaS, and IaaS cloud computing models?"",""example_answer"":""SaaS provides software over the internet, PaaS provides a platform for developing and deploying applications, and IaaS provides virtualized computing resources over the internet.""},{""question"":""How would you design a cloud solution to ensure maximum flexibility and scalability while meeting all required security controls?"",""example_answer"":""I would use a multi-cloud approach, leveraging AWS services such as IAM, S3, and Lambda to ensure scalability and security.""}],""red_flags"":[""Lack of hands-on experience with AWS or other cloud services"",""Inability to design and implement cloud solutions""],""confidence_score"":90.0}"
Sr DevOps Engineer,Firework,"Toronto, Ontario, Canada",March,2025,"Firework is the world’s leading unified video commerce platform that empowers its global partners to personalize the customer experience and engagement at scale. Firework bridges the offline and online for a robust omnichannel immersive brand experience cultivating a deeper emotional human connection between our partners and their end consumers. We are customer-centric and inspired to win together offering total solutions with endless possibilities to help our customers increase purchases and conversions using the power of video. At the heart, we are a global and diverse team of “SuperSpark” creators, entrepreneurs, life-long learners, and data geeks driven by the future of authenticity to transform commerce. Firework has raised over $235M to date, with its latest Series B round led by SoftBank Vision Fund 2. Come reimagine the online customer experience with us.

Summary
Our engineering team is growing! We’re looking for a talented DevOps Engineer to join our global team and build scalable systems that will shape the future of our cloud infrastructure for our customer-facing and internal systems.

What You'll Be Doing

Work across multiple functional teams to assess, design, build and maintain a highly fault-tolerant, elastic infrastructure of tools and automation on cloud
Create deployments, services, and other resources on Kubernetes clusters
Design, build, test, deploy, and automate stable/scalable services for the internal engineering team and end users
Champion for a flawless Service Level Agreement (SLA). Shoot for the 5 9s target
Be available on-call during your shift to handle any P0 incidents and help bring the systems back online
Create and manage CI/CD pipelines for automated testing, deployment, and any other use cases
Continuously monitor all the services and drive performance tuning
Maintain and improve our existing software engineering tools with upgrades and installations
Integrate secure solutions and compliance management including identity and access management role-based access control systems
Debug, troubleshoot, and resolve system level scale, performance, and automation problems
Provide multi-tier levels of support to engineering and non-engineering stakeholders
Check in code to Github repositories and perform code reviews for your fellow team members




What You Should Have

Bachelor’s degree in computer programming, computer science, or a related field
5+ years experience in a DevOps or Site Reliability Engineer role.
Mix of consumer technology and SaaS technology is ideal
Working and maintaining production experience of Kubernetes deployments and services
Kubernetes (k8s) and Docker production experience
Built out continuous integration and continuous deployment pipelines
Able to write Bash and/or Python scripts
Ability to own and be responsible for the projects you will be working on




We'll Be Excited If You Have

Experience working with AWS cloud infrastructure and their various services
Fluent in Terraform/Terragrunt and writing Infrastructure as Code (IaC)
Experience and thorough understanding of the Linux operating systems
Experience with high-traffic monitoring systems.
Implementation of logging (Grafana/Prometheus), telemetry (New Relic), and tracing is ideal
Experience with Nginx deployments.Closely work with SQL and NoSQL databases and experience executing zero-downtime database upgrades
Excellent eye for security and creating bulletproof secure systems
Excellent and effective verbal, written, interpersonal communication skills
Comfortable with fast-paced change: ability to demonstrate comfort with ambiguity, adapt quickly and be effective in new situations in a highly dynamic setting
Data-driven but also imaginative and intuitive in coming up with ideas and solutions
Proven ability to balance multiple priorities in a collaborative team environment




This role may be hybrid and based in our San Mateo office or may be remote in Canada or Latin America.The following represents the expected range of compensation for this role: The estimated pay range for San Mateo is CAD140,000-160,000. Other factors that impact compensation may include stock options.The posted pay range represents the anticipated low and high end of the compensation for this position and is subject to change based on business need. To determine a successful candidate’s starting pay, we carefully consider a variety of factors, including primary work location, an evaluation of the candidate’s skills and experience, market demands, and internal parity. Candidates may receive more information from the talent partner.

Don’t hold back
We understand some candidates may see the above and not apply because they don’t meet all the qualifications. We encourage you to apply anyway; we often find talented candidates that fit many other opportunities we have and look for potential too, not just what you did in the past. As an equal employment opportunity employer, we are a diverse team that strives for an inclusive environment for all. We prohibit discrimination and harassment of any kind based on race, color, sex, religion, sexual orientation, national origin, age, disability, genetic information, pregnancy, or any other protected characteristic as outlined by federal, state, or local laws.

By submitting your application, you acknowledge that you have read and understood Firework's Applicant Privacy Policy located at: https://firework.com/legal/applicantpolicy/.","{""role_summary"":""Join Firework's global team as a DevOps Engineer, building scalable cloud infrastructure and ensuring flawless service level agreements for customer-facing and internal systems."",""key_terms"":[{""term"":""Kubernetes"",""explanation"":""A container orchestration system for automating application scaling and deployment.""},{""term"":""CI/CD pipelines"",""explanation"":""Automated processes for testing, deployment, and delivery of software applications.""},{""term"":""SLA"",""explanation"":""Service Level Agreement, a commitment to meet specific performance standards for system uptime and responsiveness.""}],""skill_priorities"":{""must_have"":[""5+ years of DevOps experience"",""Kubernetes production experience"",""Bash and/or Python scripting skills""],""nice_to_have"":[""AWS cloud infrastructure experience"",""Terraform/Terragrunt skills"",""Linux operating system expertise""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design a scalable Kubernetes deployment for a high-traffic e-commerce application?"",""example_answer"":""I would use a load balancer to distribute traffic, implement horizontal pod autoscaling, and ensure efficient resource allocation.""},{""question"":""Can you explain your experience with CI/CD pipelines?"",""example_answer"":""I've built pipelines using Jenkins and GitLab CI/CD, automating testing, deployment, and delivery for multiple applications.""}],""red_flags"":[""Lack of experience with Kubernetes or Docker"",""Inability to write Bash or Python scripts"",""No experience with CI/CD pipelines""],""confidence_score"":90.0}"
DevOps Engineer Canada,Remarcable,"Vancouver, British Columbia, Canada",March,2025,"Benefits:

Bonus based on performance
Competitive salary
Home office stipend
Paid time off
Training & development


We are seeking a DevOps Engineer to join our growing team and take ownership of our cloud infrastructure, CI/CD pipelines, system reliability, observability, and scalability. The ideal candidate is passionate about automation, cloud technologies, and security best practices, ensuring seamless deployment and high availability of our applications.

Responsibilities

Design, implement, and manage CI/CD pipelines to streamline software development and deployment.
Maintain and optimize cloud infrastructure (AWS, Azure) to ensure scalability, security, and cost-effectiveness.
Automate infrastructure provisioning, monitoring, and management using Infrastructure as Code (IaC) tools (Terraform, Ansible, etc.).
Monitor system performance, troubleshoot issues, and ensure high availability and reliability.
Collaborate with software engineers to enhance deployment strategies and improve development workflows.
Implement security best practices to safeguard infrastructure and applications.
Manage containerization and orchestration tools like Docker and AWS ECS.
Optimize logging, monitoring, and alerting systems (ELK stack, etc.).
Stay up to date with the latest DevOps trends, tools, and best practices.


Requirements

3+ years of experience in a DevOps or Site Reliability Engineering (SRE) role.
Strong proficiency in cloud platforms (AWS, GCP, Azure) and cloud-native services.
Experience with CI/CD tools (GitHub Actions, GitLab CI/CD, etc.).
Proficiency in Infrastructure as Code (IaC) tools like Terraform, CloudFormation, or Ansible.
Strong scripting skills in Bash, Python for automation.
Hands-on experience with Docker and AWS ECS for container orchestration.
Knowledge of monitoring and logging tools (ELK stack, Datadog, etc.).
Experience with database management and performance optimization (SQL, NoSQL).
Understanding of security best practices, networking, and system administration.
Experience working in an agile startup environment is a plus.


Nice-to-Have Skills

Development experience with Django
Hands-on experience with Kubernetes for container orchestration.
Exposure to AI/ML workloads.


Who we are

Remarcable is a cloud based platform that helps electrical contractors and distributors streamline purchasing processes to save time and money.

Dedicated to the Electrical Contractor Industry, Remarcable provides cloud-based Procurement & Tool Management Software nationwide. With multiple workflows, two applications in one software, and direct contractor accounting integrations, Remarcable significantly, and efficiently, increases communication, streamlines workflows, and provides visibility for all users.

Our team is composed of contractor and distribution experts located coast to coast. Through collaborations with industry leaders, we've gained insight into the struggles they face. Together, we believe in providing a solution that brings efficiency, visibility, and better communication to streamline the relationship between the contractor and distributor partners.

Our Mission

To advance the adoption of technology in the construction industry and bring better efficiency, visibility, and communication to our customers.

Salary Range Disclaimer

The base salary range represents the low and high end of the Remarcable salary range for this position. Actual salaries will vary depending on factors including but not limited to location, experience, and performance. The range listed is just one component of Remarcable’s total compensation package for employees. Other components may include: PTO and a Bonus plan.

Work remote temporarily due to COVID-19.","{""role_summary"":""A DevOps Engineer responsible for designing, implementing, and managing cloud infrastructure, CI/CD pipelines, system reliability, observability, and scalability, ensuring seamless deployment and high availability of applications."",""key_terms"":[{""term"":""CI/CD pipelines"",""explanation"":""Automated processes for building, testing, and deploying software applications.""},{""term"":""Infrastructure as Code (IaC) tools"",""explanation"":""Tools like Terraform, CloudFormation, or Ansible that allow for automated infrastructure provisioning, monitoring, and management.""},{""term"":""Containerization and orchestration tools"",""explanation"":""Tools like Docker and AWS ECS that enable efficient deployment and management of applications in containers.""},{""term"":""ELK stack"",""explanation"":""A collection of tools (Elasticsearch, Logstash, Kibana) for logging, monitoring, and alerting systems.""}],""skill_priorities"":{""must_have"":[""3+ years of experience in a DevOps or Site Reliability Engineering (SRE) role"",""Strong proficiency in cloud platforms (AWS, GCP, Azure) and cloud-native services"",""Experience with CI/CD tools (GitHub Actions, GitLab CI/CD, etc.)"",""Proficiency in Infrastructure as Code (IaC) tools like Terraform, CloudFormation, or Ansible"",""Strong scripting skills in Bash, Python for automation"",""Hands-on experience with Docker and AWS ECS for container orchestration"",""Knowledge of monitoring and logging tools (ELK stack, Datadog, etc.)"",""Experience with database management and performance optimization (SQL, NoSQL)""],""nice_to_have"":[""Development experience with Django"",""Hands-on experience with Kubernetes for container orchestration"",""Exposure to AI/ML workloads""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach infrastructure provisioning and management in a cloud environment?"",""example_answer"":""I use Infrastructure as Code (IaC) tools like Terraform or Ansible to automate infrastructure provisioning and management, ensuring consistency and efficiency.""},{""question"":""Can you explain your experience with containerization and orchestration tools like Docker and AWS ECS?"",""example_answer"":""I have hands-on experience with Docker for containerization and AWS ECS for container orchestration, ensuring efficient deployment and management of applications.""}],""red_flags"":[""Lack of experience with cloud platforms (AWS, GCP, Azure) and cloud-native services"",""Inadequate scripting skills in Bash, Python for automation""],""confidence_score"":90.0}"
Cloud Infrastructure Engineer,Exposant 3,Canada,March,2025,"Cloud Infrastructure Engineer
📍 Location: Remote | Full-time
📅 Availability: As soon as possible
About Exposant 3 (E3)
Exposant 3 (E3) is a consulting firm specializing in management and information technology. With team members based in Canada and Europe, we support both public and private organizations in their digital and organizational transformations, placing innovation and people at the heart of our projects. As part of our growth, we are looking for a Cloud Infrastructure Engineer to support the day-to-day operations of our clients current cloud platforms. They assist and participate in implementing the Cloud Engineering backlog of platform enhancements and optimizations. The Cloud Engineer also works closely with our Application Development and DevOps teams to remove roadblocks and solve problems during their implementation. They will also assist our partners in Network, Storage and Security Engineering with their cloud-specific projects.
Main Responsibilities
Under the supervision of the leadership team, you will be responsible for various tasks aimed at optimizing the company’s daily operations:
Job Accountabilities
Handle day-to-day operations in the cloud including closing support tickets and incidents.
Support the Senior and Principal Engineers in implementing United Cloud Strategy efforts
Code solutions and build automations to answer complex problems or address cumbersome processes.
Build skills and knowledge in Cloud Foundations and Solution Architecture.
Assist in the testing of resiliency patterns and practices for our App Workloads.
Interacts frequently with the team through meetings, 1:1s with their leader, and Teams chat discussions to discuss overall team strategy, engage in problem solving, and share best practices and knowledge.
🎯 Required Skills and Qualities:
Bachelors or Masters Degree in related field such as Computer Science
If you have a Bachelors degree - 10+ years of experience in cloud infrastructure engineering with a focus on cloud infrastructure automation.
Experience writing and maintaining CI/CD pipeline templates and infrastructure code.
If you have a Masters Degree -7+ years of hands-on experience with AWS, including expertise in compute, containers, and serverless infrastructure
Certified AWS Cloud Practitioner or AWS Solutions Architect Associate
Knowledge of one or more Cloud providers (i.e., AWS, Azure)
hands-on experience with AWS, including in-depth knowledge of core services (e.g., EC2, S3, RDS, Lambda, CloudWatch, Config, Control Tower, DynamoDB) and multi-account governance using AWS Organizations.
Skilled in security scanning tools such as Wiz and coded remediations
Expertise in Infrastructure as Code (IaC) using CDK,CFT or Terraform, YAML, JSON.
Experienced with Azure functions, AWS Lambda's event bridge, Azure event Hub.
Proficient in programming language (Python, Go, or similar)and Bash/Powershell for scripting and automation tasks.
Knowledge of troubleshooting systems
Skills in business acumen
Skills in persuasion
Skills in effective verbal and written communication
Ability to be creative and innovative","{""role_summary"":""The Cloud Infrastructure Engineer is responsible for optimizing daily operations, handling day-to-day cloud operations, and supporting the implementation of platform enhancements and optimizations."",""key_terms"":[{""term"":""Cloud Foundations"",""explanation"":""The fundamental architecture and design of cloud-based systems.""},{""term"":""Solution Architecture"",""explanation"":""The design and implementation of comprehensive solutions that meet specific business needs.""},{""term"":""Infrastructure as Code (IaC)"",""explanation"":""The practice of managing and provisioning infrastructure through code and configuration files.""},{""term"":""CI/CD pipeline"",""explanation"":""Automated workflows that integrate code changes from development to production.""},{""term"":""Serverless infrastructure"",""explanation"":""Cloud computing architecture that dynamically allocates computing resources as needed.""},{""term"":""Multi-account governance"",""explanation"":""The management and oversight of multiple cloud accounts and resources within an organization.""}],""skill_priorities"":{""must_have"":[""AWS experience"",""Cloud infrastructure automation"",""CI/CD pipeline experience"",""Infrastructure as Code (IaC) experience"",""Programming language (Python, Go, or similar)""],""nice_to_have"":[""Azure experience"",""Certified AWS Cloud Practitioner or AWS Solutions Architect Associate"",""Experience with security scanning tools such as Wiz"",""Business acumen"",""Persuasion skills""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with cloud infrastructure automation and how you've implemented it in previous roles?"",""example_answer"":""I've worked on automating cloud infrastructure using AWS CloudFormation and Terraform. In my previous role, I automated the deployment of cloud resources, reducing deployment time by 50%.""},{""question"":""How do you stay up-to-date with the latest cloud security best practices and compliance requirements?"",""example_answer"":""I regularly attend webinars and conferences, and participate in online forums to stay current with the latest cloud security best practices and compliance requirements.""}],""red_flags"":[""Lack of hands-on experience with AWS or Azure"",""Inability to explain cloud infrastructure automation concepts""],""confidence_score"":90.0}"
Junior DevOps Engineer,Trulioo,"Vancouver, British Columbia, Canada",March,2025,"Are you ready to embark on a career that truly affects people around the world? Trulioo invites you to be a catalyst for change in the dynamic realm of digital identity verification. As the global front-runner in our industry, we are redefining how businesses grow, innovate and comply online.

Picture yourself at the forefront of innovation, contributing to our award-winning platform that enables organizations worldwide to quickly onboard customers, optimize costs and combat fraud. Fueled by Silicon Valley support, Trulioo stands as the trusted platform that can verify more than 5 billion people and 700 million business entities spanning 195 countries.

But Trulioo is more than a tech company. We are a united force of dedicated experts committed to establishing trust online.

Headquartered in Vancouver and with strategic hubs in San Diego and Dublin, we foster a culture of collaboration and open communication. Our offices support a hybrid model and staff typically work three days per week at a hub location. Join us where excitement meets innovation and contribute to a world where trust and technology unite.

What We Offer

Comprehensive Benefits: Health, dental, vision, retirement plans with company match, PTO, parental leave and an education & training fund ($1,000 local currency annually). Benefits vary by geography and will be discussed in more depth during the interview process.
Flexible Hybrid Working Environment: Our offices provide weekly lunches, delicious coffee and frequent social events. Dedicated parent rooms, gyms (in some locations), lounge spaces and flexible workstations create an environment that supports your well-being.
Wellness: We provide a variety of workshops, wellness events and a free subscription to the Headspace app to help our team members perform at their best.
Employee Resource Groups: Belonging is an important part of doing your best work. Our ERGs provide an inclusive space, support and community for employees of diverse backgrounds and allies. We host informative, fun sessions and celebrations that are often open to the entire organization.

Position Summary:

We are looking for a Junior DevOps Engineer to join our team and help us maintain and improve the reliability and performance of our cloud infrastructure. In this role, you’ll work alongside our DevOps team to ensure our systems are highly available, scalable, and performant. You’ll be helping to monitor our infrastructure, troubleshoot issues, and implement best practices to improve system reliability. As part of our 24/7 operations, you’ll also participate in the on-call rotation to assist with any technical incidents.

What you’ll be doing:

Help implement monitoring, logging, and alerting solutions to ensure the health of our systems.
Work with the team to troubleshoot and resolve issues across development, staging, and production environments.
Participate in efforts to improve security and performance across our platform.
Join the on-call rotation to help provide after-hours support for critical incidents.
Collaborate with engineers to ensure observability and reliability practices are embedded throughout the development lifecycle.

You have:

2+ years of experience with DevOps, SRE, or cloud infrastructure.
Hands-on experience with Linux or Windows systems in a production environment.
Basic experience with cloud platforms, preferably AWS.
Familiarity with scripting or programming (Python, Bash, Go, or similar).
Exposure to monitoring and logging tools (e.g., Prometheus, Grafana, New Relic, or similar).
Familiarity with version control systems (e.g., GitHub, GitLab).
A desire to learn and improve your skills in cloud infrastructure, automation, and system reliability.
Familiarity with CI/CD pipelines and tools (e.g., GitHub Actions, Jenkins, Gitlab Pipelines) is a bonus.
Exposure to Infrastructure as Code (e.g., Terraform, CloudFormation) is a bonus.

This is a great opportunity for someone looking to grow in the field of DevOps and/or Site Reliability Engineering. If you’re excited about working with cloud infrastructure, observability tools, and system reliability, we’d love to hear from you!

Pay Transparency (Vancouver)

We take a market-based and data-driven approach to compensation. We leverage data from trusted third-party compensation sources to help us understand the market value of a role based on function, level, location, and scope.

Please view the base salary range for this role below. The range listed is our expected compensation for the role. However, the pay offered may vary depending on a variety of factors including qualifications, job-related knowledge, skills, experience, and location.

Annual Salary

$75,000—$90,000 CAD

Thriving at Trulioo

At Trulioo, you’re not just an employee. You’re a valued member of our Trulicrew on a journey of professional and personal growth with a world-class organization. With Trulioo, you have the power to revolutionize the intersection of technology, digital trust and online identity to open the global economy to everyone. Together, we can shape the digital future.

We’re on the lookout for exceptional people to empower with trust, autonomy and the freedom to cultivate their potential. Your curiosity, meticulous attention to detail and passion to contribute are highly valued. If that resonates with you, apply today to become a part of our team. Join us in shaping a future where your career isn’t just a journey but also a boundless exploration into the possibilities of technology and digital identity verification.

If you don’t see yourself fully reflected in every job requirement listed on the posting above, we still encourage you to reach out and apply. Research has shown that minorities and underrepresented groups often only apply when they feel 100% qualified. We are committed to creating a more equitable, inclusive and diverse company and we strongly encourage applicants of all genders, ages, ethnicities, cultures, abilities, sexual orientations, and life experiences to apply.

Trulioo welcomes applications from people with disabilities. Support is available upon request for candidates taking part in all aspects of the selection process. Finally, we know from time-to-time emergencies happen and you may need to reschedule an interview - we understand and encourage you to be in communication without worrying about losing the opportunity or your credibility.

Privacy Notice

As part of our job application process, Trulioo collects, processes, and discloses personal data for the purpose of identifying suitable candidates for our job openings. For more detail, please visit Trulioo’s Website Privacy Policy in the section “When you apply for a job”.","{""role_summary"":""Join Trulioo as a Junior DevOps Engineer to maintain and improve the reliability and performance of our cloud infrastructure, ensuring systems are highly available, scalable, and performant."",""key_terms"":[{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and automation.""},{""term"":""Cloud infrastructure"",""explanation"":""A model for delivering computing services over the internet, allowing for on-demand access to resources.""},{""term"":""Observability"",""explanation"":""The ability to measure and understand the internal state of a system, enabling better monitoring and troubleshooting.""}],""skill_priorities"":{""must_have"":[""2+ years of experience with DevOps, SRE, or cloud infrastructure"",""Hands-on experience with Linux or Windows systems in a production environment"",""Basic experience with cloud platforms, preferably AWS"",""Familiarity with scripting or programming (Python, Bash, Go, or similar)""],""nice_to_have"":[""Familiarity with CI/CD pipelines and tools (e.g., GitHub Actions, Jenkins, Gitlab Pipelines)"",""Exposure to Infrastructure as Code (e.g., Terraform, CloudFormation)""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you troubleshoot an issue in a production environment?"",""example_answer"":""I would first identify the symptoms, then use monitoring and logging tools to isolate the root cause. If needed, I would collaborate with the team to implement a solution.""},{""question"":""Can you explain the importance of observability in a cloud infrastructure?"",""example_answer"":""Observability is crucial as it enables us to measure and understand the internal state of a system, allowing for better monitoring, troubleshooting, and ultimately improving system reliability.""}],""red_flags"":[""Lack of hands-on experience with cloud platforms"",""Inability to explain the importance of observability in a cloud infrastructure""],""confidence_score"":90.0}"
Infrastructure/DevOps Engineer,Landbase,"Toronto, Ontario, Canada",February,2025,"Landbase leverages the experience of 100+ world class sales professionals and AI to deliver targeted, high-quality leads on autopilot. Our mission is to achieve GTM automation so humans no longer need to work for their software so they can reclaim their day. We're building GTM-1 Omni - the world's first action model purpose built for lead generation.

About The Role

We're looking for an Infrastructure Engineer to help scale our cloud platform and automate our deployment processes.

Key Responsibilities

Design and implement cloud infrastructure on GCP
Manage Kubernetes clusters and containerized applications
Implement and maintain CI/CD pipelines
Monitor system performance and reliability
Implement security best practices
Automate infrastructure provisioning

Required Skills & Experience

4+ years of DevOps/Infrastructure experience
Expert knowledge of Google Cloud Platform
Experience with Kubernetes and container orchestration
Strong background in infrastructure as code
Knowledge of monitoring and observability tools
Experience with security compliance (SOC2, GDPR)

Benefits & Perks

Competitive compensation
Comprehensive health benefits
Flexible work arrangements
Professional development opportunities
Exciting work with cutting-edge AI technology
Collaborative and innovative work environment
Regular team events and gatherings","{""role_summary"":""Design and implement cloud infrastructure on GCP, manage Kubernetes clusters, and automate infrastructure provisioning to support the company's GTM automation mission."",""key_terms"":[{""term"":""GCP"",""explanation"":""Google Cloud Platform, a cloud computing service used for infrastructure and application deployment.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""},{""term"":""CI/CD pipelines"",""explanation"":""Continuous Integration and Continuous Deployment pipelines, a set of practices for automating testing, building, and deployment of software applications.""},{""term"":""Infrastructure as Code"",""explanation"":""A practice of managing and provisioning infrastructure resources through code and configuration files, rather than through graphical user interfaces.""},{""term"":""SOC2"",""explanation"":""Service Organization Control 2, a compliance framework for managing customer data and ensuring the security of cloud-based services.""},{""term"":""GDPR"",""explanation"":""General Data Protection Regulation, a European Union regulation for data protection and privacy in the European Union and the European Economic Area.""}],""skill_priorities"":{""must_have"":[""4+ years of DevOps/Infrastructure experience"",""Expert knowledge of Google Cloud Platform"",""Experience with Kubernetes and container orchestration"",""Strong background in infrastructure as code"",""Knowledge of monitoring and observability tools"",""Experience with security compliance (SOC2, GDPR)""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach infrastructure provisioning and management in a cloud-native environment?"",""example_answer"":""I use infrastructure as code tools like Terraform to manage and provision infrastructure resources, and I've implemented CI/CD pipelines to automate deployment and scaling.""},{""question"":""Can you explain your experience with Kubernetes and container orchestration?"",""example_answer"":""I've worked with Kubernetes to deploy and manage containerized applications, and I've implemented rolling updates and self-healing deployments to ensure high availability.""}],""red_flags"":[""Lack of experience with Google Cloud Platform or Kubernetes"",""Inadequate knowledge of security compliance frameworks (SOC2, GDPR)""],""confidence_score"":95.0}"
Senior DevOps Engineer,HCLTech,"Toronto, Ontario, Canada",March,2025,"Role Title: Senior DevOps Engineering Specialist
Hybrid: 3 Days / Toronto, Winnipeg, London
Salary: CAD 90,000 - 110,000

Any specific tools/skillset:
Min 5+ years of multi-disciplinary experience in a large, complex organization
Bachelors’ degree in Computer Science and/or Software Engineering or equivalent experience
Ability to build and maintain collaborative stakeholder relationships across multiple geographies and business functions
Ability to effectively communicate high-level concepts and solutions with technology and business teams
You value simplicity and are unafraid to challenge technical constraints to utilize an iterative and agile approach
Strong knowledge of infrastructure solutions, specifically in relation to cloud programs, platform migration, system security, enterprise directories, and cloud technologies
Kubernetes Expertise: Design, deploy, and maintain scalable and secure Kubernetes clusters, ensuring high availability, fault tolerance, and optimal performance for containerized applications
Experience working with technologies such as Docker, Kubernetes, Terraform, Ansible or other Infrastructure as Code (IaC) tools
Extensive experience with AWS EKS and Service Mesh
Expertise with CI/CD tooling such as Git, Jenkins, SonarQube, Nexus, Vault etc..
Experience working with at least one of the major public cloud providers (Azure, GCP or AWS) and a willingness to continue to expand your knowledge
A self-starter with the ability to comfortably operate in ambiguity
Monitoring and Troubleshooting: Monitor system performance, proactively identify issues, and implement measures for improvement to ensure system reliability and stability

Role profile description:
Reporting to the Product Owner, the DevOps Engineer is responsible for the monitoring, maintenance, and support of systems, services and tools, as well as deploying net-new capabilities aligned to Canada Life’s DevOps principles. The DevOps Engineer will leverage technical knowledge and experience across a variety of business units including, infrastructure, development, operations, and quality assurance, ensuring emerging trends and new technologies stay top of mind.

Ensure all solutions meet security and risk standards and comply with regulatory requirements as documented
Ensure all functional and non-functional requirements are met and measurable in all environments
Execute on the DevOps framework as defined by the Principal DevOps Engineer
Proactively identify areas of friction in current deployment processes and drive technical solution to remove impediments
Migrate existing services to new and existing digital stacks, while managing solutions by monitoring systems and events to avoid costly downtime
Ensure technology capabilities align with current and future business needs
Ensure alignment and adherence to enterprise technology, vendor management, and risk standards
Respond to critical and non-critical incidents based on priority and level of complexity
Work to validate and triage issues, and resolve where applicable
Manage ticket process from start to finish, interacting with other teams as necessary to identify and implement potential solutions.","{""role_summary"":""The Senior DevOps Engineering Specialist is responsible for monitoring, maintaining, and supporting systems, services, and tools, while deploying new capabilities aligned with DevOps principles."",""key_terms"":[{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""},{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice of managing and provisioning infrastructure resources through code and configuration files, rather than through graphical user interfaces.""},{""term"":""Cloud technologies"",""explanation"":""A model of delivering computing services over the internet, allowing users to access and store data, applications, and services online.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a practice of automating testing, building, and deployment of software applications to ensure faster and reliable delivery.""}],""skill_priorities"":{""must_have"":[""5+ years of multi-disciplinary experience in a large, complex organization"",""Bachelors' degree in Computer Science and/or Software Engineering or equivalent experience"",""Strong knowledge of infrastructure solutions, specifically in relation to cloud programs, platform migration, system security, enterprise directories, and cloud technologies"",""Kubernetes expertise: Design, deploy, and maintain scalable and secure Kubernetes clusters"",""Experience working with technologies such as Docker, Kubernetes, Terraform, Ansible or other Infrastructure as Code (IaC) tools""],""nice_to_have"":[""Experience working with at least one of the major public cloud providers (Azure, GCP or AWS) and a willingness to continue to expand knowledge""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and deploy a scalable and secure Kubernetes cluster?"",""example_answer"":""I would start by assessing the application requirements and identifying the necessary for the cluster. Then, I would use Kubernetes deployment tools such as kubeadm or kops to deploy the cluster, ensuring high availability and fault tolerance. Finally, I would implement monitoring and logging tools to ensure optimal performance and identify potential issues.""},{""question"":""How do you stay up-to-date with emerging trends and new technologies in DevOps?"",""example_answer"":""I regularly follow industry blogs and attend webinars to stay informed about the latest developments in DevOps. I also participate in online communities and forums to learn from others and share my own experiences.""}],""red_flags"":[""Avoid candidates without cloud experience"",""Be cautious of candidates without experience with Kubernetes or other Infrastructure as Code (IaC) tools""],""confidence_score"":90.0}"
Cloud Engineer (AWS & Azure),Jarvis Consulting Group,"Toronto, Ontario, Canada",February,2025,"Our client, a pioneer in Digital Health is looking for a Cloud Engineer to join on a contract basis, with the opportunity to go full-time. The Cloud Engineer is tasked with designing, implementing, automating, deploying, and managing production-grade services across multiple cloud providers and infrastructure platforms for the organization, its clients, and partners. This role collaborates with different teams to ensure infrastructure requirements are met for various departments, including Information Services, Privacy & Security, Engineering, Product, Client Support, and Delivery.Responsibilities:

Design, implement, automate, deploy, and operate production-grade services on various cloud platforms and infrastructure vendors.
Collaborate with multiple teams to ensure infrastructure needs are met across various departments such as Information Services, Privacy & Security, Engineering, Product, Client Support, and Delivery.
Provide expertise and recommendations related to cloud and platform provisioning to support internal and external projects.
Participate in infrastructure deployments, offering subject matter expertise on cloud components.
Develop and maintain infrastructure code for different solutions, providing support to clients and partners as needed.
Maintain technical documentation, standard operating procedures, implementation plans, and root cause analyses to support business needs.
Participate in planning for technology implementations and transformations, including assessments, proof of concepts, and technology roadmaps.
Leverage innovative cloud technologies to improve operations, security, and maintenance.
Take part in on-call rotations for application and infrastructure support, incident management, and troubleshooting as needed.
Accurately track and report working hours, ensuring proper usage of the project management tool for both billable and non-billable tasks.
Comply with privacy, security, and confidentiality policies.

Requirements:

5+ years of experience in IT, DevOps, infrastructure maintenance, system administration, cloud development, platform engineering, and/or automation development.
3+ years of experience supporting and developing templates and code for Kubernetes services, including HELM, Kustomize, and Kubernetes manifests.
2+ years of experience in a role supporting and maintaining critical infrastructure, troubleshooting escalations, and ensuring key performance metrics are met.
Deep knowledge of cloud services and hands-on experience building critical infrastructure from scratch.
Proven experience with Kubernetes and serverless infrastructure, including building new clusters and migrating applications.
Proficiency in scripting and programming languages like Powershell, Python, and Bash.
Experience translating architecture and technical requirements into cloud infrastructure.
Intermediate certifications in Cloud services (AWS, Azure, GCP) required; professional-level certifications preferred.
Kubernetes-related certifications such as CKA, CKD, and CKS.
Broad experience with core infrastructure technologies, including security, networking, databases, data streaming, deployment automation, monitoring, logging, alerting, and observability.
Strong communication and collaboration skills, with the ability to work closely with clients.
Demonstrated experience in maintaining comprehensive technical documentation, procedures, and standards.
See All Jobs","{""role_summary"":""Design, implement, and managing production-grade services across multiple cloud providers and infrastructure platforms for the organization, its clients, and partners."",""key_terms"":[{""term"":""Cloud Engineer"",""explanation"":""A professional responsible for designing, implementing, and managing cloud-based infrastructure and services.""},{""term"":""Production-grade services"",""explanation"":""High-quality services that meet the required standards for production environments.""},{""term"":""Cloud providers"",""explanation"":""Companies that offer cloud-based infrastructure and services, such as AWS, Azure, and GCP.""},{""term"":""Infrastructure platforms"",""explanation"":""Software and hardware components that provide the foundation for building and deploying applications and services.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for deploying, scaling, and managing containerized applications.""},{""term"":""Serverless infrastructure"",""explanation"":""A cloud computing model where the need to manage servers, as the cloud provider manages the infrastructure.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in IT, DevOps, infrastructure maintenance, system administration, cloud development, platform engineering, and/or automation development"",""3+ years of experience supporting and developing templates and code for Kubernetes services"",""Deep knowledge of cloud services and hands-on experience building critical infrastructure from scratch"",""Proficiency in scripting and programming languages like Powershell, Python, and intermediate certifications in Cloud services (AWS, Azure, GCP)""],""nice_to_have"":[""2+ years of experience in a role supporting and maintaining critical infrastructure, troubleshooting escalations, and ensuring key performance metrics are met"",""Kubernetes-related certifications such as CKA, CKD, and CKS"",""Broad experience with core infrastructure technologies, including security, networking, databases, data streaming, deployment automation, monitoring, logging, alerting, and observability""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with Kubernetes and serverless infrastructure, including building new clusters and migrating applications?"",""example_answer"":""I have worked on multiple projects where I had to design and implement Kubernetes clusters from scratch, and migrate applications to serverless infrastructure. I have hands-on experience with Kubernetes manifests, HELM, and Kustomize.""},{""question"":""How do you ensure infrastructure requirements are met for various departments, such as Information Services, Privacy & Security, Engineering, Product, Client Support, and Delivery?"",""example_answer"":""I collaborate with different teams to understand their infrastructure needs and ensure that the solutions meet their requirements. I also provide expertise and recommendations related to cloud and platform provisioning to support internal and external projects.""}],""red_flags"":[""Lack of experience in cloud services and infrastructure"",""Inability to work collaboratively with different teams"",""Limited knowledge of security, networking, and observability""],""confidence_score"":90.0}"
Cloud Infrastructure engineer,Open Systems Technologies,"Montreal, Quebec, Canada",March,2025,"Job Responsibilities:

We are looking for a Cloud Infrastructure engineer who is proficient in Terraform and Azure and has at least 10+ years of building enterprise infrastructure in the cloud.

The Cloud Infrastructure Engineer will be part of a team of engineers which works on automation and configuration as code for foundational architecture related to connectivity across multiple Cloud Service Providers.

They should have a strong background in infrastructure and Public Cloud technologies. They will be a part of the global team and will be responsible for connecting complex, multi-tier applications from on-prem to the Public Cloud.

They will be closely working with Product Management and Vendors to develop and deploy Cloud services to meet customer expectations.

Skills Required:
-Sound experience with Infrastructure as Code (Terraform)
-Experience in any of the following cloud service providers - Azure / AWS (Preference is Azure)
-Experience in Kubernetes and Container-based technologies
-Develop tooling and self-service capabilities
-Strong development skills in Python, Java or Golang.
-Sound experience in a scripting language such as Shell Scripting.
-Experience of leading development in projects in a distributed enterprise environments
-Experience of setting up a new development project using modern tools and practices including git, Jenkins, test-driven development, and continuous integration in a Linux-based environment
-Sound knowledge of infrastructure and cloud computing
-Ability to mentor and develop more junior programmers, including participating in constructive code reviews
-Collaborate with developers and infrastructure teams to enhance the developer experience

Desired:
10+ years’ experience of working in Azure and/or AWS.
-Working with teams using scrum, kanban or other agile practices.
-Proficiency with standard Linux command line and debugging tools.
-Experience of working with RESTful APIs, especially managing and configure compute and storage infrastructure.
-Knowledge of how to write comprehensive unit tests, including the mocking of external utilities and APIs.","{""role_summary"":""Design and deploy cloud infrastructure solutions, ensuring seamless connectivity across multiple cloud service providers, and collaborate with cross-functional teams to meet customer expectations."",""key_terms"":[{""term"":""Infrastructure as Code (Terraform)"",""explanation"":""A practice of managing and provisioning cloud infrastructure using code, allowing for version control and reproducibility.""},{""term"":""Container-based technologies"",""explanation"":""A method of packaging and their dependencies into a single container, ensuring consistency and portability across environments.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""}],""skill_priorities"":{""must_have"":[""Terraform"",""Azure"",""Infrastructure as Code"",""Python, Java, or Golang"",""Shell Scripting"",""Cloud computing""],""nice_to_have"":[""AWS"",""Kubernetes"",""Container-based technologies"",""Scrum, Kanban, or Agile practices"",""RESTful APIs"",""Unit testing""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design a scalable cloud infrastructure for a multi-tiered enterprise application?"",""example_answer"":""I would use Terraform to define the infrastructure as code, ensuring consistency and reproducibility. I would also consider factors like security, latency, and cost optimization.""},{""question"":""How do you stay up-to-date with the latest developments in cloud computing and infrastructure as code?"",""example_answer"":""I regularly follow industry blogs, attend webinars, and participate in online forums to stay current with the latest trends and best practices.""}],""red_flags"":[""Lack of experience with Terraform or Azure"",""Inability to write comprehensive unit tests""],""confidence_score"":90.0}"
Cloud Platform Engineer,Exposant 3,Canada,March,2025,"Cloud Platform Engineer
📍 Location: Remote | Full-time
📅 Availability: As soon as possible
About Exposant 3 (E3)
Exposant 3 (E3) is a consulting firm specializing in management and information technology. With team members based in Canada and Europe, we support both public and private organizations in their digital and organizational transformations, placing innovation and people at the heart of our projects. As part of our growth, we are looking for a Cloud Platform Engineer  who will be responsible for developing hardened, scalable automated systems and platforms for the creation of cloud application workloads. The ideal candidate will need to enact an engineering mindset to tactically design and operationalize solutions which will enable developers and devops engineers across the entire organization. 

The platform engineer will appropriately assess and implement coding, IAC, pipeline, tooling, or process solutions to make a measurable impact on our end users. Solutions will need to be well rounded, easy to adopt, and built with the customer in mind through frequent engagement and discovery. Supplemental key responsibilities include contributing to enterprise standards, peer reviewing solutions, clearly communicating solutions, participating in planning ceremonies, and innovating on opportunities to enhance the developer experience
Main Responsibilities
Under the supervision of the leadership team, you will be responsible for various tasks aimed at optimizing the company’s daily operations:
Job Accountabilities
Create enterprise grade Infrastructure as Code solution frameworks for delivering secure, standardized architectures (Terraform, CloudFormation, CDK)
Design and develop coding solutions for integrating platforms, automating the cloud, or developing custom utilities. (Python, Boto3, Bash, JavaScript)
Contribute towards knowledge sharing initiatives through documentation, training and knowledge sharing sessions.
Provide integration support and troubleshooting to end users through the appropriate channels.
Seamlessly integrate multiple tools into a single platform ecosystem – Kong, AWS, Artifactory, Dynatrace
Collaborate with partner teams to design, review, and plan initiatives. Engage with stakeholders to shape the product roadmap.
Embody a custom first mindset to deliver innovative solutions and improve the developer experience
Required Skills and Qualities:
Bachelors or Masters Degree in related field such as Computer Science
If you have a Bachelors degree - 8+ years of experience in software engineering or DevOps roles with a focus on cloud infrastructure automation
Certified AWS Cloud Practitioner or AWS Certified DevOps Professional
Demonstrated experience designing and managing highly available, scalable, and secure cloud-based infrastructure.
Solid understanding of networking, security best practices, and monitoring tools.
Architect and implement scalable, secure, and resilient infrastructure platforms in the cloud (e.g., AWS, Azure, GCP).
Strong proficiency in one or more IaC tools (CloudFormation, Terraform, AWS CDK).
Proficient in programming language (Python, Go, or similar) and Bash/Powershell for scripting and automation tasks.
Experience designing, implementing, and maintaining CI/CD pipeline templates and infrastructure as code.
Hands on experience developing and standardizing an automation platform, Harness is preferred.
Extensive experience with AWS services (ECS Fargate, EKS, Lambda, IAM).
Prior experience in implementing enterprise-wide standardized secure patterns is preferred.
Experienced with Agile/SDLC methodologies.
Excellent communication and collaboration skills.
Experience with monitoring and observability tools (Dynatrace)
Deep understanding of containerization and orchestration technologies (Docker, Kubernetes)
Hands on experience in Harness, It hub Actions, Artifactory is preferred","{""role_summary"":""Design and develop scalable automated systems and platforms for cloud application workloads, enabling developers and devops engineers across the organization."",""key_terms"":[{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice of managing and provisioning cloud infrastructure through code, rather than manual configuration.""},{""term"":""CloudFormation"",""explanation"":""A service offered by AWS that allows users to use templates to create and configure cloud infrastructure.""},{""term"":""CI/CD pipeline"",""explanation"":""A set of practices and tools that automate the build, test, and deployment of software applications.""},{""term"":""Containerization"",""explanation"":""A method of packaging software applications and their dependencies into a single container that can be run consistently across different environments.""}],""skill_priorities"":{""must_have"":[""AWS Cloud Practitioner or AWS Certified DevOps Professional certification"",""8+ years of experience in software engineering or DevOps roles with a focus on cloud infrastructure automation"",""Solid understanding of networking, security best practices, and monitoring tools"",""Strong proficiency in one or more IaC tools (CloudFormation, Terraform, AWS CDK)"",""Proficient in programming language (Python, Go, or similar) and Bash/Powershell for scripting and automation tasks""],""nice_to_have"":[""Prior experience in implementing enterprise-wide standardized secure patterns"",""Experience with monitoring and observability tools (Dynatrace)"",""Hands-on experience in Harness, It hub Actions, Artifactory""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement a scalable, secure, and resilient infrastructure platform in the cloud?"",""example_answer"":""I would use IaC tools like Terraform or CloudFormation to create a scalable and secure infrastructure. I would also ensure that the platform is resilient by implementing monitoring and observability tools like Dynatrace.""},{""question"":""How do you stay up-to-date with the latest developments in cloud infrastructure automation?"",""example_answer"":""I regularly read industry blogs and attend webinars to stay current. I also participate in online communities and forums to learn from others and share my own experiences.""}],""red_flags"":[""Lack of experience with cloud infrastructure automation"",""Inability to explain the concept of Infrastructure as Code (IaC)""],""confidence_score"":90.0}"
DevOps Engineer 3,Behavox,"Toronto, Ontario, Canada",March,2025,"About Behavox

Behavox is shaping the future for how businesses harness their most important raw material - data. Our mission is bold: Organize enterprise data into actionable information that protects and promotes the business growth of multinational companies around the world.

From managing enterprise risk and compliance to maximizing revenue and value, our data operating platform presents a widespread opportunity to build multilingual, AI/ML-based solutions that activate data for every function within a global enterprise.

Our approach is unique, and it’s validated by our customers who tell us to keep forging ahead because no one else is aggregating, analyzing, and acting on data to uncover opportunities or solve problems quite the way we are.

We are looking for fearless innovators who have an insatiable appetite for building what no one has built before.

About The Role

At Behavox, we are at the forefront of transforming how businesses utilize data. As a DevOps Engineer 3, you will play a critical role in enhancing our security measures ensuring the integrity, availability, and confidentiality of our systems. You will be responsible for designing, implementing, and managing the Security Information and Event Management (SIEM) infrastructure, deploying and configuring SIEM components across multi-account cloud environments, and optimizing the performance and cost-efficiency of our security operations.

Your role will also encompass integrating security into our CI/CD pipelines and implementing advanced security practices such as Static Application Security Testing (SAST) and Dynamic Application Security Testing (DAST). Your expertise in SIEM systems, cloud platforms (AWS and GCP), and log data analysis will be instrumental in detecting and responding to security threats swiftly and effectively. You will work closely with SIEM Infrastructure Engineers, Cloud Platform Engineers, and Security Analysts to ensure a seamless and secure data flow.

Work on the critical business area that will have a big impact on the company
Have freedom in implementing your ideas in an environment that is looking to constantly improve
Create a process of releasing hundreds of well-tested releases on demand

What You'll Bring

5+ years experience in a DevOps/DevSecOps/SRE engineering role, with interest and/or experience in integrating security practices into DevOps process
Hands-on experience with automation tools (e.g., Ansible, SaltStack, or Terraform with a focus on security)
Development and scripting skills (Python and Golang are preferred), with an emphasis on secure coding practices
Hands-on experience with AWS/GCP, including securing cloud environments and services
Experience in building secure CI/CD pipelines, incorporating security scans, and vulnerability assessments

What You'll Do

Participate in the building observability (metrics, logs, etc) for the product(s), along with contributing to the implementation and maintenance of security automation and tooling
Automate and streamline deployment, configuration, and maintenance processes (Ansible/Salt/Terraform)
Create tooling to automate operations (Python/Golang)
Manage and secure infrastructure in AWS/GCP
Build CI/CD pipelines, with a focus on security scans and vulnerability assessments, if possible

What We Offer

A truly global mission with a passionate community in locations all over the world
Huge impact and learning potential as our aspirations require bold innovation
Highly competitive compensation with 100% bonus pay already integrated
Benefits include great health coverage for employee and family
Generous time-off policy and flexible work schedule

About Our Process

We take Talent very seriously and we are building a community of extraordinary individuals working together in very high-performing teams. We also know that the best Talent always has options so we believe that the process has to be a two way assessment - the company AND the candidate assessing the business needs alignment, the career next step alignment, and the cultural alignment.

During the process we will begin by exploring the core factors regarding salary and location along with core experience and skills and values alignment. We will then deep dive explore the critical technical competencies we have identified for the role, and then we will deep dive in behavioral competencies.

The most aligned candidate will then be asked to do a practical work task simulation activity so we can make sure that you will enjoy the kind of work the role requires, and this task will typically be presented and discussed with a group of colleagues and managers.","{""role_summary"":""As a DevOps Engineer, you will enhance security measures, design and implement SIEM infrastructure, and optimize security operations, ensuring the integrity and confidentiality of our systems."",""key_terms"":[{""term"":""SIEM"",""explanation"":""Security Information and Event Management system, used to detect and respond to security threats.""},{""term"":""DevSecOps"",""explanation"":""The practice of integrating security into DevOps, ensuring the development and operation of secure systems.""},{""term"":""SAST"",""explanation"":""Static Application Security Testing, a method of testing applications for vulnerabilities during the development phase.""},{""term"":""DAST"",""explanation"":""Dynamic Application Security Testing, a method of testing applications for vulnerabilities during runtime.""}],""skill_priorities"":{""must_have"":[""5+ years experience in DevOps/DevSecOps/SRE engineering role"",""Hands-on experience with automation tools (e.g., Ansible, SaltStack, or Terraform)"",""Development and scripting skills (Python and Golang preferred)"",""Hands-on experience with AWS/GCP, including securing cloud environments and services""],""nice_to_have"":[""Interest and/or experience in integrating security practices into DevOps process""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure the security and integrity of cloud-based systems?"",""example_answer"":""I use a combination of security groups, IAM roles, and regular security audits to ensure the security and integrity of cloud-based systems.""},{""question"":""Can you explain how you would implement SAST and DAST in a CI/CD pipeline?"",""example_answer"":""I would implement SAST and DAST in a CI/CD pipeline by integrating tools like SonarQube and OWASP ZAP, and configuring the pipeline to fail if vulnerabilities are detected.""}],""red_flags"":[""Lack of experience with SIEM systems"",""Inability to explain security concepts, such as SAST and DAST""],""confidence_score"":95.0}"
DevOps cloud Engineer 8297-1212,Foilcon,"Toronto, Ontario, Canada",December,2024,"HM Note: This hybrid contract role is three (3) days in office

Responsibilities

Design, build and support cloud environments to create digital products

Monitor and assess the performance of applications in a cloud environment to ensure solutions are available

Create, test and implement safeguards to maintain data integrity and protect against unauthorized access

General Skills

Experience in one of the leading cloud platforms such as AWS, Azure or Google Cloud, etc

Experience in maintaining complex Linux cloud environments, like CentOS, Ubuntu, or CoreOS, to support modern web technologies: LAMP, MEAN, Drupal and Elasticsearch

Experience setting up development environments and mechanism using tools such as JIRA, Confluence, Maven and Jenkins or similar tools

Experience in scripting languages like Python, Bash, PHP, Java, JavaScript, Node, etc.

Experience in build tools like Git, Ansible, Chef, Puppet etc. for continuous integration

Knowledge of container-based virtualization technology like Docker

Integration experience in building and using APIs

Experience applying industry web, architectural and security standards and best practices

Experience in mobile device management for various versions of cellular and tablets

Skills

Experience and Skill Set Requirements

Technical Knowledge and Skills: 30%

You are a seasoned expert in Azure among other cloud platforms.
You have experience in production environments such as Kubernetes (AKS).
You are familiar with container-based virtualization technology.
Experience with microservice based architectures
You have knowledge of DevOps tools and techniques, and in-depth technical knowledge of system architectures, including technical, data, application and network architectures.
You have experience implementing software engineering practices for full software development life cycles (SDLC), including coding standards, code reviews, source code management, build processes, and testing.
You have experience working independently with high-level direction to build and maintain complex Linux cloud

environments, like CentOS, Ubuntu or CoreOS, to support modern web technologies.

You have extensive knowledge and demonstrated experience in open source search and analytics engines like Elasticsearch (Setup, configuration, watcher, and alerts).
You have fluency in scripting languages like Python, Bash, C#, Java, React, JavaScript, Node, and others.
You have experience in build tools like Git, Ansible, Chef, Puppet, Terraform, and others for continuous integration.
You have integration experience using and building APIs.
You have worked with relational and non-relational databases like MySQL, MongoDB, and others.

Standards and Best Practices Skills: 25%

You have experience applying industry cloud and security standards and best practices to your work that can be adopted by others.
You have designed, implemented and maintained DevOps continuous delivery pipelines to manage from build to deployment and cloud infrastructure using Infrastructure as code practices.
You have knowledge of common authentication technologies, security controls, and standard application security tools.
You have experience securing environments using offensive and defensive approaches.
You have shared best practices and tools with your peers across the organization.
You can research industry best practices to support DevOps standards and apply them to your work.

Communication and Collaboration Skills: 15%

You are a strong communicator who collaborates on your work within a multi-disciplinary team.
You have strong leadership skills to support and guide team members.
You have experience influencing others by persuasion rather than authority â making your case through excellent communication, speaking clearly to be easily understood, and persuasive writing skills.
Your responsibilities include working closely with internal and external partners and team members.
You are comfortable leading discussions and selling your ideas to technical and non-technical colleagues, and senior management.

Project And Digital Expertise

You can articulate methods for build/buy decisions on project components, identify common IT risks and address them with contingency plans and back-out options.
You can analyze designs and determine coding, programming and integration activities to identify issues and provide product solutions.
You have worked on an established environment, balancing the need to address technical debt with new enhancements through continuous iterations.
You are adept at navigating complex issues, handling partners and stakeholder interactions.
You have worked with partners to establish relationships with their security, operations, and IT teams.
You have experience providing production support for multiple cloud environments with a focus on quality, security, reliability and scalability.

Must Haves

You are a seasoned expert in Azure among other cloud platforms.
You have experience in production environments such as Kubernetes (AKS).","{""role_summary"":""Design, build, and support cloud environments to create digital products, ensuring data integrity and protection."",""key_terms"":[{""term"":""Cloud environments"",""explanation"":""A platform for creating digital products, ensuring data integrity and protection.""},{""term"":""Container-based virtualization technology"",""explanation"":""A technology that enables multiple isolated environments to run on a single host.""},{""term"":""Microservice-based architectures"",""explanation"":""An architecture that breaks down a large application into smaller, independent services.""},{""term"":""DevOps tools and techniques"",""explanation"":""A set of practices that combines software development and operations to improve collaboration and efficiency.""},{""term"":""Kubernetes (AKS)"",""explanation"":""A container orchestration system for automating deployment, scaling, and management.""}],""skill_priorities"":{""must_have"":[""Azure cloud platform"",""Kubernetes (AKS) experience""],""nice_to_have"":[""Experience with other cloud platforms (AWS, Google Cloud)"",""Knowledge of container-based virtualization technology (Docker)"",""Experience with microservice-based architectures"",""Experience with DevOps tools and techniques""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with Azure cloud platform and how you've used it in production environments?"",""example_answer"":""I have worked extensively with Azure, setting up and managing complex Linux cloud environments, and have experience with Kubernetes.""},{""question"":""How do you approach DevOps and continuous integration in your work?"",""example_answer"":""I use tools like Git, Ansible, and Chef to automate build and deployment processes, and ensure continuous integration and delivery.""}],""red_flags"":[""Lack of experience with Azure cloud platform"",""Inability to work independently with high-level direction""],""confidence_score"":90.0}"
Cloud Engineer III,"National Spinning Co., Inc. (USA)","Toronto, Ontario, Canada",March,2025,"OnX is a leading technology solution provider that serves businesses, healthcare organizations, and government agencies across Canada. OnX combines deep technical expertise with a full suite of flexible technology solutions—including Generative AI, Application Modernization, Managed Hybrid Cloud, Cybersecurity, Unified Communications, and Infrastructure solutions. From developing and deploying modern applications and the secure, scalable platforms on which they run, to managing, monitoring, and optimizing their operations, OnX delivers comprehensive technology solutions for its clients’ transformative business initiatives. For more information, please visit www.onx.com.

Overview

In today's rapidly evolving environment, organizations need to make data-driven decisions that deliver enterprise value. Our OnX Cloud and Artificial Intelligence practitioners design, develop, and implement large-scale data ecosystems, leveraging cloud-based platforms to integrate structured and unstructured data. We utilize automation, cognitive, and science-based techniques to manage data, predict scenarios, and prescribe actions. By continuously optimizing our cloud infrastructure and providing As-a-Service offerings, we ensure ongoing insights and improvements to enhance operational efficiency. We assist clients in transforming their businesses by developing organizational intelligence programs and strategies, enabling them to stay ahead in their markets.

Our Team Works With Clients To

Implement large-scale data ecosystems, including data management, governance, and the integration of structured and unstructured data to generate insights using cloud-based platforms.
Use automation, cognitive, and science-based techniques to manage data, predict scenarios, and prescribe actions.
Enhance operational efficiency by maintaining data ecosystems, sourcing analytics expertise, and providing As-a-Service offerings for continuous insights and improvements.

Responsibilities

As a Cloud Engineer, you will:

Design, develop, and implement large-scale data ecosystems: Collaborate with cross-functional teams to ensure seamless integration and deployment of data ecosystems in a DevOps environment, utilizing CI/CD, Docker, and Kubernetes.
Automate infrastructure provisioning and management using Infrastructure as Code (IaC) practices: Employ automation, cognitive, and science-based techniques to manage data, predict scenarios, and prescribe actions.
Support the technical implementation of cloud solutions: Troubleshoot and resolve technical issues to maintain operational efficiency. Provide technical guidance and support during the implementation and maintenance phases.
Optimize cloud infrastructure: Stay updated with the latest cloud technologies and best practices to ensure the infrastructure remains cutting-edge and provide solutions to complex data-related challenges. Maintain data ecosystems, source analytics expertise, and provide As-a-Service offerings for continuous insights and improvements.

Requirements

Required:

3-5 Years of Industry Experience
Hands-on experience with CI/CD pipelines, Docker, and Kubernetes.
Proven experience in cloud engineering or a similar role.
Strong understanding of cloud platforms (e.g., AWS, Azure, GCP).
Proficiency in Infrastructure as Code (IaC) tools, especially Terraform.
Solid understanding of networking, security, and DevOps practices.
Excellent problem-solving skills and the ability to troubleshoot complex technical issues.
2+ years of experience in Java, .NET or Python
Effective communication skills, written and oral

Nice To Have

Experience in Git, Redhat OpenShift, VMWare, Databricks, Snowflake, Python, OpenSearch, ElasticSearch, Oracle or MS SQL DBs
Familiarity with other IaC tools such as CloudFormation or Ansible.
Experience with monitoring and logging tools (e.g., Prometheus, Grafana, ELK stack).
AWS, Microsoft Azure or Google Cloud certifications

Education

Four years of College resulting in a Bachelor's Degree or equivalent Bachelor's in Business, Computer Science, Engineering, or related field

Due to U.S. Government requirements applicable to foreign-owned telecommunications providers, non-US citizens may be required to submit to an extensive government agency background check which will necessitate disclosure of sensitive Personally Identifiable Information.

The Pay Range For This Role Is

90,000 - 130,000 CAD per year(Remote - Toronto, CA)","{""role_summary"":""Design, develop, and implementing large-scale cloud-based data ecosystems, ensuring seamless integration, automation, and optimization of data management and infrastructure."",""key_terms"":[{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice that manages and provisions infrastructure through code, allowing for automation and version control.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines development and operations teams to ensure smooth collaboration and deployment of software applications.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a practice that automates testing, building, and deployment of software applications.""},{""term"":""Cloud Engineering"",""explanation"":""The practice of designing, building, and managing cloud-based infrastructure and solutions.""}],""skill_priorities"":{""must_have"":[""Hands-on experience with CI/CD pipelines, Docker, and Kubernetes"",""Proven experience in cloud engineering or a similar role"",""Strong understanding of cloud platforms (e.g., AWS, Azure, GCP)"",""Proficiency in Infrastructure as Code (IaC) tools, especially Terraform"",""Solid understanding of networking, security, and DevOps practices"",""Excellent problem-solving skills and the ability to troubleshoot complex technical issues"",""2+ years of experience in Java, .NET or Python"",""Effective communication skills, written and oral""],""nice_to_have"":[""Experience in Git, Redhat OpenShift, VMWare, Databricks, Snowflake, Python, OpenSearch, ElasticSearch, Oracle or MS SQL DBs"",""Familiarity with other IaC tools such as CloudFormation or Ansible"",""Experience with monitoring and logging tools (e.g., Prometheus, Grafana, ELK stack)"",""AWS, Microsoft Azure or Google Cloud certifications""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement a large-scale data ecosystem using cloud-based platforms?"",""example_answer"":""I would start by assessing the client's requirements and identifying the most suitable cloud platform. Then, I would design and implement the ecosystem using IaC tools, ensuring seamless integration and deployment.""},{""question"":""How do you stay updated with the latest cloud technologies and best practices?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and read relevant blogs to stay informed about the latest developments in cloud technologies.""}],""red_flags"":[""Lack of hands-on experience with CI/CD pipelines, Docker, and Kubernetes"",""Insufficient understanding of cloud platforms and IaC tools"",""Poor problem-solving skills and inability to troubleshoot complex technical issues""],""confidence_score"":95.0}"
DevOps Engineer (Vancouver),Gauss Labs,"Vancouver, British Columbia, Canada",March,2025,"Gauss Labs is a leading innovator in AI solutions for the semiconductor industry. We are seeking an experienced DevOps Engineer to join our dynamic team. The ideal candidate will have 5-10 years of experience in DevOps, focusing on building and maintaining infrastructure, managing CI/CD pipelines, deploying cloud-native, and bare-metal applications, and supporting large-scale distributed systems.

Responsibilities

Build, deploy, and manage containerized applications using Docker and Kubernetes, ensuring scalability, reliability, and fault tolerance
Design, implement, and maintain CI/CD pipelines using GitHub Actions, Jenkins, and ArgoCD to ensure efficient and reliable software delivery
Ensure compliance with security standards such as NIST, SOC, and SEMI by implementing best practices and controls to maintain data security and integrity
Develop Infrastructure as Code (IaC) using Terraform to manage AWS environments, including network configurations, security groups, and resource provisioning
Optimize cloud infrastructure costs and performance by evaluating resource usage, identifying inefficiencies, and implementing solutions to reduce expenses while maintaining performance standards
Provide guidance and mentorship to engineers across the company, offering best practice advice on Kubernetes, deployment strategies, scalability solutions, and observability techniques


Basic Qualifications

Computer Science or related degree
5-10 years of experience in DevOps or Software Engineering roles, with a proven track record of supporting Kubernetes environments
Ability to write applications and tooling, contributing to development efforts and automating processes","{""role_summary"":""DevOps Engineer responsible for building, and managing infrastructure, ensuring scalability, reliability, and fault tolerance in large-scale distributed systems."",""key_terms"":[{""term"":""CI/CD pipelines"",""explanation"":""Automated processes for delivering software applications, ensuring efficient and reliable software delivery.""},{""term"":""Containerized applications"",""explanation"":""Applications packaged with dependencies, ensuring scalability, reliability, and fault tolerance.""},{""term"":""Infrastructure as Code (IaC)"",""explanation"":""Managing and provisioning cloud environments using code, ensuring version control and reproducibility.""},{""term"":""Kubernetes"",""explanation"":""An open-source system for automating deployment, scaling, and management of containerized applications.""}],""skill_priorities"":{""must_have"":[""DevOps experience"",""Kubernetes experience"",""CI/CD pipeline experience""],""nice_to_have"":[""GitHub Actions experience"",""Jenkins experience"",""ArgoCD experience"",""Terraform experience"",""AWS experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure scalability and fault tolerance in containerized applications?"",""example_answer"":""I use Kubernetes to orchestrate container deployment, and implement rolling updates to ensure minimal downtime.""},{""question"":""Can you explain your experience with CI/CD pipelines?"",""example_answer"":""I've implemented CI/CD pipelines using GitHub Actions, ensuring efficient and reliable software delivery.""}],""red_flags"":[""Lack of experience with Kubernetes or containerized applications"",""Inability to write applications and tooling""],""confidence_score"":90.0}"
Cloud Services Engineer,Versa Networks,Canada,February,2025,"Description

About Us

At Versa Networks, we're revolutionizing the way businesses connect, secure, and optimize their networks. Our mission is to secure anywhere, anytime access to anything. As a leader in Secure SD-WAN, SSE (Secure Service Edge), SASE (Secure Access Service Edge) and Next-generation Managed Services, we are empowering organizations across the globe to transform their IT infrastructure for the modern cloud era. Our innovative products enable enterprises to deliver a seamless, scalable, and secure digital experience, no matter where their users, devices, or applications are located. Founded by industry veterans and backed by premier venture capital firms, Versa is a market leader driving innovation and growth as it positions itself for a future IPO.

We believe in fostering a culture of innovation, collaboration, and customer success. Our team is comprised of passionate, forward-thinking professionals dedicated to driving the future of networking technology. We encourage creativity, offer opportunities for growth, and provide a dynamic environment where our people can thrive and make an impact.

At Versa Networks, we don’t just build products – we build relationships, elevate businesses, and shape the digital future. Join us and be part of a fast-paced, cutting-edge company that's making a real difference in how the world connects and communicates.

Job Summary

We are looking for Cloud Services Engineer to join our Cloud Services Team. Your main responsibility will be to build cloud-scale micro-services for various projects in cloud security.

Responsibilities

Discover, Catalog and Annotate Cloud Applications
Perform In-depth Research and Analysis of Cloud Applications and Document them
Research APIs, Protocol, Headers and Data of Cloud Applications
Design, integrate security of Cloud Applications in on-premises and cloud environments
Write effective, maintainable, and well-tested code

Qualifications

BS or MS degree in Computer Science, Electrical Engineering or related field
5-10 years of related development experience
Strong cloud application programming skills
Experience working with security frameworks and cloud security paradigms
Containerization and Orchestration: Hands-on experience with Kubernetes or Docker, allowing you to manage containerized applications effectively.
Experience working with Ubuntu OS.
Expertise in platforms like AWS, Azure, or Google Cloud is added advantage
Utilize automation tools such as Ansible, Terraform, Helm and CloudFormation to streamline cloud environment provisioning.
Experience design, analysis, implementation, and maintenance of Rest APIs
Good oral and written communication
Additional Skills
Thorough understanding of web-scale/planet-scale applications
Thorough understanding of virtualization technologies and multiple cloud environments
Understanding of database technologies with hands on experience in any databases like redis, mongoDB
Experience with programming languages like Python, GoLang
Location: Canada

Applicants must be authorized to work in the Canada

The pay range for this position at commencement of employment in California, Washington, or New York City is expected in the range of $100,000 CAD to $125,000 CAD. A candidate’s specific pay within this range will depend on a variety of factors, including job-related skills, training, location, experience, relevant education, certifications, and other business and organizational needs.

Why Versa?

Benefits

At Versa Networks, we believe in taking care of our people – both professionally and personally. We offer a comprehensive benefits package designed to support the well-being, growth, and work-life balance of our employees. When you join our team, you can expect:

Competitive Salary & Incentives: We offer a competitive compensation package with and pre-IPO equity to reward your hard work and dedication.
Health & Wellness: Comprehensive medical, dental, and vision insurance plans to ensure you and your family stay healthy and covered.
Paid Time Off (PTO): Enjoy a generous PTO policy that includes vacation days, sick leave, and paid holidays to recharge and take care of personal matters.
Flexible Work Environment: We understand the importance of work-life balance. Enjoy the flexibility of remote work, and hybrid option to create the work schedule that works best for you.
Professional Development: We believe in continuous learning. Access to training, certifications, and educational resources to help you grow in your career and stay ahead of industry trends.
Employee Recognition: We celebrate achievements both big and small, with regular recognition programs and awards that highlight your contributions to our collective success.
Collaborative Culture: Be part of a dynamic, inclusive, and supportive team where innovation and collaboration are at the heart of everything we do.
Parental Leave: Generous parental leave policies to support you during life's important moments.

At Versa Networks, our benefits are designed to help you thrive both inside and outside the office. Join us and experience a rewarding, fulfilling career in a supportive environment that values your health, happiness, and success.

Versa Networks is an Equal Opportunity Employer. We are committed to providing equal employment opportunities to all employees and applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other protected characteristic. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.","{""role_summary"":""Design, integrate, and maintain cloud-scale micro-services for cloud security projects, ensuring scalability, security, and maintainability."",""key_terms"":[{""term"":""Cloud Security Paradigms"",""explanation"":""Approaches to securing cloud-based applications and data.""},{""term"":""Containerization"",""explanation"":""Packaging applications and their dependencies into containers to ensure consistency and portability.""},{""term"":""Orchestration"",""explanation"":""Automating the deployment, scaling, and management of containerized applications.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management.""},{""term"":""Docker"",""explanation"":""A containerization platform for packaging, shipping, and running applications in containers.""},{""term"":""Ansible"",""explanation"":""An automation tool for provisioning, configuring, and managing infrastructure and applications.""},{""term"":""Terraform"",""explanation"":""An infrastructure as code tool for provisioning and managing cloud and on-premises infrastructure.""},{""term"":""Helm"",""explanation"":""A package manager for Kubernetes applications, simplifying deployment and management.""},{""term"":""CloudFormation"",""explanation"":""A service for provisioning and managing AWS cloud infrastructure using templates.""},{""term"":""Rest APIs"",""explanation"":""Representational State of Resource APIs for interacting with cloud-based applications and services.""},{""term"":""Automation Tools"",""explanation"":""Software used to automate repetitive tasks, such as provisioning, deployment, and CloudFormation.""}],""skill_priorities"":{""must_have"":[""Cloud application programming skills"",""Experience with security frameworks and cloud security paradigms"",""Containerization and orchestration experience with Kubernetes or Docker"",""Experience with Ubuntu OS"",""Strong understanding of web-scale/planet-scale applications"",""Good oral and written communication""],""nice_to_have"":[""Experience with AWS, Azure, or Google Cloud"",""Experience with automation tools like Ansible, Terraform, Helm, and CloudFormation"",""Understanding of virtualization technologies and multiple cloud environments"",""Experience with programming languages like Python, GoLang"",""Hands-on experience with databases like Redis, MongoDB""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach designing a scalable cloud-based application?"",""example_answer"":""I would start by identifying the application's requirements, then select the appropriate cloud provider and design a scalable architecture using containerization and orchestration tools like Kubernetes or Docker.""},{""question"":""Can you explain the importance of security in cloud-based applications?"",""example_answer"":""Security is crucial in cloud-based applications as they are exposed to a larger attack surface. I would ensure the application is designed with security in mind, using security frameworks and paradigms, and implementing robust authentication and authorization mechanisms.""}],""red_flags"":[""Lack of experience with cloud security paradigms and frameworks"",""Inability to design scalable cloud-based applications"",""Limited understanding of containerization and orchestration""],""confidence_score"":90.0}"
"Cloud Engineer, Deloitte Global Technology",Deloitte,"Vancouver, British Columbia, Canada",March,2025,"Job Type: PermanentWork Model: RemoteReference code: 127916Primary Location: Toronto, ONAll Available Locations: Toronto, ON; Calgary, AB; Vancouver, BC

Our Purpose

At Deloitte, our Purpose is to make an impact that matters. We exist to inspire and help our people, organizations, communities, and countries to thrive by building a better future. Our work underpins a prosperous society where people can find meaning and opportunity. It builds consumer and business confidence, empowers organizations to find imaginative ways of deploying capital, enables fair, trusted, and functioning social and economic institutions, and allows our friends, families, and communities to enjoy the quality of life that comes with a sustainable future. And as the largest 100% Canadian-owned and operated professional services firm in our country, we are proud to work alongside our clients to make a positive impact for all Canadians.

By living our Purpose, we will make an impact that matters.

Have many careers in one Firm.
Enjoy flexible, proactive, and practical benefits that foster a culture of well-being and connectedness.
Learn from deep subject matter experts through mentoring and on the job coaching


What will your typical day look like?

In this role, you will:

Design and prototype Application Programming Interface (API) specifications to support provisioning of cloud infrastructure and services, automate controls and compliance, and support a more consistent, predictable, and secure delivery of cloud platform services.
Contribute to engineering and architectural strategic direction and thought leadership for cloud platform solutions.
Partner with business-led development teams to understand application lifecycle challenges and design cloud platform solutions to automate and streamline their processes.
Participate in planning and workshops with the cloud platform development team to meet cloud software development expectations and milestones.
Have a deep understanding of IaaS and PaaS services offered on the various cloud platforms and understand how to use them together to build complex solutions.
Cultivate and participate in the DevOps culture and practices by deeply understanding the tools, processes, and mindset.
Ensure cloud platform development teams are using the full set of DevOps tools by continuously reviewing and leading the establishment of the right tooling and processes that will result in a stable, consistent and fully automated build/release pipeline.
Be a trusted automation and tooling advisor for DevOps initiatives by providing objective, practical and relevant ideas, insights and advice.
Partner with business, development, and operations teams to design and prototype practical automation solutions and custom modules.
Troubleshoot automation issues and find practical solutions that move projects forward in a timely manner.
Plan, organize, and control multiple responsibilities to achieve project objectives; technically guide projects through to completion.
Ensure deliverables are completed within target timeframes and are consistently of high-quality.

About The Team

Deloitte Technology works at the forefront of technology development and processes to support and protect Deloitte around the world. In this truly global environment, we operate not in ""what is"" but rather ""what can be"" to help Deloitte deliver and connect with its clients, its communities, and one another in ways not previously conceived.

Enough about us, let’s talk about you

You bring the following:

A bachelor’s degree in computer science, Business Information Systems or similar
Public Cloud certifications (Azure, AWS, GCP)
SAFe, Agile, or Scrum certifications
Advanced proficiency with cloud solution architecture (Azure, AWS, or Google Cloud);
Agile development methodology and practices (Scaled Agile Framework or SAFe preferred); planning tools (e.g. Azure DevOps, Jira);
Advanced proficiency with using continuous integration tools (e.g. Azure DevOps, Jenkins) and p roficiency with code management tools (e.g. GitHub, BitBucket);
Intermediate proficiency with backend API design and development (e.g. OpenAPI Spec, Swagger, C# .NET, Python); configuration management tools (Puppet, Chef, Ansible);
Advanced proficiency in scripting (PowerShell, Perl, Bash);
Intermediate proficiency in enterprise application, server, software and networking architecture and troubleshooting; Windows Server administration; Linux/Unix administration; proficiency with database operations and queries (e.g. MS SQL Server, T-SQL, Mysql, MongoDB);
Familiarity with cloud security/compliance standards (ISO 27001, CIS, NIST); datacenter infrastructure (DNS, LDAP, email relays, etc.); virtualization (Hyper-V, VMWare, Openstack);
Knowledge of best practices for IT operations in an always-on, always-available service model;
Exceptional communication skills and the ability to communicate appropriately with corporate executives and technical teams; influencing and reasoning skills; good at conflict resolution and consensus building.

Total Rewards

The salary range for this position is $85,000 - $156,000, and individuals may be eligible to participate in our bonus program. Deloitte is fair and competitive when it comes to the salaries of our people. We regularly benchmark across a variety of positions, industries, sectors, targets, and levels. Our approach is grounded on recognizing people's unique strengths and contributions and rewarding the value that they deliver.

Our Total Rewards Package extends well beyond traditional compensation and benefit programs and is designed to recognize employee contributions, encourage personal wellness, and support firm growth. Along with a competitive base salary and variable pay opportunities, we offer a wide array of initiatives that differentiate us as a people-first organization. Some representative examples include: $4,000 per year for mental health support benefits, a $1,300 flexible benefit spending account, 38+ days off (including 10 firm-wide closures known as ""Deloitte Days""), flexible work arrangements and a hybrid work structure.

Our promise to our people: Deloitte is where potential comes to life.

Be yourself, and more.

We are a group of talented people who want to learn, gain experience, and develop skills. Wherever you are in your career, we want you to advance.

You Shape How We Make Impact.

Diverse perspectives and life experiences make us better. Whoever you are and wherever you’re from, we want you to feel like you belong here. We provide flexible working options to support you and how you can contribute.

Be the leader you want to be

Some guide teams, some change culture, some build essential expertise. We offer opportunities and experiences that support your continuing growth as a leader.

Have as many careers as you want.

We are uniquely able to offer you new challenges and roles – and prepare you for them. We bring together people with unique experiences and talents, and we are the place to develop a lasting network of friends, peers, and mentors.

The next step is yours

At Deloitte, we are all about doing business inclusively – that starts with having diverse colleagues of all abilities. Deloitte encourages applications from all qualified candidates who represent the full diversity of communities across Canada. This includes, but is not limited to, people with disabilities, candidates from Indigenous communities, and candidates from the Black community in support of living our values, creating a culture of Diversity Equity and Inclusion and our commitment to our AccessAbility Action Plan , Reconciliation Action Plan and the BlackNorth Initiative .

We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation for the recruitment process (including alternate formats of materials, accessible meeting rooms or other accommodations) or indigenouscareers@deloitte.ca for any questions relating to careers for Indigenous peoples at Deloitte (First Nations, Inuit, Métis).

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.

Deloitte Canada has 20 offices with representation across most of the country. We acknowledge that Deloitte offices stand on traditional, treaty, and unceded territories in what is now known as Canada. We recognize that Indigenous Peoples have been the caretakers of this land since time immemorial, nurturing its resources and preserving its natural beauty. We acknowledge this land is still home to many First Nations, Inuit, and Métis Peoples, who continue to maintain their deep connection to the land and its sacred teachings. We humbly acknowledge that we are all Treaty people, and we commit to fostering a relationship of respect, collaboration, and stewardship with Indigenous communities in our shared goal of reconciliation and environmental sustainability.","{""role_summary"":""Design and prototype API specifications, contribute to engineering and architectural strategic direction, and partner with business-led development teams to automate and streamline cloud platform services."",""key_terms"":[{""term"":""API"",""explanation"":""Application Programming Interface, used for cloud infrastructure and services""},{""term"":""IaaS"",""explanation"":""Infrastructure as a Service, a cloud computing model""},{""term"":""PaaS"",""explanation"":""Platform as a Service, a cloud computing model""},{""term"":""DevOps"",""explanation"":""Development and Operations, a set of practices for collaboration and integration""},{""term"":""SAFe"",""explanation"":""Scaled Agile Framework, a methodology for implementing Agile practices""}],""skill_priorities"":{""must_have"":[""Public Cloud certifications (Azure, AWS, GCP)"",""Advanced proficiency with cloud solution architecture (Azure, AWS, or Google Cloud)""],""nice_to_have"":[""SAFe, Agile, or Scrum certifications"",""Intermediate proficiency with backend API design and development""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing and prototyping API specifications for cloud infrastructure and services?"",""example_answer"":""I follow a structured approach, considering the requirements of the business-led development teams and the scalability of the cloud platform services.""},{""question"":""Can you explain your understanding of IaaS and PaaS services offered on various cloud platforms?"",""example_answer"":""IaaS provides virtualized computing resources, while PaaS offers a complete development and deployment environment for applications.""}],""red_flags"":[""Lack of experience with cloud security/compliance standards (ISO 27001, CIS, NIST)""],""confidence_score"":90.0}"
Cloud Architect,Signify Technology,"Vancouver, British Columbia, Canada",March,2025,"Cloud Architect – Hybrid (Vancouver, BC, Canada)
Contract: 1 year (high likelihood of extension or conversion)
Pay Rate: Up to $110/hr

My client is a global leader in the gaming industry, known for creating some of the most iconic and immersive entertainment experiences in the world. With a portfolio that includes blockbuster franchises enjoyed by millions, they are at the forefront of innovation in cloud infrastructure, multiplayer gaming, and large-scale content delivery. Their technology powers seamless, high-performance gaming experiences, pushing the limits of what’s possible in interactive entertainment.

They are looking for a Cloud Architect to design and optimize scalable cloud infrastructure, supporting cutting-edge game development and live services. This role requires expertise in DevOps, cloud platforms (AWS, Azure, GCP), and infrastructure automation, ensuring the company's systems remain highly available, secure, and efficient.
Responsibilities:

Design and implement scalable cloud infrastructure for large-scale gaming applications.
Develop Infrastructure as Code (IaC) solutions using Terraform, Python, and Go.
Manage containerized workloads with Kubernetes and Docker, optimizing for high availability and performance.
Implement and manage CI/CD pipelines with ArgoCD.
Monitor system performance and security using Grafana and other observability tools.
Collaborate with game developers, DevOps teams, and security engineers to optimize cloud environments.

Requirements:
5+ years of experience as a Cloud Architect or DevOps Engineer,
Expertise in AWS, Azure, or GCP, with hands-on experience in multi-cloud environments.
Strong knowledge of Kubernetes, Docker, and container orchestration.
Proficiency in Infrastructure as Code (Terraform) and scripting languages (Python, Go).
Experience with ArgoCD, Grafana, and cloud security best practices.
Strong problem-solving skills and the ability to work in a fast-paced, collaborative environment.

As a Cloud Architect, you will:
Work with a team of top-tier engineers at a company that sets the gold standard for gaming technology.
Build and scale cloud infrastructure that supports millions of players worldwide.
Be part of a culture that values innovation, creativity, and technical excellence.

If you’re a passionate Cloud Architect and want to work at the intersection of gaming and large-scale infrastructure, this is the opportunity for you!

We make an active choice to be inclusive towards everyone every day. Let us know if you have any accessibility requirements or would like to apply for this role another way by emailing: george.ethell@signify-tech.com

(Skillset: Cloud Architect, DevOps, AWS, Azure, GCP, Kubernetes, IaC, Terraform, Python, Go, ArgoCD, Grafana, Cloud Security, Security, Finance, FinOps, CI/CD, Docker, Cloud)","{""role_summary"":""Design and optimize scalable cloud infrastructure to support cutting-edge game development and live services, ensuring high availability, security, and efficiency."",""key_terms"":[{""term"":""Infrastructure as Code (IaC)"",""explanation"":""A practice of managing and provisioning cloud infrastructure through code, making it versionable and reproducible.""},{""term"":""Container orchestration"",""explanation"":""Automating the deployment, scaling, and management of containerized applications.""},{""term"":""CI/CD pipelines"",""explanation"":""Automated workflows that integrate code changes from development to production, ensuring faster and more reliable deployments.""}],""skill_priorities"":{""must_have"":[""Cloud Architect or DevOps Engineer experience"",""Expertise in AWS, Azure, or GCP"",""Kubernetes and Docker"",""Infrastructure as Code (Terraform)"",""Scripting languages (Python, Go)""],""nice_to_have"":[""ArgoCD"",""Grafana"",""Cloud security best practices""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing scalable cloud infrastructure for large-scale gaming applications?"",""example_answer"":""I consider factors like high availability, security, and performance, and use tools like Terraform and Kubernetes to ensure scalability.""},{""question"":""Can you explain your experience with container orchestration and how you've optimized it for high availability and performance?"",""example_answer"":""I've used Kubernetes and Docker to manage containerized workloads, ensuring high availability and performance through monitoring and optimization.""}],""red_flags"":[""Lack of experience with cloud platforms (AWS, Azure, GCP)"",""Limited knowledge of container orchestration""],""confidence_score"":95.0}"
Cloud Data Engineer,Bevertec,"Toronto, Ontario, Canada",March,2025,"DataOps/Cloud Data Engineer - Azure
Duration: 12+ Months contract
Hybrid
Toronto,ON

Experience:

Cloud DataOPS
· Expert experience with Microsoft Azure technologies, including Azure pipeline, DACPAC, storage account, disk, file share, Azure key vault, Azure portal, virtual machine, Azure DevOps, Data Lake, Data Lakehouse, Azure monitoring tools.
· Experience with Cloud data platforms, data management and data exchange tools and technologies.
· Experience with Data pipeline and workflow development, orchestration, deployment, and automation.
· Experience in DataOPS principle, best practice, and implementation and Agile project development and deployment.
· Experience in Continuous Integration/Continuous Development/Deployment (CI/CD) and Data provisioning Automation.
· Experience with digital product, data analysis, data exchange, data provisioning, and data security.
· Experience with structured, semi-structured, unstructured data collection, ingestion, provisioning and exchange technological development.
· Experience with DataOPS performance monitoring and tuning.

Database Management
· Expert data/database administration experience, e.g., Microsoft Azure SQL database and Synapse database, Oracle, IMS, DB2, etc.
· Extensive experience with SQL Server Stored Procedure, Oracle PL/SQL, PL/1 development and performance tuning.
Data Replication Pipelines
· Experience with Azure SQL, Oracle, IMS/DB2 data replication.","{""role_summary"":""Design, develop, and maintain cloud-based data pipelines and workflows on Microsoft Azure, ensuring data quality, security, and efficiency."",""key_terms"":[{""term"":""Azure pipeline"",""explanation"":""A cloud-based service for automating and managing software development and deployment processes.""},{""term"":""DACPAC"",""explanation"":""A file format for packaging and deploying SQL Server database schema and data.""},{""term"":""Data Lake"",""explanation"":""A centralized repository for storing structured, semi-structured, and unstructured data.""},{""term"":""DataOPS"",""explanation"":""A set of practices and tools for managing and maintaining data pipelines, workflows, and systems.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a software development practice for automating testing, building, and deployment of code changes.""}],""skill_priorities"":{""must_have"":[""Microsoft Azure technologies"",""Cloud data platforms"",""Data pipeline development"",""DataOPS principles"",""Agile project development"",""CI/CD"",""Data security""],""nice_to_have"":[""Oracle"",""IMS"",""SQL Server Stored Procedure"",""Oracle PL/SQL"",""PL/1 development""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach data pipeline development and orchestration in a cloud-based environment?"",""example_answer"":""I use Azure Data Factory for data pipeline development and orchestration, ensuring data quality, security, and efficiency.""},{""question"":""Can you explain your experience with DataOPS principles and Agile project development?"",""example_answer"":""I have experience implementing DataOPS principles in Agile projects, focusing on continuous integration, delivery, and monitoring.""}],""red_flags"":[""Lack of experience with Microsoft Azure technologies"",""Insufficient knowledge of cloud-based data platforms""],""confidence_score"":90.0}"
"Software Engineer, New Grad",Zip,"Toronto, Ontario, Canada",March,2025,"The simple task of buying software, services, or tools at work has become hopelessly complicated at even the most innovative companies in the world. Today, enterprises spend $120T+ per year globally (>30 times larger than annual consumer e-commerce spend) and rely on vendors more than ever before to run their businesses.

Our cofounders started Zip in 2020 to address this seemingly intractable problem with a purpose-built procurement platform that provides a simple, consumer-grade user experience. Within the last 4 years, Zip has created a new category and developed the leading solution in this $50B+ TAM space. Today, the world’s leading companies like OpenAI, Snowflake, Anthropic, Coinbase, and Prudential rely on Zip to manage billions of dollars in spend.

We have a world-class team coming from category-defining companies like Airbnb, Meta, Stripe, Salesforce, Apple, and Google. With a $2.2 billion valuation and $370 million in funding from Y Combinator, Tiger Global, BOND, DST Global, and CRV, we’re focused on developing cutting-edge technology, expanding into new global markets, and—above all–driving incredible value for our customers. Join us!

Your Role

As a Software Engineer you will be responsible for building Zip’s core products and architecture. You will ship features that will be immediately used by our customers, and will work with a tight-knit team that values open communication and cross-functional collaboration. We move quickly to solve a wide range of complex technical and product challenges. While we are an experienced team that can provide constant guidance and mentorship, we value engineers who can scope and solve difficult technical challenges.

You Will

Design and build highly reliable and resilient products and features
Work closely with cross functional product and customer-facing teams to understand requirements and ship thoughtful solutions
Write high-quality, extensible, and maintainable code
Design and build scalable frontend applications and components
Design and build APIs to drive existing and new features for a web-based application


Qualifications

Pursuing a BS or MS in Computer Science or related technical field involving coding (e.g. physics or math), with a graduation date between December 2024 - June 2025
Experience with web applications and API development. At Zip, our stack includes Python, Javascript/TypeScript, React, and GraphQL
Ability and interest to quickly learn new frameworks, architecture patterns, and programming languages as needed
Fantastic written and verbal communication skills
Prior internships in high-growth startup environment


Perks & Benefits

At Zip, we’re committed to providing our employees with everything they need to do their best work.

📈 Start-up equity
🦷 Health, vision & dental coverage
🚠 Team building events & happy hours
🌴 Flexible PTO
💻 Apple equipment plus home office budget


We're looking to hire Zippers and that means hiring people who take ownership, communicate openly, have an underdog mindset, and are excited to increase the pace of innovation for every business in the world. We encourage all candidates to apply even if your experience doesn't exactly match up to our job description. We are committed to building a diverse and inclusive workspace where everyone (regardless of age, religion, ethnicity, gender, sexual orientation, and more) feels like they belong. We look forward to hearing from you!","{""role_summary"":""As a Software Engineer, you will build Zip's core products and architecture, shipping features used by customers and working with a tight-knit team that values open communication and cross-functional collaboration."",""key_terms"":[{""term"":""GraphQL"",""explanation"":""A query language for APIs that allows for flexible and efficient data retrieval.""},{""term"":""TypeScript"",""explanation"":""A statically typed programming language that helps catch errors early and improve code maintainability.""}],""skill_priorities"":{""must_have"":[""Experience with web applications and API development"",""Ability and interest to quickly learn new frameworks, architecture patterns, and programming languages as needed""],""nice_to_have"":[""Prior internships in high-growth startup environment""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to optimize a slow-performing API?"",""example_answer"":""In my previous role, I identified a slow-performing API by analyzing performance metrics. I then optimized the API by implementing caching and reducing the number of database queries.""},{""question"":""How do you approach learning new programming languages and frameworks?"",""example_answer"":""I believe in hands-on learning, so I would start by building a small project using the new language or framework. I would also read tutorials, documentation, and online resources to deepen my understanding.""}],""red_flags"":[""Lack of experience with web applications and API development"",""Inability to learn new frameworks, architecture patterns, and programming languages quickly""],""confidence_score"":90.0}"
Azure Cloud Engineer,EY,"Waterloo, Ontario, Canada",March,2025,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.

The opportunity

We are seeking an Azure Cloud Engineer to join EY Canada. In this role, you will be required to offer expert advice, planning, and practical assistance to EY's clients who want to move their IT infrastructure to a cloud-based system. This individual will be part of a diverse team of innovative and talented professionals, committed to providing top-tier consulting services to our clients.

Your Key Responsibilities:

Work with a variety of Canadian clients across different industries to understand their specific cloud computing needs and objectives.
Design and implement tailored cloud infrastructure, applications, and platform solutions, considering Canadian data privacy laws and regulations.
Create and execute effective data migration and cloud implementation strategies, specific to each client.
Monitor, maintain, and troubleshoot cloud-based systems, ensuring optimal performance and reliability.
Develop comprehensive backup and recovery strategies that comply with Canadian business continuity standards.
Communicate complex cloud concepts, ensuring that relevant stakeholders understand the risks and benefits.
Follow EY methodologies and use EY tools to deliver seamless and compelling cloud solutions.
Stay current with trends and developments in cloud computing, with a particular focus on their relevance to the Canadian market.
Ensure EY's quality and professional standards are maintained.
Collaborate with other EY teams to create integrated solutions.
Train and support clients during the cloud transition process, maintaining good client relationships.

To qualify for this role you must have:

Bachelor’s degree in computer science, IT, Systems Engineering, or a related field. Higher degree or equivalent experience is preferred.
3-5 years of experience as a Cloud Engineer or in a similar role, with prior consulting experience.
Proven expertise in Azure Cloud – experience with AWS, GCP an asset.
Experience in Design and Implementation:
Designing and deploying scalable, highly available, and fault-tolerant systems on cloud platforms (e.g., AWS, Azure, Google Cloud Platform).
Implementing and managing cloud infrastructure and services, including compute, storage, networking, and databases.
Migrating existing on-premises applications and services to the cloud.
Experience in Maintenance and Optimization:
Monitoring cloud environments to ensure optimal performance and cost-efficiency.
Performing regular maintenance tasks, updates, and upgrades.
Troubleshooting and resolving technical issues related to cloud resources.
Experience in Security and Compliance:
Ensuring cloud environments comply with relevant security standards and regulations.
Implementing and managing security measures such as firewalls, identity and access management (IAM), and encryption.
Conducting security audits and risk assessments.
Experience in Automation and Orchestration:
Automating repetitive tasks using scripting languages (e.g., Python, Bash) and infrastructure as code (IaC) tools (e.g., Terraform, CloudFormation).
Implementing orchestration solutions to manage complex workflows and dependencies across multiple cloud services.
Experience in Collaboration and Support:
Collaborating with development teams to support DevOps practices and continuous integration/continuous deployment (CI/CD) pipelines.
Providing technical support and guidance to other teams and stakeholders.
Documenting cloud architectures and procedures.
Strong understanding of cloud-based technologies, covering data storage, networking, and cybersecurity.
Superior written and verbal communication skills in English, French language skills is a plus.
Familiarity with Canadian data protection laws and business practices.
Professional cloud certifications like AWS Solutions Architect, Google Professional Cloud Architect, or Microsoft Certified: Azure Solutions Architect Expert is a plus.
Ability to manage multiple client engagements simultaneously.
Willingness to travel, as needed, to meet client needs and project commitments.
Exhibits EY’s values – integrity, respect, and teaming, energy, enthusiasm, and the courage to lead.

What We Offer

We offer a competitive compensation package where you’ll be rewarded based on your performance and recognized for the value you bring to our business. In addition, our Total Rewards package allows you decide which benefits are right for you and which ones help you create a solid foundation for your future. Our Total Rewards package includes a comprehensive medical, prescription drug and dental coverage, a defined contribution pension plan, a great vacation policy plus firm paid days that allow you to enjoy longer long weekends throughout the year, statutory holidays and paid personal days (based on province of residence), and a range of exciting programs and benefits designed to support your physical, financial and social well-being. Plus, we offer:

Support and coaching from some of the most engaging colleagues in the industry
Learning opportunities to develop new skills and progress your career
The freedom and flexibility to handle your role in a way that’s right for you

The salary range for this job in British Columbia is $72,000 to $132,000. Individual salaries within this range are determined through a wide variety of factors including but not limited to education, experience, knowledge, skills and work location city.

Diversity and Inclusion at EY

Diversity and inclusiveness are at the heart of who we are and how we work. We’re committed to fostering an environment where differences are valued, policies and practices are equitable, and our people feel a sense of belonging. We embrace diversity and are committed to combating systemic racism, advancing gender equity and women in leadership, advocating for the 2SLGBTQIA+ community, promoting our neuroinclusion and accessibility initiatives, and are dedicated to amplifying the voices of Indigenous peoples (First Nations, Inuit, and Métis) nationally as we strive towards reconciliation. Our diverse experiences, abilities, backgrounds, and perspectives make our people unique and help guide us. Because when people feel free to be their authentic selves at work, they bring their best and are empowered to build a better working world.

EY | Building a better working world

EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.

Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.

Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.","{""role_summary"":""An Azure Cloud Engineer responsible for providing expert advice, planning, and practical assistance to clients moving their IT infrastructure to a cloud-based system."",""key_terms"":[{""term"":""Azure Cloud Engineer"",""explanation"":""A professional responsible for designing, implementing, and maintaining cloud infrastructure and applications on Azure cloud platform.""},{""term"":""Cloud computing"",""explanation"":""The practice of using remote servers accessed over the internet to store, manage, and process data.""},{""term"":""Data migration"",""explanation"":""The process of transferring data from one system to another, usually from on-premises to cloud-based systems.""},{""term"":""Cloud implementation strategies"",""explanation"":""Plans and approaches for deploying and integrating cloud-based solutions into an organization's IT infrastructure.""},{""term"":""Canadian data privacy laws"",""explanation"":""Regulations and standards governing the collection, use, and protection of personal data in Canada, such as PIPEDA.""}],""skill_priorities"":{""must_have"":[""Azure Cloud Engineer experience"",""Cloud infrastructure design and implementation"",""Data migration and cloud implementation strategies"",""Cloud security and compliance"",""Strong written and verbal communication skills""],""nice_to_have"":[""AWS or GCP experience"",""Professional cloud certifications"",""French language skills"",""Familiarity with Canadian business practices""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the differences between Azure, AWS, and GCP cloud platforms?"",""example_answer"":""Azure is a Microsoft-based cloud platform, AWS is Amazon's cloud platform, and GCP is Google's cloud platform. Each has its strengths and weaknesses, and the choice depends on the client's specific needs.""},{""question"":""How do you ensure data security and compliance in cloud-based systems?"",""example_answer"":""I implement security measures such as firewalls, IAM, and encryption, and conduct regular security audits and risk assessments to ensure compliance with relevant regulations.""}],""red_flags"":[""Lack of experience with Azure Cloud Engineer role"",""Insufficient knowledge of Canadian data privacy laws and regulations"",""Poor communication skills""],""confidence_score"":90.0}"
Sr. GCP Cloud Engineer,Rackspace Technology,Canada,March,2025,"Rackspace Technology is a leading provider of expertise and managed services across all the major public and private cloud technologies. We’ve evolved Fanatical Support to encompass the entire customer journey — providing Fanatical Experience™ from first consultation to daily operations. Our passionate experts combine the power of proactive, always-on service and expertise with best-in-class tools and automation to deliver technology when and how our customers need it.

As part of our commitment to our customers, we are dedicated to helping enable creative, automation-based solutions for all sizes of businesses and require an experienced Cloud Engineer to join our team.

The ideal candidate will have several years’ experience with Google Cloud design and implementation. You will be working in a dynamic environment and encouraged to come up with innovative solutions to technical problems, analyze and prioritize problems, putting users at the heart of every decision.

You will ideally have proven experience in multiple GCP deployments. Your engagements will see you working directly with customers and prospects. You will have confidence in knowing your skills (and limitations), you are calm and collected under pressure and always available to mentor the less experienced. Your colleagues see you as a good team player who is keen to share knowledge as well as to listen and learn from others.

Work Location: Remote (Ontario, Alberta, and British Columbia)

Key Responsibilities

Own and complete key tasks and deliverables, and collaborate with others to define and implement optimal, complete solutions based on stake holder’s needs.
Deliver solutions that solve for new levels of complexity, scale, and performance, and in turn, enable breakthrough innovations. Create and apply frameworks, methods, best practices, and artifacts that deliver prescriptive guidance to customers, and publish and present the min large forums and across various media platforms.
Technical depth and hands-on implementation experience of various practices and tools in the DevOps toolchain.
Comfortable rolling up their sleeves to design and code modules for infrastructure, application, and processes.
Design, Build and maintain cloud-based application that uses Google Kubernetes Engine


Qualifications

Security in GCP
Networking in GCP
GKE and overall compute in GCP, including GCE
GCP Storage - Spanner, Cloud SQL, MemoryStore, GCS, etc
Automation and operations in GCP
GCP Observability, GKE Observability and GCP Logs/Metrics/Traces
Datadog, New Relic and Synthetic Testing.
Bachelor’s degree, or equivalent experience, in Computer Science, Engineering. or a related field.
4+years of experience as a technical specialist.
3+years of hands-on experience of programming in languages with the following Python, Java, and GO.
Subject Matter Expert level practical Linux administration skills in a Cloud or Virtualized environment.
Expert level familiarity with automating cloud native technologies, deploying applications, and provisioning infrastructure using bash, python, or GO
Expert Knowledge of the primary Google services (compute engine, load balancing, Cloud Storage)
Experience with automating cloud native technologies, deploying applications, and provisioning infrastructure.
Expert level knowledge and Hands-on experience with Infrastructure as Code utilizing Terraform.
Experience developing cloud native CI/CD workflows and tools, such as Jenkins, Bamboo, TeamCity, Cloud Build (Google) and/or GitLab.
Hands-on experience with microservices and distributed application architecture utilizing containers, Kubernetes, and/or serverless technology.
Experience with seamless/automated build scripts used for release management across all environments.
Experience with the full software development lifecycle and delivery using Agile practices
In depth understanding of IP networking, VPN's, DNS, load balancing and firewalls.
Willingness to travel to customer locations as needed.
Experience with multi-cloud architecture and deployment


Discover your inner Racker: Racker Life

""Remote postings are limited to candidates residing within the country specified in the posting location""

About Rackspace Technology

We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future.

More on Rackspace Technology

Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.","{""role_summary"":""As a Cloud Engineer, you will design and implement Google Cloud solutions, working directly with customers and prospects, and collaborating with others to deliver optimal solutions."",""key_terms"":[{""term"":""GCP"",""explanation"":""Google Cloud Platform, a suite of cloud computing services offered by Google.""},{""term"":""GKE"",""explanation"":""Google Kubernetes Engine, a managed environment for deploying containerized applications.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development and IT operations to improve collaboration and efficiency.""},{""term"":""Infrastructure as Code"",""explanation"":""A practice of managing and provisioning infrastructure through code and configuration files.""}],""skill_priorities"":{""must_have"":[""Google Cloud design and implementation experience"",""Security in GCP"",""Networking in GCP"",""GKE and overall compute in GCP"",""GCP Storage"",""Automation and operations in GCP"",""GCP Observability"",""GCP Logs/Metrics/Traces"",""Datadog"",""New Relic"",""Synthetic Testing"",""Python"",""Java"",""GO"",""Linux administration skills"",""Automating cloud native technologies"",""Deploying applications"",""Provisioning infrastructure"",""Infrastructure as Code utilizing Terraform"",""Cloud native CI/CD workflows"",""Microservices and distributed application architecture"",""Seamless/automated build scripts"",""Full software development lifecycle"",""Agile practices"",""IP networking"",""VPN's"",""DNS"",""load balancing"",""firewalls""],""nice_to_have"":[""Multi-cloud architecture and deployment"",""Experience with seamless/automated build scripts""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with Google Cloud design and implementation?"",""example_answer"":""I have worked on multiple GCP projects, designing and implementing scalable solutions for clients.""},{""question"":""How do you approach automating cloud native technologies?"",""example_answer"":""I use tools like Terraform and Ansible to automate infrastructure provisioning and application deployment.""}],""red_flags"":[""Lack of hands-on experience with Google Cloud Platform"",""Inability to work in a dynamic environment"",""Limited experience with automation and operations in GCP""],""confidence_score"":90.0}"
Ingénieur DevOps / DevOps Engineer,Clear Destination,Greater Montreal Metropolitan Area,December,2024,"Ingénieur DEVOPS (English follow) 
 Vous recherchez un environnement de travail stimulant au sein d'une équipe jeune et dynamique ? 
 Nous sommes à l'avant-garde de la fourniture de solutions logicielles dans un environnement collaboratif en constante évolution. Notre mission est d'autonomiser les entreprises avec une technologie évolutive, sécurisée et innovante. Nous recherchons un ingénieur DevOps Azure compétent avec une expertise approfondie de Kubernetes, Docker et des services partagés pour rejoindre notre équipe en pleine croissance. 
 Si vous êtes passionné par la conteneurisation, l'automatisation et la livraison transparente de logiciels dans des environnements dynamiques basés sur le cloud, nous voulons vous entendre ! 
 Aperçu du rôle 
En tant qu'ingénieur DevOps Azure, vous jouerez un rôle essentiel dans la conception, la mise en œuvre et la maintenance de nos processus DevOps et de notre infrastructure sur Azure. Vous travaillerez avec Kubernetes et Docker pour concevoir, mettre en œuvre et optimiser les charges de travail conteneurisées dans nos environnements Azure .NET. Vous favoriserez également l'adoption de services partagés pour rationaliser le développement et l'efficacité opérationnelle. Vous travaillerez en étroite collaboration avec des équipes interfonctionnelles, notamment les développeurs, l'assurance qualité et les opérations, afin de garantir des pipelines CI/CD transparents, une infrastructure robuste et des performances système optimales. 
 Principales responsabilités 
Expertise en matière de conteneurisation : Construire et gérer des applications .NET conteneurisées à l'aide de Docker et orchestrer des déploiements avec Kubernetes dans Azure (AKS). 
Pipelines CI/CD : Développer et maintenir des pipelines CI/CD dans Azure DevOps pour permettre l'intégration et la livraison continues. 
Architecture de services partagés : Concevoir et mettre en œuvre des plateformes de services partagés (i.e., journalisation, surveillance, identité) pour normaliser et optimiser les flux de travail de développement et d'exploitation. 
Infrastructure as Code (IaC) : Automatiser le provisionnement et la gestion de l'infrastructure à l'aide de Terraform. 
Architecture en nuage : Concevoir, déployer et maintenir des environnements Azure évolutifs et sécurisés pour prendre en charge des applications conteneurisées et basées sur des microservices. 
Surveillance et dépannage : Maintenir et améliorer les solutions de surveillance comme Datadog et Azure Monitor pour assurer la santé et la performance du système. 
Automatisation : Rationalisez et automatisez les tâches opérationnelles, en réduisant les interventions manuelles. 
Sécurité et conformité : Intégrez les meilleures pratiques de sécurité dans les processus DevOps, en garantissant la conformité avec les normes du secteur. 
Documentation : Créer une documentation complète pour les pratiques de conteneurisation, les services partagés et les flux de travail opérationnels. 
 Compétences et qualifications 
5+ ans d'expérience en tant qu'ingénieur DevOps, avec un accent sur les environnements Azure. 
Forte expertise dans Kubernetes (AKS de préférence) et Docker pour la gestion des applications .NET conteneurisées. 
Expérience avérée dans la conception et la mise en œuvre de plateformes de services partagés. 
Maîtrise de la configuration et de la gestion du pipeline CI/CD à l'aide d'Azure DevOps. 
Expérience pratique de l'infrastructure en tant que code (i.e.,Terraform). 
Maîtrise des langages de script comme PowerShell, Python ou Bash. 
Solide compréhension des principes de mise en réseau, de sécurité et d'évolutivité du cloud. 
Expérience avec des outils de surveillance comme Datadog et Azure Monitor. 
 Atouts 
Certifications Azure (i.e., AZ-400, AZ-104 ou AZ-305). 
Expérience des services administrés et Service Mesh.  
Connaissance des méthodologies Agile et des outils tels que Jira ou Azure Boards et Confluence. 

Parlons maintenant des avantages!
Télétravail
Un régime de rémunération attrayant
Un environnement Agile qui est génial, expérimenté et amusant
Programmes de formation et de remboursement des frais de scolarité
Régime complet de soins de santé et d'avantages sociaux, avec un compte de mieux-être.
RRSP/DPSP
Un équilibre travail-vie personnelle apprécié
Des collègues et des dirigeants formidables
Des événements employés tout au long de l'année pour célébrer nos victoires et apprendre à se connaître

  --------------------------------------------------------- 
 DEVOPS Engineer 
 Looking for a stimulating work environment in a young and dynamic team? 
 We are at the forefront of delivering software solutions in a fast-paced, collaborative environment. Our mission is to empower businesses with scalable, secure, and innovative technology. We are seeking a skilled Azure DevOps Engineer with deep expertise in Kubernetes, Docker, and shared services to join our growing team. 
 If you’re passionate about containerization, automation, and enabling seamless software delivery in dynamic, cloud-based environments, we want to hear from you! 
 Role Overview 
As an Azure DevOps Engineer, you will play a critical role in designing, implementing, and maintaining our DevOps processes and infrastructure on Azure. Working with Kubernetes and Docker to design, implement, and optimize containerized .NET workloads across our Azure environments. You will also drive the adoption of shared services to streamline development and operational efficiency. You'll work closely with cross-functional teams, including developers, QA, and operations, to ensure seamless CI/CD pipelines, robust infrastructure, and optimal system performance. 
 Main responsibilities 
Containerization Expertise: Build and manage containerized .NET applications using Docker and orchestrate deployments with Kubernetes in Azure (AKS). 
CI/CD Pipelines: Develop and maintain CI/CD pipelines in Azure DevOps to enable continuous integration and delivery. 
Shared Services Architecture: Design and implement shared services platforms (e.g., logging, monitoring, identity) to standardize and optimize development and operations workflows. 
Infrastructure as Code (IaC): Automate infrastructure provisioning and management using Terraform. 
Cloud Architecture: Design, deploy, and maintain scalable and secure Azure environments to support containerized and microservices-based applications. 
Monitoring & Troubleshooting: Maintain and improve monitoring solutions like Datadog and Azure Monitor to ensure system health and performance. 
Automation: Streamline and automate operational tasks, reducing manual intervention. 
Security & Compliance: Integrate security best practices into DevOps processes, ensuring compliance with industry standards. 
Documentation: Create comprehensive documentation for containerization practices, shared services, and operational workflows. 
 Skills and Qualifications 
5+ years of experience as a DevOps Engineer, with a focus on Azure environments. 
Strong expertise in Kubernetes (AKS preferred) and Docker for containerized .NET application management. 
Proven experience designing and implementing shared services platforms. 
Proficient in CI/CD pipeline setup and management using Azure DevOps. 
Hands-on experience with Infrastructure as Code (e.g., Terraform). 
Proficiency in scripting languages like PowerShell, Python, or Bash. 
Strong understanding of cloud networking, security, and scalability principles. 
Experience with monitoring tools like Datadog or Azure Monitor. 
 Preferred
Azure certifications (e.g., AZ-400, AZ-104, or AZ-305). 
Experience with administered services and Service Mesh.  
Knowledge of Agile methodologies and tools like Jira or Azure Boards and confluence. 

Now let's talk Perks!
Remote work (from Canada)
Attractive compensation package
An Agile environment that is great, experienced and fun
Training and tuition reimbursement programs
Full health and benefit plan, with Wellness account of 500$
RRSP/DPSP
Valued work-life balance
Great coworkers and leaders
Employee gatherings throughout the year to celebrate our victories and to get to know one another.","{""role_summary"":""Design, implement, and maintain DevOps processes and infrastructure, ensuring seamless CI/CD pipelines, robust infrastructure, and optimal system performance in a dynamic, cloud-based environment."",""key_terms"":[{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""},{""term"":""Docker"",""explanation"":""A containerization platform for packaging, shipping, and running applications in containers.""},{""term"":""Azure DevOps"",""explanation"":""A suite of services to plan, develop, deliver, and operate software applications, providing end-to-end support for DevOps practices.""},{""term"":""Terraform"",""explanation"":""An infrastructure as code (IaC) tool for provisioning and managing cloud and on-premises infrastructure.""},{""term"":""CI/CD Pipelines"",""explanation"":""Automated workflows for building, testing, and deploying software applications, ensuring continuous integration and delivery.""}],""skill_priorities"":{""must_have"":[""5+ years of experience as a DevOps Engineer"",""Strong expertise in Kubernetes (AKS) and Docker for containerized .NET application management"",""Proven experience designing and implementing shared services platforms"",""Proficient in CI/CD pipeline setup and management using Azure DevOps"",""Hands-on experience with Infrastructure as Code (e.g., Terraform)""],""nice_to_have"":[""Azure certifications (e.g., AZ-400, AZ-104, or AZ-305)"",""Experience with administered services and Service Mesh"",""Knowledge of Agile methodologies and tools like Jira or Azure Boards and Confluence""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you design and implement containerized .NET applications using Docker and Kubernetes in Azure?"",""example_answer"":""I would use Docker to package the .NET application and Kubernetes to orchestrate the deployment in Azure, ensuring scalability and high availability.""},{""question"":""Can you explain your experience with CI/CD pipelines in Azure DevOps and how you ensure continuous integration and delivery?"",""example_answer"":""I have implemented CI/CD pipelines using Azure DevOps, automating testing, and deployment of .NET applications to ensure continuous integration and delivery.""}],""red_flags"":[""Lack of experience with Kubernetes and Docker"",""Inability to design and implement shared services platforms"",""Insufficient knowledge of Azure DevOps and CI/CD pipelines""],""confidence_score"":90.0}"
Java Cloud Engineer (AWS or GCP),Iris Software Inc.,"Mississauga, Ontario, Canada",March,2025,"Iris's client, one of the world's largest financial institutions is looking to hire a Java Cloud Engineer – (AWS or GCP) for a long term contract opportunity.

Our client is one of the world's largest financial institutions, serving individual consumers, small and middle market businesses and large corporations with a full range of banking, investing, asset management and other financial and risk-management products and services. It is a leading provider of global corporate and investment banking services.



Position: Cloud Engineer – (AWS or GCP)
Location: Mississauga, ON
Duration: Long Term Open Ended Contract



Must have:

Strong programming skills with hands-on experience designing and implementing high volume, high availability applications with a very high degree of automation. Technical proficiency in the required programming languages, frameworks and technologies, including Java, SpringBoot, MongoDB, JSON and XML data notations.
In-depth knowledge of AWS services such as ECS, EC2, DocumentDB, Lambda, and S3, and their integration into complex cloud architectures.
Excellent interpersonal and communication skills.



About Iris Software Inc.

With 4,000+ associates and offices in India, U.S.A. and Canada, Iris Software delivers technology services and solutions that help clients complete fast, far-reaching digital transformations and achieve their business goals. A strategic partner to Fortune 500 and other top companies in financial services and many other industries, Iris provides a value-driven approach - a unique blend of highly-skilled specialists, software engineering expertise, cutting-edge technology, and flexible engagement models. High customer satisfaction has translated into long-standing relationships and preferred-partner status with many of our clients, who rely on our 30+ years of technical and domain expertise to future-proof their enterprises. Associates of Iris work on mission-critical applications supported by a workplace culture that has won numerous awards in the last few years, including Certified Great Place to Work in India; Top 25 GPW in IT & IT-BPM; Ambition Box Best Place to Work, #3 in IT/ITES; and Top Workplace NJ-USA.","{""role_summary"":""Design and implement high-volume, high-availability cloud architectures using Java and AWS or GCP, ensuring strong automation and integration with various cloud technologies."",""key_terms"":[{""term"":""ECS"",""explanation"":""A container orchestration service in AWS that manages and scales containerized applications.""},{""term"":""EC2"",""explanation"":""A virtual server service in AWS that provides resizable compute capacity in the cloud.""},{""term"":""DocumentDB"",""explanation"":""A document-oriented database service in AWS that stores, manages, and scales document-based data.""},{""term"":""Lambda"",""explanation"":""A serverless compute service in AWS that runs code in response to events, without provisioning or managing servers.""},{""term"":""S3"",""explanation"":""A cloud-based object storage service in AWS that stores and retrieves data as objects.""},{""term"":""SpringBoot"",""explanation"":""A Java-based framework for building web applications and microservices, known for its simplicity and ease of use.""},{""term"":""MongoDB"",""explanation"":""A NoSQL document-based database that stores data in JSON-like documents, allowing for flexible schema design and scalability.""}],""skill_priorities"":{""must_have"":[""Java"",""AWS"",""SpringBoot"",""MongoDB"",""JSON"",""XML""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design a highly available cloud architecture using Java and AWS?"",""example_answer"":""I would use a combination of EC2 instances, ECS for container orchestration, and S3 for storing and retrieving data. I would also implement load balancing and auto-scaling to ensure high availability.""},{""question"":""How do you handle data storage and retrieval in a cloud-based application?"",""example_answer"":""I would use a NoSQL database like MongoDB to store data in JSON-like documents, and use AWS Lambda for serverless compute to handle data retrieval.""}],""red_flags"":[""Lack of hands-on experience with AWS services and Java-based technologies."",""Inability to design and implement high-volume, high-availability cloud architectures.""],""confidence_score"":90.0}"
Cloud Security Engineer,SIA Innovations Inc.,"Montreal, Quebec, Canada",February,2025,"Ingénieur – Défense numérique (« SRE – Security »)

Élevez les affaires chez SIA Innovations

Alors que les organisations dépendent de plus en plus des données et de l'automatisation, la confiance zéro et la gestion des menaces continuent de gagner en importance de manière exponentielle. Nous voulons être à l'avant-garde, en guidant nos clients vers des opérations informatiques sûres et résilientes avec une sécurité sans friction.

Chez SIA Innovations, nous sommes des innovateurs qui s'engagent à aider nos clients dans leur virage numérique en tirant parti des technologies IA et cloud hybride d'IBM et Palo Alto Networks. Nous créons de la valeur en aidant nos clients à augmenter la productivité, à améliorer l'agilité et la résilience, et à soutenir les opérations durables.

Votre rôle et responsabilités

En tant qu'Ingénieur – Défense numérique, vous jouerez un rôle central pour guider nos clients et sécuriser leurs parcours de confiance zéro (« zero trust »). Vous montrerez l'exemple en dirigeant notre studio de Sécurité et notre équipe de spécialistes sur des projets clients et de la R&D interne. Vous faites la promotion de notre leadership en matière de solutions de confiance numérique et gestion des menaces qui font de SIA le partenaire de choix de nos clients en matière de cybersécurité.

Le candidat idéal pour ce poste excelle dans des environnements dynamiques et rapides et fait preuve d'une forte combinaison de compétences techniques, de connaissances des affaires, de créativité et de capacités de leadership. Vous êtes capable de relever des défis complexes, de concevoir des solutions innovantes et de guider les projets et les équipes vers les résultats commerciaux souhaités.

L'Ingénieur – Défense numérique est axé sur le client et sur les résultats, et ses responsabilités incluront :

Prendre en charge des projets d'architecture, de développement et de déploiement de solutions innovantes qui tirent parti des plateformes et technologies de sécurité de Palo Alto Networks et d'IBM.
Veiller à ce que les solutions soient alignées sur les exigences ; influencer et obtenir l'adhésion des principales parties prenantes ; gérer les attentes et garantir la satisfaction du client.
Diriger le studio « Sécurité » – prendre en charge les projets, encadrer l'équipe, animer les réunions agiles (« scrums » et « sprints »), faire des présentations mensuelles, aider les RH en menant des évaluations de performance pour les employés du studio et en participant à des activités de recrutement.
Diriger les activités et projets de recherche et développement expérimental pour accroître nos connaissances et compétences, développer et améliorer nos méthodologies, et élaborer des offres de solutions et services SIA.
Fournir un support prévente à l'équipe marketing et ventes de SIA (saisir les besoins des clients, répondre aux appels d'offres, développer des propositions et des plans de projet, créer et animer des présentations techniques, des démos, des ateliers et des PoT / PoC).
Participer activement aux médias sociaux et à d'autres occasions de réseautage pour promouvoir votre marque et notre entreprise (y compris des messages et des articles sur les pages vitrines).

Expertise technique et professionnelle requise

Les candidats idéals possèdent le profil suivant :

Compréhension approfondie des technologies de sécurité de Palo Alto Networks (Cortex XSIAM) et d'IBM (QRadar SIEM/SOAR/EDR/XDR, Guardium, Verify).
Compréhension des réseaux de données et du DevSecOps.
Familiarité avec les technologies et déploiements cloud, en particulier Kubernetes et Red Hat OpenShift.
Solides capacités de leadership, de communications, d'empathie et un esprit de croissance.
Maîtrise de l'anglais et du français.
Curiosité (explorateur), créativité et compétences organisationnelles.
À l'aise avec les ventes complexes et des cycles de vente longs.

Autres détails

Emploi permanent à temps plein en présentiel (bureau au centre-ville de Montréal).
Doit être résident de la région de Montréal et avoir l'autorisation de travailler au Canada.
Doit être disponible pour des déplacements occasionnels au Canada, aux États-Unis et aux Caraïbes – pour des projets client, des conférences et de la formation.

Cloud Security Engineer

Elevate business at SIA Innovations

As organizations rely more and more on data and automation, zero-trust and threat management continue to grow exponentially in importance. We want to be at the forefront, guiding our customers towards secure and resilient IT operations with frictionless security.

At SIA Innovations, we are innovators committed to helping our customers transform digitally by leveraging AI and hybrid cloud technologies from IBM and Palo Alto Networks. We create value by helping our customers increase productivity, improve agility & resiliency, and support sustainable operations.

Your role and responsibilities

As an Engineer – Digital Defense, you will play a central role in guiding our customers and securing their zero trust journeys. You will lead by example by directing our Security studio and it's team of specialists on customer and internal R&D projects. You will promote our leadership in digital trust and threat management solutions that make SIA the cybersecurity partner of choice for our customers.

The ideal candidate for this position excels in fast-paced, dynamic environments and demonstrates a strong combination of technical skills, business knowledge, creativity and leadership abilities. You are able to tackle complex challenges, design innovative solutions and guide projects and teams towards the desired business outcomes.

The Engineer - Digital Defense is customer-focused and results-driven, with responsibilities that include:

Taking ownership of projects to architect, develop and deploy innovative solutions that leverage Palo Alto Networks and IBM security platforms and technologies.
Ensure solutions are aligned with requirements; influence and gain buy-in from key stakeholders; manage expectations and ensure customer satisfaction.
Lead the Security studio - take charge of projects, coach the team, lead agile meetings (""scrums"" and ""sprints""), make monthly presentations, assist HR by conducting performance reviews for studio employees and participating in recruitment activities.
Lead research and experimental development activities and projects to increase our knowledge and skills, develop and improve our methodologies, and develop SIA solution and service offerings.
Provide pre-sales support to SIA's marketing and sales team (understand customer needs, respond to RFPs, develop proposals & project plans, create & facilitate technical presentations, demos, workshops, and PoT / PoCs).
Actively participate in social media and other networking opportunities to promote your brand and our company (including posts and articles on showcase pages).

Technical and professional expertise required

Ideal candidates have the following profile:

In-depth understanding of security technologies from Palo Alto Networks (Cortex XSIAM) and IBM (QRadar SIEM/SOAR/EDR/XDR, Guardium, Verify).
Understanding of data networks and DevSecOps.
Familiarity with cloud technologies and deployments, particularly Kubernetes and Red Hat OpenShift.
Strong leadership and communication skills, empathy, and a growth mindset.
Curiosity (explorer), creativity and organizational skills.
Fluency in English and French.
Comfortable with complex sales and long sales cycles.

Other details

Permanent, full-time, face-to-face position (office located in downtown Montreal).
Must be a resident of the Montreal area and have authorization to work in Canada.
Must be available for occasional travel in Canada, the U.S. and the Caribbean - for customer projects, conferences and training.

Apply today!

Join the SIA Innovations team, where your knowledge, experience and winning attitude will help you contribute to SIA's success and growth. We value diversity and employees with a growth mindset (explorers who are adaptable, teachable and coachable), personal & professional agility, and values that align with SIA's purpose, mission and culture.

SIA's CX North Star is to guide and support our customers on their journey to becoming virtual enterprises. Our mission is to make intelligent digital solutions affordable for our customers through the currency of our skills. In embracing transparency, adaptability, and a growth mindset, we open the doors to continuous improvement, innovation and unlimited potential for us and society's future. If you're passionate about growth through innovation, trend spotting and real-time tracking for agile execution, SIA Innovations is your ideal next step.

Ready to contribute to SIA's growth and success? Apply now and help us shape a successful digital future for our customers.","{""role_summary"":""Lead the development and deployment of innovative security solutions, guiding customers towards secure and resilient IT operations with frictionless security."",""key_terms"":[{""term"":""Zero Trust"",""explanation"":""A security concept that assumes no user or device, whether inside or outside an organization, is trusted, and verifies the identity and permissions of all users and devices before granting access to resources.""},{""term"":""DevSecOps"",""explanation"":""A practice that integrates security into DevOps, ensuring the secure development, deployment, and operation of software systems.""},{""term"":""Cortex XSIAM"",""explanation"":""A security information and event management (SIEM) system from Palo Alto Networks that provides real-time threat detection and incident response.""},{""term"":""QRadar SIEM/SOAR/EDR/XDR"",""explanation"":""A suite of security information and event management (SIEM) solutions from IBM that provide threat detection, incident response, and security orchestration.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating the deployment, scaling, and management of containerized applications.""},{""term"":""Red Hat OpenShift"",""explanation"":""A container application platform that provides a hybrid cloud environment for deploying containerized applications.""}],""skill_priorities"":{""must_have"":[""In-depth understanding of security technologies from Palo Alto Networks and IBM"",""Understanding of data networks and DevSecOps"",""Familiarity with cloud technologies and deployments, particularly Kubernetes and Red Hat OpenShift""],""nice_to_have"":[""Curiosity (explorer), creativity and organizational skills"",""Fluency in English and French"",""Comfortable with complex sales and long sales cycles""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design an innovative security solution that leverages Palo Alto Networks and IBM security platforms and technologies?"",""example_answer"":""I would start by understanding the customer's security requirements and then design a solution that integrates Palo Alto Networks' Cortex XSIAM with IBM's QRadar SIEM/SOAR/EDR/XDR capabilities. I would also ensure that the solution is aligned with the customer's DevSecOps practices.""},{""question"":""How do you stay current with the latest developments in cloud technologies and deployments, particularly Kubernetes and Red Hat OpenShift?"",""example_answer"":""I regularly follow industry blogs and attend conferences to stay updated on the latest developments in cloud technologies. I also participate in online forums and discussion groups to learn from others and share my own experiences.""}],""red_flags"":[""Lack of experience with Palo Alto Networks and IBM security technologies"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Platform Engineer,Nirmata,"Toronto, Ontario, Canada",February,2025,"At Nirmata, our mission is to accelerate adoption of cloud native technologies for enterprises. We believe that software can radically transform the world and are building a solution to help enterprises deliver and operate mission critical software at scale. Nirmata is an enterprise-grade multi-cloud Kubernetes platform.

As a Platform Engineer at Nirmata, you will play a key role in operation and lifecycle management of Nirmata’s cloud-native environment delivering SaaS services to customers. You will be implementing necessary tools and processes to deliver a highly available, secure, performant and compliant global SaaS service. You will be collaborating with development, operations and customer success teams to deliver the right solution for Nirmata customers. Your areas of responsibility will span cloud infrastructure builds, CI/CD pipeline, security, performance and availability, monitoring and site reliability engineering.

Responsibilities

Responsible for production and development environment performance and availability.
Manage lifecycle of production and development cloud infrastructure, pipelines, security, monitoring and site reliability.
Troubleshoot and resolve technical issues in production systems.
Provide design and operational solutions for
Manage production and development escalations and work with engineering teams to resolve critical issues.
Create and update technical documentation of different solutions and processes being implemented in the production and dev environment.
Build tools and automation for smooth deployment of applications in production and development environments.
Be a point of escalation to resolve production and development environment issues.
Assist with scoping efforts for deployments and new integrations.
Maintain current technical knowledge of relevant technologies, including Nirmata, Kubernetes, virtualization, networking, monitoring, converged infrastructure, and storage networks.
Responsible for security and compliance of the production and development environments.

Requirements

Bachelor of Arts/Science or equivalent degree in computer science or related field
4+ years of professional experience
Experience with multi-account AWS infrastructure management
Strong Linux OS administration and management skills
Proficiency in shell scripting or Python
Experience with containers, Docker, and Kubernetes
Strong communication and collaboration skills
Ability to diagnose complex technical problems and provide solutions
Broad knowledge in other technical areas to manage complex integration efforts.

Skills

Kubernetes, docker, containers.
AWS cloud - EKS, IAM, networking, storage,
Has experience in DevOps methodologies, tools, and automation.
Linux OS administration and management skills.
Automation skills with shell scripting or python.
Experience with technologies like containers, Docker, and Kubernetes.
Strong problem-solving and analytical skills to troubleshoot complex technical issues.
Familiarity with compliance and security management in cloud environments.

About Nirmata

Nirmata empowers organizations to innovate rapidly without compromising security or compliance. With Gartner forecasting that 99% of cloud security failures will result from misconfigurations by 2027, Nirmata's policy-as-code platform offers a proactive solution. Nirmata's highly customizable policies seamlessly integrate with your cloud-native environments, ensuring robust governance and security at scale. Trusted by top financial institutions and global enterprises—and with over 3.2 billion downloads of Kyverno, Nirmata's open source policy engine —Kyverno simplifies compliance, mitigates risk, and accelerates the enterprise journey to secure innovation.

Nirmata’s success is built on the diverse contributions of its employees. We're committed to an inclusive workplace where everyone's perspective is valued, and we do not discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, marital, veteran, or disability status. All application information will be kept confidential in accordance with EEO guidelines.

Nirmata uses E-Verify for US-based roles, confirming work authorization after a job offer is accepted and the I-9 is completed. If E-Verify can't confirm authorization, we'll provide instructions on contacting DHS or SSA before any action is taken. See the Notice of Right to Work for details.

By submitting your application, you acknowledge that Nirmata will process your personal data in accordance with our Privacy Policy.","{""role_summary"":""As a Platform Engineer at Nirmata, you will play a key role in operation and lifecycle management of Nirmata’s cloud-native environment delivering SaaS services to customers."",""key_terms"":[{""term"":""Cloud-native environment"",""explanation"":""A software application designed to take advantage of cloud computing models and scalable infrastructure.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized workloads.""},{""term"":""CI/CD pipeline"",""explanation"":""A set of practices that combines continuous integration and continuous delivery, ensuring code changes are automatically built, tested, and released to production.""},{""term"":""Site reliability engineering"",""explanation"":""A discipline that combines software engineering and operations to build and run scalable, reliable, and efficient systems.""}],""skill_priorities"":{""must_have"":[""Experience with multi-account AWS infrastructure management"",""Strong Linux OS administration and management skills"",""Proficiency in shell scripting or Python"",""Experience with containers, Docker, and Kubernetes""],""nice_to_have"":[""Broad knowledge in other technical areas to manage complex integration efforts"",""Familiarity with compliance and security management in cloud environments""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you troubleshoot and resolve technical issues in a production system?"",""example_answer"":""I would use tools like Kubernetes logs and monitoring tools to identify the issue, then use my knowledge of Linux OS administration to resolve the problem.""},{""question"":""Can you explain how you would implement security and compliance in a cloud-native environment?"",""example_answer"":""I would use tools like IAM and Kubernetes network policies to implement security and ensure the environment is compliant with relevant regulations.""}],""red_flags"":[""Lack of experience with Kubernetes and Docker"",""Inability to diagnose complex technical problems""],""confidence_score"":90.0}"
IT Security Engineer,MindPal,"Calgary, Alberta, Canada",December,2023,"We are looking for IT Security Engineer

Responsibilities

Implementation, management, and monitoring of IT security measures and protections within the organization
Analysis and evaluation of potential threats, designing and implementing security solutions
Monitoring IT infrastructure to identify security vulnerabilities and taking appropriate corrective actions
Responding to security incidents and providing technical support in IT security
Collaborating with IT teams and other departments to implement and maintain security policies, standards, and procedures
Managing security tools, creating IT security reports, and conducting audits
Adjusting security strategies to changing industry requirements and regulations

Requirements

Minimum 3 years of experience in IT Security or a related field
Knowledge of IT security tools and technologies
Ability to identify and analyze potential threats, and develop appropriate security solutions
Knowledge of risk management principles and procedures for responding to security incidents
Ability to work in a team and good interpersonal communication skills
IT security certifications such as CISSP, CISM, CEH, are an additional advantage

We Offer

B2B contract type
Full-time employment
Remote and flexible working hours","{""role_summary"":""An IT Security Engineer is responsible for implementing, managing, and monitoring IT security measures, identifying and responding to security threats, and collaborating with teams to maintain security policies and procedures."",""key_terms"":[{""term"":""CISSP"",""explanation"":""Certified Information Systems Security Professional, a prestigious credential in IT security.""},{""term"":""CISM"",""explanation"":""Certified Information Security Manager, a certification demonstrating expertise in information security management.""},{""term"":""CEH"",""explanation"":""Certified Ethical Hacker, a certification demonstrating expertise in ethical hacking and penetration testing.""}],""skill_priorities"":{""must_have"":[""Knowledge of IT security tools and technologies"",""Ability to identify and analyze potential threats"",""Ability to work in a team and good interpersonal communication skills""],""nice_to_have"":[""IT security certifications such as CISSP, CISM, CEH""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a recent security threat you identified and how you responded?"",""example_answer"":""I identified a vulnerability in our firewall configuration and worked with the team to implement a patch and update our security protocols.""},{""question"":""How do you stay current with changing industry requirements and regulations in IT security?"",""example_answer"":""I regularly review industry publications and attend webinars to stay informed about emerging threats and best practices.""}],""red_flags"":[""Lack of experience in IT security or a related field"",""Inability to identify and analyze potential threats""],""confidence_score"":85.0}"
Cybersecurity Analyst,Dialogue,"Montreal, Quebec, Canada",June,2024,"Your role as Cybersecurity Analyst

Reporting to CISO, you will contribute to securing Dialogue systems against cyber threats, ensuring the integrity, confidentiality and availability of data through detailed analysis, incident response, policy and protocols development and implementation.

What You’ll Be Doing

Monitor, review, and analyze the security of systems and processes, including network logs and security data. Perform security incident response activities and develop relevant indicators (KRIs/KPIs) based on complex analysis.
Assist in threat response exercises and business continuity plan testing. Support daily cybersecurity operations such as incident response, patch management, vulnerability management, and access management.
Develop, administer, and implement cybersecurity policies, protocols, plans, and guidelines. This includes creation and maintenance of security plans and protocols to prevent and mitigate potential incidents.
Conduct information systems security controls and risk assessments to identify vulnerabilities. Assist in the creation and maintenance of the security risk register, audit requests, and vendor assessments.
Review and maintain information security policies and training materials, respond to security questionnaires, and collaborate in change management communications and processes. Consult with IT and Engineering directors to develop the objectives of the cybersecurity program and facilitate compliance training.

We'd Love To Hear From You If You Have

5+ years of experience in cybersecurity operations with increasing responsibilities.
Demonstrated expertise or experience with Incident Response, Vulnerability Management, Network Security, Identify and Access Management, Cloud-based technology (Okta, Auth0, AWS, DataGuard, GCP, Google Workspace), Zero Trust Network Access, scripting knowledge is a plus.
Knowledge of frameworks and industry standards: NIST CSF, OWASP, MITRE ATT&CK, SSDLC.
Information security certifications (CRISC, CISA, CISM, CGEIT, CISSP, CCSP) are considered an asset.

Please note that as we serve customers across Canada, bilingualism is essential for this position. You may be required to communicate in French and English.

At Dialogue, your well-being is our priority

Taking care of others also means taking care of our team. We’ve got you covered!

A fully funded benefits plan, including a wellness reimbursement program
Unlimited access to a variety of Dialogue's programs for you and your immediate family
4 weeks of vacation, 9 wellness days and 1 paid volunteer day
A hybrid work approach that involves 3 days per week in our beautiful Montreal or Toronto offices
Access to a custom learning program, including an allocated budget for continuous external training
Short and long-term incentive plans, including restricted stock units (RSUs)
An optional parental benefits program
Qualifying permanent and part-time employees are eligible for a Group Retirement Savings Program (GRSP) with a matching employer contribution from their first day at Dialogue, in accordance with policy terms

About Dialogue

Dialogue is the #1 virtual care provider in Canada. By developing our Integrated Health Platform🅫, we provide exceptional online health and wellness programs (primary care, mental health, iCBT, EAP, and wellness) to organizations that want to improve the wellness of their employees and families.

When It Comes To Our Work, We Set The Bar High. Together, We’re Transforming Health And Helping Millions Improve Their Well-being. We’re Firm Believers That Great People Don’t Settle On

Impact

Community

Growth

Excellence

Feel like you can make a difference? Good news, we saved you a seat!

Come as you are. As a proud equal opportunity employer, Dialogue is dedicated to creating a diverse and inclusive workplace for everyone. Qualified applicants will be considered regardless of citizenship, ethnicity, race, colour, religion, gender, gender identity or expression, sexual orientation, disability, age, or veteran status. Applicants who require specialized accommodation are encouraged to contact accessibility@dialogue.co.","{""role_summary"":""Contribute to securing Dialogue systems against cyber threats, ensuring data integrity, confidentiality, and availability through analysis, incident response, policy development, and implementation."",""key_terms"":[{""term"":""Incident Response"",""explanation"":""Responding to and managing cybersecurity threats to minimize damage.""},{""term"":""Vulnerability Management"",""explanation"":""Identifying and mitigating weaknesses in systems to prevent cyber attacks.""},{""term"":""Network Security"",""explanation"":""Protecting computer networks from unauthorized access, use, disclosure, disruption, modification, or destruction.""},{""term"":""Zero Trust Network Access"",""explanation"":""A security approach that assumes no user or device is trusted, and verifies identities before granting access.""},{""term"":""Cloud-based technology"",""explanation"":""Using cloud computing services like Okta, Auth0, AWS, DataGuard, GCP, and Google Workspace for storing, processing, and transmitting data.""},{""term"":""NIST CSF"",""explanation"":""A cybersecurity framework providing guidelines for managing and reducing cybersecurity risk.""},{""term"":""OWASP"",""explanation"":""An open-source web application security project providing resources for secure web development.""},{""term"":""MITRE ATT&CK"",""explanation"":""A knowledge base of cyber attacks and techniques used to identify and mitigate threats.""},{""term"":""SSDLC"",""explanation"":""A secure software development life cycle approach integrating security practices into software development.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in cybersecurity operations"",""Demonstrated expertise or experience with Incident Response, Vulnerability Management, Network Security, Identify and Access Management, Cloud-based technology"",""Knowledge of frameworks and industry standards: NIST CSF, OWASP, MITRE ATT&CK, SSDLC""],""nice_to_have"":[""Scripting knowledge"",""Information security certifications (CRISC, CISA, CISM, CGEIT, CISSP, CCSP)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with incident response and vulnerability management?"",""example_answer"":""I have worked on several incident response projects, identifying and mitigating vulnerabilities in our systems. I have also developed and implemented vulnerability management plans to minimize the risk of future incidents.""},{""question"":""How do you stay current with industry standards and frameworks in cybersecurity?"",""example_answer"":""I participate in online forums and attend webinars to stay updated on the latest developments in NIST CSF, OWASP, MITRE ATT&CK, and SSDLC. I also network with peers to share knowledge and best practices.""}],""red_flags"":[""Lack of experience in cloud-based technology"",""No knowledge of industry standards and frameworks"",""No information security certifications""],""confidence_score"":90.0}"
Cyber Security Analyst I (3am-11amPST),Ntirety,"Vancouver, British Columbia, Canada",June,2024,"COMPANY OVERVIEW:

With over two decades of successfully operating, managing, and securing private, public, and hybrid cloud environments, Ntirety has led enterprises across industries through the volatile early days of data hosting into the world of 24x7 managed security with our premier Compliant Security solutions. Through cost effective and scalable solutions tailored to business-specific needs, Ntirety eliminates gaps in both security posture and compliance documentation by delivering solutions that cover the entire application, the entire compliance and security process, the entire time.

When it comes to a cybersecurity crisis, the question is not if, but when it will happen - that's why Ntirety's mission to provide proactive compliant security is crucial in today's business landscape. No matter what role or department you work in, being a part of Ntirety means supporting all of our different teams to help keep our clients protected and updated on the latest in cybersecurity.

Join the team at the forefront of this mission-critical industry. For more information about Ntirety, please visit www.ntirety.com.

POSITION PURPOSE:

Cyber security analysts are responsible for managing, monitoring, troubleshooting and protecting both the security of our internal environment and that of our customers. They will perform any steps necessary to that end. They will design, implement, monitor, and evaluate the security systems that protect an organization's computer systems and data. As a Cyber Security Analyst, you will monitor the computer networks under management for security issues, install security software, and document any security issues you identify. This role also acts as the first point of contact for customer related security incidents and questions.

In order to be eligible for the Employee Bonus Plan, all employees are required to be performing their job duties satisfactorily during the applicable bonus period. This includes consistent responsiveness during any assigned On Call periods. Employees should also review the Employee Bonus Plan eligibility requirements to determine if they are eligible. If you have any questions on your eligibility for the Employee Bonus Plan please contact Human Resources.

ESSENTIAL JOB DUTIES AND RESPONSIBILITIES:

Monitor computer networks for security issues and respond accordingly, including:
Creating/Managing firewall rules
Managing anti-virus endpoint tools
Performing event correlation analysis on potential threats identified through our SIEM
Configuring/Managing log management
Configuring/Managing file integrity monitoring
Performing vulnerability scans and remediation of identified risks
The methodology & analysis of identifying compromised servers
Performing rule tuning in our SIEM for improved detection capabilities
Interact with customers by phone, chat, or trouble ticket on any customer facing security issues
Investigate, document and assess security breaches and other cyber security incidents
Install security measures and operate software to protect systems and information infrastructure, including firewalls and data encryption programs
Prepare security reports for customer business insights reviews to support our guidance level agreements initiatives
Identify and fix detected vulnerabilities to maintain a high-security standard
Work with other technology teams and customers to perform tests and uncover network or other vulnerabilities
May be relied upon as a technical point of contact during Escalated Events relating to security
Review, investigate and respond to any external ""abuse"" complaints coming from our IP space
Develop best practices for IT security
Research security enhancements and make recommendations to management
Handle escalated internal or customer security issues from support or other operations team
Takes part in any security-oriented projects or critical initiatives
Stay up to date on information technology & security news, trends and standards
Deliver an exceptional customer experience every day
Other duties as identified or assigned


DESIRED ROLE OUTCOMES:

Keep us and our customers free from security incidents but respond capably when one occurs
Contribute to continually improving our detection of security threats
Provide valuable insights and visibility around security incidents to our customers
Have a staff of customer focused, energetic and security savvy team members


Requirements

DESIRED MINIMUM QUALIFICATIONS:

Must have technical troubleshooting and problem-solving skills
Understanding of network management principles
Experience in systems administration of Windows and Linux based operating systems
Working knowledge of Palo Alto firewalls, Juniper networking equipment, LogRhythym SIEM solution or similar technologies
Understanding of firewalls, proxies, SIEM, antivirus, penetration testing, vulnerability scans and IDS/IPS concepts
Ability to identify and mitigate network vulnerabilities and explain how to avoid them
Understanding of patch management with the ability to deploy patches in a timely manner while understanding business impact
Ability to learn and communicate technical information to non-technical people
Must have excellent written & oral communication skills, and strong interpersonal skills
Must emulate the Ntirety Values in all that they do
Bachelor's degree in computer science or related field or equivalent experience


PREFERRED SKILLS:

Additional certifications in security related disciplines (eg: Security+, CEH, CISSP, etc.)


Benefits

Ntirety is an Equal Employment Opportunity / Affirmative Action Employer (EEO/AA).

Ntirety offers a competitive salary and benefits including Paid Time Off, FREE Medical to Employees, Dental, retirement plan with 401(k) match, and much more. If you are interested in joining a profitable, growing, and dynamic company, we want to hear from you! Ntirety is an Equal Opportunity Employer and does not discriminate on the basis of race, color, religion, sex, age, national origin, disability, veteran status, sexual orientation, or any other classification protected by Federal, State or local law.

Ntirety thanks all candidates for their interest; however, only shortlisted candidates will be contacted.","{""role_summary"":""Manage, monitor, troubleshoot and protect internal and customer environments from cyber security threats, designing and implementing security systems and evaluating their effectiveness."",""key_terms"":[{""term"":""SIEM"",""explanation"":""Security Information and Event Management, a system that monitors and analyzes security-related data from various sources.""},{""term"":""Palo Alto firewalls"",""explanation"":""A type of firewall that provides network security and protects against cyber threats.""},{""term"":""IDS/IPS"",""explanation"":""Intrusion Detection System/Intrusion Prevention System, a system that detects and blocks potential security threats.""},{""term"":""LogRhythym SIEM solution"",""explanation"":""A specific Security Information and Event Management system.""}],""skill_priorities"":{""must_have"":[""Technical troubleshooting and problem-solving skills"",""Understanding of network management principles"",""Experience in systems administration of Windows and Linux based operating systems"",""Ability to identify and mitigate network vulnerabilities""],""nice_to_have"":[""Additional certifications in security related disciplines (e.g. Security+, CEH, CISSP, etc.)""]},""proposed_screening_questions_with_answers"":[{""question"":""What steps would you take to identify and mitigate a network security threat?"",""example_answer"":""I would use a combination of tools such as firewalls, intrusion detection systems, and vulnerability scans to identify potential threats. Then, I would implement measures to mitigate the threat, such as patch management and configuring log management.""},{""question"":""How would you explain a technical security concept to a non-technical person?"",""example_answer"":""I would use analogies and simple language to explain the concept, avoiding technical jargon. For example, I would explain a firewall as a virtual barrier that protects a network from unauthorized access.""}],""red_flags"":[""Lack of experience in systems administration of Windows and Linux based operating systems"",""Inability to communicate technical information to non-technical people""],""confidence_score"":90.0}"
Info Security Analyst x6,Randstad Canada,"Toronto, Ontario, Canada",June,2024,"Are you a Info Security Analyst looking for a new opportunity?

Are you looking for a new contract opportunity?

We are pleased to offer you a new contract opportunity for you to consider: Info Security Analyst

Start: ASAP
Estimated length: 6 months
Location: Toronto
Hybrid role- onsite twice a week

Advantages

You will have an opportunity to work with a leading employer in the local market.
Potential for contract extension and conversion.

Responsibilities

Develop and implement comprehensive risk management strategies and policies to mitigate identified risks, including but not limited to, cyber threats, data breaches, IT outages, and technology compliance issues.
Collaborate with IT, business units, and cybersecurity teams to enhance the banks cyber and technology risk posture through proactive risk identification, assessment, and response planning.
Oversee and guide the risk assessment process for new and existing technologies, digital initiatives, and third-party service providers, ensuring comprehensive risk evaluation and mitigation planning.
Provide expert advice and guidance to senior management on technology and cyber risk trends, potential impacts on the bank, and recommended risk mitigation strategies.
Facilitate and promote a culture of risk awareness and cybersecurity resilience across the organization, including the development and delivery of risk management training programs.
Monitor and analyze developments in technology and cybersecurity threats, including regulatory changes, to continuously refine and update risk management strategies.
Prepare and present detailed risk reports and dashboards to senior management and relevant committees, highlighting the banks risk posture, emerging risks, and effectiveness of risk mitigation efforts.

Qualifications

Compliance testing experience
Fraud/AML/KYC/Insider Risk experience
Financial institution background
Cyber Risk Assessment experience
BISO – Business Information Security Officer

NICE TO HAVE

Company’s Bank experience

Summary

Do you have this experience? If you answer YES, then please apply IMMEDIATELY to so we can then discuss your experience and interest in this opportunity!

Randstad Technologies Group

Canada's largest provider of IT Staffing Solutions, offering hundreds of permanent and contract opportunities across all roles, levels and platforms. Our Web-based tools help you see and apply for jobs matched automatically to your skills and preferences. When you're ready to interview we meet with you in person to help you build the technology career path you've always wanted. Visit www.randstad.ca to get started!

Randstad Canada is committed to fostering a workforce reflective of all peoples of Canada. As a result, we are committed to developing and implementing strategies to increase the equity, diversity and inclusion within the workplace by examining our internal policies, practices, and systems throughout the entire lifecycle of our workforce, including its recruitment, retention and advancement for all employees. In addition to our deep commitment to respecting human rights, we are dedicated to positive actions to affect change to ensure everyone has full participation in the workforce free from any barriers, systemic or otherwise, especially equity-seeking groups who are usually underrepresented in Canada's workforce, including those who identify as women or non-binary/gender non-conforming; Indigenous or Aboriginal Peoples; persons with disabilities (visible or invisible) and; members of visible minorities, racialized groups and the LGBTQ2+ community.

Randstad Canada is committed to creating and maintaining an inclusive and accessible workplace for all its candidates and employees by supporting their accessibility and accommodation needs throughout the employment lifecycle. We ask that all job applications please identify any accommodation requirements by sending an email to accessibility@randstad.ca to ensure their ability to fully participate in the interview process.","{""role_summary"":""The Info Security Analyst will develop and implement risk management strategies, collaborate with IT and cybersecurity teams, and provide expert advice on technology and cyber risk trends."",""key_terms"":[{""term"":""Cyber Risk Assessment"",""explanation"":""Evaluating potential cyber threats and developing strategies to mitigate them.""},{""term"":""BISO – Business Information Security Officer"",""explanation"":""A role responsible for overseeing and implementing information security measures within an organization.""},{""term"":""AML/KYC/Insider Risk"",""explanation"":""Anti-Money Laundering, Know Your Customer, and Insider Risk management to prevent financial fraud and ensure compliance.""}],""skill_priorities"":{""must_have"":[""Compliance testing experience"",""Fraud/AML/KYC/Insider Risk experience"",""Financial institution background"",""Cyber Risk Assessment experience"",""BISO – Business Information Security Officer""],""nice_to_have"":[""Company’s Bank experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with cyber risk assessment and mitigation strategies?"",""example_answer"":""I have worked on several projects where I identified potential risks and developed strategies to mitigate them, ensuring compliance with regulatory requirements.""},{""question"":""How do you stay up-to-date with emerging cyber threats and technology risks?"",""example_answer"":""I regularly attend webinars, read industry publications, and participate in online forums to stay current and informed about the latest threats and trends.""}],""red_flags"":[""Lack of experience in compliance testing and fraud/AML/KYC/Insider Risk"",""No experience working in a financial institution""],""confidence_score"":90.0}"
Information Security Analyst,CanDeal,"Toronto, Ontario, Canada",June,2024,"JOB PURPOSE

Reporting to the Information Security Officer, the Information Security Analyst will possess a strong background in managing infrastructure, coupled with significant experience and expertise in cybersecurity. This role will involve analyzing threats, implementing security controls, responding to incidents, and supporting cybersecurity initiatives and projects.

PRIMARY RESPONSIBILITIES
Oversee and create all Information Security-related tasks within CanDeal environments and new projects.
Conduct in-depth security assessments of infrastructure components to identify vulnerabilities, assess risks, and recommend mitigation strategies.
Monitor security alerts and events, investigate incidents, and lead incident response efforts to contain and remediate security breaches.
Provide level 3 support to the Security Operations teams, particularly in conducting investigations derived from threat intelligence.
Develop and implement security policies, standards, and procedures to ensure compliance with regulatory requirements and industry best practices.
Manage and maintain security technologies and tools, including firewalls, intrusion detection/prevention systems (IDS/IPS), antivirus, and endpoint security solutions.
Proficiency in conducting penetration tests, including planning, executing, and analyzing results to identify vulnerabilities and enhance security measures.
Collaborate with cross-functional teams to integrate security requirements into the design and deployment of IT systems and applications.
Provide guidance and support to IT teams on security-related matters, including security awareness training and adherence to security policies.
Stay abreast of the latest cybersecurity threats, trends, and technologies through continuous learning and participation in industry events and training programs.
Assist in the development and implementation of cybersecurity initiatives and projects to enhance the organization's security posture.
Read, analyze, and design process and procedure, also, be able to identify enhancements opportunities, prepare supporting data and present to management for approval.
Conducting audit meetings, summarizing the discussions, defining action items, and follow up until completion.
Participate in on-call rotation to provide after-hours support for security incidents and emergencies.

QUALIFICATIONS

Education & Experience
Bachelor’s degree in computer science, technology or related field is required.
AWS Certified Security and/or AWS Solutions Architect Certification is required.
Certification(s) in cybersecurity (e.g. CISSP, CCSP, CySA+, GSEC, OSCP, Azure Security Engineer) preferred.
Minimum of four (4) years of experience in IT security-related projects, including working with security controls and processes, with a preference for experience in the financial services industry.

Knowledge, Skills & Abilities
Demonstrated proficiency in technology troubleshooting and exceptional analytical abilities, capable of thinking creatively to resolve issues.
Experience with security technologies and tools, such as firewalls, IDS/IPS, antivirus, and endpoint security solutions.
Strong technical knowledge of networking, operating systems, and cloud environments.
Robust experience in cloud security to enhance organization's resilience in an increasingly cloud-centric environment.
Familiarity with security frameworks and standards, including NIST Cybersecurity Framework and ISO 27001/27002.
Excellent verbal and written communication skills, with the ability to effectively clarify complex technical issues and concepts in a business-friendly manner to various audiences.
Strong organizational skills, with the abilities to manage multiple deliverables in a demanding, time-sensitive environment, adapt to frequently changing priorities by prioritizing tasks and escalate / communicate issues or seek assistance to overcome obstacles.
Ability to work effectively within a team, as well as independently.

Key Qualities for Success
Have a deep interest in computing and cybersecurity.
Self-motivated and driven.
Highly attentive to detail and committed to quality.
Enthusiastic, service oriented.

DECISION MAKING
Recommends IT security tools to the ISO based on current industry knowledge and best practice and provides input to IT Security policies.
Collaborate with teams to align security measures with organizational goals and continuously improve security posture through proactive initiatives.","{""role_summary"":""The Information Security Analyst is responsible for managing infrastructure, analyzing threats, implementing controls, responding to incidents, and supporting initiatives. They oversee security tasks, conduct assessments, monitor alerts, and develop policies to ensure compliance with regulations and industry best practices."",""key_terms"":[{""term"":""IDS/IPS"",""explanation"":""Intrusion Detection/Prevention Systems, which monitor network traffic for signs of unauthorized access or malicious activity.""},{""term"":""Endpoint security solutions"",""explanation"":""Software that protects devices like laptops and smartphones from cyber threats by monitoring and controlling their behavior.""},{""term"":""NIST Cybersecurity Framework"",""explanation"":""A set of guidelines for managing and reducing cybersecurity risk, widely adopted by organizations.""},{""term"":""CISSP"",""explanation"":""Certified Information Systems Security Professional, a prestigious certification for information security professionals.""}],""skill_priorities"":{""must_have"":[""AWS Certified Security"",""4+ years of IT security experience"",""Bachelor's degree in computer science or related field""],""nice_to_have"":[""CISSP"",""CCSP"",""CySA+"",""GSEC"",""OSCP"",""Azure Security Engineer"",""experience in financial services industry""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your experience with cloud environments and how you've enhanced an organization's security posture?"",""example_answer"":""In my previous role, I implemented security controls and processes that improved our cloud security by 30%. I'm familiar with AWS and Azure security best practices.""},{""question"":""How do you stay current with the latest cybersecurity threats and trends?"",""example_answer"":""I participate in industry events, read relevant blogs, and engage in online forums to stay informed. I also hold certifications like CISSP and AWS Security.""}],""red_flags"":[""Lack of experience with cloud security"",""Inability to communicate technical issues effectively""],""confidence_score"":95.0}"
Cyber Security Engineer,Momentum Financial Services Group,"Toronto, Ontario, Canada",June,2024,"Company Description

Momentum Financial Services is a leading provider of financial services in North America. For 40 years, we've been committed to providing financial solutions that meet the evolving needs of consumers and business owners. Through our retail network of over 400 locations, known as Moneymart, Insta Cheques and the Cheque Cashing store, we provide access to cash and related products to help our customers achieve their goals.

Our highly skilled workforce puts customers first in everything we do. We serve 2 million people annually with diverse and innovative financial products such as loans, cheque cashing, money transfer and prepaid cards. Through this ever-evolving suite of services, we empower customers to manage their finances and improve their lives. Wherever customers are on their financial journey, Momentum Financial Services Group provides solutions.

#Corporate

Job Description

Candidates must reside in the GTA area to be considered for this role as they will be required to be in office 3 days a week at the Toronto Corporate Office.

General Function

We are seeking a highly skilled and experienced Cyber Security Engineer to join our dynamic team. The successful candidate will play a crucial role in ensuring the integrity, confidentiality, and availability of our systems and data. As a Cyber Security Engineer, you will be responsible for designing, implementing, and maintaining security measures to protect our organization against cyber threats and vulnerabilities.

Responsibilities

Develop and implement robust security solutions to safeguard our systems, networks, and applications.
Conduct regular security assessments, and vulnerability scans to identify and mitigate potential risks.
Monitor security logs and alerts to detect and respond to security incidents in a timely manner.
Collaborate with cross-functional teams to integrate security best practices into the development and deployment of new technologies and initiatives.
Stay abreast of emerging cyber threats, security technologies, and industry best practices to continuously enhance our security posture.
Provide technical guidance and support to internal stakeholders on security-related matters.
Participate in incident response activities and assist in post-incident analysis and remediation efforts.
Ensure compliance with relevant regulatory requirements and industry standards related to information security.

Qualifications

Bachelor's degree in Computer Science, Information Security, or a related field. Advanced degree or relevant certifications (e.g., CISSP, CISM, CEH) preferred.
Proven experience in cyber security engineering/Architecture roles, preferably within the financial industry.
Strong understanding of security principles, protocols, and technologies, including but not limited to firewalls, intrusion detection/prevention systems, encryption, application security, and endpoint security.
Hands-on experience with security tools and technologies such as SIEM, IDS/IPS, DLP, and vulnerability management platforms.
Proficiency in scripting and programming languages (e.g., Python, PowerShell) for automation and tool development.
Excellent analytical and problem-solving skills with a keen attention to detail.
Effective communication and interpersonal skills with the ability to collaborate effectively across teams and communicate complex technical concepts to non-technical stakeholders.
Ability to work independently and prioritize tasks in a fast-paced environment.

Additional Information

All your information will be kept confidential according to EEO guidelines.

Notice to Ontario Applicants – Momentum Financial Services Group is committed to accommodating applicants with disabilities up to the point of undue hardship during the recruitment, assessment, and selection process. If you are selected for an interview, please notify Momentum Financial Services Group if you require accommodation in respect of the materials or procedures used at any time during this process. If you require accommodation, we will work with you to determine how to meet your needs.

Note to Internal Applicants: All internal applicants are required to notify current manager regarding interest in applying for this role.","{""role_summary"":""A Cyber Security Engineer responsible for designing, and maintaining security measures to protect the organization against cyber threats and vulnerabilities."",""key_terms"":[{""term"":""Cyber Security Engineer"",""explanation"":""A professional responsible for ensuring the integrity, confidentiality, and availability of systems and data.""},{""term"":""SIEM"",""explanation"":""Security Information and Event Management system, used to monitor security logs and alerts.""},{""term"":""IDS/IPS"",""explanation"":""Intrusion Detection/Prevention Systems, used to detect and respond to security incidents.""},{""term"":""DLP"",""explanation"":""Data Loss Prevention, a system used to detect and prevent unauthorized access.""},{""term"":""CISSP"",""explanation"":""Certified Information Systems Security Professional, a certification for security professionals.""}],""skill_priorities"":{""must_have"":[""Proven experience in cyber security engineering/architecture roles"",""Strong understanding of security principles, protocols, and technologies"",""Hands-on experience with security tools and technologies"",""Proficiency in scripting and programming languages""],""nice_to_have"":[""Advanced degree or relevant certifications (e.g., CISSP, CISM, CEH)"",""Experience within the financial industry""]},""proposed_screening_questions_with_answers"":[{""question"":""What is your experience with security information and event management systems?"",""example_answer"":""I have worked with SIEM systems to monitor security logs and alerts, and have experience with configuring and customizing SIEM systems to meet organizational needs.""},{""question"":""How do you stay current with emerging cyber threats and technologies?"",""example_answer"":""I regularly review industry publications and attend conferences to stay current with emerging threats and technologies.""}],""red_flags"":[""Lack of experience with security tools and technologies"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Security Operations Analyst (Contract),KUBRA,"Mississauga, Ontario, Canada",June,2024,"KUBRA is looking for a Security Operations Analyst to join our Information Security team!

As a Security Operations Analyst your job will be to enhance and validate the compliance, integrity, and security of KUBRA's systems and services.

This is an 18-month contract opportunity with a hybrid work model based out of our office Mississauga, ON.

What You Get To Do Every Day

Maintain the security infrastructure (Firewalls, IDS/IPS, AV, SIEM, FIM, servers etc)
Monitor systems, software and skills to stay ahead of emerging threats:
Participate in security investigations and Assist during Incident Response and Recovery activities.
Maintain and enforce KUBRA’s IT management control framework that defines the institution’s overall approach to IT risk and control
Participate in on-call rotation to respond, investigate and resolve Security Incidents
Track and action alerts to ensure proper response is taken by coordinating the work efforts of internal teams and actions required of external service providers.
Apply understanding of environment and operational issues to work with external or internal parties for implementation or optimization of specific SIEM use cases to help improve detection and response.
Maintain the vulnerability security digest and provide updates to relevant parties
Monitor threat feeds and provide regular threat intelligence updates.
Conduct access control reviews on a case-by-case basis to systems and work with internal and external resources to update user control lists and provide reports.
Assist in remediation tasks related to audits/penetration tests.
Evaluate and provide guidance to exemption requests as per corporate policy and tandards, to advise of risk involved.

What kind of person should you be?

Ability to detail and effectively discriminate relevant logs / security events
Ability to handle multiple tasks and projects concurrently
Excellent written and verbal communication skills
Ability to plan and manage complex security projects, and meet the deadlines
Excellent organization, time management and problem-solving skills
Ability to handle pressure under minimum or no direct supervision

What skills do you need?

Degree or equivalent Experience in Computer Information Systems Incident Handler certification i.e., E|CIH, GCIH, IHRP, CSIH, CIHE is required
Other relevant certifications that are considered an asset including MCSE, CCNA, CCNP, GCIH, GCIA, GCFE, GREM, GCFA, GSEC etc.
1-2 years experience in a Security Operations role
1-2 years of experience in Incident Management and related processes
Prior experience with Cloud based services (AWS/Azure) is considered a strong asset
Prior experience architecting information security solutions considered a strong asset
Knowledge of PCI DSS requirements is preferred

What can you expect from us?

Award-winning culture that fosters growth, diversity and inclusion for all
Free unlimited access to our refreshment stations (fully stocked with tea, coffee and other beverages)

While we value the skills and experiences listed in our job requirements, we also recognize that talent comes in many forms, and welcome applications from candidates who meet most but not all specified requirements. If you possess a strong desire to learn and grow in a dynamic work environment, apply now!

KUBRA is a fast-growing company that delivers customer communications solutions to some of the largest utility, insurance, and government entities across North America. KUBRA offers billing and payments, mapping, mobile apps, proactive communications, and artificial intelligence solutions for customers. With more than 1.5 billion customer interactions annually, KUBRA services reach over 40% of households in the U.S. and Canada. KUBRA is an operating subsidiary of Hearst.

Our office is small enough to allow creative individuals to flourish, yet large enough to provide long-term stability. We place a tremendous amount of responsibility on our team members to be productive, focused and self-motivated. We offer a casual work environment, competitive compensation and a stellar benefits program.","{""role_summary"":""The Security Operations Analyst is responsible for maintaining the security infrastructure, monitoring systems, and participating in security investigations to ensure the compliance, integrity, and security of KUBRA's systems and services."",""key_terms"":[{""term"":""IDS/IPS"",""explanation"":""Intrusion Detection System/Intrusion Prevention System, which monitors network traffic for signs of unauthorized access or malicious activity.""},{""term"":""SIEM"",""explanation"":""Security Information and Event Management, a system that collects, monitors, and analyzes security-related data from various sources to provide real-time insights and incident response.""},{""term"":""FIM"",""explanation"":""File Integrity Monitoring, which monitors and detects changes to critical system files and data to ensure the integrity of the system.""},{""term"":""IT management control framework"",""explanation"":""A set of policies, procedures, and controls that define the approach to managing IT risks and ensuring the security of IT systems.""},{""term"":""SIEM use cases"",""explanation"":""Specific scenarios or applications of SIEM systems to detect and respond to security threats.""},{""term"":""Threat feeds"",""explanation"":""Real-time streams of data on potential security threats, used to stay informed about emerging threats and improve threat intelligence.""},{""term"":""Vulnerability security digest"",""explanation"":""A summary of identified vulnerabilities in the system, used to track and prioritize remediation efforts.""},{""term"":""Incident Handler certification"",""explanation"":""A certification that demonstrates expertise in handling and responding to security incidents, such as E|CIH, GCIH, IHRP, CSIH, CIHE.""}],""skill_priorities"":{""must_have"":[""Degree or equivalent Experience in Computer Information Systems"",""Incident Handler certification (e.g., E|CIH, IHRP, CSIH, CIHE)"",""1-2 years experience in a Security Operations role"",""1-2 years of experience in Incident Management and related processes""],""nice_to_have"":[""MCSE, CCNA, CCNP, GCIH, GCIA, GCFE, GREM, GCFA, GSEC certifications"",""Prior experience with Cloud-based services (AWS/Azure)"",""Prior experience architecting information security solutions"",""Knowledge of PCI DSS requirements""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the importance of SIEM in a security operations center?"",""example_answer"":""SIEM is crucial in a security operations center as it provides real-time insights and incident response, enabling the team to detect and respond to security threats effectively.""},{""question"":""How would you handle a security incident with minimal supervision?"",""example_answer"":""I would follow the incident response plan, assess the incident, contain the damage, and communicate with the team and stakeholders to resolve the incident efficiently.""}],""red_flags"":[""Lack of experience in Security Operations or Incident Management"",""No relevant certifications in Information Security"",""Limited knowledge of Cloud-based services""],""confidence_score"":90.0}"
Security Assessment -Cyber Risk /AML,BeachHead,"Toronto, Ontario, Canada",June,2024,"orking with one of the top financial clients this role calls for a Security Assessment -Cyber Risk /AML who will be responsible for leading the identification and assessment of technology and cybersecurity risks across the bank's digital assets, IT infrastructure, and operations, ensuring alignment with the bank’s risk appetite and regulatory requirements. The successful candidate will facilitate and promote a culture of risk awareness and cybersecurity resilience across the organization, including the development and delivery of risk management training programs.
Responsibilities:
Develop and implement comprehensive risk management strategies and policies to mitigate identified risks, including but not limited to, cyber threats, data breaches, IT outages, and technology compliance issues.
Collaborate with IT, business units, and cybersecurity teams to enhance the bank's cyber and technology risk posture through proactive risk identification, assessment, and response planning.
Oversee and guide the risk assessment process for new and existing technologies, digital initiatives, and third-party service providers, ensuring comprehensive risk evaluation and mitigation planning.
Provide expert advice and guidance to senior management on technology and cyber risk trends, potential impacts on the bank, and recommended risk mitigation strategies.
Monitor and analyze developments in technology and cybersecurity threats, including regulatory changes, to continuously refine and update risk management strategies.
Prepare and present detailed risk reports and dashboards to senior management and relevant committees, highlighting the bank's risk posture, emerging risks, and effectiveness of risk mitigation efforts.

Desired Skill Set:
2 years of experience as a BISO – Business Information Security Officer
2 years of proven expertise in Audit or AML/Compliance testing experience
2 years of experience in Cyber Risk Assessment
Financial institution background
2 years of Fraud/AML/KYC/Insider Risk experience

Nice To Have:
Previous financial institution experience

BeachHead is an equal opportunity agency and employer. We advocate for you and welcome anyone regardless of race, color, religion, national origin, sex, physical or mental disability, or age.","{""role_summary"":""Lead the identification and assessment of technology and cybersecurity risks across the bank's digital assets, IT infrastructure, and operations, ensuring alignment with the bank's risk appetite and regulatory requirements."",""key_terms"":[{""term"":""Cyber Risk"",""explanation"":""The risk of loss or harm resulting from a cyber-attack or data breach.""},{""term"":""AML"",""explanation"":""Anti-Money Laundering, a set of regulations to prevent illegal financial activities.""},{""term"":""BISO"",""explanation"":""Business Information Security Officer, a role responsible for ensuring the security of business information.""}],""skill_priorities"":{""must_have"":[""Cyber Risk Assessment"",""Audit or AML/Compliance testing experience"",""Financial institution background"",""Fraud/AML/KYC/Insider Risk experience""],""nice_to_have"":[""Previous financial institution experience""]},""proposed_screening_questions_with_answers"":[{""question"":""What is your experience with Cyber Risk Assessment, and how do you stay updated with the latest trends and threats?"",""example_answer"":""I have 2 years of experience in Cyber Risk Assessment, and I regularly follow industry reports and attend conferences to stay updated.""},{""question"":""Can you explain your experience with Audit or AML/Compliance testing experience?"",""example_answer"":""I have 2 years of experience in Audit or AML/Compliance testing, and I have identified and reported several compliance issues, resulting in process improvements.""}],""red_flags"":[""Lack of experience in Cyber Risk Assessment"",""No experience in a financial institution""],""confidence_score"":90.0}"
Information Security Engineer,Techedin,Canada,March,2024,"Explore the opportunity to join us as an Information Security Engineer in Canada. Details are provided below. This is a full-time position with remote work options, but candidates must reside in Canada.

Job Type: Full Time (100% Remote)

Responsibilities

Monitor, evaluate, and maintain systems and procedures to safeguard infrastructure, databases, and Web-based security.
Identify, integrate, monitor, and improve infosec controls by understanding business processes. Assist in defining security requirements and reviewing systems to determine if they have been designed to comply with established security standards. Help in developing new standards as necessary.
Conduct vulnerability assessments and monitor systems for potential security concerns. Design and configure infrastructure systems to help mitigate findings and improve security posture.
Assist with security architecture reviews and conduct threat modeling exercises as new products and features are rolled out
Research security trends, new methods, and techniques used in unauthorized data access to preemptively eliminate the possibility of system breaches.
Respond to alerts from information security tools and triage and analyze potential security issues
Troubleshoot security system and related issues.
Collaborate and maintain relationships with various engineering teams across the organization to communicate and remediate security issues on time
Educate engineering teams on security best practices and promote security by design
Ensure compliance with regulations and privacy laws.

Skills Required

Minimum 5 years of experience working in security or related industry
Proficient in one or more programming languages such as React, Python, Ruby, etc.
Minimum 2 years of experience in secure coding/development
Effective communication skills and experience collaborating with engineering teams
Have a deep understanding of common application security vulnerabilities
Demonstrated expertise in the Infrastructure security domain
Understanding of Infrastructure security in the context of SDLC and CI-CD
Experience working in all parts of the Infrastructure lifecycle
Effective in communicating security vulnerabilities to key stakeholders
Cloud Security Certifications like AWS Certified Security Specialty is preferred.

Apply!

Techedin is a global IT Services company complementing the efforts of technology-driven enterprises in developing cutting-edge solutions for humans. We offer services in enterprise app development, content management solutions (CMS), customer relationship management (CRM), cloud engineering, custom software development, and data engineering. Our services include IT Consulting, project management, Software Quality Assurance, and data and analytics services. We develop and maintain various software applications and all other computer-related ancillary services. We have excellent professionals working round the clock to build the best technology teams and products for our customers.","{""role_summary"":""An Information Security Engineer is responsible for maintaining and improving the security of systems, infrastructure, and data. This involves identifying and mitigating security risks, developing security standards, and educating engineering teams on security best practices."",""key_terms"":[{""term"":""Infosec controls"",""explanation"":""Security measures implemented to protect information and systems.""},{""term"":""Security posture"",""explanation"":""The overall security status of an organization's systems and infrastructure.""},{""term"":""Threat modeling"",""explanation"":""A process to identify and prioritize potential security threats to an organization.""},{""term"":""SDLC"",""explanation"":""Software Development Life Cycle, a process for designing, developing, and testing software.""},{""term"":""CI-CD"",""explanation"":""Continuous Integration and Continuous Deployment, a process for automating software development and deployment.""},{""term"":""Infrastructure security"",""explanation"":""The protection of an organization's infrastructure, including hardware, software, and networks.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in security or related industry"",""Proficient in one or more programming languages"",""Minimum 2 years of experience in secure coding/development"",""Effective communication skills"",""Deep understanding of common application security vulnerabilities"",""Demonstrated expertise in Infrastructure security domain""],""nice_to_have"":[""Cloud Security Certifications like AWS Certified Security Specialty""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the importance of secure coding practices in application development?"",""example_answer"":""Secure coding practices are essential to prevent vulnerabilities in applications, which can lead to data breaches and other security issues. It's crucial to follow best practices and guidelines to ensure the security of the code.""},{""question"":""How do you stay updated with the latest security trends and techniques?"",""example_answer"":""I regularly follow industry leaders and security experts on social media, attend conferences, and participate in online forums to stay updated on the latest security trends and techniques.""}],""red_flags"":[""Lack of experience in secure coding/development"",""Inability to communicate security vulnerabilities to key stakeholders""],""confidence_score"":90.0}"
XDR - Cyber Security,Zortech Solutions,"Toronto, Ontario, Canada",June,2024,"Hi,

Hope you are doing Great!!!

This side Priya Rajput from Zortech Solutions trying to reach you for an exciting job opening, kindly have a look to job description and revert me with your positive feedback. My mail ID is priya@zortechsolutions.ca or call me on +1 (437) 370-7612.

Role: XDR - Cyber Security

Location: Toronto, ON-Onsite

Duration: Fulltime Permanent

Required Skills And Responsibilities

The job description for a Palo Alto XDR (Extended Detection and Response) role typically includes the following responsibilities:
Deploying and managing Palo Alto XDR solutions: The XDR specialist is responsible for the installation, configuration, and maintenance of Palo Alto's XDR platform. This involves working with various teams to ensure proper setup and integration with existing security infrastructure.
Monitoring and analyzing security events: The XDR specialist will monitor the XDR platform for security events, including threats, vulnerabilities, and anomalous activities. They will analyze the data and alerts generated by the system to identify potential security incidents.
Incident response and investigation: In case of a security incident, the XDR specialist will be responsible for quickly and effectively responding to the incident. This involves taking appropriate actions to mitigate the impact, identifying the root cause, and conducting a thorough investigation to prevent similar incidents in the future.
Threat hunting and intelligence: The XDR specialist should actively engage in threat hunting activities, proactively looking for signs of malicious activity or potential vulnerabilities within the network. They should stay up-to-date with the latest Security Threats and intelligence to enhance the organization's defense against evolving threats.
Collaboration and communication: The XDR specialist will work closely with other teams, such as Network Security, system administrators, and the Security Operations Center (SOC), to ensure smooth integration and effective incident response. They should also effectively communicate any detected threats or incidents to appropriate stakeholders.
Documentation and reporting: The XDR specialist will maintain accurate and up-to-date documentation of configurations, incidents, investigations, and any other relevant information. They should also prepare and present regular reports on security events, incidents, and overall system performance to management.
Continuous improvement: The XDR specialist should actively seek opportunities to enhance the effectiveness and efficiency of the XDR platform and related security processes. This includes evaluating new features and updates, implementing best practices, and providing feedback to the vendor for product improvement..

Required Skills Set: -

Required Skills

Years of Experience

When Last Used This Skill In Your Career Project Year And Month

Rating (E1 as Lowest to E5 as Highest)

Overall Experience

Cyber Security

XDR (Extended Detection and Response)

Security Threats

Network Security

Security Operations Center (SOC)

Documentation and Reporting

Continuous Improvement



Thanks & Regards

Priya Rajput | Account Manager

Email- priya@zortechsolutions.ca

2600 Skymark Ave, Building 7 Suite 104, Mississauga Ontario, L4W 5B2 Canada.

The information contained in this electronic message and any attachments to this message are intended for the exclusive use of the addressee(s) and may contain proprietary, confidential or privileged information. If you are not the intended recipient, you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately and destroy all copies of this message and any attachments. The views expressed in this E-mail message (including the enclosure/(s) or attachment/(s) if any) are those of the individual sender, except where the sender expressly, and with authority, states them to be the views of ZorTech Solutions Inc. Before opening any e-mail and attachments please check them for viruses. ZorTech Solutions Inc does not accept any liability for virus infected mails.","{""role_summary"":""The XDR Cyber Security role is responsible for deploying, managing, and monitoring Palo Alto XDR solutions to detect and respond to security threats, ensuring the security of the organization's network and systems."",""key_terms"":[{""term"":""XDR (Extended Detection and Response)"",""explanation"":""A security solution that detects and responds to threats in real-time.""},{""term"":""Palo Alto XDR"",""explanation"":""A specific XDR solution provided by Palo Alto.""},{""term"":""Security Threats"",""explanation"":""Potential risks to the organization's network and systems.""},{""term"":""Network Security"",""explanation"":""The protection of the organization's network from unauthorized access, misuse, or other malicious activities.""},{""term"":""Security Operations Center (SOC)"",""explanation"":""A team responsible for monitoring and responding to security incidents.""}],""skill_priorities"":{""must_have"":[""XDR (Extended Detection and Response)"",""Cyber Security"",""Security Threats"",""Network Security"",""Security Operations Center (SOC)""],""nice_to_have"":[""Documentation and Reporting"",""Continuous Improvement""]},""proposed_screening_questions_with_answers"":[{""question"":""What experience do you have with Palo Alto XDR solutions?"",""example_answer"":""I have worked with Palo Alto XDR for the past 2 years, deploying and managing the solution for a large enterprise network.""},{""question"":""How do you stay up-to-date with the latest security threats and intelligence?"",""example_answer"":""I regularly follow industry blogs and attend webinars to stay current with the latest security threats and trends.""}],""red_flags"":[""Lack of experience with Palo Alto XDR solutions."",""Inability to effectively communicate security threats and incidents to stakeholders.""],""confidence_score"":90.0}"
Cyber Security Project Coordinator,TV2 Consulting,"Toronto, Ontario, Canada",June,2024,"Collaborate with both internal and external partners and stakeholders to decompose high-level information into detailed business requirements
Facilitate work sessions, focus groups, and coordinate/conduct application demonstrations as required
Contribute to the quality of design and implementation by identifying risks and issues and effectively managing and communicating them to all stakeholders
Support the development of a prioritized product backlog, including the development of user stories, acceptance criteria and scenarios from which the development team to start building applications
Represent the voice of the customer throughout the software development lifecycle
Engage in day-to-day activities with the solution teams as required. This includes, but is not limited to: attending daily scrum meetings, leading refinement sessions, engaging with the development team, and providing direction/focus
Make recommendations that go beyond the initial requests
Provide input to the test plans, sign off on test cases, and participate in end-to-end (E2E) and User Acceptance Testing (UAT)
Write and edit user procedural documentation such as user guides and manuals
Provide support for customer issues and follow up on a timely basis to ensure the problem has been resolved
Concisely document all problems and their resolution in the ticketing system


Requirements

10 years previous experience in the telecommunication industry and Government of Canada contracts

Experience in business analysis - collecting, documenting and articulating requirements
Excellent communications skills, both written and verbal, with the ability to effectively communicate and present to various audiences
Highly organized, detail-oriented and the ability to manage multiple projects simultaneously with aggressive timelines
Action oriented and demonstrated ability to deliver results
Ability to work with change/ambiguity, in a competitive environment where priorities change frequently
Proven problem-solving ability with complex, technical and abstract concepts
Tenacity and creative approach to achieving goals
A team player with the confidence to challenge and escalate when necessary


Benefits

Work hours are Monday - Friday, normal 37.5 hours weeks working onsite up to 5 days a week
Location: Onsite in Toronto
Type of job: Temporary Contractor
Hourly contract rate: TBD depending on experience
Date candidate required: Immediate
Length of Contract: 12 months with the possibility of extension","{""role_summary"":""Collaborate with stakeholders to gather and document business requirements, and support the development of software applications, ensuring effective communication and problem-solving throughout the process."",""key_terms"":[{""term"":""Business Requirements"",""explanation"":""Detailed descriptions of what a business needs to achieve its goals, often gathered through stakeholder collaboration.""},{""term"":""Product Backlog"",""explanation"":""A prioritized list of features or user stories to be developed by a development team.""},{""term"":""User Stories"",""explanation"":""Brief descriptions of a software feature from the user's perspective, used to guide development.""},{""term"":""Acceptance Criteria"",""explanation"":""Conditions that must be met for a software feature to be considered complete.""},{""term"":""Scrum Meetings"",""explanation"":""Daily team meetings to discuss progress, goals, and any obstacles in agile development.""},{""term"":""End-to-End (E2E) Testing"",""explanation"":""A comprehensive testing approach that covers all aspects of a software application, from start to finish.""},{""term"":""User Acceptance Testing (UAT)"",""explanation"":""A testing phase where real users evaluate a software application to ensure it meets their needs.""}],""skill_priorities"":{""must_have"":[""10 years of experience in the telecommunication industry and Government of Canada contracts"",""Experience in business analysis"",""Excellent communication skills"",""Highly organized and detail-oriented"",""Ability to work with change and ambiguity""],""nice_to_have"":[""Proven problem-solving ability with complex concepts"",""Creative approach to achieving goals""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to gather and document complex business requirements from stakeholders?"",""example_answer"":""In my previous role, I worked with cross-functional teams to gather requirements for a new software application. I facilitated workshops, conducted interviews, and created detailed requirement documents that were used to guide development.""},{""question"":""How do you ensure effective communication with stakeholders, especially when working on multiple projects with aggressive timelines?"",""example_answer"":""I prioritize regular check-ins with stakeholders, use project management tools to track progress, and proactively escalate any issues that may impact project timelines.""}],""red_flags"":[""Lack of experience in the telecommunication industry and Government of Canada contracts"",""Poor communication skills, leading to misunderstandings with stakeholders""],""confidence_score"":90.0}"
Threat Analyst 3,Sophos,Canada,June,2024,"About Us
Sophos is a worldwide leader and innovator of advanced cybersecurity solutions, including Managed Detection and Response (MDR) and incident response services and a broad portfolio of endpoint, network, email, and cloud security technologies that help organizations defeat cyberattacks. As one of the largest pure-play cybersecurity providers, Sophos defends more than 500,000 organizations and more than 100 million users globally from active adversaries, ransomware, phishing, malware, and more. Sophos’ services and products connect through its cloud-based Sophos Central management console and are powered by Sophos X-Ops, the company’s cross-domain threat intelligence unit. Sophos X-Ops intelligence optimizes the entire Sophos Adaptive Cybersecurity Ecosystem, which includes a centralized data lake that leverages a rich set of open APIs available to customers, partners, developers, and other cybersecurity and information technology vendors. Sophos provides cybersecurity-as-a-service to organizations needing fully managed, turnkey security solutions. Customers can also manage their cybersecurity directly with Sophos’ security operations platform or use a hybrid approach by supplementing their in-house teams with Sophos’ services, including threat hunting and remediation. Sophos sells through reseller partners and managed service providers (MSPs) worldwide. Sophos is headquartered in Oxford, U.K. More information is available at www.sophos.com. 

Role Summary
As a Threat Analyst on our Managed Threat Response (MTR) team, you will provide best-in-class monitoring, detection, and response services to proactively defend customer environments before attacks prevail. You will work alongside and contribute to a team of cyber threat hunters, incident response analysts, engineers, and ethical hackers by using enterprise, log analysis and endpoint collection systems to facilitate investigations, identification, and neutralization of cyber threats. 
Shift- 8 AM - 5 PM EST

What You Will Do
Investigate and analyze logs and security-related events via Sophos tooling
Identify and respond to cyber threats occurring within customer environments
Communicate and document findings to various customer audiences including technical and executive teams
Follow up with customers through to issue resolution and drive continuous improvement by providing detailed recommendations to minimize risk in customer environments 
Acknowledge and satisfy inbound customer requests and interact with customers through various mediums
Collaborate and assist with core security and threat response teams
Actively research emerging Indicators of Compromise/Attack, exploits and vulnerabilities with the intent of operationalizing findings to better protect our customers

What You Will Bring
Willingness to work outside of standard business hours, including weekends and holidays – our MTR service is 24x7x365
Excellent troubleshooting and analytical skills, with proven ability to think outside the box
Customer service-oriented with strong written and verbal communication skills
Must thrive within a team environment as well as on an individual basis
Passion for all things related to information technology and cybersecurity
Natural curiosity and ability to learn new skills quickly
Innovative mindset and driven to contribute to a team providing a best-in-class cybersecurity service
Minimum 4+ years of experience working in a SOC environment or computer security team in an IT environment
Experience with threat hunting
Experience with endpoint and network security monitoring 
Experience administering and supporting Windows OS (both workstations and server) and one of the following: Apple or Linux-based operating systems (e.g. XP, Windows 7, 2003, 2008, OS X)
Knowledge of common adversary tactics and techniques, e.g., obfuscation, persistence, defense evasion, etc
Knowledge of Mitre ATT&CK framework
Knowledge of incident response procedures
Basic understanding of network traffic analysis including TCP/IP, routing, switching, protocols, etc
Basic understanding of Windows event log analysis
A plus if you have:
Experience with SQL query construction 
Experience with OSQuery 
Experience with enterprise information security data management - SIEM experience 
Programming and scripting skills - proficient knowledge of Powershell 


In the United States, the base salary for this role ranges from $83,000 to $138,000. In Canada, the base salary for this role ranges from $74,000 to $123,000. In addition to base salary, we offer additional compensation including bonus eligibility and a comprehensive benefits package.  A candidate’s specific pay within this range will depend on a variety of factors, including job-related skills, training, location, experience, relevant education, certifications, and other business and organizational needs. 
#B2

Ready to Join Us?
At Sophos, we believe in the power of diverse perspectives to fuel innovation. Research shows that candidates sometimes hesitate to apply if they don't check every box in a job description. We challenge that notion. Your unique experiences and skills might be exactly what we need to enhance our team. Don't let a checklist hold you back – we encourage you to apply.
What's Great About Sophos?
·   Sophos operates a remote-first working model, making remote work the primary option for most employees. However, some roles may necessitate a hybrid approach. Please refer to the location details in our job postings for further information.
·   Our people – we innovate and create, all of which are accompanied by a great sense of fun and team spirit
·   Employee-led diversity and inclusion networks that build community and provide education and advocacy
·   Annual charity and fundraising initiatives and volunteer days for employees to support local communities
·   Global employee sustainability initiatives to reduce our environmental footprint
·   Global fitness and trivia competitions to keep our bodies and minds sharp
·   Global wellbeing days for employees to relax and recharge 
·   Monthly wellbeing webinars and training to support employee health and wellbeing
Our Commitment To You
We’re proud of the diverse and inclusive environment we have at Sophos, and we’re committed to ensuring equality of opportunity.   We believe that diversity, combined with excellence, builds a better Sophos, so we encourage applicants who can contribute to the diversity of our team.  All applicants will be treated in a fair and equal manner and in accordance with the law regardless of gender, sex, gender reassignment, marital status, race, religion or belief, color, age, military veteran status, disability, pregnancy, maternity or sexual orientation.  We want to give you every opportunity to show us your best self, so if there are any adjustments we could make to the recruitment and selection process to support you, please let us know. 
Data Protection
If you choose to explore an opportunity, and subsequently share your CV or other personal details with Sophos, these details will be held by Sophos for 12 months in accordance with our Privacy Policy and used by our recruitment team to contact you regarding this or other relevant opportunities at Sophos.  If you would like Sophos to delete or update your details at any time, please follow the steps set out in the Privacy Policy describing your individual rights.  If you have any questions about Sophos’ data protection practices, please contact dataprotection@sophos.com.","{""role_summary"":""Provide best-in-class monitoring, detection, and response services to proactively defend customer environments from cyber threats."",""key_terms"":[{""term"":""Threat Hunting"",""explanation"":""Identifying and responding to cyber threats in customer environments.""},{""term"":""Endpoint Security Monitoring"",""explanation"":""Monitoring and analyzing endpoint data to identify potential security threats.""},{""term"":""Mitre ATT&CK framework"",""explanation"":""A knowledge base of adversary tactics and techniques used to identify and respond to cyber threats.""},{""term"":""SIEM"",""explanation"":""Security Information and Event Management systems used to collect, analyze, and respond to security-related data.""}],""skill_priorities"":{""must_have"":[""4+ years of experience in a SOC environment or IT team"",""Experience with threat hunting"",""Experience with endpoint and network security monitoring"",""Knowledge of common adversary tactics and techniques"",""Knowledge of Mitre ATT&CK framework"",""Basic understanding of network traffic analysis and Windows event log analysis""],""nice_to_have"":[""Experience with SQL query construction"",""Experience with OSQuery"",""Experience with Powershell""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your experience with threat hunting in a previous role?"",""example_answer"":""In my previous role, I used threat hunting techniques to identify and respond to a ransomware attack, resulting in minimal data loss and downtime for our customers.""},{""question"":""How do you stay current with emerging indicators of compromise and attack vectors?"",""example_answer"":""I regularly review industry reports and participate in online forums to stay informed about emerging threats and tactics.""}],""red_flags"":[""Lack of experience in a SOC environment or IT team"",""knowledge of common adversary tactics and techniques""],""confidence_score"":90.0}"
SOC Analyst (Onsite - Night Shift),Quantum Technology Recruiting Inc. (QTR),"Toronto, Ontario, Canada",June,2024,"Position: SOC Analyst
Location: Downtown Toronto
Job Type: Permanent Full Time

Our client is an MSSP security organization, and they are looking for a SOC Analyst who will join their Security Operations Center (SOC) team to help monitor and respond to security incidents. The Analyst will work closely with a team of experienced cybersecurity professionals to detect, analyze, and mitigate potential threats.

This role needs someone to work from office and night shifts.

If you have prior experience in similar area, then please reach out on Shubham.sharma@qauntum-qtr.com.

Responsibilities:
Monitor and analyze alerts from security tools, networks, and systems to identify and validate security incidents.
Perform initial assessment and triage on the security alerts and escalate as needed.
Participate in incident response efforts, collaborating with other teams as required.
Document incident details and actions taken in the incident management system.
Maintain knowledge of the latest cybersecurity threats and trends.
Participate in continuous learning and professional development opportunities.
Support the development and refinement of SOC processes and procedures.

Qualifications:
Bachelor’s degree in computer science, Information Technology, Cybersecurity, or a related field.
1-2 years of experience in a SOC or similar cybersecurity role preferred.
Familiarity with various security technologies (SIEM, EDR, NDR, etc.) and security concepts, ideally knows Sumologic
Basic understanding of network protocols, system vulnerabilities, and malware.
Strong analytical and problem-solving skills.","{""role_summary"":""Monitor and respond to security incidents as part of a Security Operations Center team, working closely with experienced cybersecurity professionals to detect and mitigate threats."",""key_terms"":[{""term"":""SIEM"",""explanation"":""Security Information and Event Management, a type of security technology used to monitor and analyze security-related data.""},{""term"":""EDR"",""explanation"":""Endpoint Detection and Response, a type of security technology used to monitor and respond to endpoint security threats.""},{""term"":""NDR"",""explanation"":""Network Detection and Response, a type of security technology used to monitor and respond to network security threats.""},{""term"":""Sumologic"",""explanation"":""A specific security technology used for log analysis and security monitoring.""}],""skill_priorities"":{""must_have"":[""Analytical and problem-solving skills"",""Familiarity with security technologies (SIEM, EDR, NDR, etc.)"",""Basic understanding of network protocols, system vulnerabilities, and malware""],""nice_to_have"":[""1-2 years of experience in a SOC or similar cybersecurity role"",""Knowledge of Sumologic""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for analyzing and triaging security alerts?"",""example_answer"":""I would start by reviewing the alert details, then assess the severity and potential impact. I would then triage the alert, escalating it to the necessary teams as required.""},{""question"":""How do you stay current with the latest cybersecurity threats?"",""example_answer"":""I regularly review industry reports and blogs, and participate in continuous learning and professional development opportunities.""}],""red_flags"":[""Lack of experience working in a SOC or similar cybersecurity role"",""Inability to work night shifts""],""confidence_score"":85.0}"
IT Security Analyst,Houle,"Burnaby, British Columbia, Canada",April,2024,"A career that gives you purpose. A company that stands up for you. A team where you can be yourself. Sound too good to be true? This is life at Houle. We believe in empowering communities through local projects that positively impact people's lives. We're a passionate group of people who love collaborating on innovative and challenging projects.

About This Role

We are recruiting for an IT Security Analyst to join our Corporate IT team based in Burnaby. Here's how your role will strengthen our team.

This position will collaborate with the IT department to develop and implement security policies and procedures, investigate security incidents, and ensure smooth operations of all IT systems from a security perspective across Houle office locations and job sites.

Your Responsibilities

Identify and address vulnerabilities in network, applications, infrastructure, and source code vulnerabilities leveraging appropriate security tools
Coordinate the resolution of risks from penetration testing and vulnerability scanning activities
Support implementation, maintenance, and improvement of security tools such as SIEM, EDR/XDR, security Firewalls, Spam and Web filtering, Access control, Mobile security etc.
Conduct risk assessments, threat modelling, privacy assessments and information security reviews on projects and all existing technology and systems
Assist in regularly assessing the strength of the organization's IT security governance and current processes, procedures, and technical security controls best practices, and propose, and implement initiatives to remediate control gaps to reduce enterprise risk

Your Experience And Skills

Bachelor's degree in computer science, or equivalent training or education
Minimum 4 years related IT experience in an Enterprise IT environment, with recent relevant experience
Currently hold or working towards relevant Professional IT Security Certifications (CISSP, etc.)
Excellent written and verbal communication skills
Strong aptitude to take on new challenges and learn innovative technologies
Collaborative personality and work well with customers and internal team members

About Houle

As BC's leading electrical contractor and systems integrator, we believe in delivering safe, reliable power for the future. From hospitals and universities, to airports, shipping terminals and shopping centres, our electrical and technology professionals proudly provide innovative solutions that create value for our customers every day.

Since 1944, we've been dedicated to our craft, committed to quality workmanship, and building teams that thrive. Driven by purpose and connected through collaboration, our focus on people guides our success in delivering some of the most exciting infrastructure projects in the province.

As a certified Great Place to Work and Best Managed company, we have been recognized for our efforts in creating a safe and inclusive work environment.

Why join our team?

We emphasize having a work-life balance - We offer flexible work schedules and a competitive vacation policy.
Continuous development is a top priority - Whether you're looking for a corporate career or a career in the field, you are supported with access to tools and training for development and growth.
Our employee benefits prioritize your financial, physical, and mental well-being - From RRSP matching to health and wellness reimbursements and additional Houle days off, we've got you covered.
We have many exciting project opportunities - With many projects on the go around BC, we're certain you will find countless ways to bring communities to life.
We have fun! Connection is key at Houle, from industry events to themed office gatherings, we never miss an opportunity to celebrate. Join us for our summer bbqs, potlucks, charity fundraisers, community volunteering, and many more fun events!
A safe space for everyone - We celebrate diversity and are proud to be an equal-opportunity employer. We're committed to diversity and inclusion and strive to foster, cultivate and preserve a culture of belonging for all employees.

Salary range: $68,000-$90,000 per year plus a competitive total compensation package. Actual salary will be commensurate with experience, skills and overall match to the position offered. Let's chat throughout the hiring process and determine the best fit.

Sound like a match? We'd love to connect.

Please visit https://www.houle.ca/current-career-opportunities/ and click on the listing for IT Security Analyst. The opportunity will remain open until it has been filled.

Connect with us on LinkedIn, Instagram, Facebook, and Twitter!","{""role_summary"":""Collaborate with the IT department to develop, implement, and ensure smooth operations of all IT systems from a security perspective."",""key_terms"":[{""term"":""SIEM"",""explanation"":""Security Information and Event Management system that monitors and analyzes security-related data from various sources.""},{""term"":""EDR/XDR"",""explanation"":""Endpoint Detection and Response/Extended Detection and Response systems that monitor endpoints and respond to threats.""},{""term"":""CISSP"",""explanation"":""Certified Information Systems Security Professional, a certification for IT security professionals.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in computer science or equivalent"",""Minimum 4 years IT experience in an IT environment"",""Excellent written and verbal communication skills""],""nice_to_have"":[""Relevant Professional IT Security Certifications (CISSP, etc.)"",""Strong aptitude to take on new challenges and learn innovative technologies""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you identify and address vulnerabilities in network, applications, infrastructure, and source code?"",""example_answer"":""I would leverage security tools such as vulnerability scanning and penetration testing to identify vulnerabilities, and then prioritize and address them based on risk assessment and business impact.""},{""question"":""Can you give an example of a risk assessment, threat modeling, or privacy assessment you conducted in a previous role?"",""example_answer"":""In my previous role, I conducted a risk assessment on a new software implementation and identified potential security risks. I then worked with the development team to implement security measures to mitigate those risks.""}],""red_flags"":[""Lack of experience in an Enterprise IT environment"",""No relevant Professional IT Security Certifications""],""confidence_score"":90.0}"
Security Analyst (Co-op),Control Gap Inc.,"Mississauga, Ontario, Canada",June,2024,"We’re looking for entry-level security specialists to grow our team. If you are a student and looking to work a co-op term as an Information Security Analyst or Specialist and look forward to working in challenging and changing environments, we have an excellent opportunity for you.

As part of the Control Gap team, you’ll work with high-profile clients in various industries and collaborate with a team of highly-skilled security consultants on challenging projects, large and small. We analyse, assess and design effective security controls to help clients achieve Payment Card Industry (PCI) compliance, privacy compliance, and to improve enterprise-wide security.

As an entry-level subject matter expert, you’ll work within our team to input and help advise clients on data security to help prevent potential security breaches before they occur. We provide services onsite at our client sites and also remotely.

We value strong knowledge of information security controls and principles, privacy frameworks, the Payment Card Industry Data Security Standard (PCI DSS). You also must have exceptional written and verbal skills. As a co-op student, no real world work experience as an information security analyst or specialist is required.

After your co-op work term, you can earn an option to join our team fulltime. As a fulltime employee, our intent is to have you learn and grow with us while, if you desire, working towards being a well rounded security consultant and to obtain the elite Payment Card Industry Qualified Security Assessor (PCI QSA) certification, and other valuable industry security and audit related certifications.

Our people are our most valuable assets and we believe in fostering career development and growth opportunities for every individual on our team. We also offer a competitive benefits package and an excellent work environment that encourages team work. 

Responsibilities:

Assisting with conducting various information security, compliance assessments, analyses, and providing advice and consultation (e.g. Report on Compliance, Risk Assessments, Gap Analysis, and more)
Assisting with creating professional reports for our clients that detail your assessment findings, and your advice
Assisting with consulting with clients to help them understand our findings and their remediation options
Assisting with providing advisory and input on security architecture with regards to PCI, Privacy, and Cyber Security
Assisting our sales team with pre-sales activities, proposal creation, needs analysis, and solution design
Attending industry events and webinars
Working with multiple clients on a number of projects
Writing summaries and executive briefs

Education and Work Experience:

You must be working on a degree in Information Security, or in a related field
Minimum 0 years of experience in an Information Technology field
Minimum 0 years of experience working in Information Security domains
Minimum 0 years of experience measuring security controls, IT auditing, business processes, providing advice, and/or related security consulting experience

Industry Certifications:

Any industry certification in Information Security or Audit is an asset

Technical Skills:

Familiarity with as much of the following, or the eagerness to learn and to be proficient in these areas
Familiarity with Information Technology systems
Familiarity with various information security concepts, including; network and wireless security, application security, industry best practices, systems hardening, data encryption, data privacy, incident response, business continuity, physical security, risk assessments, vulnerability scanning, penetration testing, file integrity monitoring, log monitoring, and documented security governance controls (i.e. policies, processes, standards, procedures).
Familiarity with a variety of security products and technologies
Familiarity with industry best practices and standards such as CIS and NIST, including security hardening techniques
Understanding of Unix, Linux, Windows and database server configurations
Understanding of networking systems configurations, including firewalls
Understanding of application architecture, software development lifecycle processes, including secure coding techniques
Understanding of server virtualization technologies, including AIX, ZOS, and SAN storage systems

Soft Skills:

Exceptional customer service, communication and interpersonal skills
Strong written and verbal communication skills.
Strong organizational skills
Strong time management skills
Honesty and integrity
Dedication to providing solutions to meet or exceed client's needs and expectations
Ability to handle challenges and project work loads

Benefits:

Start as a co-op student, and earn an option for fulltime employment
Hourly compensation as a co-op student
Company team building events throughout each year","{""role_summary"":""Assist in conducting information security assessments, analyses, and provide advice to clients as an entry-level security specialist in a co-op term, with potential for full-time employment."",""key_terms"":[{""term"":""PCI DSS"",""explanation"":""Payment Card Industry Data Security Standard, a set of security controls to ensure secure handling of payment card data.""},{""term"":""PCI QSA"",""explanation"":""Payment Card Industry Qualified Security Assessor, an elite certification for security consultants to assess PCI compliance.""},{""term"":""CIS"",""explanation"":""Center for Internet Security, a non-profit organization providing industry best practices and benchmarks for security.""},{""term"":""NIST"",""explanation"":""National Institute of Standards and Technology, a US government agency providing guidelines and standards for information security.""}],""skill_priorities"":{""must_have"":[""Information Security principles"",""Privacy frameworks"",""PCI DSS"",""Strong written and verbal skills""],""nice_to_have"":[""Industry certifications in Information Security or Audit"",""Familiarity with security products and technologies"",""Understanding of server virtualization technologies""]},""proposed_screening_questions_with_answers"":[{""question"":""What do you know about PCI DSS and how would you apply it in a real-world scenario?"",""example_answer"":""PCI DSS is a set of security controls to ensure secure handling of payment card data. In a real-world scenario, I would ensure that a client's payment processing system meets the PCI DSS requirements to prevent security breaches.""},{""question"":""How would you approach a risk assessment for a client's information system?"",""example_answer"":""I would follow industry best practices such as NIST framework to identify vulnerabilities, assess risks, and provide recommendations to the client to mitigate those risks.""}],""red_flags"":[""Lack of understanding of information security principles"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Cybersecurity Specialist,TrustFlight,"Vancouver, British Columbia, Canada",June,2024,"TrustFlight is at the forefront of digitizing the aviation industry with the creation of intelligent workflow applications that automate operating and maintenance processes, enabling our customers to focus on the data and insights that matter. TrustFlight has bases in both England (London & Leamington Spa) and Canada (Vancouver). Our business is rapidly expanding, and we’re proud to share that we’re entirely self-funded and consistently profitable.

Not only are we disrupting the sector, we are creating a great place to work that gives our people the freedom to create, innovate and influence how we do this. We continue to build an amazing group of people who are all here to make our products, services and culture the most envied in the industry!

We are in search of a proficient Cybersecurity Specialist to join our Operations team, focusing on the most critical element for both our company and our clients: security. This vital role involves conducting thorough security assessments, developing and implementing robust security policies, and ensuring compliance with industry standards and best practices. As a key member of our team, you will delve into every aspect of our security operations, providing comprehensive protection across various layers — from network and cloud infrastructure to application layer and customer-facing interfaces. This position offers an exceptional opportunity to be at the forefront of cybersecurity in the aviation industry, where you will play a pivotal role in safeguarding our operations and maintaining our pioneering status.

In this role, you will be energized and guided by our experienced Operations team, fostering a dynamic environment for continuous learning and improvement. Your contributions will be instrumental in elevating our cybersecurity capabilities to their fullest potential, thereby enhancing the efficiency and safety of the aviation industry. At TrustFlight, we deeply value teamwork and are committed to the personal and professional growth of each team member. We are looking for professionals who are confident in their ability to acquire new skills and grow their expertise through dedicated mentorship and a supportive work culture.

Responsibilities

Conduct security assessments, risk analysis, and vulnerability testing of various operating environments.
Develop and review policies and standards with stakeholders.
Ensure compliance with cybersecurity policies and industry standards.
Assist in upholding and managing security certifications such as ISO27001, SOC2, and others.
Provide training and guidance on security protocols and best practices.
Research and evaluate new and emerging security technologies and integrations.
Influence Operational decisions by contributing insightful security perspectives that consider both technical and strategic aspects.
Collaborate with IT and cross-functional teams to ensure security best practices are integrated into all aspects of technology.
Manage and respond to cybersecurity incidents.


You ideally need the following to qualify:

Bachelor’s degree in Computer Science, Information Technology, Cybersecurity, or a related field.
Experience with implementing and managing security systems and tools.
Knowledge and experience of IT Controls, IT Security, NIST CSF-RMF, ISO 27001/2, and COBIT.
Professional certifications such as CRISC, CISSP, CISM, CISA, CompTIA Security+, GSEC or equivalent are highly desirable.
Experience working with SaaS, PaaS, and IaaS providers, providing guidance on secure system and service configuration.
Familiarity with scripting languages (e.g., Python, PowerShell) for automation of security tasks.
Proficiency in written and verbal communication skills.
Demonstrated eagerness and capability to quickly learn and master missing hands-on skills as needed.


The following will be considered as a significant plus and would enhance your candidacy:

Hands-on infrastructure experience with Google Cloud and Microsoft Azure platform security.
Knowledge of network security protocols, firewall administration, intrusion detection systems, SIEMs, ACLs, security groups, endpoint protection, and secure coding practices.
Experience in enforcing IT access control policies using MDM/MAM.
Knowledge of GRC tools.


Job location

This role will be based out of our office in Vancouver. With our hybrid working policy, we encourage a harmonious balance between working from home and collaborating in the office, typically three days per week. This empowers an agile and flexible environment that supports your needs. However, it’s important to note that for you to fully harness the benefits of collaborating closely with our exceptional team across multiple timezones, this role demands a heightened level of flexibility.

Benefits

We offer a generous holiday allowance that increases the longer you are here. We are keen for birthdays to be celebrated and so we offer an additional day off to everyone.
It is important to us that we all work in an environment that is supportive of health and wellbeing; healthcare cover for all our people covers your health, dental and ophthalmic requirements to support you physically and mentally.
Our generous company contribution to your pension is greater than the local requirements and over time you can plan effectively for your future with our matching contribution scheme.
We place huge importance on the contribution and experience you bring to the team, the salary will be based on the value you will bring to the role with a range spanning from 75-115K CAD.


How To Apply

Tell us about you in a cover letter, outlining what you will bring to the role and how you can contribute to creating best in class tools and services throughout the aviation industry. Please also include your resume.

TrustFlight is an equal opportunity employer. We work together to create the most talented team that celebrates inclusivity, diversity and equality in a serious way. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. All candidates will receive consideration for this role without regard for gender, gender identity, race, national origin, colour, religion, disability or age. Our inclusive culture empowers all of us to inspire, enlighten and thrive.","{""role_summary"":""A Cybersecurity Specialist is required to join the Operations team, focusing on security assessments, policy development, and compliance with industry standards. The role involves providing comprehensive protection across various layers, from network infrastructure to customer-facing interfaces."",""key_terms"":[{""term"":""ISO27001"",""explanation"":""An international standard for information security management systems.""},{""term"":""SOC2"",""explanation"":""A set of compliance standards for service organizations, ensuring the secure management of customer data.""},{""term"":""NIST CSF-RMF"",""explanation"":""A framework for managing and reducing cybersecurity risk, providing guidelines for implementing cybersecurity controls.""},{""term"":""COBIT"",""explanation"":""A framework for IT governance and management, focusing on aligning business goals with IT resources.""},{""term"":""CRISC"",""explanation"":""A professional certification for IT professionals, focusing on risk and information systems control.""},{""term"":""CISSP"",""explanation"":""A professional certification for IT professionals, focusing on information security and risk management.""},{""term"":""CISM"",""explanation"":""A professional certification for IT professionals, focusing on information security management and risk management.""},{""term"":""CISA"",""explanation"":""A professional certification for IT professionals, focusing on information systems auditing and control.""},{""term"":""CompTIA Security+"",""explanation"":""An entry-level certification for IT professionals, covering security concepts, threats, and best practices.""},{""term"":""GSEC"",""explanation"":""A professional certification for IT professionals, focusing on information security and risk management.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in Computer Science, Cybersecurity, or a related field"",""Experience with implementing and managing security systems and tools"",""Knowledge and experience of IT Controls, IT Security, NIST CSF-RMF, ISO 27001/2, and COBIT"",""Professional certifications such as CRISC, CISSP, CISM, CISA, CompTIA Security+, GSEC or equivalent"",""Experience working with SaaS, PaaS, and IaaS providers, providing guidance on secure system and service configuration"",""Familiarity with scripting languages (e.g., Python, PowerShell) for automation of security tasks"",""Proficiency in written and verbal communication skills""],""nice_to_have"":[""Hands-on infrastructure experience with Google Cloud and Microsoft Azure platform security"",""Knowledge of network security protocols, firewall administration, intrusion detection systems, SIEMs, ACLs, security groups, endpoint protection, and secure coding practices"",""Experience in enforcing IT access control policies using MDM/MAM"",""Knowledge of GRC tools""]},""proposed_screening_questions_with_answers"":[{""question"":""What experience do you have with implementing and managing security systems and tools?"",""example_answer"":""I have worked with various security tools, including firewalls and intrusion detection systems, and have experience implementing security policies and procedures.""},{""question"":""How do you stay current with emerging security technologies and integrations?"",""example_answer"":""I participate in industry conferences, read security blogs and publications, and engage with online security communities to stay informed about the latest security trends and technologies.""},{""question"":""Can you describe your experience with IT Controls, IT Security, NIST CSF-RMF, ISO 27001/2, and COBIT?"",""example_answer"":""I have worked with these frameworks to develop and implement security policies, procedures, and controls, ensuring compliance with industry standards and best practices.""}],""red_flags"":[""Lack of experience with implementing and managing security systems and tools"",""Inability to communicate technical information to non-technical stakeholders"",""Limited knowledge of industry standards and best practices""],""confidence_score"":90.0}"
Staff Security Analyst,Lightspeed Commerce,"Montreal, Quebec, Canada",June,2024,"Hi there! Thanks for stopping by 👋

Are you actively looking for a new opportunity? Or just checking the market? Well… you might just be in the right place to join our team.

The Staff Analyst, Security is a critical member of Lightspeed’s Security Operations Team. They actively monitor, analyze, and respond to security incidents, conduct in-depth analysis of security events, aid in the development and maintenance of standard operating procedures for incident detection and response, and collaborate with cross-functional teams to resolve incidents, while proactively identifying and mitigating emerging threats.

What you'll be responsible for

Monitor and triage security alerts from various sources, including SIEM, IDS/IPS, firewalls, and endpoint protection systems.
Conduct in-depth analysis of security events to identify potential threats and vulnerabilities.
Develop and implement best practices for detection engineering.
Aid in the development and maintenance of standard operating procedures for incident detection and response.
Collaborate with cross-functional teams to resolve security incidents promptly.
Proactively identify and mitigate emerging threats.
Oversee the transition from SIEM to SOAR (Security Orchestration, Automation, and Response).
Maintain and update security tools and technologies.
Provide timely reports on security activities.
Communicate effectively with both technical and non-technical stakeholders
Partner / mentor fellow security team members.
Advocate for security best practices and proactive threat mitigation throughout the organization.
Participate in incident response planning and lead remediation efforts in case of security breaches.


What you’ll be bringing to the team

Significant experience with incident response procedures, including containment, eradication, and recovery.
Significant experience using SIEM tools for log analysis and threat detection.
Significant experience with additional security tools, such as EDR, CSPM, and DLP.
Significant experience in detection engineering.
Crowd strike experience a plus, and extensive knowledge of security controls, access controls, network security, vulnerability management.
Experience transitioning from SIEM to SOAR.
Experience working with large-scale cloud environments (AWS, GCP, etc).
Thorough understanding of threat intelligence sources and how to apply them in security operations.
Demonstrated ability to lead cross-functional initiatives.
Relevant certifications, such as CompTIA Security+ or CISSP, are a plus


What's in it for you?

Join a fast-paced, high-growth company.
Surround yourself with strong talent and enjoy continuous professional growth.
Develop in a modern and proven technology stack.
Great benefits and perks, including equity and flexible/hybrid remote work options, in a diverse and inclusive environment.
Development of very high traffic products, used at the global scale.
Opportunities to learn and expand your skill set
Become a valued part of the diverse and inclusive Lightspeed family.


… and enjoy a range of benefits that’ll keep you happy, healthy and (not) hungry:

Lightspeed equity scheme (we are all owners)
Flexible paid time off policy
Health Insurance
Health and wellness benefit of $500 per year
Paid leave and assistance for new parents
Mental health online platform and counseling & coaching services
Volunteer day


To all recruitment agencies: Lightspeed does not accept unsolicited agency resumes. If we have not directly engaged your company in writing to supply candidates for a specific vacancy, Lightspeed will not be responsible for any fees related to unsolicited resumes.

Lightspeed is a proud equal opportunity employer and we are committed to creating an inclusive and barrier-free workplace. Lightspeed welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.

Where to from here?

Obviously, this has to be mutually beneficial: we want you to step into a role you love, and we want to offer you a place you’re proud to come to every day. For a glimpse into our world check out our career page here.

Lightspeed is building communities through commerce, and we need people from all backgrounds and lived experiences to do that. We were founded in 2005, in Montreal’s gay village and our original members were all part of the LGBTQ+ community. The ethos of our business has been about inclusion from the very beginning, and we strive to provide a workplace where everyone belongs.

Who We Are

Powering the businesses that are the backbone of the global economy, Lightspeed's one-stop commerce platform helps merchants innovate to simplify, scale, and provide exceptional customer experiences. Our cloud commerce solution transforms and unifies online and physical operations, multichannel sales, expansion to new locations, global payments, financial solutions, and connection to supplier networks.

Founded in Montréal, Canada in 2005, Lightspeed is dual-listed on the New York Stock Exchange (NYSE: LSPD) and Toronto Stock Exchange (TSX: LSPD). With teams across North America, Europe, and Asia Pacific, the company serves retail, hospitality, and golf businesses in over 100 countries.

Lightspeed handles your information in accordance with our Applicant Privacy Statement.","{""role_summary"":""The Staff Analyst, Security is a critical member of Lightspeed's Security Operations Team, responsible for monitoring, analyzing, and responding to incidents, conducting in-depth analysis of security events, and collaborating with cross-functional teams to resolve incidents."",""key_terms"":[{""term"":""SIEM"",""explanation"":""Security Information and Event Management, a system that monitors and analyzes security-related data from various sources.""},{""term"":""IDS/IPS"",""explanation"":""Intrusion Detection System/Intrusion Prevention System, a system that detects and prevents unauthorized access to a network.""},{""term"":""Endpoint Protection System"",""explanation"":""A system that protects endpoint devices from various types of threats, including malware and unauthorized access.""},{""term"":""SOAR"",""explanation"":""Security Orchestration, Automation, and Response, a solution that automates and streamlines security incident response.""},{""term"":""EDR"",""explanation"":""Endpoint Detection and Response, a solution that monitors endpoint devices for signs of malicious activity.""},{""term"":""CSPM"",""explanation"":""Cloud Security Posture Management, a solution that monitors and manages cloud security configurations.""},{""term"":""DLP"",""explanation"":""Data Loss Prevention, a solution that monitors and prevents unauthorized data exfiltration.""},{""term"":""Crowd Strike"",""explanation"":""A cloud-based endpoint security solution that provides threat intelligence and incident response.""}],""skill_priorities"":{""must_have"":[""Significant experience with incident response procedures"",""Significant experience using SIEM tools for log analysis and threat detection"",""Significant experience with additional security tools, such as EDR, CSPM, and DLP"",""Significant experience in detection engineering""],""nice_to_have"":[""Crowd Strike experience"",""Relevant certifications, such as CompTIA Security+ or CISSP""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the difference between SIEM and SOAR?"",""example_answer"":""SIEM is a system that monitors and analyzes security-related data, while SOAR is a solution that automates and streamlines security incident response.""},{""question"":""How do you stay current with emerging threats and vulnerabilities?"",""example_answer"":""I regularly review threat intelligence sources and participate in industry forums to stay informed.""}],""red_flags"":[""Lack of experience with SIEM tools"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Security Analyst II,Cyderes,Greater Montreal Metropolitan Area,June,2024,"Cyderes (Cyber Defense and Response) is a pure-play, full life-cycle cybersecurity services provider with award-winning managed security services, identity and access management, and professional services designed to manage the cybersecurity risks of enterprise clients. We specialize in multi-technology, complex environments with the in speed and agility needed to tackle the most advanced cyber threats. We leverage our global scale and decades of experience to accelerate our clients’ cyber outcomes through a full lifecycle of cybersecurity services. We are a global company with operating centers in the United States, Canada, the United Kingdom, and India.

About The Role
The Managed Services Security Analyst II is responsible for security solutions for clients. The Security Analyst II will demonstrate the capacity to consistently meet and exceed client expectations representing and reinforcing the Cyderes brand through positive interaction with other teams within the company. Perform deep

dive investigations into security threats, understand and implement MITRE mapping to identify customers current security posture.

Responsibilities

Perform triage and advanced analysis tasks across endpoint, server, and network infrastructure
Perform Threat Hunting on customer networks to detect, isolate threats and provide recommendations
Provide proactive security investigation and searches on client environment to detect malicious activities
Coordinate Incident investigations and deep dive analysis on detected threats
Understand and identify indicators of attack and compromise in alerts, by hunting through data, and from review of investigation notes
Have full understanding of the MITRE ATT&CK framework. Mapping clients use cases to tactics and techniques
Update documentation and runbooks to ensure repeatable analysis
Actively participate in an after-hours on-call rotation as Incident Controller
Scope customer security incidents




Requirements

3 or more years of progressing/in-depth IT security experience
System Administration experience (Windows, Unix/Linux, Mac)
Advanced understanding of networking concepts and ability to analyze network artifacts
Demonstrate experience in using Endpoint Detection and Response software (Sentinel1, Crowdstrike, Defender ETC.)
Advanced knowledge of at least one leading SIEM platform (Sentinel, Splunk, Elastic, IBM Qradar, Chronicle etc.)
Possess at least one industry certification Sec+, CEH, SANS Certification (e.g. GCIH, GCIA, GSEC, GMON), OSCP etc. or working towards a related certification
Basic scripting or development experience in one of the following languages: Python, JavaScript, PowerShell, bash, etc




Cyderes is an Equal Opportunity Employer (EOE). Qualified applicants are considered for employment without regard to race, religion, color, sex, age, disability, sexual orientation, genetic information, national origin, or veteran status.

Note: This job posting is intended for direct applicants only. We request that outside recruiters do not contact us regarding this position.","{""role_summary"":""The Managed Services Security Analyst II is responsible for providing security solutions to clients, performing deep dive investigations into security threats, and implementing MITRE mapping to identify customers' current security posture."",""key_terms"":[{""term"":""MITRE ATT&CK framework"",""explanation"":""A globally recognized framework for identifying and mitigating cyber threats.""},{""term"":""Endpoint Detection and Response software"",""explanation"":""Tools used to detect and respond to security threats on endpoint devices such as laptops and desktops.""},{""term"":""SIEM platform"",""explanation"":""Security Information and Event Management system that monitors and analyzes security-related data from various sources.""}],""skill_priorities"":{""must_have"":[""3+ years of IT security experience"",""System Administration experience"",""Advanced knowledge of networking concepts"",""Experience with Endpoint Detection and Response software"",""Advanced knowledge of at least one leading SIEM platform"",""Industry certification (e.g. Sec+, CEH, SANS Certification)""],""nice_to_have"":[""Basic scripting or development experience in Python, JavaScript, PowerShell, bash, etc.""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would perform a deep dive investigation into a security threat?"",""example_answer"":""I would start by gathering relevant data from various sources, then analyze it using tools like Endpoint Detection and Response software and SIEM platforms. I would identify indicators of attack and compromise, and finally, provide recommendations for mitigation.""},{""question"":""How do you stay up-to-date with the latest cyber threats and trends?"",""example_answer"":""I regularly review industry reports, participate in online forums and discussions, and pursue relevant certifications to stay current.""}],""red_flags"":[""Lack of experience with Endpoint Detection and Response software"",""Inability to explain the MITRE ATT&CK framework""],""confidence_score"":90.0}"
OneTrust Application Security Analyst,TV2 Consulting,"Toronto, Ontario, Canada",June,2024,"The team of resources will provide thought leadership for the Data Privacy Enablement Project along with design and technical expertise for the OneTrust implementation. They will be responsible for leading their work streams by developing roadmaps, conducting execution planning, composing user stories, and collaborating with interfacing teams. Team members must be full-stack privacy analysts who are able to provide hands-on-keyboard OneTrust configuration and troubleshooting along with in-depth data privacy compliance knowledge and expertise. Must be OneTrust certified and know how to fully develop , configure and troubleshoot within the OneTrust applications.

Develop technical architectures, frameworks and strategies, either for an organization or for a major application area, to meet the business and application requirements.
Analyze and evaluate alternative technology solutions to meet business problems. Ensure the integration of all aspects of technology solutions.
Evaluate hardware and software relative to their ability to support specified requirements and by determining potential and actual bottlenecks, improve system performance through recommended hardware changes.
Review computer software systems and data requirements as well as communication and response needs and determine operating systems and languages needed to support them.
Monitor industry trends to ensure that solutions fit with best practice directions for technology.
Provide information, direction and support for emerging technologies.
Review application and program design or technical infrastructure design to ensure adherence to standards and to recommend performance improvements


Requirements

Certifications required:
Security Analyst: OneTrust Certified in PIA & DPIA Automation
Security Analyst: OneTrust Certified in PIA & Privacy Rights Automation
Experience required:
Security Analyst: 3+ years of systems integrations experience, 2+ years of OneTrust: experience
Security Analyst: 2+ years of systems integrations experience, 1+ years of OneTrust experience

Benefits

Type of job: Temporary Contractor - 1 year
Date candidate required: Immediate
Location: Toronto
Work hours are Monday - Friday, normal 37.5 hour week","{""role_summary"":""Lead the Data Privacy Enablement Project, providing technical expertise for OneTrust configuration, troubleshooting, and data privacy compliance."",""key_terms"":[{""term"":""OneTrust"",""explanation"":""A software platform for data privacy compliance and risk management.""},{""term"":""PIA"",""explanation"":""Privacy Impact Assessment, a process to identify and mitigate privacy risks.""},{""term"":""DPIA"",""explanation"":""Data Protection Impact Assessment, a process to identify and mitigate data protection risks.""}],""skill_priorities"":{""must_have"":[""OneTrust certification"",""OneTrust configuration and troubleshooting experience"",""Data privacy compliance knowledge"",""Systems integration experience""],""nice_to_have"":[""Experience with emerging technologies""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach a OneTrust configuration task?"",""example_answer"":""I would first review the requirements, then use my knowledge of OneTrust to set up the configuration, and finally test it to ensure it meets the requirements.""},{""question"":""How do you stay up-to-date with industry trends in data privacy compliance?"",""example_answer"":""I regularly read industry publications, attend conferences, and participate in online forums to stay current.""}],""red_flags"":[""Lack of OneTrust certification or experience"",""Inability to provide hands-on-keyboard configuration and troubleshooting examples""],""confidence_score"":90.0}"
"Cybersecurity Specialist - Milwaukee, WI - USA",Intellectt Inc,"Toronto, Ontario, Canada",June,2024,"Hello,

I Hope you are doing great.

This is Bhanu from Intellectt INC; we’ve got an important role Cybersecurity Specialist( Medical device ) - Milwaukee, WI with one of our prestigious clients. Interested candidates can please send your updated resume at bhanu@intellectt.com

We're happy to sponsor TN VISA who are qualified and ready to relocate immediately. (Passport Mandatory)

Role: Cybersecurity Specialist( Medical device )

Location: Milwaukee, WI

Essential Job Functions

Develop deep understanding of Medtech security processes and procedures to serve as a subject matter expert on cybersecurity activities
Partner with engineering teams to drive successful adherence to Medtech product security programs during product development, testing, and release phases.
Work with external partners as well as collaborate with internal cross functional teams to own and drive cybersecurity project deliverables.
Collaborate with product development teams to identify potential cybersecurity risks during the pre-market phase.
Deliver documentation for pre-market development activities including security plans, architecture and data flow diagrams, threat models, requirements, SBOM, and risk documentation.
Monitor and drive post-market vulnerability management activities, with adherence to strict timelines.
Recommend and execute security measures to mitigate identified risks and improve product security.
Guide teams to make decisions that balance business needs with security objectives.
Think across organizational boundaries and empathize with customers, both internal and external.
Perform other related duties and responsibilities, as assigned

Knowledge And Experience

Bachelor's degree in Computer Science, Cybersecurity, or a related field (or equivalent practical experience). 6+ yrs of experience.
In-depth knowledge of pre-market product security and familiarity with industry best practices.
Experience with security risk management techniques and tactics.
Experience in assessing pre-market cybersecurity risks, vulnerability testing, and implementing security measures.
Strong understanding of secure software development lifecycles (SDLC) and related processes.
Working knowledge of regulatory standards and compliance frameworks (e.g., NIST Cybersecurity Framework, ISO27001, SOC2, HIPAA, GDPR).
Experience working in a regulated environment, FDA-regulated preferred.
Demonstrated organizational skills, attention to detail, the ability to handle multiple assignments simultaneously in a timely manner and be able to meet assigned deadlines.
Committed to working with a sense of urgency and embracing new challenges.
Strong communication and interpersonal skills.

Qualification

BS degree in Computer Science; MS in Cybersecurity preferred



Poldas Ajay Bhanu | Sr Recruiter

Intellectt INC

732 784 4384

732 412 6999- Ext: 159

Bhanu@intellectt.com intellectt.com/

517 Route 1 South, Suite 1115 Iselin, NJ 08830.

WhatsApp: https://chatwith.io/s/bhanu","{""role_summary"":""The Cybersecurity Specialist will develop and maintain cybersecurity processes and procedures for medical devices, collaborating with engineering teams and external partners to ensure product security and mitigate risks."",""key_terms"":[{""term"":""Medtech security"",""explanation"":""Security processes and procedures specific to medical technology devices.""},{""term"":""Pre-market development"",""explanation"":""The phase of product development before a product is released to the market.""},{""term"":""SBOM"",""explanation"":""Software Bill of Materials, a list of components used in software development.""},{""term"":""NIST Cybersecurity Framework"",""explanation"":""A set of guidelines for managing and reducing cybersecurity risk.""}],""skill_priorities"":{""must_have"":[""6+ years of experience"",""In-depth knowledge of pre-market product security"",""Experience with security risk management techniques and tactics"",""Strong understanding of secure software development lifecycles (SDLC)""],""nice_to_have"":[""MS in Cybersecurity"",""Experience working in a regulated environment, FDA-regulated preferred""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with pre-market product security and how you've mitigated cybersecurity threats in the past?"",""example_answer"":""In my previous role, I worked with a cross-functional team to identify and mitigate potential security risks during the pre-market phase. I developed and implemented a comprehensive security plan, which included threat modeling, risk assessment, and vulnerability testing.""},{""question"":""How do you stay current with industry best practices and regulatory standards in cybersecurity?"",""example_answer"":""I regularly attend industry conferences, participate in online forums and discussions, and engage with peers to stay informed about the latest trends and developments in cybersecurity.""}],""red_flags"":[""Lack of experience in regulated environments, particularly FDA-regulated"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":85.0}"
Security Analyst - HYBRID,Randstad Canada,"Calgary, Alberta, Canada",June,2024,"Are you passionate about cybersecurity and ready to make an impact in a dynamic environment? Our Calgary client is expanding their Cybersecurity Office (CSO) Governance, Risk and Compliance (GRC) team and we're looking for a motivated Cybersecurity Compliance Specialist to join their team. In this role, you'll play a crucial part in ensuring compliance with company policies and standards, conducting assessments, and reporting on cybersecurity across our corporate and ICS environments. If you're ready to grow your expertise and contribute to safeguarding our client's operations, apply now and be part of a mission to secure the future of energy.

Advantages

Contribute to cybersecurity governance across corporate and ICS environments, ensuring critical infrastructure protection.
Opportunity to expand knowledge and skills in cybersecurity compliance, automation, and risk management.
Work with PowerBI and ServiceNow to develop innovative dashboards and automate security controls.
Engage with a supportive team of cybersecurity professionals and collaborate closely with IT and business stakeholders.
Influence cybersecurity strategy by identifying and mitigating emerging security risks through comprehensive assessments and compliance attestations.

Responsibilities

Perform assessments and report on cybersecurity compliance across TC Energy
Conduct internal Cybersecurity audits
Participate in Cybersecurity Compliance attestations
Drive automation of security controls with a focus on continuous monitoring
Develop scripts to automate manual tasks and processes within the Cybersecurity Office
Develop PowerBI and ServiceNow dashboards leveraging available data sources
Develop ServiceNow GRC Compliance features, such as integration with Governance and Risk areas and management of Non-Conformances
Review Vulnerability Management Metrics and streamline processes to improve efficiency
Collaborate with system administrators, developers, and IT teams to coordinate the remediation of identified vulnerabilities
Conduct research to maintain and expand knowledge on the latest cybersecurity controls and standards, as well as the threat and vulnerability landscape
Collaborate with CSO GRC Manager, Cybersecurity Office team members, IS teams, business units and other stakeholders on areas related to cybersecurity governance,

Qualifications

5+ years in cybersecurity compliance, risk management, or related fields.
Proficiency in interpreting and implementing cybersecurity policies and standards.
Proven ability to conduct cybersecurity audits and assessments across complex environments.
Experience in automating security controls and processes, with scripting skills in languages such as Python or PowerShell.
Strong understanding of cybersecurity technologies, including vulnerability management, and experience with tools like ServiceNow and PowerBI.

Summary

If you're ready to leverage your expertise in a role that offers both challenges and rewards, we invite you to apply now via this job ad or reach out to your Randstad Digital representative immediately!

P.S. Don’t forget that when you update your profile on Randstad.ca it helps us find you faster when we do have roles that match your skills! So even if this role isn’t for you please update your profile so we can find you!

We look forward to supporting you in your job search!

Good luck!

Randstad Canada is committed to fostering a workforce reflective of all peoples of Canada. As a result, we are committed to developing and implementing strategies to increase the equity, diversity and inclusion within the workplace by examining our internal policies, practices, and systems throughout the entire lifecycle of our workforce, including its recruitment, retention and advancement for all employees. In addition to our deep commitment to respecting human rights, we are dedicated to positive actions to affect change to ensure everyone has full participation in the workforce free from any barriers, systemic or otherwise, especially equity-seeking groups who are usually underrepresented in Canada's workforce, including those who identify as women or non-binary/gender non-conforming; Indigenous or Aboriginal Peoples; persons with disabilities (visible or invisible) and; members of visible minorities, racialized groups and the LGBTQ2+ community.

Randstad Canada is committed to creating and maintaining an inclusive and accessible workplace for all its candidates and employees by supporting their accessibility and accommodation needs throughout the employment lifecycle. We ask that all job applications please identify any accommodation requirements by sending an email to accessibility@randstad.ca to ensure their ability to fully participate in the interview process.","{""role_summary"":""A Cybersecurity Compliance Specialist ensures compliance with company policies and standards, conducts assessments, and reports on cybersecurity across corporate and ICS environments."",""key_terms"":[{""term"":""Cybersecurity Governance"",""explanation"":""Ensuring critical infrastructure protection across corporate and ICS environments.""},{""term"":""ICS Environments"",""explanation"":""Industrial Control Systems environments that require cybersecurity protection.""},{""term"":""PowerBI"",""explanation"":""A business analytics service by Microsoft used for developing innovative dashboards.""},{""term"":""ServiceNow"",""explanation"":""A cloud-based IT service management platform used for automating security controls and developing GRC compliance features.""},{""term"":""GRC Compliance"",""explanation"":""Governance, Risk, and Compliance features in ServiceNow used for managing cybersecurity compliance.""},{""term"":""Vulnerability Management Metrics"",""explanation"":""Metrics used to measure and improve the efficiency of vulnerability management processes.""}],""skill_priorities"":{""must_have"":[""5+ years in cybersecurity compliance, risk management, or related fields"",""Proficiency in interpreting and implementing cybersecurity policies and standards"",""Proven ability to conduct cybersecurity audits and assessments across complex environments"",""Experience in automating security controls and processes, with scripting skills in languages such as Python or PowerShell"",""Strong understanding of cybersecurity technologies, including vulnerability management, and experience with tools like ServiceNow and PowerBI""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with cybersecurity compliance attestations and how you've identified and mitigated emerging security risks?"",""example_answer"":""In my previous role, I conducted regular compliance attestations, identifying areas for improvement and implementing remediation plans to mitigate emerging security risks.""},{""question"":""How do you stay current with the latest cybersecurity controls and standards, as well as the threat and vulnerability landscape?"",""example_answer"":""I regularly review industry publications and attend webinars to stay current with the latest controls and standards, and participate in threat intelligence sharing groups to stay informed about emerging threats.""}],""red_flags"":[""Lack of experience with ServiceNow and PowerBI"",""Limited understanding of cybersecurity governance and risk management""],""confidence_score"":90.0}"
Security Incident Analyst 2,Behavox,"Toronto, Ontario, Canada",June,2024,"About Behavox

Behavox is shaping the future for how businesses harness their most important raw material - data. Our mission is bold: Organize enterprise data into actionable information that protects and promotes the business growth of multinational companies around the world.

From managing enterprise risk and compliance to maximizing revenue and value, our data operating platform presents a widespread opportunity to build multilingual, AI/ML-based solutions that activate data for every function within a global enterprise.

Our approach is unique, and it’s validated by our customers who tell us to keep forging ahead because no one else is aggregating, analyzing, and acting on data to uncover opportunities or solve problems quite the way we are.

We are looking for fearless innovators who have an insatiable appetite for building what no one has built before.

About The Role

As part of the Behavox Cyber Security team the Security Incident Response Analyst will monitor, detect, analyze, and mitigate cyber security incidents. The role requires a highly talented individual who is willing to demonstrate strong problem-solving skills, has experience in various investigation toolsets and best practices, is able to think critically, and can allow for flexible scheduling. This role will act as an appointed leader of the Incident Response Team (IRT) for the duration of the incident being responded to.

This is a great opportunity for the right talented individual to:

Improve and optimization of SIEM security events working on a team dedicated to extraordinary Cyber Security standards.
Use modern IR approaches and frameworks (e.g. MITRE ATT&CK and Threat Intelligence).
Learn and manage our EDR (Endpoint Detection and Response) platform.

What You'll Bring

A deep and genuine interest in Behavox as demonstrated by a connection to its mission, marketplace and/or technologies.
2+ years of working experience in cyber security incident response, managing threat intelligence strategy, monitoring of cloud infrastructure and web application security.
Experience working with Endpoint Detection and Response (EDR) tools, Intrusion Detection Systems, Firewalls, Vulnerability Assessment tools.
Experience working with Security Information and Event Management (SEIM) solutions with Security-related designations e.g. GCIH/CCFP preferred.
Background in hands-on computer and networking experience to include an understanding of TCP/IP, routing, and major Internet protocols.

What You'll Do

Respond to security incidents using SIEM systems and/or IDS monitoring to contain, eradicate and report on them.
Design and/or improve on Incident Response capabilities that positively impact risk assessmnet and planning.
Implement Incident Response capabilities utilizing EDR or other relevant technologies that deliver efficiencies in incident handling.
Document Incident Response processes through the development of Playbooks and/or Runbooks to provide continuous improvement.
Write Incident Reports that incorporate recommendations and directives to create iterative feedback loops.

What We Offer

A truly global mission with a passionate highly talented community in locations all over the World.
The ability to have significant impact and potential for learning as our aspirations require bold innovation.
A highly competitive cash compensation package with performance bonuses baked into salary payments .
A flexible work schedule that allows for Remote or Hybrid work as appropriate to the role and location.
A very generous time-off policy (30 days annually), with public holidays for your geography in addition.

About Our Process

We take Talent very seriously and we are building a community of extraordinary individuals working together in very high performing teams. We also know that the best Talent always has options so we believe that the process has to be a two way assessment - the company AND the candidate assessing the business needs alignment, the career next step alignment, and the cultural alignment.

During the process we will begin by exploring the core factors regarding salary and location along with core experience and skills and values alignment. We will then deep dive explore the critical technical competencies we have identified for the role, and then we will deep dive in behavioral competencies.

The most aligned candidate will then be asked to do a practical work task simulation activity so we can make sure that you will enjoy the kind of work the role requires, and this task will typically be presented and discussed with a group of colleagues and managers. Finally we will ask you to meet with a number of our senior leaders to make sure that you are making the most informed call possible.","{""role_summary"":""The Security Incident Response Analyst will detect, analyze, and mitigate cyber security incidents, leading the Incident Response Team and improving SIEM security events, using modern IR approaches and frameworks."",""key_terms"":[{""term"":""SIEM"",""explanation"":""Security Information and Event Management, a solution for monitoring and managing security-related data from various sources.""},{""term"":""EDR"",""explanation"":""Endpoint Detection and Response, a platform for detecting and responding to endpoint threats.""},{""term"":""MITRE ATT&CK"",""explanation"":""A globally recognized framework for identifying cyber-attack tactics and techniques.""}],""skill_priorities"":{""must_have"":[""2+ years of experience in cyber security incident response, managing threat intelligence strategy, monitoring of cloud infrastructure and web application security.""],""nice_to_have"":[""Experience working with Endpoint Detection and Response (EDR) tools, Intrusion Detection Systems, Firewalls, Vulnerability Assessment tools.""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to contain and eradicate a security incident using SIEM systems and/or IDS monitoring?"",""example_answer"":""In my previous role, I responded to a security incident by containing the threat using SIEM systems and then eradicated it by implementing a patch.""},{""question"":""How do you stay updated with the latest threat intelligence strategies and tactics?"",""example_answer"":""I regularly follow industry blogs and attend conferences to stay updated on the latest threat intelligence strategies and tactics.""}],""red_flags"":[""Lack of experience in managing threat intelligence strategy, monitoring of cloud infrastructure and web application security.""],""confidence_score"":90.0}"
Vulnerability Assessment Analyst,LastPass,Canada,June,2024,"LastPass, the #1 password leader, provides password and identity management solutions that are convenient, easy to manage, and effortless to use, helping more than 32 million users and 100,000 businesses organize and protect their online lives. As a pioneer in cloud security technology, LastPass provides award-winning password and identity management solutions that are convenient, effortless, and easy to manage. LastPass values users’ privacy and security, so your sensitive information is always hidden – even from us.

We welcome new ideas, support your growth, and recognize your value, if this aligns with what you are looking for in your next career move, Join Us

LastPass is looking for a Vulnerability Assessment Analyst:

As a Trust & Security team member, you will collaborate with security professionals and engineering teams to identify, verify, prioritize, and address vulnerabilities. This joint effort is aimed at enhancing overall security and minimizing potential threats. Additionally, you will contribute to developing a strong vulnerability management program, ensuring the organization's security and compliance standards are upheld.

If you are passionate about complex problem solving and motivated by scale, then this is the role for you!

Who will you work with?

You will be part of our Security Posture and Attack Surface Engineering & Research (SPASER) team. You'll collaborate with Trust & Security teams to enhance our vulnerability management program. You'll focus on daily vulnerability assessments and support critical security functions like threat intelligence and incident response. Working closely with engineering teams, you'll improve our security posture by treating vulnerabilities and suggesting enhancements.

What are some of the exciting challenges you will be working on?

Regularly assessing the organization's information systems, networks, and applications, using both automated scans and manual methods, across on-premise and cloud-based environments.
Analyzing vulnerability scan results to pinpoint risks, threats, and potential vulnerabilities.
Delivering clear, concise reports to key stakeholders, including IT, Platform, and Software Engineering teams.
Collaborating with the vulnerability treatment team to prioritize and address vulnerabilities based on risk level and potential impact.
Working closely with incident response and threat intelligence teams to identify and mitigate security risks.
Offering strategies to mitigate and remediate identified vulnerabilities.
Validating vulnerability assessment findings, including false positives and false negatives.
Staying updated on emerging threats and technologies to evolve testing methodologies.
Supporting improvements to vulnerability management tools for effective detection and fewer false positives.
Monitoring and tracking vulnerability status and trends.
Establishing metrics to evaluate vulnerability management effectiveness and find areas for enhancement.
Building strong partnerships across security and non-security teams to support vulnerability management processes.

What does it take to work at LastPass?

Previous experience in cybersecurity roles.
Passion for cybersecurity, particularly in vulnerability management, and a knack for spotting vulnerabilities.
Hands-on experience with vulnerability management tools, methods, and strategies.
Familiarity with cloud environments, including cloud-specific security measures and best practices.
Strong analytical skills and critical thinking ability, always striving for process improvement.
Self-motivated and able to work independently, but also effective in teamwork.
Excellent written and verbal communication in English, enabling effective collaboration.
Positive, can-do attitude and willingness to contribute hands-on to the team.

Why LastPass?

Market-leading password manager
High-growth, collaborative environment with inclusive teams
Remote first culture
Competitive compensation
Flexible Paid time off policies including but not limited to: Monthly self-care days (12 extra paid days off annually), volunteering days
Generous Parental leave
Comprehensive health coverage, dependents included
Home office setup support
LastPass families free account up to 5 members
Continuous learning and development opportunities

Unlock your potential with us - your skills, experience, and unique perspective matter more than just checking the boxes. Apply today, and let's build the future together!

We’re building an inclusive community that reflects the people of all races, genders, sexual orientations, national origins, backgrounds, and perspectives who share our world.

For all US based jobs please review our Applicant Privacy Notice

For all EU based jobs please review our Candidate Privacy Notice

Please review our CCPA Notice","{""role_summary"":""Collaborate with security professionals and engineering teams to identify, verify, prioritize, and address vulnerabilities, enhancing overall security and minimizing potential threats."",""key_terms"":[{""term"":""Vulnerability management"",""explanation"":""The process of identifying, classifying, prioritizing, and mitigating vulnerabilities in an organization's information systems, networks, and applications.""},{""term"":""Cloud security"",""explanation"":""The practice of protecting cloud computing environments, data, and applications from unauthorized access, use, disclosure, disruption, modification, or destruction.""},{""term"":""Threat intelligence"",""explanation"":""The process of gathering, analyzing, and sharing information about potential or actual threats to an organization's security posture.""}],""skill_priorities"":{""must_have"":[""Previous experience in cybersecurity roles"",""Hands-on experience with vulnerability management tools, methods, and strategies"",""Familiarity with cloud environments, including cloud-specific security measures and best practices""],""nice_to_have"":[""Passion for cybersecurity, particularly in vulnerability management"",""Strong analytical skills and critical thinking ability""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your experience with vulnerability management tools and strategies?"",""example_answer"":""I have hands-on experience with Nessus and Qualys, and I've developed strategies for prioritizing and addressing vulnerabilities based on risk level and potential impact.""},{""question"":""How do you stay updated on emerging threats and technologies in vulnerability management?"",""example_answer"":""I regularly read industry blogs and attend conferences to stay informed about the latest threats and technologies, and I've developed a network of peers who share knowledge and best practices.""}],""red_flags"":[""Lack of experience in cybersecurity roles"",""Inability to work independently and as part of a collaborative environment""],""confidence_score"":90.0}"
Senior Security Analyst,Neo Financial,"Calgary, Alberta, Canada",June,2024,"Come Build a Better Financial Future for all Canadians

At Neo, we're building a more rewarding financial experience for all Canadians.

Life at a rapidly expanding tech startup is demanding, exhilarating, and not for everyone.

From world-class creative minds to brilliant engineers, it's high-performing people that make Neo a workplace with passion and purpose.

Since being founded in 2019, Neo has built incredible traction and is one of the fastest growing fintechs in Canada.

LinkedIn's Top Startup in Canada for 2022 and 2023
Top-ranked mobile apps and credit cards
Canada's top-rated credit card
Team of 700+ people
1M+ customers in 3 years
11K+ retail partners


High Performance at Neo

We recruit, hire, and build our company culture around these attributes:

Teamwork: We trust, respect, encourage, and show up for each other — through good times and hard. We're on this mission not just for ourselves, but also for the people we work with — and ultimately, for our customers.

Ownership: We all have a stake in Neo's success — so we go out of our way to do what needs to get done. We hold ourselves accountable to deliver on our commitments — to our customers, to our partners, and to our team. When we fall short, we find a way to do better in the future.

Professional Integrity: We're asking millions of Canadians to trust us with their hard-earned money — so we hold ourselves (and each other) to the highest standards of integrity.

The Role

We are seeking a skilled and experienced Senior Security Analyst to join our IT Security team. The Senior Security Analyst will be responsible for implementing security measures to safeguard our organization's IT systems and data, monitoring, analyzing, and responding to security incidents, and assessing threats.

What You'll Be Doing

Implementation and maintenance of security controls, policies, and procedures to protect against cyber threats
Architect cloud-first security systems (e.g. Netskope, Zscaler, Crowdstrike, Cloud-native DLP, AWS security, etc)
Monitor security alerts and logs from various systems, applications, and network devices to detect and investigate potential security incidents
Conduct security event analysis and triage security alerts to identify and prioritize potential threats or vulnerabilities
Perform security assessments, risk analysis, and vulnerability scans to identify weaknesses in systems and recommend remediation measures
Collaborate with cross-functional teams to integrate security into IT infrastructure, applications, and services
Provide guidance and expertise on security best practices and recommend security enhancements
Document security incidents, investigations, and actions taken for future reference and improvement
Stay updated on emerging security threats, vulnerabilities, and industry best practices


Who We're Looking For

Bachelor's degree in Computer Science, Information Security, or related field (or equivalent work experience)
5+ years experience as a Security Analyst or in a similar role focusing on standards and compliance
Proven experience in IT security, incident response, or a related field
Familiarity with security tools and technologies such as SIEM, IDS/IPS, antivirus, and endpoint protection
Knowledge of security frameworks and best practices (e.g., NIST, CIS, SOC2, PCI, etc)
Strong analytical and problem-solving skills
Excellent communication and teamwork abilities


Working at Neo

Joining Neo means betting on yourself and discovering your full potential. As individuals and as a team, we continually challenge ourselves and each other to do our best work. We're making change happen at a rapid pace — providing endless opportunities to sharpen your skills, expand your knowledge, and find new solutions to complex problems. That means rapid career progression and constant learning opportunities.

The people who thrive at Neo are resourceful, relentless, and want to win. We hold ourselves to high standards, because we're on a mission that matters — to transform financial services for the better. If that's what you're looking for, read on.

We trust, respect, and show up for each other. That means truthful conversations, frequent feedback, and working with people who push you to be your best. We're evolving quickly as an organization, we work together in person, and the pace of progress isn't for everyone. That's why we're looking for change-makers who love a challenge — who would rather blaze a trail through uncertainty than travel a well-paved road.

Our team members earn meaningful equity in the company through stock options — so Neo's growth benefits everyone who helps make it happen. That also means taking on more responsibility than you may have had at your last job. We don't get hung up on job titles or hierarchy — we're focused on doing what it takes to accomplish our mission.

Check out these videos from our employees to learn more about Working at Neo.

Apply with Us

We believe in equal opportunity, and are committed to creating an inclusive climate where everyone can thrive. Customers trust us with their finances, so successful candidates for this position will be required to undergo a security screening, including a criminal records check and a credit check.","{""role_summary"":""A Senior Security Analyst responsible for implementing security measures, monitoring and responding to security incidents, and assessing threats to protect Neo's IT systems and data."",""key_terms"":[{""term"":""Cloud-first security systems"",""explanation"":""Security systems designed to operate primarily in cloud-based environments.""},{""term"":""SIEM"",""explanation"":""Security Information and Event Management system, used to monitor and network devices for security alerts.""},{""term"":""IDS/IPS"",""explanation"":""Intrusion Detection System/Intrusion Prevention System, used to detect and prevent unauthorized access to systems and networks.""},{""term"":""NIST"",""explanation"":""National Institute of Standards and Technology, a framework for security best practices and standards.""}],""skill_priorities"":{""must_have"":[""5+ years experience as a Security Analyst"",""Proven experience in IT security, incident response"",""Familiarity with security tools and technologies"",""Knowledge of security frameworks and best practices""],""nice_to_have"":[""Bachelor's degree in Computer Science, Information Security, or related field""]},""proposed_screening_questions_with_answers"":[{""question"":""What experience do you have with implementing security controls and policies?"",""example_answer"":""I have implemented security controls and procedures to protect against cyber threats in my previous role as a Security Analyst.""},{""question"":""How do you stay updated on emerging security threats and vulnerabilities?"",""example_answer"":""I regularly review industry reports and attend webinars to stay current on emerging security threats and vulnerabilities.""}],""red_flags"":[""Lack of experience with security tools and technologies"",""Inability to work in a fast-paced, rapidly changing environment""],""confidence_score"":90.0}"
Cybersecurity expert,Alter Solutions Canada,"Toronto, Ontario, Canada",June,2024,"ALTER SOLUTIONS is a consulting and technology expertise company founded in 2006. Our mission is to support our clients with their technical and organizational cybersecurity challenges. Our services are structured around the following areas of expertise:
Security Management
Architecture and Integration
Audit and Penetration Testing
Cyber Defense
We are an international group established in over ten countries, with a team of 750 employees.
Our success is driven by the development and fulfillment of each team member, and we place great importance on providing the best possible working conditions:
Remote work available for a majority of our projects
A Flex Office work environment available to everyone at all times to promote communication and collaboration
Expert communities to share and disseminate skills within the group
Close project management and HR support
Annual training and certification opportunities
Recognition of our consultants' expertise development
Strong openness to short-term or long-term international mobility

Job Description

We are looking for a cybersecurity expert for one of our client, a french multinational.
The group is established in 38 countries and operates 90 industrial sites.
The security of information systems has become a top priority for our client in recent years, especially to adapt to new challenges around cloud and cybersecurity. To continue its security plan, our client is seeking a Cybersecurity Expert. Reporting to the Group Information Systems Security Manager, the position has an international context. You will work as the technical Security reference for the entire Group.
Key Responsibilities:
Leverage your advanced technical expertise to contribute to the selection and implementation of appropriate security solutions.
Participate in the development and updating of security policies and ensure their dissemination and explanation to entities (international context).
Provide technical support on cybersecurity tools provided to all Group Information Security Managers.
Participate in technical analysis and lead the resolution of security incidents in connection with impacted entities and external stakeholders (CSIRT, ANSSI, etc.).
Optimize and automate security controls.
Conduct technical monitoring related to market security solutions and current affairs.
Implement and animate the cybersecurity community, bringing together cybersecurity experts from the client’s global locations.
Identify, communicate, and present risks, and provide associated solutions to the cybersecurity community.
Lead and provide technical support during vulnerability and intrusion audits on services used by the Group or specific entities. Ensure the dissemination of results and the definition and follow-up of remediation actions.
Document existing initiatives and best practices.
Participate in the development of regular user and IT security awareness campaigns.
Investigate resources exposed on the Internet without following validation processes.
Optional: Knowledge of security issues in industrial environments. Ability to assist requesting entities in implementing security policies in industrial environments (existing installations or projects).
Technical environment:
Windows 10/2016 ou +
Azure/Office 365
Varonis
Qualys
SentinelOne
ElasticSearch/QRadar

Qualifications

A technical background with at least 5 years of experience in cybersecurity.
Rigorous and autonomous.
Desired skills :
Expertise in choosing and implementing security solutions.
Experience in developing and updating security policies and ensuring their dissemination.
Ability to provide technical support on cybersecurity tools.
Proficiency in technical analysis and incident resolution.
Skill in optimizing and automating security controls.
Knowledge of market security solutions and current affairs.
Ability to build and lead a cybersecurity community.
Proficiency in identifying, communicating, and presenting risks.
Experience in leading vulnerability and intrusion audits.
Capability to document initiatives and best practices.
Experience in developing user and IT security awareness campaigns.
Ability to investigate internet-exposed resources.
Optional Skills:
Knowledge of security in industrial environments.
Ability to assist in implementing security policies in industrial environments.","{""role_summary"":""The Cybersecurity Expert will leverage advanced technical expertise to select and implement security solutions, develop and update security policies, and provide technical analysis and incident resolution. The role will also involve leading the cybersecurity community, identifying and presenting risks, and optimizing security controls."",""key_terms"":[{""term"":""CSIRT"",""explanation"":""Computer Security Incident Response Team, responsible for responding to cybersecurity incidents.""},{""term"":""ANSSI"",""explanation"":""Agence Nationale de la Sécurité des Systèmes d'Information, a French government agency responsible for ensuring the security of information systems.""},{""term"":""Azure/Office 365"",""explanation"":""Cloud-based productivity and collaboration tools.""},{""term"":""Varonis"",""explanation"":""A cybersecurity platform that provides data security and analytics.""},{""term"":""Qualys"",""explanation"":""A cloud-based security and compliance platform that provides vulnerability management and penetration testing.""},{""term"":""SentinelOne"",""explanation"":""An endpoint security platform that provides real-time threat detection and response.""},{""term"":""ElasticSearch/QRadar"",""explanation"":""A log management and security information and event management (SIEM) platform.""}],""skill_priorities"":{""must_have"":[""Technical background with at least 5 years of experience in cybersecurity"",""Expertise in choosing and implementing security solutions"",""Experience in developing and updating security policies"",""Ability to provide technical support on cybersecurity tools"",""Proficiency in technical analysis and incident resolution"",""Skill in optimizing and automating security controls"",""Knowledge of market security solutions and current affairs"",""Ability to build and lead a cybersecurity community"",""Proficiency in identifying, communicating, and presenting risks"",""Experience in leading vulnerability and intrusion audits"",""Capability to document initiatives and best practices"",""Experience in developing user and IT security awareness campaigns"",""Ability to investigate internet-exposed resources""],""nice_to_have"":[""Knowledge of security in industrial environments"",""Ability to assist in implementing security policies in industrial environments""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience in developing and updating security policies?"",""example_answer"":""I have worked on several projects where I had to develop and update security policies for various clients. I understand the importance of keeping policies up-to-date and ensuring they are disseminated to all stakeholders.""},{""question"":""How do you stay current with market security solutions and current affairs?"",""example_answer"":""I regularly follow industry blogs and news, attend webinars, and participate in online forums to stay current with the latest security solutions and trends.""},{""question"":""Can you walk me through your process for identifying and presenting risks to stakeholders?"",""example_answer"":""I use a risk assessment framework to identify potential risks, and then prioritize them based on their likelihood and impact. I present my findings to stakeholders in a clear and concise manner.""}],""red_flags"":[""Lack of experience in developing and updating security policies"",""Inability to provide technical support on cybersecurity tools"",""Limited knowledge of market security solutions and current affairs""],""confidence_score"":90.0}"
Cyber Security Admin,Soho Square Solutions,"Montreal, Quebec, Canada",June,2024,"Description

Role: Cybersecurity

Location: Montreal, QC

Bilingual: French and English

Duration; 12 Months (Contract)

Hybrid Role

We want a French-speaking candidate

You are recognized for your ability to integrate and evolve systems, you are excited about the idea of working on Cybersecurity solutions? Relevant to IT Cybersecurity delivery for the business line responsible for cybersecurity, it is at the heart of our reflections on ways of doing things and creating value for the business lines and the Bank. You will have the opportunity to represent the Bank's values and use your power to act to participate in the creation of innovative solutions by responding to real business problems, putting the use of IT resources into perspective form the bank. Your knowledge of the technologies and platforms supporting identity and access management functions will allow you to develop them.

We will count on you to implement actions to achieve our vision. To support our development, we are currently looking for a person who will be able to act as an integrator for GIA services in the Entra ID (Azure AD) environment.

Responsibilities:

Act as an expert with internal customers by supporting them in their consumption of GIA services and identity directories: Entra ID (Azure AD), LDAP, Active Directory
Ensure compliance with existing processes by completing all analyzes leading to the effective integration of the Bank's applications into GIA solutions;
Contribute to the development of tools facilitating the collection of information or the optimization of existing processes;
Participate in the company's documentation effort (training support, Wiki) and produce the reports/procedures necessary for the quality of deliverables for our clients;


Actor in sharing knowledge and transferring knowledge to other advisors; Skills sought:

Have good communication and collaboration skills;
Be naturally “customer” oriented;
Be able to adapt quickly and evolve in your working methods;
Know how to manage unforeseen events that may arise throughout projects;
Be aware of identity management and Cybersecurity challenges;


Know how to anticipate issues in order to avoid them to facilitate the team's work; Technically and conceptually master the following aspects:

Master Entra ID (Azure AD), Active Directory Services, Enterprise Apps, Certificates,
Knowledge of SAML, OIDC, LDAP, Graph API protocols;
Familiar with SSO application integrations with Entra ID (Azure AD);
AWS knowledge is a plus;
Advanced knowledge of complex and extensive business networks in a multi-cloud and hybrid context;


Good understanding of networks and firewalls;



Hold a college diploma with a specialization in computer science or a certificate of relevant studies;



Have a minimum of 6 years of experience in a similar position;



Holding relevant Microsoft Azure or AWS certifications is a plus

:","{""role_summary"":""Act as a cybersecurity expert, integrating and evolving systems to support identity and access management functions, ensuring compliance and contributing to innovative solutions."",""key_terms"":[{""term"":""Entra ID (Azure AD)"",""explanation"":""A cloud-based identity and access management solution used by the bank.""},{""term"":""GIA services"",""explanation"":""A set of services related to identity and access control.""},{""term"":""LDAP"",""explanation"":""A protocol used for directory services and identity management.""},{""term"":""SAML"",""explanation"":""A protocol used for single sign-on (SSO) and identity federation.""},{""term"":""OIDC"",""explanation"":""A protocol used for authentication and identity management.""},{""term"":""Graph API"",""explanation"":""A set of APIs used for accessing and managing data in Azure AD.""},{""term"":""AWS"",""explanation"":""A cloud computing platform used by the bank.""}],""skill_priorities"":{""must_have"":[""Entra ID (Azure AD)"",""Active Directory Services"",""Enterprise Apps"",""Certificates"",""OIDC"",""LDAP"",""Graph API"",""SSO application integrations with Entra ID (Azure AD)""],""nice_to_have"":[""AWS knowledge""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would integrate a new application with Entra ID (Azure AD) environment?"",""example_answer"":""I would follow the bank's existing processes, completing all necessary integration steps, and ensuring compliance with identity and access management policies.""},{""question"":""How do you stay up-to-date with the latest developments in identity management and cybersecurity?"",""example_answer"":""I regularly follow industry blogs and news, participate in online forums, and pursue relevant certifications to stay current.""}],""red_flags"":[""Lack of experience with Entra ID (Azure AD) or similar identity management solutions."",""Inability to adapt quickly to changing project requirements.""],""confidence_score"":85.0}"
Security Architect,TV2 Consulting,"Toronto, Ontario, Canada",June,2024,"designing, implementing, optimizing, and supporting IT infrastructure across on-premises and Azure Cloud environments, encompassing virtualization and cybersecurity
Proficient in configuring and migrating from legacy third-party Mobile Device Management (MDM) solutions to Microsoft Intune
Deep understanding of design and configuration for MDM, for a replacement for Blackberry UEM
Expertise in security policies tailored to support the M365 security posture, responsible for defining and configuring security policies such as Conditional Access policies and DLP policies
Key responsibility includes support configuring and refining existing security policies and MDM policies to facilitate migrations to M365


Requirements

Outstanding knowledge of change management principles and performance evaluation processes
Exceptional technical knowledge
Effective written and oral communication skills
7+ years of relevant work experience


Benefits

Type of job: Temporary Contractor - 1 year
Date candidate required: Immediate
Location: Toronto
Work hours are Monday - Friday, normal 37.5 hour week","{""role_summary"":""Design, implement, optimize, and support IT infrastructure across on-premises and Azure Cloud environments, focusing on virtualization, cybersecurity, and mobile device management."",""key_terms"":[{""term"":""Azure Cloud"",""explanation"":""A cloud computing platform for building, deploying, and managing applications and services.""},{""term"":""Microsoft Intune"",""explanation"":""A cloud-based endpoint management solution for managing and securing devices.""},{""term"":""MDM (Mobile Device Management)"",""explanation"":""A set of policies, procedures, and technologies for managing and securing mobile devices in an organization.""},{""term"":""M365 security posture"",""explanation"":""A set of security policies and configurations for Microsoft 365 to protect against cyber threats.""},{""term"":""Conditional Access policies"",""explanation"":""Policies that grant or deny access to resources based on user and device conditions.""},{""term"":""DLP policies"",""explanation"":""Data Loss Prevention policies that detect and prevent unauthorized data exfiltration.""}],""skill_priorities"":{""must_have"":[""Azure Cloud"",""Microsoft Intune"",""MDM (Mobile Device Management)"",""M365 security posture"",""change management principles"",""performance evaluation processes""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the differences between Azure Cloud and on-premises infrastructure?"",""example_answer"":""Azure Cloud is a cloud-based infrastructure, whereas on-premises is a locally managed infrastructure. Azure Cloud provides scalability and flexibility, while on-premises provides more control and security.""},{""question"":""How do you configure and refine existing security policies and MDM policies for migrations to M365?"",""example_answer"":""I would assess the current security policies and MDM configurations, identify areas of improvement, and implement changes to ensure a seamless migration to M365.""}],""red_flags"":[""Lack of experience with Azure Cloud and Microsoft Intune"",""Inability to explain MDM and M365 security posture concepts""],""confidence_score"":90.0}"
Infotek Consulting Services Inc.,"Toronto, Ontario, Canada",1 week ago,June,2024,"Infotek Consulting is searching for a seasoned Information Security Analyst to work on a hybrid contract assignment based in Toronto.

Project: Mitigate the next generation of cross-pillar security challenges and financial crimes through the establishment of a Fusion capability. Fusion takes a collaborative, integrated, cross-pillar approach to prevent, detect, investigate, and respond to threats and risks. B

How you’ll succeed
• Consulting - Review and interpret requirements documentation, architecture diagrams and solution designs to help determine the feasibility of a project and its security risk. Assess business needs against potential risks and provide your recommendations to enhance our information security landscape.
• Delivery and Execution - You will help us execute detailed threat risk and information security assessments, deviations, coordination of penetration testing and reporting. Help us complete requests from external partners (corporate and institutional clients) and recommend new controls to reduce risks.
• Communication - Build and present documentation to executive management aimed at communicating potential risks and providing recommendations. Provide feedback to and participate in the design and implementation of security assessment processes across the organization. Research, design, and implement security monitoring practices and operationalize these processes across the group.

Must Haves:
1. Information security analyst – 10+ years
2. Experience in Risk advisory – 5+ years
3. Experience with Archer – 2 years
4. Relationship management experience
5. Cloud Azure experience – 2 years

Nice to have:
1. Experience with financial crime
2. banking/financial industry experience","{""role_summary"":""An Information Security Analyst will work on a hybrid contract assignment to mitigate security challenges and financial crimes by establishing a Fusion capability, which involves reviewing requirements, assessing risks, and providing recommendations to enhance information security."",""key_terms"":[{""term"":""Fusion capability"",""explanation"":""A collaborative approach to prevent, detect, investigate, and respond to threats and risks by integrating cross-pillar security.""},{""term"":""Archer"",""explanation"":""A software solution for governance, risk, and compliance management.""},{""term"":""Cloud Azure"",""explanation"":""A cloud computing platform for building, deploying, and managing applications and services.""}],""skill_priorities"":{""must_have"":[""Information security analysis"",""Risk advisory"",""Archer experience"",""Relationship management"",""Cloud Azure experience""],""nice_to_have"":[""Financial crime experience"",""Banking/financial industry experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with Archer platform and how you've utilized it in previous roles?"",""example_answer"":""I've worked with Archer for 2 years, and I've used it to implement governance, risk, and compliance management. I've also utilized it to identify and mitigate potential risks.""},{""question"":""How do you stay current with emerging threats and risks in the financial industry?"",""example_answer"":""I regularly review industry reports, attend webinars to stay informed about the latest threats and risks. I also network with peers to share knowledge and best practices.""}],""red_flags"":[""Lack of experience with Archer or Cloud Azure"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
"Cybersecurity Analyst, Application Solutions",American Iron & Metal (AIM),"Montréal-Est, Quebec, Canada",June,2024,"Company Description

American Iron & Metal (AIM) is a family-owned company and recognized global leader in the metal recycling industry with more than 125 sites and 4000 employees worldwide. We have continued to prosper for the last eight decades thanks to the dedication of our employees and the ongoing trust and support of our customers.

Become part of team AIM, a growing team with an entrepreneurial spirit who has over the years evolved into a successful and multifaceted company with business divisions that include metal recycling, decommissioning and demolition, auto-parts sales and recycling, manufacturing of solder assemblies, construction waste recycling, and production of customized industrial and mining products.

We take pride in doing good things for the environment to help create a greener, more sustainable future for all.

It’s simple; we do it right. We AIM for excellence.

What we offer!

Competitive salary + other perks
Group insurance & RRSP program
Company-wide events throughout the year (BBQ, Holiday party etc.)
Free gym on site
Two cafeterias on site (subsidized meal program available)
Dynamic & rewarding work environment- work on high-impact, meaningful projects while also having fun!

Job Description

We are looking for an innovative and skilled Cybersecurity Analyst to join our security team. The successful candidate will be responsible for managing application vulnerabilities and supporting the software development lifecycle (SDLC) to integrate security practices by design and actively participate in SecOps activities. This person will play a crucial role in protecting the business from threats to our applications.

Cybersecurity Solution Design and Implementation: Develop and deploy strategies and tools to secure the company's IT assets.
Application vulnerability analysis and management: Identify, analyze and manage vulnerabilities in the company's software applications using specialized tools (SonarQube, Invicti, Qualys, etc.), perform regular scans and take corrective actions by collaborating with the development teams to support the resolution.
SDLC Support: Collaborate closely with development teams to integrate security measures (DevSecOps) from the earliest phases of software development (Security by design), ensuring that security is a priority at every stage of the cycle.
Application Security Policy Definition: Establish and maintain security procedures for application development, including codification of secure coding best practices.
Participate in SecOps activities: Improve security posture through continuous monitoring, incident management, and rapid response.
Technology Watch: Stay informed of the latest trends and technologies in cybersecurity to anticipate and defend against new threats.
Reporting and documentation: Write detailed reports on application vulnerabilities, security audits, and corrective actions taken.
Training and mentoring: Provide training and guidance to developers on application security best practices and the importance of security in the development lifecycle.
Cross-departmental collaboration: Work closely with the entire IT team and partners, specifically the development team, to integrate security practices into all aspects of application development.

Qualifications

Degree in computer science, information security, or related field.
Minimum 5 years of experience in a similar position
Mastery of application vulnerability management tools, Cloud development and in-depth understanding of software development processes including the DevSecOps approach.
Technical knowledge: Azure, AzureDevOps, AzurePipeline, Apps Security (dotnet prefered), OWASP, Qualys, SonarQube, SAST, and DAST tool.
Certifications like CISSP, CEH, or CompTIA Security+ are preferred, with a particular focus on those focused on application security, such as GWAPT or CSSLP.
Ability to analyze complex data and make recommendations based on analytics.
Excellent communication skills and ability to collaborate effectively with development and security teams.

Additional Information

American Iron & Metal and its subsidiaries is an equal opportunity employer. All qualified applicants are given consideration regardless of race, religion, colour, gender, sex, age, sexual orientation, gender identity, national origin, marital status, citizenship status, disability, veteran status, or any other protected class as provided in applicable employment laws.

Although we’d love to be able to speak with everyone that applies, due to the volume of applicants we receive and time constraints, only those selected to move forward will be contacted.","{""role_summary"":""The Cybersecurity Analyst will manage application vulnerabilities, support software development lifecycle, and integrate security practices to protect the business from threats."",""key_terms"":[{""term"":""DevSecOps"",""explanation"":""A practice that integrates security measures into every stage of software development.""},{""term"":""SonarQube"",""explanation"":""A tool used to identify and manage vulnerabilities in software applications.""},{""term"":""SecOps"",""explanation"":""A practice that involves continuous monitoring, incident management, and rapid response to improve security posture.""},{""term"":""Azure"",""explanation"":""A cloud computing platform used for development and deployment of applications.""},{""term"":""OWASP"",""explanation"":""An open-source project that helps organizations improve web application security.""}],""skill_priorities"":{""must_have"":[""Experience in application vulnerability management"",""Mastery of application vulnerability management tools"",""In-depth understanding of software development processes"",""Technical knowledge of Azure, AzureDevOps, AzurePipeline, Apps Security""],""nice_to_have"":[""Certifications like CISSP, CEH, or CompTIA Security+"",""Knowledge of OWASP, Qualys, SonarQube, SAST, and DAST tool""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you stay informed of the latest trends and technologies in cybersecurity?"",""example_answer"":""I regularly follow industry blogs and attend webinars to stay up-to-date on the latest threats and technologies.""},{""question"":""Can you give an example of a time when you had to collaborate with a development team to integrate security measures into an application?"",""example_answer"":""In my previous role, I worked with a development team to implement secure coding practices and conduct regular security audits.""}],""red_flags"":[""Lack of experience in application vulnerability management"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
"Security Analyst, Governance, Risk & Compliance (GRC)",Jobber,Canada,June,2024,"We’re looking for a Security Analyst- GRC to be part of our Security department at Jobber.

This role is ideal for intermediate level candidates in the security, governance, risk and compliance space. This opportunity fits those earlier in their security career or those looking to pivot into cybersecurity who bring transferrable SaaS skillsets including strong collaboration and communication skills. Our Security Analyst, GRC, focuses on the governance side of security and is not a technical security operations position requiring specific technical certifications or experience. Our ideal candidate is strong with data and possesses analytical skills.

Jobber exists to help people in small businesses be successful. We work with small home service businesses, like your local plumbers, painters, and landscapers, to transform the way service is delivered through technology. With Jobber they can quote, schedule, invoice, and collect payments from their customers, while providing an easy and professional customer experience. Running a small business today isn’t like it used to be—the way we consume and deliver service is changing rapidly, technology is evolving, and customers expect more. That’s why we put the power and flexibility in their hands to run their businesses how, where, and when they want!

Our culture of transparency, inclusivity, collaboration, and innovation has been recognized by Great Place to Work, Canada’s Most Admired Corporate Cultures, and more. Jobber has also been named on the Globe and Mail’s Canada’s Top Growing Companies list, and Deloitte Canada’s Technology Fast 50™, Enterprise Fast 15, and Technology Fast 500™ lists. With an Executive team that has over thirty years of industry experience of leading the way, we’ve come a long way from our first customer in 2011—but we’ve just scratched the surface of what we want to accomplish for our customers.

The team:

Jobber has a Security team led by our Sr. Director, Security. We have a split focus between governance and operations. All team members are specialized generalists (a primary focus but do a bit of everything). As our team develops and grows you will be collaborating with each member while we work towards making Jobber as secure as possible. We’ll also drive toward team member specialization as we ramp up on capacity and tooling.

The role:

We are seeking a motivated and detail-oriented individual to join our team as a Security Analyst - GRC. Your primary focus will be on governance and awareness, ensuring that our information systems and processes adhere to industry regulations and Jobber best practices. In this role, you will report directly to the Sr.Director, Security and assist in maintaining and enhancing the security posture of our organization. This is an excellent opportunity to gain hands-on experience in the field of information security while working closely with the Jobber Security team.

You'll support a wide range of security initiatives and in the future will have opportunity to specialize as you grow your career.

The Security Analyst - GRC will:

Aid in the maintenance and application of information security policies, standards, and procedures.
Participate in regular audits and assessments to ensure compliance with regulatory requirements, industry standards, and internal policies.
Collaborate with cross-functional teams to identify vulnerabilities and assess the effectiveness of existing controls.
Contribute to the development and maintenance of security documentation, including risk assessments, control frameworks, and incident response plans.
Work with leaders throughout the organization to assess and document risks and treatment plans.
Stay up-to-date with the latest security trends, vulnerabilities, and compliance requirements, and propose recommendations for improvement.
Distribute risk and governance information through reports and presentations
Assist in supplier risk assessments and ensure their compliance with Jobber’s security requirements.

To be successful, you should have:

Excellent analytical and problem-solving skills, with a keen eye for detail.
Ability to work independently as well as collaboratively in a team environment.
Strong verbal and written communication skills, with the ability to effectively communicate technical concepts to non-technical stakeholders.
High level of integrity and confidentiality when handling sensitive information.
A passion for learning and a drive to stay updated with emerging technologies and security trends.

Nice to have:

Audit, risk management experience
Cloud technology specifically AWS
Startup mindset

All interviews are currently being conducted virtually—via phone or video.

What you can expect from Jobber:

Having been named as a Top 10 Great Place to Work in Canada, we walk the talk. Here are just some of the great things you can expect from us:

A total compensation package that includes an extended health benefits package with fully paid premiums for both body and mind, RRSP matching, and stock options.
A dedicated Coaching and Development function, including Development Coaches, to help build the career you want and hit the goals you set, while ensuring you’re reaching your fullest potential.
Support for all your breaks: from vacation to rest and recharge, your birthday off to celebrate, health days to support your physical and mental health, and parental leave top-ups to support your growing family.
A unique opportunity to build, grow, and leave your impact on a $400-billion industry that has no dominant player...yet.
To work with a group of people who are humble, supportive, and give a sh*t about our customers.

We believe that diverse teams perform better and that fostering an inclusive work environment is a key part of growing a successful team. We welcome people of diverse backgrounds, experiences, and perspectives. We are an equal opportunity employer, and we are committed to working with applicants requesting accommodation at any stage of the hiring process.

A bit more about us:

Job by job, we’re transforming the way service is delivered. Your lawn care provider, home cleaning service, plumber or painter could use Jobber to better connect with their customers, save time in the office, invoice faster, and get paid! We’re bringing tens of thousands of people together with technology to deliver billions of dollars a year in services to happy customers. Jobber exists to help make these small businesses successful, and when they’re successful we all win!","{""role_summary"":""The Security Analyst - GRC role focuses on governance and awareness, ensuring that information systems and processes adhere to industry regulations and Jobber best practices."",""key_terms"":[{""term"":""GRC"",""explanation"":""Governance, Risk, and Compliance, referring to the governance side of security.""},{""term"":""SaaS"",""explanation"":""Software as a Service, a software delivery model where applications are hosted and managed by a third-party provider.""},{""term"":""AWS"",""explanation"":""Amazon Web Services, a cloud computing platform providing a range of services for computing, storage, and more.""}],""skill_priorities"":{""must_have"":[""analytical skills"",""strong collaboration and communication skills"",""ability to work independently and collaboratively"",""strong verbal and written communication skills""],""nice_to_have"":[""audit, risk management experience"",""cloud technology specifically AWS"",""startup mindset""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a time when you had to analyze complex data and present your findings to a non-technical audience?"",""example_answer"":""In my previous role, I was tasked with analyzing customer data to identify trends and opportunities for improvement. I created a clear and concise report, which I presented to our marketing team, and we were able to implement changes that increased customer engagement by 20%.""},{""question"":""How do you stay current with emerging technologies and security trends?"",""example_answer"":""I regularly read industry publications and attend webinars to stay up-to-date on the latest developments in cybersecurity. I also participate in online forums and discussions to stay informed about best practices and new technologies.""}],""red_flags"":[""Lack of experience in governance, risk, and compliance"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":85.0}"
Network Security Engineer,PEOPLE FORCE CONSULTING INC,"Mississauga, Ontario, Canada",June,2024,"This is a Permanent role with one of our client

Network Security Engineer
Perm role with an End Client
Location: Mississauga, ON - Hybrid- 3 days in office
Hands on network firewall administration on Palo Alto, Fortinet or checkpoint
Must be well versed with next generation firewall
Understands and as implemented network segmentation using firewall policies
Working knowledge of SASE technology such as Netskope or Zscaler
Hands on experience with Web application firewall capabilities such as F5, Barracuda, Cloudflare, Akamai
Worked with Qualys or Tenable or Rapid 7 vulnerability mgmt tools
Worked with Symantec/Mcafee/Cylance/Eset/Sentinel One end point protection
Worked with Splunk, Netskope, S1","{""role_summary"":""This Network Security Engineer role is responsible for hands-on network firewall administration, network segmentation, and vulnerability management."",""key_terms"":[{""term"":""Next Generation Firewall"",""explanation"":""A type of firewall that provides advanced security features and threat protection.""},{""term"":""SASE technology"",""explanation"":""Secure Access Service Edge technology that provides secure and fast access to applications.""},{""term"":""Web application firewall"",""explanation"":""A firewall that protects web applications from attacks and unauthorized access.""},{""term"":""Vulnerability mgmt tools"",""explanation"":""Tools used to identify and manage vulnerabilities in systems and applications.""},{""term"":""End point protection"",""explanation"":""Software that protects devices such as laptops and desktops from malware and other threats.""}],""skill_priorities"":{""must_have"":[""Hands on network firewall administration"",""Experience with next generation firewall"",""Network segmentation using firewall policies"",""Working knowledge of SASE technology"",""Hands on experience with Web application firewall capabilities"",""Worked with Qualys or Tenable or Rapid 7 vulnerability mgmt tools"",""Worked with Symantec/Mcafee/Cylance/Eset/Sentinel One end point protection""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you have implemented network segmentation using firewall policies?"",""example_answer"":""I have implemented network segmentation by creating separate zones for different departments and restricting access to sensitive areas.""},{""question"":""How do you stay up to date with the latest developments in SASE technology?"",""example_answer"":""I follow industry leaders and attend webinars to stay current.""}],""red_flags"":[""Lack of hands-on experience with network firewall administration"",""No experience with next generation firewall""],""confidence_score"":90.0}"
Security Awareness & Engagement Analyst- Operations,Jobber,Canada,June,2024,"We’re looking for a Security Awareness & Engagement Analyst (early career) to be part of our Security department.

This role is ideal for entry level candidates interested in the security space. This opportunity fits those earlier in their security career, new graduates with internship experience, or those looking to pivot into cybersecurity who bring transferrable SaaS skill sets including strong collaboration and communication skills. Our Security Awareness & Engagement Analyst focuses on the education and engagement side of security and is not a deeply technical position requiring specific certifications or experience. Our ideal candidate is seasoned at cross functional team engagement, by branding the importance of strong security posture within an organization.

Jobber exists to help people in small businesses be successful. We work with small home service businesses, like your local plumbers, painters, and landscapers, to transform the way service is delivered through technology. With Jobber they can quote, schedule, invoice, and collect payments from their customers, while providing an easy and professional customer experience. Running a small business today isn’t like it used to be—the way we consume and deliver service is changing rapidly, technology is evolving, and customers expect more. That’s why we put the power and flexibility in their hands to run their businesses how, where, and when they want!

Our culture of transparency, inclusivity, collaboration, and innovation has been recognized by Great Place to Work, Canada’s Most Admired Corporate Cultures, and more. Jobber has also been named on the Globe and Mail’s Canada’s Top Growing Companies list, and Deloitte Canada’s Technology Fast 50™, Enterprise Fast 15, and Technology Fast 500™ lists. With an Executive team that has over thirty years of industry experience of leading the way, we’ve come a long way from our first customer in 2011—but we’ve just scratched the surface of what we want to accomplish for our customers.

The team:

Jobber has a Security team led by our Sr. Director, Security. We have a split focus between governance and operations. Team members are specialized generalists (we have a primary focus but do a bit of everything). As our team develops and grows you will be collaborating with each member while we work towards making Jobber as secure as possible. We’ll also drive toward team member specialization as we ramp up on capacity and tooling.

The role:

We are seeking a motivated and detail-oriented individual to join our team as a Security Awareness & Engagement Analyst. This is an entry level position and an exciting opportunity to join the Security industry. Your primary focus will be on awareness, training, and internal engagement, ensuring that our awareness program is meeting the best practices set by the industry. In this role, you will report directly to the Sr.Director, Security and assist in maintaining and enhancing the security engagement within Jobber. This is an excellent opportunity to gain hands-on experience in the field of information security while working closely with the Jobber Security team.

You'll support a wide range of security initiatives and in the future will have opportunity to further specialize as you grow your career

The Security Awareness Analyst will:

Lead the development and delivery of security awareness training and educational materials for employees across the organization ranging from general awareness to role-specific security training.
Design and run phishing simulation exercises, analyze results, and provide feedback to leaders across the org.
Maintain day to day operations of the training platforms and evaluate ongoing solution fit - you’ll have an opportunity to shape the future of the program
Engage with employees across the organization to foster a security-first culture through the security help desk, presentations, and regular communications.
Regularly review and update training materials, staying current with the latest security trends and threats, and collecting feedback to enhance effectiveness.
Other duties as assigned

To be successful, you should have:

Strong verbal and written communication skills, with the ability to effectively communicate technical concepts to non-technical stakeholders.
Excellent analytical and problem-solving skills, with a keen eye for detail.
Ability to work independently as well as collaboratively in a team environment.
High level of integrity and confidentiality when handling sensitive information.
A passion for learning and a drive to stay updated with emerging technologies and security trends.

Nice to have:

Security Awareness Platform Experience (KnowB4, Ninjio, InfoSec IQ etc)
Startup mindset
Experience with the creation and rollout of new training materials

All interviews are currently being conducted virtually—via phone or video.

What you can expect from Jobber:

Having been named as a Top 10 Great Place to Work in Canada, we walk the talk. Here are just some of the great things you can expect from us:

A total compensation package that includes an extended health benefits package with fully paid premiums for both body and mind, RRSP matching, and stock options.
A dedicated Coaching and Development function, including Development Coaches, to help build the career you want and hit the goals you set, while ensuring you’re reaching your fullest potential.
Support for all your breaks: from vacation to rest and recharge, your birthday off to celebrate, health days to support your physical and mental health, and parental leave top-ups to support your growing family.
A unique opportunity to build, grow, and leave your impact on a $400-billion industry that has no dominant player...yet.
To work with a group of people who are humble, supportive, and give a sh*t about our customers.

We believe that diverse teams perform better and that fostering an inclusive work environment is a key part of growing a successful team. We welcome people of diverse backgrounds, experiences, and perspectives. We are an equal opportunity employer, and we are committed to working with applicants requesting accommodation at any stage of the hiring process.

A bit more about us:

Job by job, we’re transforming the way service is delivered. Your lawn care provider, home cleaning service, plumber or painter could use Jobber to better connect with their customers, save time in the office, invoice faster, and get paid! We’re bringing tens of thousands of people together with technology to deliver billions of dollars a year in services to happy customers. Jobber exists to help make these small businesses successful, and when they’re successful we all win!","{""role_summary"":""The Security Awareness & Engagement Analyst is an entry-level role that focuses on educating and engaging employees across the organization to maintain a security-first culture."",""key_terms"":[{""term"":""Security Awareness"",""explanation"":""Educating employees on best practices to prevent security breaches.""},{""term"":""Phishing Simulation"",""explanation"":""Simulating phishing attacks to test employees' ability to identify and respond to threats.""},{""term"":""Security-First Culture"",""explanation"":""Fostering a culture where security is a top priority for all employees.""}],""skill_priorities"":{""must_have"":[""Strong verbal and written communication skills"",""Excellent analytical and problem-solving skills"",""Ability to work independently and collaboratively""],""nice_to_have"":[""Security Awareness Platform Experience"",""Startup mindset"",""Experience with creation and rollout of new training materials""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach creating a security awareness training program for non-technical employees?"",""example_answer"":""I would focus on using clear, concise language and relatable examples to educate employees on security best practices.""},{""question"":""Can you give an example of a successful security awareness campaign you've led or been a part of?"",""example_answer"":""In my previous role, I developed a phishing simulation exercise that resulted in a 90% reduction in successful phishing attempts.""}],""red_flags"":[""Lack of experience in security or training and development"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":85.0}"
IT Security TRA and C&A Analyst,ADGA Group,"Ottawa, Ontario, Canada",June,2024,"ADGA provides strategic vision, world-class technology and service excellence in the areas of defence, security and enterprise computing to clients in the federal government, other levels of government and the private sector. In a world dominated by convergence, ADGA provides the expertise and innovation that organizations need to stay safe, efficient and productive. This is based on an exceptional balance sheet built since 1967, protecting some of Canada's most critical assets. Headquartered in Ottawa, with offices across Canada, ADGA is a privately owned Canadian company employing more than 800 employees, technical consultants and subject matter experts.

Job Description

ADGA requires the services of an Information Technology Security TRA and C&A Analyst to work on the Identity Credential and Access Management (ICAM) team that is developing an identity solution for small departments and agencies (SDA) in the Government of Canada. The team requires an IT Security TRA and C&A Analyst to assist them in preparing for a Security Assessment of the new architecture, which leverages components of the legacy ICAM solution. The objective of the Security Assessment would be for the new service to gain Authority to Operate on an Enterprise basis with an acceptable level of risk. The ICAM team has identified that the system, once in place, will need to satisfy Protected B – Medium Integrity, Medium Availability (PBMM) security requirements.
The IT Security TRA and C&A Analyst’s responsibilities will include, but are not limited to, the following:
Reviewing, analyzing, and/or applying Federal, Provincial or Territorial IT Security policies, System IT Security Certification & Accreditation processes, IT Security products, safeguards and best practices, and the IT Security risk mitigation strategies.
Identifying threats to, and vulnerabilities of operating systems (such as MS, Unix, Linux, and Novell), and wireless architectures.
Identifying personnel, technical, physical, and procedural threats to and vulnerabilities of Federal, Provincial or Territorial IT systems.
Developing reports such as:
Data security analysis,
Concepts of Operation,
Statements of Sensitivity (SoSs),
Threat assessments,
Privacy Impact Assessments (PIAs),
Non-technical Vulnerability Assessments,
Risk assessments,
IT Security threat, vulnerability and/or risk briefings.
Conducting Certification activities such as:
Developing Security Certification Plans, verifying that the security safeguards meet the applicable policies and standards,
Validating the security requirements by mapping the system-specific security policy to the functional security requirements, and mapping the security requirements through the various stages of design documents, verifying that security safeguards have been implemented correctly and that assurance requirements have been met.
Confirming that the system has been properly configured and that the safeguards meet applicable standards, conduct security testing and evaluation (ST&E) to determine if the technical safeguards are functioning correctly,
Assessing the residual risk provided by the risk assessment to determine if it meets an acceptable level of risk.
Conduct Accreditation activities such as a review of the certification results in the design review documentation by the Accreditation Authority to ensure that the system will operate with an acceptable level of risk and that it will comply with the departmental and system security policies and standards and identify the conditions under which a system is to operate (for approval purposes). This may include the following types of approvals:
Developmental approval by both the Operational and the Accreditation Authorities to proceed to the next stage in an IT system's life cycle development if sensitive information is to be handled by the system during development.
Operational written approval for the implemented IT system to operate and process sensitive information if the risk of operating the system is deemed acceptable, and if the system is in compliance with applicable security policies and standards.
Interim approval—a temporary written approval to process sensitive information under a set of extenuating circumstances where the risk is not yet acceptable, but there is an operational necessity for the system under development.
Develop and deliver training material relevant to the resource category.
The proposed resource may not be solely responsible for the completion of these deliverables. The consultant will be expected to work collaboratively with staff to ensure the work is completed in a way that ensures maximum knowledge transfer.

Qualifications

A minimum of a three-year college diploma in computer science or other IT-related field, a university degree at the Bachelor level in Information Technology or other IT-related field; OR a minimum of 5years within the last 15 years of work experience in the IT field.
A minimum of 5 years experience performing tasks like those listed in the Job Description above.
Must currently have or be eligible for a PWGSC Secret (LVL II) security clearance.
A minimum of 5 years of experience, in the last 10 years, with IT security, including experience in security operations, architecture, incident response, and team leadership.
A minimum of 5 years of experience, in the last 10 years identifying and mitigating risks, along with knowledge of legal and regulatory compliance requirements.
A minimum of 5 years of experience, in the last 10 years developing and implementing comprehensive security policies and frameworks that align with business goals.
Certifications such as CISSP, CISM, CRISC, SABSA Chartered Security Architect, CEH, CCSP, and various GIAC credentials.
A minimum of 5 years of experience, in the last 10 years demonstrating leadership and project management skills, with the ability to guide teams and influence organizational security strategy.

Additional Information

Work-Life Balance
We strongly support a healthy and productive work-life balance. This starts with a flexible approach to work, and policies designed to support employees through their day-to-day routines and major life events. For example, we offer a Maternity/Parental Top-Up (up to 52 weeks) and a Reservist Leave Top-Up (up to 180 days).
Belong@ADGA
ADGA continuously strives to integrate advanced Diversity, Equity & Inclusion (DEI) approaches and practices into our work culture. Our employee-based DEI Committee explores activities and invites discussions that foster an environment where all employees feel valued, respected, and heard.
Compensation
Above and beyond our commitment to offer a competitive base salary, ADGA has a company-wide profit-sharing plan for all full-time and part-time employees.
Comprehensive Benefits and Total Rewards
We offer a comprehensive benefit program, providing employees with the choice between base or enhanced plans. Depending on the plan, ADGA pays for Health & Dental, a Health Spending Account, Short-Term Disability, an Employee Assistance Program, and a Telemedicine service. Also offered: discounts on gym memberships, 5,000+ perks through Perkoplis, a Deferred Profit Sharing Plan, and access to a wide range of other employee-centric services and savings programs.","{""role_summary"":""An Information Technology Security TRA and C&A Analyst to assist in preparing for a Security Assessment of a new architecture, ensuring the system meets an acceptable level of risk."",""key_terms"":[{""term"":""Authority to Operate"",""explanation"":""A formal approval for a system to function with an acceptable level of risk.""},{""term"":""Protected B – Medium Integrity, Medium Availability (PBMM)"",""explanation"":""A security requirement for a system to ensure it meets specific integrity and availability standards.""},{""term"":""Certification & Accreditation (C&A)"",""explanation"":""A formal evaluation of a system's security safeguards to ensure they meet applicable policies and standards.""}],""skill_priorities"":{""must_have"":[""5+ years of IT security experience"",""5+ years of experience in security operations, architecture, incident response, and team leadership"",""5+ years of experience identifying and mitigating risks"",""5+ years of experience developing and implementing comprehensive security policies and frameworks"",""PWGSC Secret (LVL II) security clearance""],""nice_to_have"":[""CISSP, CISM, CRISC, SABSA Chartered Security Architect, CEH, CCSP, and various GIAC credentials"",""Leadership and project management skills""]},""proposed_screening_questions_with_answers"":[{""question"":""What experience do you have with IT security risk assessments and mitigation strategies?"",""example_answer"":""I have 5+ years of experience in identifying and mitigating risks, including developing and implementing comprehensive security policies and frameworks.""},{""question"":""Can you describe your experience with Certification & Accreditation (C&A) processes?"",""example_answer"":""I have 5+ years of experience with C&A, including developing Security Certification Plans and verifying security safeguards meet applicable policies and standards.""}],""red_flags"":[""Lack of experience with IT security risk assessments and mitigation strategies"",""Inability to obtain a PWGSC Secret (LVL II) security clearance""],""confidence_score"":90.0}"
"Legal Assistant, Privacy & Cybersecurity",Dentons,"Toronto, Ontario, Canada",June,2024,"Dentons is designed to be different. Our firm leads the way in a rapidly changing legal marketplace. We challenge the status quo and deliver consistent results as well as uncompromising quality and value to our clients. Our global presence is renowned as a firm with over 21,000 individuals in more than 200 offices serving clients across 80+ countries.

Dentons Canada is committed to its people and communities. We are consistently recognized as an employer of choice having received numerous awards including being selected as one of Canada’s Top 100 Employers (2024); Canada’s Top Employers for Young People (2024), and Canada’s Best Diversity Employers (2024).

This role is an opportunity for you to join the world’s largest law firm, a firm that offers opportunities to build your career while growing your skills and deepening your expertise.


POSITION SUMMARY

The Legal Assistant will support lawyers and a Senior Manager within the Privacy Group, as well as support and manage the practice of the National Practice Group Lead (NPGL) for Privacy and Cybersecurity. The Legal Assistant must demonstrate strong technical skills and knowledge to accurately and efficiently manage the production demands of the practice and also possess proven abilities to proactively support the management of the practice, including client relationship management. The position will require a polished, confident and reliable assistant who is able to manage multiple priorities. You are highly organized, proactive, and have a client first approach to work. You are professional and possess a high degree of business maturity and are an active partner in developing and managing the practice.

Generally, the hours of work are from 9 am to 5 pm., however, due to the nature of the role some pre-authorized overtime and flexibility in core hours may be required.


RESPONSIBILITIES

Correspondence/Document management:
Accurately prepare and edit correspondence, reports, minutes and presentations and other documents as required
Updating and maintaining client/matter lists and current client contact records electronically to meet Dentons’ requirements
File management, timekeeping and billing:
Entering and maintaining lawyer’s dockets and coordinating with the Accounting Department, when necessary; preparing detailed billings, and assisting in the management of WIP and AR reports
File opening and closing, and general management of files
Preparing and updating cheque requisitions and expense reports
Maintaining and organizing files, both electronic and hard copy as required
Practice management generally:
Provide support for meetings, including driving agendas, transcribing meeting minutes, executing action steps, and coordinating meeting requirements
Assess the urgency and importance of situations and take the appropriate action
Act as a resource to both internal and external contacts
Develop relationships with all internal stakeholders and act as a liaison between lawyer/clients and colleagues to facilitate work and accomplish objectives in a collaborative effort
Dealing with and responding to client inquiries expeditiously and conducting follow up; keeping the lawyers apprised of interactions in their absence
Competently utilize the Firm’s technology and tools
Processing incoming and outgoing mail, including timely filing and management of email, and managing bring forward
NPGL practice management:
Manage the NPGL calendar by scheduling appointments, changing meetings as required, planning and anticipating the NPGLs needs. Maintain a system to track items requiring follow-up and follow-through
Develop a full working knowledge of the firm's structure, the NPGL’s line of business, key personnel and organizational policies and procedures.
Support Group budget management activities i.e. prepare and submit expense reports, prepare spreadsheets
Manage the calendar, calls, mail, e-mails, meetings and domestic and international travel for the NPGL and coordinate events originating from that position
Support the NPGL in holding others accountable to timelines and commitments by ensuring follow up as required
Juggle multiple competing tasks and demands keeping focused on priorities and deadlines and assisting NPGL to do the same
Maintain a list of active files, their current statuses, and plans for their progression or any pending tasks and hold regular stand-up meeting with the NPGL to advance the files
Support the NPGL with delegation of files and development of a plan for distribution of work to team members
General administrative:
Duties such as scheduling appointments and meetings, photocopying materials, booking meeting rooms, making travel arrangements, etc.; working with other related Departments/services internally to provide documents and other materials on time to meet client needs
Ensuring strict adherence to confidentiality; accountability in relation to both internal and external clients to achieve outputs and goals for the Department and the Firm
Other duties as assigned


REQUIREMENTS

Legal Assistant diploma or college certificate in office or business administration or equivalent
Minimum 5 years of experience as a legal assistant or as an assistant supporting leadership with experience ideally acquired in a professional services environment
Ability to produce a high quality and quantity of work, occasionally under tight timelines
Able to meet deadlines, work well under pressure and take initiative using sound judgment
Strong interpersonal and communication skills (both verbal and written)
Proficiency in Microsoft Office applications and technically savvy
Knowledge of accounting / time entry systems (Intapp Time) and document management systems (Elite and iManage)
Excellent organizational and follow up skills; ability to exercise sound judgment in setting priorities
Professional client and telephone manner and a proven track record of working with confidential information
Able to work independently in a fast-paced, team-oriented environment
Must have excellent problem solving skills, and the ability to work with little instruction
Responsive and proactive
Demonstrated commitment to privacy and ethical conduct


We thank all applicants for their interest, however, only those selected for an interview will be contacted.


At Dentons we are committed to offering equitable and competitive pay, we achieve this by aligning internal salary ranges for specific roles to similar positions in the external market. In the normal course, our practice is to hire, transfer and promote employees within the entry part of our range, adjusting as needed based on the prior experience, skills and competencies required for the role along with any market differentials.

Recognizing our exceptional talent means providing a comprehensive total rewards package beyond a competitive salary. We have curated our employee benefits portfolio to offer inclusive and comprehensive wellbeing and developmental programs for our people. With extended benefits and mental health plans, paid time off, savings plans, fitness subsidy, parental leave top up and more, our benefits are flexible, aligned to our core values and supports the various needs of our people. Additionally, our personal and professional development programs include people networks, mentorships, and leadership series programming to help people grow their career.
Note: Availability of the benefits and perks may be subject to your location and employment type and may have certain eligibility requirements. Dentons reserves the right to alter these programs and offerings in whole or in part at any time without advance notice.


Equal Opportunity Statement
At Dentons Canada, inclusion, diversity and equity (ID&E) are not just ancillary values, they are foundational to our business. We believe that ID&E is essential to the shared success of our team and our clients. Our forward-thinking and inclusive culture supports the professional development of all our people, enhances the leading services we offer to our clients, and informs our commitment to make a positive impact in the communities where we live and work. As a testament to our commitment to ID&E, we have been recognized as one of Canada’s Best Diversity Employer’s for 12 consecutive years (2011-2022), as well as one of Canada’s Top Employers for Young People (2022) for the fifth time.
Dentons Canada is an equal opportunity employer and we welcome your application. All employment decisions, including hiring, will be made without regard to age, ancestry, citizenship, colour, creed, disability, ethnic origin, family status, gender assigned at birth, gender identity, marital status, place of origin, race, sexual orientation or any other characteristic protected by applicable human rights legislation.
We are committed to providing you with an inclusive, barrier-free and accessible workplace to support your success. Should you require accommodation during the recruitment process, for example as a result of a disability, please contact us at careers.canada@dentons.com.","{""role_summary"":""Support lawyers and a Senior Manager in the Privacy Group, managing the production demands of the practice and proactively supporting the management of the practice, including client relationship management."",""key_terms"":[{""term"":""NPGL"",""explanation"":""National Practice Group Lead for Privacy and Cybersecurity""},{""term"":""WIP and AR"",""explanation"":""Work in Progress and Accounts Receivable reports""},{""term"":""Intapp Time"",""explanation"":""Accounting/time entry system""},{""term"":""Elite and iManage"",""explanation"":""Document management systems""}],""skill_priorities"":{""must_have"":[""Legal Assistant diploma or college certificate in office or business administration or equivalent"",""Minimum 5 years of experience as a legal assistant or as an assistant supporting leadership"",""Proficiency in Microsoft Office applications"",""Knowledge of accounting/time entry systems and document management systems"",""Excellent organizational and follow-up skills""],""nice_to_have"":[""Experience in a professional services environment"",""Ability to produce high-quality and quantity of work under tight timelines""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you prioritize tasks and manage multiple deadlines in a fast-paced environment?"",""example_answer"":""I would use a task list to prioritize tasks, break down larger tasks into smaller ones, and communicate with the team and stakeholders to ensure everyone is aware of deadlines and expectations.""},{""question"":""Can you give an example of a time when you had to handle confidential information?"",""example_answer"":""In my previous role, I had access to confidential client information and ensured that it was handled and stored securely, only sharing it with authorized personnel.""}],""red_flags"":[""Lack of experience in a professional services environment"",""Inability to work independently in a fast-paced environment""],""confidence_score"":90.0}"
"Security Analyst, Lawful Acces",Rogers Communications,"Toronto, Ontario, Canada",June,2024,"We are committed to connecting Canadians through unique partnerships, our world-class network and content Canadians love—and our innovative team is growing. We are looking for dedicated team members to join our Corporate team who have a genuine passion for making positive impacts on customers and the communities where we live and work. We have a variety of business units with exciting and meaningful work waiting for you, including Communications, HR, Legal and Corporate Affairs, Supply Chain, Finance, and Real Estate. If you are considering your next step, we have exciting opportunities waiting for you. Come build a rewarding career at Rogers and be a driving force behind our success story!

12 months contract /Lawful Access Analyst

Ability to work various shifts inclucing midnight-8am,4pm-midnight, 8am-4pm)

Imagine working for an exciting entrepreneurial company where employees are committed to meeting big challenges and making a real difference. That’s Rogers. A leading communications and media company where people come to do great work. Right now we are looking for talented individuals to join our winning team where you will have a chance to innovate, grow and to do what really matters.

Responsibilities Include

Respond to Canadian law enforcement agency phone inquiries requesting assistance due to exigent (emergency) circumstances.
Live answer all calls to determine the nature of the law enforcement inquiry and what is required from Rogers to assist law enforcement.
Support 911 Public Safety Answering Points (PSAPs) across Canada by facilitating access to customer information under exigent circumstances.
Respond to all inquiries from law enforcement agencies pursuant to their criminal investigations as per departmental procedures.
Analyze records and prepare reports containing data stored within business systems in response to court orders.
Manage special projects as assigned.

Qualifications

Bilingualism is required French and English
Ability to work various shifts inclucing midnight-8am,4pm-midnight, 8am-4pm)
Must be able to work shifts. (days, evenings, overnights, week-ends, and statutory holidays
Applicants with a background in legal, telecommunications, or law enforcement related programs are encouraged to apply.
Must be able to obtain and maintain a federal government security clearance.
Excellent communications and customer service skills.
Strict attention to detail.
Must have been living in Canada for 10 years
Professionalism and ability to maintain confidentiality of information.
Previous experience in a call centre and / or customer service role is an asset.
Knowledge of Rogers technologies is an asset.
Knowledge of Vision 21, SGI, AS400, MS Word, Excel preferred.
Credit and criminal background checks will be conducted for all final candidates.

Schedule Full time

Shift Night

Length of Contract 12 Months

Work Location 1 Mount Pleasant (083), Toronto, ON

Travel Requirements None

Posting Category/Function Finance & Accounting & Corporate Security

Requisition ID 311232

At Rogers, we believe the key to a strong business, is a diverse workforce where equity and inclusion are core to making everyone feel like they belong. We do this by embracing our diversity, celebrating our different perspectives, and working towards creating environments that empower our people to bring their whole selves to work. Everyone who applies for a job will be considered. We recognize the business value in creating a workplace where each team member has the tools to reach their full potential by removing any barriers for equal participation. We work with our candidates who are experiencing a disability throughout the recruitment process to ensure that they have what they need to be at their best. Please reach out to our recruiters and hiring managers to begin a conversation about how we can ensure that you deliver your best work. You matter to us! For any questions, please visit the Recruitment Process FAQ.

Successful candidates will be required to complete a background check as part of the hiring process.

Posting Notes Corporate","{""role_summary"":""Work as a Lawful Access Analyst in a fast-paced environment, responding to law enforcement inquiries, supporting 911 Public Safety Answering Points, and analyzing records to prepare reports."",""key_terms"":[{""term"":""Exigent circumstances"",""explanation"":""Emergency situations requiring immediate assistance from law enforcement agencies.""},{""term"":""PSAPs"",""explanation"":""Public Safety Answering Points, which are responsible for answering emergency calls in Canada.""},{""term"":""Court orders"",""explanation"":""Legal documents issued by a court that require Rogers to provide information or assistance to law enforcement agencies.""}],""skill_priorities"":{""must_have"":[""Bilingualism (French and English)"",""Ability to work various shifts"",""Excellent communications and customer service skills"",""Strict attention to detail"",""Must have been living in Canada for 10 years""],""nice_to_have"":[""Background in legal, telecommunications, or law enforcement related programs"",""Previous experience in a call centre and/or customer service role"",""Knowledge of Rogers technologies"",""Knowledge of Vision 21, SGI, AS400, MS Word, Excel""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you handle a high-pressure situation where law enforcement agencies require immediate assistance?"",""example_answer"":""I would prioritize the request, assess the situation, and provide timely assistance while ensuring confidentiality and adhering to procedures.""},{""question"":""Can you describe a situation where you had to analyze records and prepare a report for a critical inquiry?"",""example_answer"":""In my previous role, I had to analyze customer data and prepare a report for a law enforcement agency. I ensured accuracy, attention to detail, and timely delivery of the information.""}],""red_flags"":[""Avoid candidates without experience working in a fast-paced, high-pressure environment."",""Be cautious of candidates who lack attention to detail or have difficulty maintaining confidentiality.""],""confidence_score"":85.0}"
Data Analyst,KOHO,Canada,June,2024,"About KOHO

KOHO’s purpose is to empower Canadians to build a great financial foundation with products that are radically transparent and easy to manage. We first launched in 2017, and we have since built a community of over 1 million users . Leading investors around the globe believe in our vision, and we’ve successfully raised over $320M to make our vision a reality.

Discover our culture here and get the inside scoop from our team here !

About The Role

KOHO is seeking a highly motivated Data Analyst to collaborate with various departments in leveraging data for informed decision-making. If you thrive on automating reports, building pipelines in DBT, crafting dashboards, and extracting actionable insights from financial data, this role is tailored for you. As part of our team, you will immerse yourself in writing SQL queries, collaborating with technical teams and Product Managers building our features, and engaging in consultative sessions with stakeholders across the business.

What You'll Do

Analyze new and existing data sources to develop accurate and insightful reports.
Build data pipelines in DBT to power our reporting
Perform in-depth analysis of product data to drive strategic decision-making.
Prioritize and manage incoming data requests effectively within your workflow.
Collaborate closely with other members of the data team to execute projects and uphold the integrity of our data warehouse as the cornerstone of truth at KOHO.
Be immersed in a tech pod. Participate in the feature development process from requirements to product launches. Collaborate with software engineers to ensure the data collected meets reporting needs

Who You Are

Proven experience in a data analyst role, with a focus on data modelling
Proficiency in SQL for data manipulation, including self-joins, window functions, and parameter usage.
Demonstrated experience with dbt from previous roles.
Quick grasp of business concepts, metrics, and KPIs.
Well-organized with excellent time management skills.
Bonus: Experience working with Product teams

At KOHO, we are dedicated to providing pay transparency to all candidates. Compensation at KOHO is determined through various factors including but not limited to: comparable salary market data within Canada, technical skill assessment, a holistic view of previous work history, and internal pay equity with other KOHO team members.

Target Base Salary Range

$83,000 — $95,000 CAD

What's In It For You?

We Invest Time And Resources Into Making Sure KOHO Is As Good As The People We Hire. Here Are Some Of The Reasons We Attract The Best People

🧘‍♂️ Balance Your Life - Company-wide summer wellness days, winter holiday closure, personal days, a wellness spending account, and maternity & parental leave top-up

💻 Remote First - Work from anywhere in Canada with a budget to set up your home office

🆙 Level Up - Access to an in-house certified performance coach and an annual training budget

🥅 Reach Your Goals - Salary assessments twice per year

🙌 The KOHO Culture - We have won 7 ""Great Place to Work ®"" awards since 2019

🤝 Be an Owner - Every KOHO employee gets a generous amount of equity with a 10 year exercise window

The KOHO culture is one of collaboration, creativity, and diverse perspectives. We are committed to building and fostering an inclusive, accessible environment for everyone. If you have any questions, concerns, or requests regarding accessibility needs, please contact peopleaccessibility@koho.ca and the People and Culture team will be happy to help.","{""role_summary"":""Collaborate with various departments to leverage data for informed decision-making, automating reports, building pipelines, and extracting actionable insights from financial data."",""key_terms"":[{""term"":""DBT"",""explanation"":""A data transformation tool used to build data pipelines for reporting.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and manipulating data in relational database management systems.""}],""skill_priorities"":{""must_have"":[""Data analysis"",""SQL"",""DBT"",""Data modeling"",""Time management""],""nice_to_have"":[""Experience working with Product teams""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a data pipeline in DBT?"",""example_answer"":""I would start by identifying the data sources and requirements, then design the pipeline architecture, and finally implement the pipeline using DBT.""},{""question"":""How do you stay organized when managing multiple data requests?"",""example_answer"":""I prioritize tasks based on urgency and impact, break down complex tasks into smaller ones, and maintain a clear record of progress and deadlines.""}],""red_flags"":[""Lack of experience with data modeling"",""Inability to work collaboratively with technical teams""],""confidence_score"":90.0}"
Business Data Analyst,Genpact,"Toronto, Ontario, Canada",June,2024,"Role: Business Data Analyst
Location: Toronto Canada ( 3 days onsite/week)
Duration: Fulltime

JD:
Understanding the process of auto ingestion and its validation
Building a strategic platform on Azure from the legacy systems
Experience in Data mapping and doing it in a more efficient way and if anything has been done wrong in the source system then get it corrected
Analyse the data what is being done today and how it can be further improved for future
Streamline the data so that it can be used simultaneously at multiple places
Make sure data completion and data accuracy checks have been done on datasets bringing out to cloud platforms
Experience in SQL server and PySpark as legacy system has SQL and strategic platform has PySpark
Experience working in confluence
Experience working on Azure Databricks
Tech stacks for legacy and strategic platform are as below:
Skill required.
Storage - SQL
ETL - SSIS, Stored Procedures
Data type – most batch (ASCII and EBCIDIC)

Must Have :
Data centric project (retail banking/fraud/AML) / work packages for Tier 2-4, low to moderate risk and regulatory projects with multiple stakeholders and across multiple LoB
Advanced to expert knowledge of capital markets products, regulatory reporting, business systems analysis, project delivery practices and standards across the project life-cycle
Data profiling of large datasets using tools like Python notebooks, SQL, MS Excel is a major plus.
Gain/acquire sound to advanced understanding of business and user interaction with technology throughout project delivery
Works independently as the senior or lead business analyst and coaches and guides members within area of expertise
Identifies and leads problem resolution for complex issues at all levels
Contributes to the communication and change management activities across multiple stakeholders
Undergraduate degree (technical or finance discipline)
Azure certification is an asset
Basic python knowledge (data analysis/profiling) is an asset.
5-7 years related business analysis experience


Genpact is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws. Genpact is committed to creating a dynamic work environment that values diversity and inclusion, respect and integrity, customer focus, and innovation. For more information, visit www.genpact.com . Follow us on Twitter, Facebook, LinkedIn, and YouTube.



Best Regards
Kavirala Sandeep Kumar
Talent Acquisition
E: Sandeep.Kavirala@genpact.com
Cell : 713-354-9580
www.Genpact.com","{""role_summary"":""The Business Data Analyst will analyze and improve data processes, build a strategic platform on Azure, and ensure data accuracy and completeness. They will work independently, lead problem resolution, and contribute to communication and change management activities."",""key_terms"":[{""term"":""Auto ingestion"",""explanation"":""Automatically importing data into a system without manual intervention.""},{""term"":""Data mapping"",""explanation"":""Matching data fields from one system to another to ensure accurate transfer.""},{""term"":""PySpark"",""explanation"":""A Python library for large-scale data processing, used in the strategic platform.""},{""term"":""Azure Databricks"",""explanation"":""A cloud-based platform for working with big data and analytics.""},{""term"":""Confluence"",""explanation"":""A collaboration tool for teams to share information and work together.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a data integration process.""},{""term"":""SSIS"",""explanation"":""SQL Server Integration Services - a tool for building ETL processes.""},{""term"":""Stored Procedures"",""explanation"":""Pre-written SQL code that can be executed on a database.""},{""term"":""Data profiling"",""explanation"":""Analyzing data to understand its structure, quality, and relationships.""},{""term"":""Capital markets products"",""explanation"":""Financial instruments and systems used in trading and investment.""},{""term"":""Regulatory reporting"",""explanation"":""Submitting required data to regulatory bodies to comply with laws and regulations.""}],""skill_priorities"":{""must_have"":[""Data centric project experience"",""Advanced to expert knowledge of capital markets products"",""Regulatory reporting"",""Business systems analysis"",""Project delivery practices and standards"",""5-7 years of business analysis experience""],""nice_to_have"":[""Azure certification"",""Basic Python knowledge"",""Data profiling experience"",""SQL Server experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach data mapping and validation in a large-scale data integration project?"",""example_answer"":""I would start by identifying the data sources and their formats, then create a mapping plan to ensure accurate data transfer. I would also validate the data at each stage to ensure data quality.""},{""question"":""How do you stay up-to-date with changing regulatory requirements and their impact on business systems?"",""example_answer"":""I regularly review regulatory updates and industry conferences to stay current. I also network with peers and attend training sessions to stay informed.""}],""red_flags"":[""Lack of experience with data-centric projects"",""Inability to work independently as a senior or lead business analyst"",""Limited knowledge of capital markets products and regulatory reporting""],""confidence_score"":90.0}"
Data Analyst (Python),Selby Jennings,"Montreal, Quebec, Canada",June,2024,"About: Selby Jennings has partnered with a leading Global trading firm to bring on a Data Analyst to support the Event Analysis and Insights team and work on the analysis of post event data, reports and providing insight.

Qualifications:
3+ YOE of relevant professional experience in data analysis
Exceptional attention to detail and data gathering skills
Bachelor’s degree in a related field - Economics, Finance, Information Technology, or Computer Science
Strong knowledge of Python for data manipulation and visualization

Responsibilities:
Analyze non-financial post event data in order to gain insight and discover potential issues.
Create reports and visualizations to help bring forward relevant information to the stake holders.
Collaborate with the development team to improve and create the necessary analysis tools.
Creating issue tickets and following up with the appropriate teams.
Participate in the research effort revolving around the trade strategies.
Develop necessary scripts for data gathering and manipulation.

This is a full-time, Direct hire opportunity-- No C2C!","{""role_summary"":""Support the Event Analysis and Insights team by analyzing post-event data, creating reports and visualizations, and improving analysis tools."",""key_terms"":[{""term"":""Post-event data"",""explanation"":""Data collected after an event, used to gain insights and identify potential issues.""},{""term"":""Data manipulation"",""explanation"":""The process of transforming and preparing data for analysis, often using programming languages like Python.""}],""skill_priorities"":{""must_have"":[""Python"",""Data analysis"",""Attention to detail"",""Data gathering skills""],""nice_to_have"":[""Economics"",""Finance"",""Information Technology"",""Computer Science""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for analyzing post-event data to identify potential issues?"",""example_answer"":""I would start by cleaning and preparing the data, then use visualization tools to identify trends and patterns. Finally, I would create reports and present my findings to stakeholders.""},{""question"":""How do you stay organized when working on multiple projects simultaneously, such as creating issue tickets and following up with teams?"",""example_answer"":""I prioritize my tasks based on urgency and deadlines, and use project management tools to keep track of my progress and deadlines.""}],""red_flags"":[""Lack of experience with Python"",""Inability to work collaboratively with development teams""],""confidence_score"":85.0}"
Data Analyst specialist,Tata Consultancy Services,"Toronto, Ontario, Canada",June,2024,"About TCS
TCS operates on a global scale, with a diverse talent base of more than 600,000 associates representing 153 nationalities across 55 countries. TCS has been recognized as a Global Top Employer by the Top Employers Institute - one of only eight companies worldwide to have achieved this status. Our organizational structure is domain-led and designed to offer businesses a single window into industry-specific solutions. Our agile industry units have embedded capabilities to enable rapid responses that provide a competitive edge to our customers. This, coupled with a unique Global Network Delivery Model™ (GNDM™), is recognized as the current benchmark of excellence in technology deployment. We have made significant investments in digital technology, horizontal, and vertical platforms, allowing us to successfully serve our clients for over 50 years.
Required Skills and Responsibilities:
•Data cleaning and preparation
•Filtering the historical data, handling different values and preparing data set for analysis
•Data exploration - Use statistical tools and techniques to explore and analyze data, identify patterns, relationships and trends.
•Data Visualization -- create visual representation of data using graphs and charts.
•Reporting - prepare reports and presentations to communicate insights and findings.
•Collaboration with business and technology
•Technical skills Microsoft Excel Power BISQL, Python
•Critical thinking, communication, team skills
Tata Consultancy Services Canada Inc. is committed to meeting the accessibility needs of all individuals in accordance with the Accessibility for Ontarians with Disabilities Act (AODA) and the Ontario Human Rights Code (OHRC). Should you require accommodations during the recruitment and selection process, please inform Human Resource
Thank you for your interest in TCS. Candidates that meet the qualification for this position will be contacted within a 2-week period. We invite you to continue to apply for other opportunities that match your profile.","{""role_summary"":""This role is responsible for data analysis, including data cleaning, exploration, and reporting. The analyst will work with business and technology teams to identify trends and insights, and communicate findings effectively."",""key_terms"":[{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that allows users to visualize and analyze data.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and analyzing data in relational database management systems.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to help understand and communicate insights.""}],""skill_priorities"":{""must_have"":[""Microsoft Excel"",""Power BI"",""SQL"",""Python"",""Critical thinking"",""Communication"",""Team skills""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to clean and prepare a large dataset for analysis?"",""example_answer"":""In my previous role, I had to work with a dataset of over 10,000 rows. I used formulas and pivot tables to clean and prepare the data for analysis.""},{""question"":""How do you ensure that your data visualizations are effective in communicating insights?"",""example_answer"":""I use a combination of charts and graphs to visualize different aspects of the data. I also make sure to label the axes and provide a clear title to ensure that the visualization is easy to interpret.""}],""red_flags"":[""Lack of experience with data visualization tools"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Senior Data Analyst,LatentView Analytics,"Toronto, Ontario, Canada",June,2024,"Looking for Experience in B2B Digital Analytics.

Job Responsibilities:
Partner with analytics teams of leading digital businesses, to design & deliver high-impact analytics solutions to a variety of business problems spanning product, marketing and customer insights
Structure and analyze major business and customer questions through a hypothesis-driven approach
Translate business objectives into actionable analysis and own end-to-end analytics, and effectively communicate complex analytics to a broader audience in writing and presentation formats
Create insightful automated dashboards and data visualizations to track key business metrics
Be an effective execution as well as thought partner to clients, being equally comfortable in taking a 30,000-ft view of business problems as well as get involved in the minutiae of data wrangling and analysis

Mandatory Skills and Qualifications:
3-8 years’ experience in core analytics
Strong hands-on SQL, Forecasting, Data Science/Machine Learning
Good amount of B2B Experience
Stakeholder Management Experience
Experience in R/Python, scripting & automation, visualization tools like Tableau a plus.
Strong communication skills, written and verbal; ability to present data and its implications in a clear, concise manner.
Strong research and analytical mindset and extremely detail-oriented
Self-motivated, energetic, ""can-do"" attitude in a fast-paced environment
Ability to manage priorities across multiple stakeholders

At LatentView Analytics, we value a diverse, inclusive workforce and we provide equal employment opportunities for all applicants and employees. All qualified applicants for employment will be considered without regard to an individual’s race, color, sex, gender identity, gender expression, religion, age, national origin or ancestry, citizenship, physical or mental disability, medical condition, family care status, marital status, domestic partner status, sexual orientation, genetic information, military or veteran status, or any other basis protected by federal, state or local laws.","{""role_summary"":""Partner with analytics teams to design and deliver high-impact analytics solutions to business problems, and communicate complex analytics to a broader audience."",""key_terms"":[{""term"":""Hypothesis-driven approach"",""explanation"":""A method of structuring and analyzing business and customer questions by forming educated guesses and testing them.""},{""term"":""Data wrangling"",""explanation"":""The process of cleaning, transforming, and preparing data for analysis.""},{""term"":""Data visualization"",""explanation"":""The process of creating graphical representations of data to communicate insights and trends.""}],""skill_priorities"":{""must_have"":[""3-8 years of experience in core analytics"",""Strong hands-on SQL"",""Strong communication skills"",""Strong research and analytical mindset"",""Self-motivated, energetic, 'can-do' attitude""],""nice_to_have"":[""Experience in R/Python, scripting & automation"",""Experience with visualization tools like Tableau"",""Stakeholder Management Experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process of structuring and analyzing complex business and customer questions?"",""example_answer"":""I use a hypothesis-driven approach, where I form educated guesses and test them to identify key insights.""},{""question"":""How do you communicate complex analytics to a broader audience?"",""example_answer"":""I use clear and concise language, and create insightful automated dashboards and data visualizations to track key business metrics.""}],""red_flags"":[""Lack of experience in B2B digital analytics"",""Inability to communicate complex analytics to a broader audience""],""confidence_score"":90.0}"
"Analyst, Data Analytics",CPKC,"Calgary, Alberta, Canada",June,2024,"Canadian Pacific (CP) and Kansas City Southern (KCS) are now CPKC. As the only truly North American railway, we are making big moves! Drawing on our strong foundations and heritage, CPKC moves essential goods across our 20,000-mile network to support economic growth throughout Canada, the U.S. and Mexico. Be a part of history as we connect a continent and create exciting career opportunities across our new transnational network. Visit cpkcr.com to learn about the CPKC advantage, our purpose and culture

PURPOSE OF THE POSITION:

The Analyst, Data Analytics (internally called Specialist, Data Analytics) is responsible for delivering Internal Audit’s data analytics roadmap and supporting completion of the annual audit plans. The successful candidate will work closely with the Internal Audit team and stakeholders across the organization to provide analytics insight on multiple audit engagements and build-out our continuous assurance program. This role will report to the Director, IS Internal Audit and does not have any direct reports.

POSITION ACCOUNTABILITIES:

The successful candidate will perform the following activities
Creatively work with multiple tools to manage and analyze large volumes of data from multiple sources
Work with IA leadership to consistently advance our continuous assurance program
Provide analytics support during planning, execution and reporting phases of audit engagements
Take leadership on audit engagements with a significant data component
Support the development and maintenance of IA’s risk monitoring dashboards
Offer coaching to progressively improve data literacy of the broader audit team
Maintain and develop competencies in advanced analytics, process automation and artificial intelligence
Maintain objectivity and independence while fostering positive and professional relationships with Management
Maintain skills and knowledge through education, training, internal and external partners, colleagues and information sources
Promote innovation within Internal Audit and provide leadership on the use of AI, Machine Learning and similar technologies
Develop knowledge of the railroad and industry/CPKC specific processes and technologies.
Support IA software in the “Super User"" capacity

POSITION REQUIREMENTS:

University degree in Business, Data Science, Computer Science or related field
2+ years of data analytics experience. Audit and/or risk management related experience would be considered as a significant additional asset.
Solid understanding of a combination of ETL and data visualization
Established analytical, investigative, problem-solving and root cause identification skills
Excellent verbal and written communication capabilities with technical and non-technical audiences
Must be both team oriented and able to work independently with limited supervision
Desire to drive change and innovation

WHAT CPKC HAS TO OFFER:

Flexible and competitive benefits package
Competitive company pension and/or retirement plans
Employee Share Purchase Plan
Performance Incentive Program
Annual Fitness Subsidy
Part-time Studies Program

ADDITIONAL INFORMATION:

As an employer with North American presence, the possibility does exist that the location of your position may be changed based on organizational requirements. (Canada and US all Non-Union positions only)

Drug Test Elements:

CPKC is committed to the safety and health of its employees and the general public. New hires may be required to undergo a drug screen. We appreciate your cooperation in keeping CPKC safe and drug free.

Background Investigation:

The successful candidate will need to successfully complete the following clearances:

Criminal history check
Reference check
Background checks that may included 7 years of employment history and Social Security number verification

Management Conductor Program:

Becoming a qualified conductor or locomotive engineer is the single best way for a management employee to learn the business at CPKC. You may be required to obtain a certification or to maintain your current certification/qualification as a conductor or locomotive engineer.

For our US applicants, CPKC is an equal opportunity/affirmative action employer, inclusive of protected veterans and individuals with disabilities. For Canadian applicants CPKC is an employment equity employer committed to the principles of employment equity and inclusion. We encourage all qualified candidates to apply including women, Black, Indigenous, People of Colour (BIPOC), members of the LGBTQ+ community, and people with disabilities. Accommodations for the job application process can be provided, as appropriate, upon request. All applicant information will be managed in accordance with the federal Personal Information Protection and Electronic Documents Act (PIPEDA).

Req ID: 103037
Department: Finance & Accounting
Job Type: Full-Time
Position Type: Non-Union
Location: Calgary, Alberta
Country: Canada
% of Travel: None
# of Positions: 1
Job Grade: 4
Job Available to: Internal & External","{""role_summary"":""The Analyst, Data Analytics is responsible for delivering Internal Audit's data analytics roadmap, supporting audit plans, and providing analytics insights to stakeholders across the organization."",""key_terms"":[{""term"":""Data Analytics"",""explanation"":""The process of extracting insights from data to support business decisions.""},{""term"":""Continuous Assurance"",""explanation"":""A program that provides ongoing monitoring and assessment of an organization's internal controls and risk management processes.""},{""term"":""ETL (Extract, Transform, Load)"",""explanation"":""A process used to extract data from multiple sources, transform it into a standardized format, and load it into a target system for analysis.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to facilitate understanding and insights.""},{""term"":""AI, Machine Learning"",""explanation"":""Technologies used to develop predictive models and automate processes.""}],""skill_priorities"":{""must_have"":[""University degree in Business, Data Science, Computer Science or related field"",""2+ years of data analytics experience"",""Solid understanding of ETL and data visualization"",""Established analytical, investigative, problem-solving and root cause identification skills"",""Excellent verbal and written communication capabilities""],""nice_to_have"":[""and/or risk management related experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing large volumes of data from multiple sources?"",""example_answer"":""I would use a combination of ETL tools and data visualization techniques to extract insights from the data.""},{""question"":""How do you stay current with advancements in data analytics?"",""example_answer"":""I participate in training and education programs, attend industry conferences, and network with peers to stay current.""}],""red_flags"":[""Lack of experience in data analytics"",""Inability to work independently with limited supervision""],""confidence_score"":90.0}"
Data Analyst (SAS),Brooksource,"Toronto, Ontario, Canada",June,2024,"Data Analyst (SAS)
Location: Toronto, Canada - Hybrid 1x/week
Contract: 1 year Contract (+extension)

One of our Fortune 500 clients in the Banking Industry is looking for a SAS Developer/SQL Analyst to join their team.

Data Analytics & Reporting
Understands and articulates the business case of business questions and the estimated value being delivered. Designs dashboards and analyzes to be performed, and appropriate visualization and analytics tools to use. Identifies trends and patterns to address identified business questions and provide insights through reporting and data visualization techniques. Works with other data and analytics professionals to optimize, refine, automate and scale analysis into repeatable analytics solutions and decision support tools.

Builds various reporting dashboards using the most appropriate data extraction, data cleaning and data visualization techniques.
Provides value through insights, reporting and data visualization techniques. Selects, configures and implements analytics solutions for consistency and repeatability.
Researches and applies continuous improvement in data visualization by identifying trends and patterns to transform raw data into actionable business insights.
Works with different teams, management and stakeholders to enhance the usability and aesthetic appeal of data analytics solutions deployed in the organization.
Translates business needs to technical specifications and evaluates existing data visualization systems in order to improve them.
Develops data visualizations of ""large"" amounts of data that facilitate the intuitive presentation of data to decision makers.
Documents data flow, systems and processes to improve the design, implementation and management of business/group processes.
Develops tools and delivers training programs for use of reporting tools and self-serve analytics by non-analytical end users; may include delivery of training to audiences.
Focus is primarily on business/group within BMO; may have broader, enterprise-wide focus.
Exercises judgment to identify, diagnose, and solve problems within given rules.
Works independently on a range of complex tasks, which may include unique situations.
Broader work or accountabilities may be assigned as needed.

Qualifications:
Key Skills:
SQL Queries to pull and combine data – There will be a test.
SAS Queries to pull and transform data.
SSRS/Visual studio/Power BI experience for report building.
Foundational level of proficiency:
Technical design optimization.
Decision Making.
Systems Thinking.
Data visualization.
Data storytelling.
Data mining.
Illustration.
Creative thinking.
Problem Solving.
Intermediate level of proficiency:
Insights design.
Insights development and reporting.
Verbal & written communication skills.
Collaboration & team skills.
Technical proficiency gained through education and/or business experience.

ABOUT EIGHT ELEVEN:
At Eight Eleven, our business is people. Relationships are at the center of what we do. A successful partnership is only as strong as the relationship built. We’re your trusted partner for IT hiring, recruiting and staffing needs.
For over 16 years, Eight Eleven has established and maintained relationships that are designed to meet your IT staffing needs. Whether it’s contract, contract-to-hire, or permanent placement work, we customize our search based upon your company's unique initiatives, culture and technologies. With our national team of recruiters placed at 21 major hubs around the nation, Eight Eleven finds the people best-suited for your business. When you work with us, we work with you. That’s the Eight Eleven promise.

Eight Eleven Group provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, national origin, age, sex, citizenship, disability, genetic information, gender, sexual orientation, gender identity, marital status, amnesty or status as a covered veteran in accordance with applicable federal, state, and local laws.","{""role_summary"":""A Data Analyst (SAS) responsible for designing dashboards, analyzing data, and providing insights through reporting and data visualization techniques to address business questions."",""key_terms"":[{""term"":""SAS Developer/SQL Analyst"",""explanation"":""A professional who develops and analyzes data using SAS and SQL languages.""},{""term"":""Data Visualization"",""explanation"":""The process of presenting data in a graphical or visual format to facilitate understanding and decision-making.""},{""term"":""SSRS/Visual Studio/Power BI"",""explanation"":""Software tools used for building reports and dashboards.""}],""skill_priorities"":{""must_have"":[""SQL Queries"",""SAS Queries"",""SSRS/Visual Studio/Power BI experience"",""Technical design optimization"",""Decision Making"",""Systems Thinking"",""Data visualization"",""Data storytelling"",""Data mining"",""Illustration"",""Creative thinking"",""Problem Solving""],""nice_to_have"":[""Insights design"",""Insights development and reporting"",""Verbal & written communication skills"",""Collaboration & team skills""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach a complex data analysis task?"",""example_answer"":""I would first identify the business question, then design a dashboard and select appropriate visualization tools. Next, I would analyze trends and patterns, and finally, provide insights through reporting and data visualization techniques.""},{""question"":""How do you stay current with new tools and technologies in data visualization?"",""example_answer"":""I regularly research and apply continuous improvement in data visualization by identifying trends and patterns to transform raw data into actionable business insights.""}],""red_flags"":[""Lack of experience with SAS or SQL"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
BI Analyst,Fusemachines,"Toronto, Ontario, Canada",June,2024,"About Fusemachines

Fusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 400 full-time employees). Fusemachines seeks to bring its global expertise in AI to transform companies around the world.

About The Role

As a Business Intelligence Engineer, you will play a pivotal role in leveraging data to drive strategic decisions and enhance operational efficiency. You will be responsible for designing, developing, and maintaining PowerBI dashboards and reports that provide valuable insights to various stakeholders across the organization. Your work will directly contribute to optimizing business processes and improving customer experiences.

This is a remote role on a contract basis.

Qualification & Experience

Bachelor's or master's degree in a quantitative field such as statistics, mathematics, or computer science
At least 4 years of experience in data analytics, with a focus on business intelligence and data visualization

Required Skills/Competencies

Proven experience as a PowerBI Developer or similar role, with a strong portfolio showcasing impactful dashboards and reports
Proficiency in SQL for data extraction, transformation, and manipulation
Solid understanding of data modeling concepts and experience in designing efficient data models
Strong analytical and problem-solving skills, with the ability to translate business requirements into technical solutions
Excellent communication and collaboration skills, with the ability to work effectively in cross-functional teams
Experience with other BI tools (e.g., Tableau) is a plus

Roles and Responsibilities

Collaborate with cross-functional teams to understand business requirements and translate them into actionable insights using SQL and PowerBI
Develop visually appealing and interactive dashboards and reports to effectively communicate key performance indicators (KPIs), trends, and anomalies
Optimize data models and queries to ensure efficient performance and scalability of PowerBI solutions
Implement best practices for data visualization, ensuring clarity, consistency, and usability for end users
Work closely with data engineers to integrate data from various sources and maintain data accuracy and integrity
Provide training and support to end users to maximize adoption and utilization of PowerBI tools
Stay updated on industry trends and advancements in data visualization and analytics technologies, recommending improvements and innovations as appropriate
Collaborate with IT teams to ensure compliance with data security and governance policies

Fusemachines is an Equal Opportunities Employer, committed to diversity and inclusion. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or any other characteristic protected by applicable federal, state, or local laws.

Powered by JazzHR

2Nx0znfcUN","{""role_summary"":""As a Business Intelligence Engineer, you will leverage data to drive strategic decisions, enhance operational efficiency, and optimize business processes."",""key_terms"":[{""term"":""PowerBI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""},{""term"":""Data Modeling"",""explanation"":""The process of creating a conceptual representation of data structures to store and manage data efficiently.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and manipulating data in relational database management systems.""}],""skill_priorities"":{""must_have"":[""PowerBI development experience"",""SQL proficiency"",""Data modeling understanding"",""Analytical and problem-solving skills"",""Communication and collaboration skills""],""nice_to_have"":[""Experience with other BI tools (e.g., Tableau)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize data models and queries for efficient performance and scalability in PowerBI?"",""example_answer"":""I would analyze the data requirements, identify bottlenecks, and apply best practices for data modeling and query optimization to ensure efficient performance and scalability.""},{""question"":""How do you ensure data accuracy and integrity when integrating data from various sources in PowerBI?"",""example_answer"":""I work closely with data engineers to ensure data accuracy and integrity by implementing data validation, data quality checks, and data governance policies.""}],""red_flags"":[""Lack of experience with PowerBI development and SQL proficiency"",""Inability to communicate technical solutions to non-technical stakeholders""],""confidence_score"":90.0}"
Marketing Data Analyst,Insight Global,"Mississauga, Ontario, Canada",June,2024,"Must-haves
- Experience building reports from data in Adobe Analytics technologies
- Knowledge of Adobe back-end segments to identify data discrepancies and flag any issues (ie. Duplicate data)
- Strong Experience with Python
- Hands-on experience writing complex SQL queries and a strong understanding of data quality and complexity – Most important
- Hands-on experience using visualization tools such as Tableau, PowerBI, or Looker to develop reports for various business stakeholders
- Experience using analytics tools to transform data-driven results into actional insights through storytelling

Plusses
- Hands-on experience using BigQuery
- Experience working within eCommerce and knowledge of pre and post-sale data structures
- Previous exposure to a loyalty program
- Ability to make recommendations and next steps based on the data

Day-to-Day
Insight Global is looking for a Marketing Analyst to join the team with one of our largest retail clients in the Greater Toronto Area on a 12-month contract. The selected candidate will be responsible for the following:

- Maintain the accuracy of weekly automated dashboards for the Digital Marketing team. Ensure any supporting documents such as marketing spend tracker and marketing KPI plans are updated and accurate for dashboard automation. Execute and coordinate new automation requests or changes with the automation team.
- Using analytic tools, transform data-driven results into actionable insights through storytelling. Consolidate data into easy-to-understand reports for presentation.
- Highlight and explain discrepancies in data and correct as required.
- Monthly report of data validation/governance
- Support with data pulls related to weekly performance dashboards, campaign performance, voucher activities, or test-and-learn initiatives.
- Ability to complete work functions using Adobe Analytics, Google Analytics, Big Query, SQL, MS Excel, and PowerPoint.","{""role_summary"":""The Marketing Analyst is responsible for maintaining accurate weekly automated dashboards, transforming data-driven results into actionable insights, and ensuring data quality and governance."",""key_terms"":[{""term"":""Adobe Analytics"",""explanation"":""A tool for tracking and analyzing website and mobile app data.""},{""term"":""Back-end segments"",""explanation"":""A feature in Adobe Analytics that helps identify data discrepancies.""},{""term"":""Data quality"",""explanation"":""The process of ensuring data is reliable, accurate, and complete.""},{""term"":""Data visualization"",""explanation"":""The process of presenting complex data in a clear and understandable format.""},{""term"":""BigQuery"",""explanation"":""A cloud-based data warehousing and analytics platform.""}],""skill_priorities"":{""must_have"":[""Experience with Adobe Analytics"",""Knowledge of back-end segments"",""Strong Python skills"",""Hands-on experience with SQL"",""Experience with data visualization tools"",""Ability to transform data into actionable insights""],""nice_to_have"":[""Hands-on experience with BigQuery"",""Knowledge of eCommerce data structures"",""Previous exposure to loyalty programs""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would identify and correct data discrepancies in Adobe Analytics?"",""example_answer"":""I would use Adobe Analytics' back-end segments to identify data discrepancies, and then correct them by updating the data sources and re-processing the data.""},{""question"":""How do you ensure data quality and complexity?"",""example_answer"":""I ensure data quality by validating data against business rules, and complexity by breaking it down into smaller, manageable parts.""}],""red_flags"":[""Lack of experience with Adobe Analytics"",""Inability to write complex SQL queries"",""Limited experience with data storytelling""],""confidence_score"":90.0}"
Data Analyst II,Techedin,Canada,June,2024,"We are looking for a Data Analyst II / Data Engineer in Canada. The position's description is given below. The role provides 100% remote flexibility on a full-time (permanent)/T4 hourly basis; however, candidates must be located in Canada.

Must have skills: Python, SQL, Looker

Minimum Qualifications

Bachelor’s degree or higher in a quantitative field
At least 3 years of experience in a data analysis role
3+ years of experience in Python, SQL, and visualization tools like Looker.
A proven track record of decision-making and problem-solving based on analytics.

Conceptual thinking skills must be complemented by a strong quantitative orientation.

Strong business judgment, leadership, and integrity. You should be a tenacious decision-maker, able to bring a healthy, aggressive, yet responsible approach to business.
Excellent written and oral communication skills, coupled with strategic influencing skills and the ability to drive agreement through intellect, interpersonal skills, and negotiation.
self-starter and adaptable. You’re energized and thrive in a fast-paced environment.
Skilled in using data mining techniques, including supervised and unsupervised learning.
Experienced in analysing and debugging data with Spark/PySpark
Solid understanding of databases and proficiency in writing SQL in systems like Hive, Snowflake, and Presto.
Strong skills in BI tools, Looker, and Excel.

Techedin is a global IT Services company complementing the efforts of technology-driven enterprises in developing cutting-edge solutions for humans. We offer services in enterprise app development, content management solutions (CMS), customer relationship management (CRM), cloud engineering, custom software development, and data engineering. Our services include IT Consulting, project management, Software Quality Assurance, and data and analytics services. We develop and maintain various software applications and all other computer-related ancillary services. We have excellent professionals working round the clock to build the best technology teams and products for our customers.","{""role_summary"":""A Data Analyst II / Data Engineer responsible for analyzing and interpreting complex data to drive business decisions, SQL, and visualization tools like Looker."",""key_terms"":[{""term"":""Looker"",""explanation"":""A business intelligence and analytics platform used for data visualization and reporting.""},{""term"":""Spark/PySpark"",""explanation"":""An open-source data processing engine used for large-scale data processing and analytics.""},{""term"":""Hive"",""explanation"":""A data warehousing and SQL-like query language used for managing and analyzing large datasets.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform used for storing and analyzing large datasets.""},{""term"":""Presto"",""explanation"":""An open-source distributed SQL engine used for fast data analytics and querying.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Looker""],""nice_to_have"":[""Data mining techniques"",""Spark/PySpark"",""BI tools"",""Excel""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach data analysis for a complex business problem?"",""example_answer"":""I would start by identifying the key stakeholders and their requirements, then gather and analyze relevant data using tools like Looker and SQL. Finally, I would present my findings and recommendations to the stakeholders.""},{""question"":""How do you stay up-to-date with new tools and technologies in data engineering?"",""example_answer"":""I regularly follow industry blogs and attend webinars to stay current with the latest developments in data engineering.""}],""red_flags"":[""Lack of experience with cloud-based data warehousing platforms like Snowflake or Presto."",""Inability to effectively communicate technical results to non-technical stakeholders.""],""confidence_score"":90.0}"
Tableau BI Data Analyst,Paymentus,"Greater Toronto Area, Canada",June,2024,"Summary
Paymentus leads the North American marketplace in electronic bill payment solutions and is looking for high performers to join our team, building SaaS Fintech solutions across a range of industries. You will contribute to a massively scalable data platform, that is built on top of a world-class enterprise platform, supporting thousands of clients and into the millions of transactions daily. Paymentus' success and rapid growth provides employees with opportunities for career advancement.

Objective
The Tableau BI Data Analyst will assist in growing our reporting and BI infrastructure. The ideal candidate is excited by learning new things, has a passion for applying innovative technology, has excellent problem-solving and communication skills, and also has significant experience within Tableau design and development.

Essential Functions & Responsibilities
Advanced hands-on design, development, and publishing of Tableau dashboards using Tableau Desktop and Tableau Server; experience in data modelling and visualization techniques
Be proficient in building aesthetically pleasing dashboards
Gather and document user requirements for new reports and dashboards
Assist stakeholders with data-related technical issues and support data infrastructure needs
Monitor the performance of reports and dashboards and take corrective action to optimize and improve dashboard performance as necessary
Work with data and analytics experts to achieve greater functionality in our data systems
Build DBT models to feed data to reporting structures

Education & Experience
A bachelor's degree in Software Engineering, Computer Science, or a related technical degree
Experience with cloud-based data warehousing, transformation, and ETL tools, such as Snowflake and DBT
Understanding of time series and relational databases (Oracle, Snowflake, InfluxDB)
High proficiency in SQL
Experience with ETL processes (bonus points for DBT experience)
Experience as a successful problem solver and communicator

Preferred but not Required
Software development and source code management (Git, etc.)
Knowledge of at least one programming language like Java or Python is plus

Supervisory Responsibility
This position does not have any supervisory responsibility or direct reports.

Work Environment
This job operates in a professional office environment. This role routinely uses standard office equipment such as laptop computers, photocopiers and smartphones.

Physical Demands
The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.

Specific vision abilities required by this job include close vision and ability to adjust focus. Prolonged periods sitting at a desk and working on a computer. Must be able to lift up to 15 pounds at times.

Position Type/Expected Hours of Work
This is a full-time position. Days and hours of work are Monday through Friday, during normal business hours. Occasional evening and weekend work may be required as job duties demand.

Travel
Little to no travel is expected for this position.

Other Duties
Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.

EEO Statement
Paymentus is an equal opportunity employer. We enthusiastically accept our responsibility to make employment decisions without regard to actual or perceived race, creed, color, age, sex or gender (including pregnancy, childbirth and related medical conditions), gender identity or gender expression (including transgender status), sexual orientation, national origin, ancestry, citizenship status, religion, marital status, physical or mental disability, military service or veteran status, genetic information, protected medical condition as defined by applicable state or local law, genetic information, or any other classification protected by applicable federal, state, and local laws and ordinances. Our management is dedicated to ensuring the fulfillment of this policy with respect to hiring, placement, promotion, transfer, demotion, layoff, termination, recruitment advertising, pay, and other forms of compensation, training, access to facilities and programs and general treatment during employment.

Reasonable Accommodation
Paymentus recognizes and supports its obligation to endeavor to accommodate job applicants and employees with known physical or mental disabilities who are able to perform the essential functions of the position, with or without reasonable accommodation. Paymentus will endeavor to provide reasonable accommodations to otherwise qualified job applicants and employees with known physical or mental disabilities, unless doing so would impose an undue hardship on the Company or pose a direct threat of substantial harm to the employee or others.

An applicant or employee who believes he or she needs a reasonable accommodation of a disability should discuss the need for possible accommodation with the Human Resources Department, or his or her direct supervisor.","{""role_summary"":""The Tableau BI Data Analyst role contributes to the growth of reporting and BI infrastructure, designing and developing Tableau dashboards, and supporting data infrastructure needs."",""key_terms"":[{""term"":""Tableau"",""explanation"":""A data visualization tool used to create interactive dashboards.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from sources, transforming it into a usable format, and loading it into a target system.""},{""term"":""DBT"",""explanation"":""A tool used for data transformation and loading into reporting structures.""},{""term"":""Cloud-based data warehousing"",""explanation"":""A cloud-based storage solution for large amounts of data, used for reporting and analytics.""}],""skill_priorities"":{""must_have"":[""Tableau design and development"",""Data modeling and visualization"",""SQL proficiency"",""ETL experience"",""Cloud-based data warehousing experience""],""nice_to_have"":[""Software development and source code management (Git)"",""Programming language like Java or Python""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a complex data visualization you created in Tableau and how you approached the design?"",""example_answer"":""I created a dashboard to track customer behavior, using a combination of bar charts and scatter plots to show correlations. I used Tableau's data modeling features to create a clear and concise visualization.""},{""question"":""How do you approach data quality and data governance in your work?"",""example_answer"":""I ensure data accuracy by implementing data validation rules and performing regular data quality checks. I also work closely with stakeholders to ensure data meets business requirements.""}],""red_flags"":[""Lack of experience with cloud-based data warehousing"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
"ICQA Data Analyst - Bolton, ON, YYZ7",Amazon,"Bolton, Ontario, Canada",June,2024,"Description

At Amazon, we're working to be the most customer-centric company on earth. To get there, we need exceptionally talented, bright, and driven people. If you'd like to help us build the place to find and buy anything online, this is your chance to make history. Amazon Canada Fulfillment Services is hiring a Data Analyst to support the Inventory Control / Quality Assurance (ICQA) team. The Data Analyst assigned to ICQA will work closely with the ICQA and operations teams in Inbound and Outbound to provide data and analytical support for ACES initiatives, root cause investigation of defects, and will provide support to ensure compliance to ICQA-related SoX requirements. The Data Analyst will own the insights, set up analysis, and create automated dashboards and reporting. They will be responsible for identifying data sources (internal / external) to invent and simplify mechanisms and create custom reporting and analytics automation tools. Operating in a fast-moving and sometimes ambiguous environment, you will be required to work autonomously, taking full control and responsibility for achieving business objectives. This role provides real opportunity to develop original ideas, approaches and solutions in an ever-changing and competitive business climate.

Key job responsibilities

Development of data collection processes and data management systems
Maintenance of data integrity (0% error rate)
Designing of queries, compiling of data, and generation of reports in MS Excel
Charting and graphing of data for reporting purposes
In depth research of defect trends
Data collection and entry as needed
Data mining and problem solving
Back up for Process Assistant duties

Basic Qualifications

2+ years of professional or military experience
Experience with Microsoft Office products and applications

Preferred Qualifications

Experience with end-to-end project management

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, disability, age, or other legally protected status. If you would like to request an accommodation, please notify your Recruiter.


Company - Amazon Canada Fulfillment Services, ULC.

Job ID: A2684542","{""role_summary"":""Support the Inventory Control/Quality Assurance team by providing data analysis and insights to drive business objectives, ensuring data integrity and compliance with regulatory requirements."",""key_terms"":[{""term"":""Inventory Control/Quality Assurance (ICQA)"",""explanation"":""A team responsible for ensuring the quality and accuracy of inventory management processes.""},{""term"":""SoX requirements"",""explanation"":""Sarbanes-Oxley Act requirements, which are regulatory standards for financial reporting and disclosure of publicly traded companies.""},{""term"":""ACES initiatives"",""explanation"":""Amazon Customer Excellence System initiatives, aimed at improving customer satisfaction and loyalty.""}],""skill_priorities"":{""must_have"":[""Microsoft Office products and applications"",""Data analysis and reporting skills"",""Data management and integrity skills""],""nice_to_have"":[""End-to-end project management experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for identifying and addressing data discrepancies in a large dataset?"",""example_answer"":""I would first identify the source of the discrepancy, then use data visualization tools to understand the impact of the error. Next, I would work with stakeholders to develop a plan to correct the issue and implement a process to prevent it from happening again in the future.""},{""question"":""How do you stay organized and manage competing priorities in a fast-paced environment?"",""example_answer"":""I prioritize tasks based on business objectives and deadlines, using project management tools to track progress and communicate with stakeholders. I also maintain a clean and organized workspace, both physically and digitally, to ensure easy access to information.""}],""red_flags"":[""Lack of experience with data analysis and reporting tools"",""Inability to work autonomously in a fast-paced environment""],""confidence_score"":85.0}"
Junior Data BI Analyst,Patterned Learning Career,"Calgary, Alberta, Canada",July,2024,"This is a remote position.

Junior Data BI Analyst - Remote Job, 1+ Year Experience

Annual Income: $55K - $65K

A valid work permit is necessary in Canada

About us: Patterned Learning is a platform that aims to help developers code faster and more efficiently. It offers features such as collaborative coding, real-time multiplayer editing, and the ability to build, test, and deploy directly from the browser. The platform also provides tightly integrated code generation, editing, and output capabilities.

Are you a talented BI Analyst with a passion for data analysis and a strong background in business intelligence? We are seeking a skilled and motivated individual to join our team as a BI Analyst. As a BI Analyst, you will be responsible for analyzing complex data sets, generating insights, and providing actionable recommendations to drive business growth and efficiency.

Responsibilities:

Analyze large datasets to identify trends, patterns, and insights.
Develop and maintain data models, dashboards, and reports to support business decision-making.
Collaborate with cross-functional teams to understand business requirements and translate them into data-driven solutions.
Conduct ad-hoc analysis to answer specific business questions and provide actionable recommendations.
Stay up-to-date with industry trends and best practices in data analysis and business intelligence.

Requirements:

Bachelor's Degree required with an emphasis in business, economics, math, engineering, or analytics preferred. Advanced degree or certification preferred.
1+ years of experience, with at least 1 year of analytic experience.
Proficiency in interacting with various database and file storage systems (Examples: Oracle, Hadoop, NoSQL). Understanding of join types.
Experience with data manipulation languages, such as SQL, is required.
Knowledge of statistical concepts and analytic techniques, including descriptive statistics, forecasting, economic modeling, exploratory analysis, and variance analysis is required.
Ability to perform uni-variate analytic analytical techniques.
Experience using Microsoft Excel, including the use of pivot tables, formulas, macros, VBA, and charts/graphs.
Experience with visualization tools such as Tableau, PowerBi, or QlikView.
Strong analytical, critical, and systems thinking is required.

Skills:

Good understanding of Agile framework (SCRUM).
Familiarity with Salesforce is a plus.

Benefits:

Competitive salary based on skills, qualifications, and experience 1.
Comprehensive health, dental, and vision insurance plans.
Retirement program with lifetime pension benefits.
Paid time off and holidays.
Flexible work schedule and remote work options.
Opportunities for professional development and growth.
Collaborative and inclusive work environment.

Why Patterned Learning LLC?

Patterned Learning can provide intelligent suggestions, automate repetitive tasks, and assist developers in writing code more effectively. This can help reduce coding errors, improve productivity, and accelerate the development process.

Pattern recognition is particularly relevant in the context of coding. Neural networks, especially deep learning models, are commonly employed for pattern detection and classification tasks. These models simulate human decision-making and can identify patterns in data, making them well-suited for tasks like code analysis and generation.","{""role_summary"":""Analyze complex data sets, and provide actionable recommendations to support business decision-making and growth."",""key_terms"":[{""term"":""Business Intelligence"",""explanation"":""The process of analyzing and presenting data to help businesses make better decisions.""},{""term"":""Data Models"",""explanation"":""Conceptual representations of data used to organize and structure data for analysis and reporting.""},{""term"":""Agile Framework (SCRUM)"",""explanation"":""An iterative approach to project management that emphasizes flexibility and teamwork.""},{""term"":""Pattern Recognition"",""explanation"":""The ability of machines to identify patterns in data, used in applications like code analysis and generation.""}],""skill_priorities"":{""must_have"":[""1+ years of analytic experience"",""Proficiency in interacting with various database and file storage systems"",""Experience with data manipulation languages, such as SQL"",""Knowledge of statistical concepts and analytic techniques"",""Ability to perform uni-variate analytic techniques"",""Experience using Microsoft Excel"",""Experience with visualization tools such as Tableau, PowerBi, or QlikView""],""nice_to_have"":[""Advanced degree or certification"",""Familiarity with Salesforce""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing a complex dataset to identify trends and patterns?"",""example_answer"":""I would start by understanding the business requirements and then applying statistical concepts and data visualization tools to identify insights.""},{""question"":""How do you stay up-to-date with industry trends and best practices in data analysis and business intelligence?"",""example_answer"":""I regularly read industry blogs and attend webinars to stay current with the latest developments in data analysis and business intelligence.""}],""red_flags"":[""Lack of experience with data manipulation languages like SQL"",""Inability to perform uni-variate analytic techniques""],""confidence_score"":90.0}"
SQL Developer / Data Analyst,Techedin,Canada,June,2024,"We are looking for a ""SQL Developer / Data Analyst"" in Canada. Please find the detailed job description below. This position provides full-time employment with remote work, though candidates must reside within Canadian borders.

Job Description

Bachelor’s degree or higher in a quantitative field
5+ years of experience in a data analysis role
3+ years of experience in Python, SQL, and visualization tools like Looker/PowerBI
A proven track record of decision-making and problem-solving based on analytics.
Conceptual thinking skills must be complemented by a strong quantitative orientation.
Self-starter and adaptable. You’re energized and thrive in a fast-paced environment.
Solid understanding of databases and proficiency in writing SQL in systems like Hive, Snowflake, and Presto.
Strong skills in BI tools and Excel and Knowledge of PowerBI is a plus.

Techedin is a global IT Services company complementing the efforts of technology-driven enterprises in developing cutting-edge solutions for humans. We offer services in enterprise app development, content management solutions (CMS), customer relationship management (CRM), cloud engineering, custom software development, and data engineering. Our services include IT Consulting, project management, Software Quality Assurance, and data and analytics services. We develop and maintain various software applications and all other computer-related ancillary services. We have excellent professionals working round the clock to build the best technology teams and products for our customers.","{""role_summary"":""A SQL Developer / Data Analyst responsible for making data-driven decisions, and creating visualizations using tools like Looker/PowerBI."",""key_terms"":[{""term"":""Hive"",""explanation"":""A data warehousing and SQL-like query language for Hadoop.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and analyzing data.""},{""term"":""Presto"",""explanation"":""An open-source, distributed SQL query engine for big data analytics.""},{""term"":""Looker"",""explanation"":""A business intelligence and data analytics platform for creating visualizations and reports.""},{""term"":""PowerBI"",""explanation"":""A business analytics service by Microsoft for creating interactive visualizations and business intelligence reports.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Data Analysis"",""Visualization tools"",""Quantitative field degree""],""nice_to_have"":[""PowerBI"",""BI tools"",""Excel""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach data analysis and visualization for decision-making?"",""example_answer"":""I use tools like Looker/PowerBI to create interactive visualizations, and then analyze the data to identify trends and patterns, and finally make data-driven decisions.""},{""question"":""Can you explain a time when you had to troubleshoot a complex SQL query?"",""example_answer"":""I once had to optimize a slow-performing SQL query in Hive by rewriting it to use more efficient joins and indexing, which resulted in a significant performance improvement.""}],""red_flags"":[""Lack of experience with cloud-based data warehousing platforms like Snowflake or Presto."",""Inability to write efficient SQL queries in systems like Hive.""],""confidence_score"":85.0}"
Technical Data Analyst,Carbon6,"Toronto, Ontario, Canada",June,2024,"Who We Are
We go beyond software. Carbon6 is building a community to support ecommerce sellers by removing the barriers to selling online and simplifying their path to success. Developed by the brightest minds in the marketplace ecosystem, our suite of software tools and resources help entrepreneurs succeed at every stage of their journey. We are a global company across North America, Europe and Asia, made up of passionate entrepreneurs, expert sellers, and innovative thought leaders.

Founded in 2021, we have raised close to $100 million and quickly grown into a market leader. We work with the largest and most successful sellers, brands, agencies, and aggregators around the world to drive growth, maximize profitability and manage with intelligence to scale their businesses. In addition to collaborating with global giants such as Amazon, Walmart, Alibaba, and others, we foster partnerships with key industry players like BigCommerce, Teikametrics, Jungle Scout, and more. Through our innovative solutions and strategic alliances, we empower businesses of all sizes to excel in today's competitive landscape, driving success and fostering long-term growth for both our clients and partners.

The Opportunity (Hybrid)

Do you look at spreadsheets and think… why is this clearer? More actionable? Enhanced with meaningful visualizations? Do you stare at rows of data and love looking for and finding patterns? Is there a joy you find when you take an unordered collection of raw information and turn it into something meaningful, and better yet, see others use what you’ve created to make great decisions? If these all ring true to you, then you just might be the Data Analyst that we’re looking for.

Carbon6 is searching for a Data Analyst for our best-of-breed, multi-million dollar Amazon reimbursements and recovery tool. In this role, you’ll have a massive influence on the decisions that our internal team and our customers make–many who are themselves million-dollar Amazon sellers. This role is hands-on, and far more than just creating charts and graphs through a BI tool. You’ll be deeply involved in our data collection, migration, aggregation, analysis, and automation.

Your Responsibilities

Metrics Development: Define and establish key metrics that matter to our organization, and drive toward calculating those metrics across massive and often disparate datasets, both internal and external.
Data Integration: Identify and integrate new data sources into our data ecosystem to enhance our analytical capabilities from key Amazon, Walmart, and key third parties across the ecommerce ecosystem
Cross-functional Collaboration: Work closely with sales, operations, and of course product and engineering to understand their data needs and prioritize them in line with business goals
Data Processing: Leverage SQL to transform raw data into actionable insights, continuously optimizing our data platform for improved performance and scalability
Automation and Quality Assurance: Build trust in our data through robust automation and data quality processes that ensure that we never expose invalid or inaccurate data to your internal and external consumers
Data Visualization: Use your skills in BI tools (PowerBI, Tableau, Sisense, or similar) to create compelling reports and dashboards that support data-driven decisions, going beyond basic informatics to reveal key insights and drive decision making
Ad-hoc Solutions: Develop quick, temporary data solutions for immediate needs while contributing to long-term data infrastructure
Documentation: Ensure that all data processes and solutions are well-documented and sustainable for future use




Your Qualifications

Practical Experience: Solid track record as an Intermediate/Senior Data Analyst for a minimum of 4 years, actively involved in crafting and sustaining data analytics in complex settings
SQL Expertise: Proficient in SQL, including data modeling and crafting advanced queries
Business Intelligence Tools: Experienced in using BI tools like PowerBI, Tableau, or Sisense to visualize data and build dashboards
Detail-oriented: Strong attention to detail, with a passion for solving complex data challenges and ensuring data accuracy
Best Practices: Comprehensive grasp of data analysis principles, methodologies, and tools, encompassing data retrieval, staging, and visualization
Analytical Skills: Exceptional analytical prowess, coupled with the capability to dissect intricate data compilations and extract significant interpretations
Teamwork and Communication: Adept at seamlessly collaborating with diverse teams and stakeholders
Agile: Proven experience working on an Agile team with 1- or 2-week sprints, Scrum, and daily standups.
BONUS: Amazon Vendor/Seller Central experience either directly or through APIs




Perks & Benefits
🚀 As an early member of our team, you'll receive competitive compensation and a generous stock option plan.

🦷 Extended health benefits including Medical, Dental, and Vision starting on Day 1.

🌴 Flexible paid time off that includes paid vacation days and paid personal days.

💻 You'll receive a laptop conveniently delivered to your door to get you started and set up for success Day 1.","{""role_summary"":""The Data Analyst will have a significant impact on the decisions made by the internal team and customers, by collecting, integrating, analyzing, and automating data sets to drive business growth and profitability."",""key_terms"":[{""term"":""Data Integration"",""explanation"":""Combining data from different sources into a unified system to enhance analytical capabilities.""},{""term"":""Data Visualization"",""explanation"":""Presenting complex data in a clear and actionable way to support data-driven decisions.""},{""term"":""SQL Expertise"",""explanation"":""Proficiency in using SQL to transform raw data into actionable insights.""},{""term"":""Business Intelligence Tools"",""explanation"":""Using tools like PowerBI, Tableau, or Sisense to create compelling reports and dashboards.""}],""skill_priorities"":{""must_have"":[""Practical experience as an Intermediate/Senior Data Analyst"",""SQL Expertise"",""Business Intelligence Tools"",""Detail-oriented"",""Analytical Skills"",""Teamwork and Communication""],""nice_to_have"":[""Amazon Vendor/Seller Central experience"",""Agile experience with Scrum and daily standups""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach integrating new data sources into our data ecosystem?"",""example_answer"":""I would first identify the key data sources, then assess their compatibility with our existing infrastructure. Next, I would develop a plan to integrate the new sources, ensuring data quality and consistency.""},{""question"":""How do you ensure data accuracy and quality in your analysis?"",""example_answer"":""I implement robust data quality processes, perform regular data audits, and maintain detailed documentation of data processes and solutions.""}],""red_flags"":[""Lack of experience with SQL or business intelligence tools"",""Inability to work in an Agile environment"",""Insufficient attention to detail""],""confidence_score"":90.0}"
Data Integrity Analyst,Rexall Pharmacy Group ULC,"Mississauga, Ontario, Canada",June,2024,"At Rexall, we are community difference makers. We are leaders in health and wellness and a talent destination for over 7000+ Rexall team members. Together, we are defining better health through innovation, service, and living the “I2CARE”values. Talk about a dream team!


The Role:
Reporting directly to the Manager, Merchandising Systems and Data Integrity, you'll play a pivotal role in supporting the Category Management team. Your responsibilities will encompass a critical spectrum, including the accurate listing of new items, the meticulous maintenance of pricing details, and the unwavering commitment to data integrity within our merchandising systems.


What you are looking for:
A closely connected culture
A total rewards package meant to enhance your work-life flexibility
Fully utilizing your talent
Professional growth and development via challenging projects and assignments
Warm and fuzzy feelings knowing you have helped your community, your team, the business and social causes through the Rexall Care Network


The road ahead is one of adventure and heart. Are you our next all-star?


What you will be doing:
Responsible for the addition of all new items as well as the maintenance of pricing and item information into system to ensure the data integrity of our system are maintained at all times and items scan accurately at store level.
Investigates and resolves store issues regarding product inquiries in a timely manner reflecting corporate policy.
Researching and reviewing regulations such as taxation and environmental levies regularly and ensures that accurate data is captured in the system
Ensures the accuracy of the setup of all item information in the Merchandise systems
Perform data validation and providing results to the category management teams, for off shelf display, planogram and seasonal programs.
Perform other duties as assigned to support Rexall Pharmacy Group ULC


How you will succeed:
2-3 years’ experience working in a retail or merchandising environment.
Excellent time management and prioritization skills.
Excellent verbal and written communication skills.
Excellent organizational, financial and analytic skills.
Sophisticated Microsoft Office skills, including Excel
Must possess the right balance between being inquisitive and paying attention to detail.
Ability to work a fast paced and changing environment.
Quick learner who is motivated to learn new things can retain knowledge.
Demonstrated presentation skills.
Solutions oriented thinking.

At Rexall, we are better together. We serve our customers, partners, and patients best—we are our best—when everyone brings their true self to work. Our connected, inclusive culture celebrates our lived experiences, backgrounds, expertise, and self-expression to let us win as one team. Leveraging our differences distinguishes us and brings out our best performance.

Are you #ALLin?

Rexall Pharmacy Group ULC is committed to providing an accessible environment for all of our customers, employees, and job applicants. Rexall Pharmacy Group ULC will make available to any selected applicants’ accommodations and/or accessible formats should they require. Candidates are encouraged to discuss any accommodation they may need in order to allow for the most effective selection process.","{""role_summary"":""Support the Category Management team by maintaining data integrity in merchandising systems, ensuring accurate product information and resolving store issues."",""key_terms"":[{""term"":""Data Integrity"",""explanation"":""Ensuring accurate and consistent data in merchandising systems.""},{""term"":""Item Information"",""explanation"":""Product details such as pricing, descriptions.""},{""term"":""Merchandising Systems"",""explanation"":""Software used to manage product data and inventory.""}],""skill_priorities"":{""must_have"":[""Microsoft Office skills, including Excel"",""Excellent time management and prioritization skills"",""Excellent verbal and written communication skills"",""Ability to work in a fast-paced and changing environment""],""nice_to_have"":[""Demonstrated presentation skills"",""Solutions-oriented thinking""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to resolve a data discrepancy in a previous role?"",""example_answer"":""In my previous role, I identified a pricing error in our system. I worked with the issue, corrected the data, and ensured the change was reflected in our stores.""},{""question"":""How do you stay organized when working on multiple projects with tight deadlines?"",""example_answer"":""I prioritize tasks, break them down into smaller steps, and use tools like Excel to track progress and ensure timely completion.""}],""red_flags"":[""Lack of experience in a retail or merchandising environment."",""Inability to work in a fast-paced and changing environment.""],""confidence_score"":85.0}"
Data Analyst-DA - Canada,Zortech Solutions,"Calgary, Alberta, Canada",May,2024,"Role: Data Analyst-DA

Location: Alberta-Onsite

Duration: 6-12+ Months

Job Description

Roles, Responsibilities and Qualifications

Role Description

A Data Analyst provides expertise in instrumentation and data collection, data-driven storytelling, statistical analysis, modelling and data visualizations, developing data policies and governance standards, and developing service analytics standards and practices (inclusive of both digital and non-digital service implementation).

Responsibilities

Creates plans and strategies that will identify the various linkages between new and existing data forms, resulting in the integration of data models, development of data policies, and presentation of statistical analysis and data visualizations to help understand and improve service delivery online and offline.
Supports governance based on the service data model, service analytics standards, and the development of analytics tools, inclusive of both digital and non-digital service implementation.
Works to implement develop, and share service metrics and service performance dashboards for internal and public use.
Facilitates and informs program area workshops about current data and performance practices.
Uses the service journey to frame future measurement models.
Mentors team members and others to develop and grow their analytics fluency.
Researches best practices and makes recommendations for the direction of data-driven governance policies to support the adoption of digital services, and service delivery information management.
Creates data statistical analysis and data visualizations leveraging data querying languages within available data management technologies.
Supports corporate priorities based upon data-driven evidence by leveraging existing and new analytics, data visualizations, data modeling and storytelling.
Other responsibilities as required or requested.

Qualifications a) Experience leading data science and analytics work, including digital and non-digital services.

Experience with leadership, communications, relationship building, and planning.
Experience with current methodologies in analytics, data visualizations, data modeling and storytelling.
Experience working with cross-functional teams to understand detailed requirements and align these requirements with product vision and user needs.
Experience working in a complex enterprise environment (10,000 employees or greater).
Experience with agile projects in a public sector organization.
Experience with web development and digital product design.
Experience providing analytics support to user experience, customer experience, or service design teams.
Experience with quantitative research methods such as surveys.
Experience developing and maintaining relationships with multiple clients and stakeholders, including negotiating agreements and resolving conflicts.","{""role_summary"":""A Data Analyst provides expertise in data collection, analysis, and visualization to improve service delivery. They develop data policies, governance standards, and service analytics, and support data-driven decision-making."",""key_terms"":[{""term"":""Data-driven storytelling"",""explanation"":""Presenting data insights in a clear and compelling way to inform decision-making.""},{""term"":""Service analytics standards"",""explanation"":""Establishing guidelines for analyzing and reporting on service performance to ensure consistency and quality.""},{""term"":""Data governance"",""explanation"":""Developing policies and procedures to ensure data quality, security, and compliance with regulations.""},{""term"":""Data visualizations"",""explanation"":""Presenting complex data in a clear and concise visual format to facilitate understanding and decision-making.""},{""term"":""Service metrics"",""explanation"":""Developing and tracking metrics to measure service performance and inform improvement initiatives.""}],""skill_priorities"":{""must_have"":[""Experience leading data science and analytics work"",""Experience with analytics, data visualizations, data modeling, and storytelling"",""Experience working with cross-functional teams"",""Experience working in a complex enterprise environment""],""nice_to_have"":[""Experience with agile projects in a public sector organization"",""Experience with web development and digital product design"",""Experience providing analytics support to user experience teams"",""Experience with quantitative research methods such as surveys""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to develop a data-driven story to inform a business decision?"",""example_answer"":""In my previous role, I created a data visualization dashboard to show the impact of a new marketing campaign on sales. The insights from the dashboard helped the business leaders adjust their strategy and increase revenue.""},{""question"":""How do you ensure data quality and governance in your analytics work?"",""example_answer"":""I develop data validation rules and data quality checks to ensure accuracy and consistency. I also establish data governance policies and procedures to ensure compliance with regulations and organizational standards.""}],""red_flags"":[""Lack of experience leading data science and analytics work"",""Inability to communicate complex data insights effectively"",""Limited experience working with cross-functional teams""],""confidence_score"":90.0}"
Sr. Data Analyst,GBIT (Global Bridge InfoTech Inc),Canada,June,2024,"Sr. Data Analyst -REMOTE
Need resource in Canada
NEED STRONG IN SQL AND EXPERTISE IN LOOKML/LOOKER.
SQL Query Optimization expertise is needed.

About the Role:
Client is looking for curious data analysts who are deft at working with SQL and who are comfortable with a variety of databases and raw data formats. We function in a fast-paced and friendly environment. You will collaborate and work with teams across the organization to ensure our data standards, pipelines and processes are held to high standards in order to guide finance, product, and marketing decisions.
This role is ideal for a highly technical, analytical and results-oriented professional with a passion for transforming healthcare data into actionable insights. This individual is passionate and proficient in data storytelling and dashboard design with a proven ability to create visually compelling, interactive reports and dashboards to communicate meaningful data.
Responsibilities
● Monitor database content and provide recommendations to ensure that data quality, sanity, and accuracy are upheld
● Collaborate with a range of cross-functional stakeholders in multiple departments to understand data content, clarify business requirements, and formulate recommendations
● Perform intensive investigation and analysis of data anomalies and determine root causes
● Perform statistical analysis of large datasets
● Develop and manage monthly reporting for a range of internal customers
● Develop reporting tools & content to identify data outliers and issues
● Develop Enterprise data pipelines & dashboards
● Build valuable insights for our stakeholders by performing the analytical work to enable fast and accurate attribution and adjudication of prescription claims and coupons as well as improve vendor & pharmacy relationships and maximize patient savings
● Monitor transaction performance, implement automated reporting and conduct deep dives on drivers behind trends and anomalies that impact GoodRx’s top key results dramatically
Skills & Qualifications
● The ideal candidate for this role is someone who enjoys both being in-the-weeds with data and synthesizing analyses for non-technical collaborators and product leadership
● Ability to work extensively with SQL
● Expertise in LookML - able to build complex Looker Visualization using custom scripts
● Experience working with AWS, dbt
● Proven ability to manipulate and interpret data to produce insights and recommendations across large/diverse datasets
● Ability to communicate complex ideas clearly and concisely, verbally and in writing
● Presentation-building skills (PowerPoint, Google Slides, etc.) and a good eye for concise data visualization (Excel, Google Charts, etc)
● Ability to triage suspected inconsistency with data and work through SQL scripts to determine root cause
● Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
● Ability to define and manage overall schedule and availability for a variety of data sets
● Use of data mining techniques to extract information from data sets and identify correlations and patterns to help build and improve our products
● Knowledge of statistics and experience using one or more statistical packages for analyzing datasets (Excel, SPSS, SAS, etc.)
● Proven working experience as a Data Analyst or Business Data Analyst
● 4+ years in strategy, analytics or finance role supporting multiple stakeholders","{""role_summary"":""A senior data analyst role that involves working with SQL, LookML, and AWS to analyze and create insights for healthcare data, with a focus on data quality, accuracy, and storytelling."",""key_terms"":[{""term"":""LookML"",""explanation"":""A data modeling language used to build complex visualizations in Looker.""},{""term"":""SQL Query Optimization"",""explanation"":""The process of improving the efficiency of SQL queries to reduce processing time and improve performance.""},{""term"":""Data Storytelling"",""explanation"":""The process of extracting insights from data and presenting them in a compelling narrative.""},{""term"":""dbt"",""explanation"":""A tool used for data transformation and loading into warehouses.""}],""skill_priorities"":{""must_have"":[""SQL"",""LookML"",""Data Analysis"",""Data Visualization"",""Communication Skills""],""nice_to_have"":[""AWS"",""dbt"",""Statistics"",""PowerPoint"",""Google Slides""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach optimizing a slow-performing SQL query?"",""example_answer"":""I would use the EXPLAIN command to identify the bottleneck, then refactor the query to reduce processing time.""},{""question"":""How do you ensure data quality and accuracy in your reports?"",""example_answer"":""I use data validation rules and data profiling techniques to identify anomalies, and then investigate and resolve any issues found.""}],""red_flags"":[""Lack of experience with LookML or SQL query optimization"",""Inability to communicate complex ideas clearly""],""confidence_score"":90.0}"
Business Intelligence Analyst,Longbow Advantage,"Ontario, Canada",June,2024,"Company Overview & Job purpose:
Founded in 2002, Longbow advantage is a leading Supply Chain Technology Company built to provide best-in-class WMS, EWM, WM, LMS, and TMS implementation and integration services. Our team of supply chain professionals have experience and expertise that is unmatched throughout the industry. We have a 17-year track record of delivering successful logistics execution solutions and delivering on the commitments we make to customers. All of this has resulted in customer satisfaction scores that are world class
This position is responsible for gathering specific data extracts and developing, deploying, and maintaining widgets that dynamically and graphically represent the data. This role provides technical analysis and evaluation of clients’ requests.
Principle Responsibilities:
Design and implement metrics based on clients’ requests.
Responsible for developing polls and flows through data mining, data extraction and data analysis.
Assist in troubleshooting, resolution of data related issues as well as optimization of SQL queries.
Establish clear objectives for implementation and prioritize customer needs to respond with urgency to achieve customer expectations and ensure user adoption of the software.
Configure solutions to meet customers’ requirements.
Document solutions pertaining to customer set up, widget configuration, and polls and flows configuration.
Maintain a repository of process flows and polls for the Rebus team
Retrieve data from clients and manage data clean up
Comprehend, analyze, and solve highly complex technical problems involving system functionality, architecture, and relational databases
Strong ability to quickly understand scope and requirements and transform information into design and development
Meet with team members to configure and implement client’s requirements
Comply to policies and practices related to Longbow SOC2 compliance
Qualified Candidateswill possess most, if not, all of the following knowledge, skills, and abilities:
Minimum Bachelor’s degree in Computer Science or related University degree
Minimum 1+ year of experience with SQL Server, Oracle, or MySQL
Experience with MongoDB (aggregation pipeline) or another NoSQL database Preferred.
Knowledge and experience in JavaScript
Operating systems – Windows and UNIX
Microsoft Office suite
Knowledge of one major supply chain software system: Blue Yonder (formerly JDA), HighJump, Manhattan, SAP etc highly preferred.
Ability to work independently as well as multi-task","{""role_summary"":""Design and implement data-driven solutions to meet client needs, ensuring user adoption and resolving technical issues."",""key_terms"":[{""term"":""WMS"",""explanation"":""Warehouse Management System, a software solution for managing warehouse operations.""},{""term"":""EWM"",""explanation"":""Extended Warehouse Management, a software solution for managing warehouse operations.""},{""term"":""WM"",""explanation"":""Warehouse Management, a software solution for managing warehouse operations.""},{""term"":""LMS"",""explanation"":""Labor Management System, a software solution for managing labor operations.""},{""term"":""TMS"",""explanation"":""Transportation Management System, a software solution for managing transportation operations.""},{""term"":""SQL"",""explanation"":""Structured Query Language, a programming language for managing relational databases.""},{""term"":""NoSQL"",""explanation"":""A database that does not use structured query language to manage data.""},{""term"":""MongoDB"",""explanation"":""A NoSQL database that uses a document-oriented data model.""},{""term"":""JavaScript"",""explanation"":""A programming language used for client-side scripting on the web.""},{""term"":""SOC2"",""explanation"":""Service Organization Control 2, a standard for managing and implementing controls for secure data processing.""}],""skill_priorities"":{""must_have"":[""SQL Server"",""JavaScript"",""Operating systems – Windows and UNIX"",""Microsoft Office suite""],""nice_to_have"":[""MongoDB"",""Yonder (formerly JDA)"",""HighJump"",""Manhattan"",""SAP""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize a slow-performing SQL query?"",""example_answer"":""I would analyze the query, identify the root cause of the performance issue, and refactor the query to improve indexing, reduce joins, and optimize the database structure.""},{""question"":""Can you explain how you would design a widget to display client metrics?"",""example_answer"":""I would gather requirements from the client, design a user-friendly interface, and develop a widget that dynamically displays the metrics using JavaScript and a NoSQL database like MongoDB.""}],""red_flags"":[""Lack of experience with SQL Server, Oracle, or MySQL"",""Inability to work independently and multitask""],""confidence_score"":90.0}"
Reference Data Analyst,CanDeal,"Toronto, Ontario, Canada",June,2024,"Why join the CanDeal Team?

CanDeal Group is a leading provider of electronic marketplaces and data services for Canadian dollar fixed income securities and derivatives. CanDeal’s Markets Division, provides access to a deep pool of liquidity for Canadian government, agency, provincial and corporate bonds, as well as money market instruments and interest rate swaps. CanDeal Data & Analytics (DNA) delivers data and analytics products and other services that support business, trading and technology needs for participants in the Canadian capital markets.

CanDeal Group is a growing and entrepreneurial organization with a solid foundation in the Canadian fixed income markets and an ownership group which includes: BMO Nesbitt Burns Inc., CIBC World Markets Inc., National Bank Financial Inc., RBC Dominion Securities Inc., Scotia Capital Inc., TD Securities Inc. and TMX Group.

This is an exciting time to join a growing organization led by visionary leaders who are helping to shape their industry’s future.

Job Purpose

The successful candidate will form a key part of the Reference Data team responsible for maintaining the smooth running of the day-to-day operations of bonds product and services as well as supporting the questions and requests of our internal and external clients. Their primary responsibilities are to ensure the accuracy of reference data of fixed income securities added to DNA’s Security Master (includes cross-checking accuracy of calculations). Will work closely with other functions within the wider team – product management, business analysis, technology, and testing.

Primary Duties

The candidate will perform a wide range of duties including but not limited to the following:

Researching and updating of newly issued deals into the database on a real time basis.
Operational maintenance of reference data for the trading and pricing products.
Cross-check fixed income calculations for accuracy. Identity and troubleshoot discrepancies in calculations. Document and communicate discrepancies to developers and follow through to resolution.
Manage client (internal and external) queries and client escalations.
Liaise with counterparts/stakeholders within the wider team.

Secondary Duties

User acceptance testing for new or enhanced product functionality. Execute test cases to confirm completion of technical, functional requirements for new fixed income product and system releases.
Identify data quality improvement projects and opportunities to enhance operational efficiency.

Knowledge, Skills, and Abilities

3 years+ of business-related experience in the fixed income financial services industry.
Experience related to fixed income reference data management an asset.
Strong knowledge and understanding of a range of fixed income products, including bonds, money market products and interest rate derivatives.
Strong knowledge of fixed income trading and familiarity with terms and conditions of fixed income securities, including settlement protocols.
Strong investigating and problem-solving skills - acute attention to detail.
Demonstrates analytical thinking and sound judgement when making decisions.
Outstanding organizational skills, highly motivated and adaptable to a changing business environment.
Must have exceptional time management skills.
Working knowledge of new bond issuance procedure desirable.
Working knowledge of corporate bonds and new bond issuance procedure desirable.
Bilingualism (French/English) is an asset.

Key Qualifications

Long term desire to stay focused on static data.
Knowledge of fixed income reference data (past experience at the banks – fixed income/syndicate desks).
Content in handling data entry and daily tasks (ex. Experience in handling Capital Market settlements).
Experience with Data Management and Governance.
Experience with SQL.

Education

University degree in a related discipline.
Canadian Securities Course (CSC) certification is an asset.

Please inform us if you require any accommodation during the hiring process.","{""role_summary"":""Maintain the accuracy of reference data for fixed income securities, supporting internal and external clients, and ensuring smooth day-to-day operations."",""key_terms"":[{""term"":""Fixed income securities"",""explanation"":""Financial instruments that provide a fixed return, such as bonds and interest rate derivatives.""},{""term"":""Reference data"",""explanation"":""Standardized information about financial instruments, used for trading and pricing.""},{""term"":""Security Master"",""explanation"":""A centralized database of reference data for financial instruments.""}],""skill_priorities"":{""must_have"":[""3+ years of business-related experience in fixed income financial services"",""Strong knowledge of fixed income products and trading"",""Analytical thinking and problem-solving skills"",""Exceptional time management skills""],""nice_to_have"":[""Experience in fixed income reference data management"",""Knowledge of corporate bonds and new bond issuance procedure"",""Bilingualism (French/English)"",""Canadian Securities Course (CSC) certification""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you ensure the accuracy of reference data for fixed income securities?"",""example_answer"":""I would cross-check calculations, document discrepancies, and communicate with developers to resolve issues.""},{""question"":""Can you give an example of a time when you had to troubleshoot a data quality issue?"",""example_answer"":""I identified a discrepancy in fixed income calculations, and worked with the development team to resolve the issue and implement a process to prevent it in the future.""}],""red_flags"":[""Lack of experience in fixed income reference data management"",""Inability to work in a fast-paced environment""],""confidence_score"":85.0}"
Marketing Data Analyst (12 month contract),HOOPP (Healthcare of Ontario Pension Plan),"Toronto, Ontario, Canada",June,2024,"Why you’ll love working here:

high-performance, people-focused culture
our commitment that equity, diversity, and inclusion are fundamental to our work environment and business success, which helps employees feel valued and empowered to be their authentic selves
learning and development initiatives, including workshops, Speaker Series events and access to LinkedIn Learning, that support employees’ career growth
membership in HOOPP’s world class defined benefit pension plan, which can serve as an important part of your retirement security
competitive, 100% company-paid extended health and dental benefits for permanent employees, including coverage supporting our team's diversity and mental health (e.g., gender affirmation, fertility and drug treatment, psychological support benefits of $2,500 per year, and newly extended maternity/parental leave top of 26 weeks)
optional post-retirement health and dental benefits subsidized at 50%
yoga classes, meditation workshops, nutritional consultations, and wellness seminars
access to an annual wellness reimbursement program for health and wellness-related expenses for permanent and temporary employees
the opportunity to make a difference and help take care of those who care for us, by providing a financially secure retirement for Ontario healthcare workers

Job Summary

We are seeking a detail-oriented and versatile Data Analyst to join our Marketing Analytics function to enhance our data management and analytics capabilities. In this position, you will be responsible for handling a variety of data processes including extraction, cleaning, preparation, and validation of complex data sets to support comprehensive reporting. You will build data models and pipelines, advanced dashboards and visualizations, and SQL scripts to deliver meaningful insights, and assist IT in meeting the function’s short- and long-term data analytics needs.

If you are passionate about solving complex problems through analytical thinking and enjoy working with both technical and non-technical teams, we encourage you to apply for this role.

What you will do:

Assist in the collection, cleaning, and preparation of data from diverse sources for reporting purposes
Develop advanced dashboards and visualizations using data from different sources to provide meaningful insights
Create and maintain data models that ensures data consistency, accuracy, and accessibility
Provide ad-hoc reporting support to diverse stakeholders
Develop and maintain documentation for data infrastructure and data governance and actively monitor and execute data governance controls
Develop and document business processes and workflows for data preparation and marketing analytics processes
Collaborate with other departments and data vendors to coordinate data automation and data centralization initiatives
Design, develop, and deploy Power BI scripts and perform analysis that can help in decision-making
Create complex SQL queries, perform optimization of slow running queries incl. leveraging T-SQL data structures to complement report development
Trouble shoot and optimize Power BI and SQL Server report-based data solutions
Design, build, and maintain data pipelines and workflows that extract, transform, and load data from various sources into our data warehouse
Maintain, integrate, and update data sources to ensure data quality and accuracy
Develop and implement data integrity checks and processes, investigate, and resolve data quality issues
Structure the collected data into a well-organized format, creating metadata, and maintain a data catalog for easy access and discoverability
Implement and test new analytics tracking requirements for new elements and features on our digital properties
Maintain and optimize data analytics tools and platforms
Stay up-to-date with emerging trends and technologies in marketing analytics, machine learning and automation
Apply AI and machine learning concepts in relation to data and analytics initiatives

What you will bring:

Bachelor’s degree in computer science, mathematics, or a related field
Microsoft Data and/or BI certifications preferred
3-5 years of experience in data analytics preferred
Experience with data platforms such as GCP (as a BigQuery Viewer), Data Bricks and/or Snowflake
Experience with data Ingestion using Synapse Pipelines and/or Azure Data Factory
Intermediate level BI dashboarding and visualization experience with tools such as PowerBI, Tableau or similar; performance optimization tuning for Power BI
Strong experience with data manipulation and visualization languages such as T-SQL, DML, DDL, DAX, Python and/or R
Knowledge of data analysis, visualization principles, data modeling techniques and best practices
Experience developing data governance best practices, processes, and standards
Experience creating and documenting end-to-end reporting, data processes and ETL
Experience in managing digital marketing and web analytics platforms such as Google Analytics 4 (incl. building reports, dimensions, and calculated metrics) and Google Tag Manager
Empathetic, humble, and collaborative mindset with the ability to work well with both technical and non-technical teams
Ability to work closely with cross-functional teams, including developers, business analysts, and stakeholders
Strong communication skills, capable of presenting data insights to non-technical stakeholders in a clear and concise manner
Strong problem-solving and analytical skills
Ability to work independently and as part of a team","{""role_summary"":""Support the Marketing Analytics function by handling data processes, building data models, and creating advanced dashboards and visualizations to deliver meaningful insights."",""key_terms"":[{""term"":""Data Governance"",""explanation"":""The process of managing and controlling data assets to ensure data consistency, accuracy, and accessibility.""},{""term"":""ETL"",""explanation"":""Extract, Transform, and Load data from various sources into a data warehouse for reporting and analytics purposes.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that allows users to create visualizations and business intelligence reports.""},{""term"":""T-SQL"",""explanation"":""A set of programming extensions for SQL that allow for more complex and efficient querying and data manipulation.""},{""term"":""Data Modeling"",""explanation"":""The process of creating a conceptual representation of data structures to ensure data consistency, accuracy, and accessibility.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in computer science, mathematics, or a related field"",""Experience with data platforms such as GCP, Data Bricks, and/or Snowflake"",""Intermediate level BI dashboarding and visualization experience with tools such as PowerBI, Tableau or similar"",""Strong experience with data manipulation and visualization languages such as T-SQL, DML, DDL, DAX, Python and/or R""],""nice_to_have"":[""Microsoft Data and/or BI certifications"",""Experience with data Ingestion using Synapse Pipelines and/or Azure Data Factory"",""Experience developing data governance best practices, processes, and standards"",""Experience creating and documenting end-to-end reporting, data processes and ETL""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach data governance in a marketing analytics function?"",""example_answer"":""I would ensure data consistency, accuracy by implementing data governance controls, documenting data infrastructure, and actively monitoring data quality issues.""},{""question"":""How do you stay up-to-date with emerging trends and technologies in marketing analytics, machine learning, and automation?"",""example_answer"":""I regularly read industry blogs, attend webinars, and participate in online forums to stay current with the latest developments in marketing analytics and automation.""}],""red_flags"":[""Lack of experience with data platforms such as GCP, Data Bricks, and/or Snowflake"",""Inability to work with both technical and non-technical teams"",""Limited experience with data manipulation and visualization languages such as T-SQL, DML, DDL, DAX, Python and/or R""],""confidence_score"":90.0}"
Billing Data Analyst,Enercare Inc.,"Markham, Ontario, Canada",June,2024,"Enercare Inc. is one of Canada’s largest home and commercial services companies, providing leading products and services in heating, cooling, plumbing, electrical, water heating and water purification. Our purpose is to provide energy-efficient products and services to our customers, so together we can take action for a greener tomorrow, starting in our homes and buildings.

We are a company that believes strongly in the health, safety and wellness of our people. Enercare is a place where careers are made. We take pride in caring for and continually striving to make a positive impact in the communities we operate in. In our values and our ambitions, we embrace change, and support our team members along the way.

Nationally, Enercare Inc. operates under several brands including Enercare, Service Experts, HydroSolution, Pioneer Plumbing & Heating, and Syles Mechanical Services, servicing Canadians in Ontario, Manitoba, Saskatchewan, Alberta, British Columbia, Quebec and New Brunswick. We are united through our joint commitment to excellent customer service to the Canadians we service every day, and our mission to contribute to a resilient, sustainable future. Enercare Inc. Is wholly owned by Brookfield Infrastructure Partners LP (“Brookfield”), a global leader in the management of alternative assets across real estate, infrastructure, renewable power, and private equity.

Summary:

This position is responsible for executing tasks that will support various billing related operations with internal and external groups. The successful candidate’s primary responsibilities will include: configuring, managing and building SalesForce Marketing Cloud email notification journeys and fully supporting the end to end notification requirements. Will be responsible for conducting various functions such as processing transactions, monitoring system exceptions, analysis of files and batches related to billing or payments, billing and rate management as well as researching and resolving exceptions in these key areas. This role will also include analysis of system and user processes to propose and implement process, documentation and training for internal and external groups. The Analyst will also play a key role in contributing towards Enercare's success by meeting business objectives, improving the performance of internal operations, ensuring customer satisfaction and continuous improvement of operating practices and procedures to reduce risk and increase operational effectiveness.

Accountabilities:

Configure and manage Salesforce Marketing Cloud Notifications from build, design and complete execution of enabling a marketing cloud journey
Must be able to report on number of notifications delivered, identity errors and lead driving solutions forward
Maintain and update templates according to business needs or new notification journeys
Prepare process documentation and report on learning with the team by collaborating and knowledge sharing
Work closely with various departments to support the architecture and own configuring best-in-class implementations of Billing and Sales Cloud.
Configure Salesforce Solutions using point and click tools available on the platform ex. Process Builder and Visual Flows
Understand and leverage Salesforce Platform to implement scalable solutions
Work closely with reporting and analytics team to develop and monitor controls to ensure all exceptions from order to cash are monitored and actioned
Partner with Billing and Offline managers to ensure that all controls are being actioned according to defined processes
Create adhoc queries using SQL, PowerBI and other tools and reports in order to understand billing or system exceptions
Resolve exceptions by identifying root cause, implementing solutions and fixing customer accounts Conduct account research and support for Billing & Collections, which includes research in various systems and requests from various functions across the organization
Prepare, validate and execute any bill messaging, letters or inserts required in regular or ad hoc situations
Demonstrates a commitment to process improvement while provides recommendations and driving change
Foster and develop the capability to be a ‘Super User’ for internal systems while cultivating a position as a Subject Matter Expert within various Enercare systems
Maintaining documentation of internal processes to ensure processes are up to date
Work closely with Training and Quality Assurance teams to optimize Billing and revenue related processes
Provide analysis and present recommendations to leadership on system or process improvements Supporting other departments to achieve production service levels and any on-going project objectives Any other duties or initiatives required to maintain or enhance service levels

Qualifications:

Salesforce CPQ , Service Cloud, Community Cloud and Sales Cloud certifications
Experience with SaaS Billing and Revenue solutions such as Zuora Billing and Zuora Revenue
BBA or equivalent post-secondary education
Excellent written and oral communications skills
Superior working knowledge of Microsoft Applications such as Excel and Access.
Experience with PowerBI or SQL is an asset
Minimum three years of experience in an operational environment, financial analysis or other roles that focus on root cause analysis within the scope of billing and revenue systems, with the development and implementation of controls and procedures
Self-starter with strong interpersonal and conflict resolution skills Ability to quickly form relationships and interact effectively in a complex environment Strong desire to understand operations and root causes of issues
Strong organizational and time-management skills with ability to multi-task and work under tight timelines
Ability to understand financial impacts and back-end banking environments
Ability to prioritize deliverables and work with various people in all levels including customers to achieve personal and team objectives with the flexibility to adapt to changing priorities
Extensive experience handling multiple billing systems and exceptions management
Ability to create and formally present recommendations to all levels, including senior leadership teams

Enercare is an equal opportunity employer. We are committed to equal employment opportunity regardless of race, colour, ancestry, national origin, religion, sex, age, sexual orientation, gender identity, citizenship, marital status, disability, pregnancy, military status, protected veteran status or other characteristics protected by applicable law. Enercare’s recruitment process includes accommodation for applicants with disabilities in accordance with applicable provincial accessibility laws and regulations. All accommodations will take into account the applicant’s accessibility needs due to disability and are available upon request.","{""role_summary"":""This role supports billing-related tasks, configuring and building Salesforce Marketing Cloud email notification journeys, and conducting various functions such as processing transactions, monitoring system exceptions, and researching and resolving exceptions."",""key_terms"":[{""term"":""Salesforce Marketing Cloud"",""explanation"":""A cloud-based platform for creating and managing customer journeys and marketing automation.""},{""term"":""SalesForce CPQ"",""explanation"":""Configure, Price, and Quote software for sales teams to automate and streamline sales processes.""},{""term"":""SaaS Billing and Revenue solutions"",""explanation"":""Software as a Service billing and revenue management solutions, such as Zuora Billing and Zuora Revenue, for managing subscription-based services.""},{""term"":""Process Builder and Visual Flows"",""explanation"":""Point-and-click tools in Salesforce for building and automating business processes.""},{""term"":""SQL and PowerBI"",""explanation"":""Query languages and business intelligence tools for data analysis and reporting.""}],""skill_priorities"":{""must_have"":[""Salesforce CPQ certifications"",""Experience with SaaS Billing and Revenue solutions"",""BBA or equivalent post-secondary education"",""Excellent written and oral communications skills"",""Superior working knowledge of Microsoft Applications such as Excel and Access."",""Minimum three years of experience in an operational environment, financial analysis or other roles that focus on root cause analysis within the scope of billing and revenue systems""],""nice_to_have"":[""Experience with PowerBI or SQL"",""Ability to create and formally present recommendations to all levels, including senior leadership teams""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with Salesforce Marketing Cloud and how you've used it to support billing-related operations?"",""example_answer"":""I've worked with Salesforce Marketing Cloud to configure and manage email notification journeys, and I've used it to support billing-related operations by creating and executing notification journeys, reporting on notification delivery, and identifying errors.""},{""question"":""How do you stay organized and manage multiple billing systems and exceptions?"",""example_answer"":""I prioritize deliverables, work with various people at all levels, and adapt to changing priorities. I also have strong organizational and time-management skills, which enable me to work under tight timelines.""}],""red_flags"":[""Lack of experience with Salesforce CPQ, Service Cloud certifications"",""Inability to work with various departments to support billing and sales cloud implementations"",""Limited experience with billing and revenue systems, including Zuora Billing and Zuora Revenue""],""confidence_score"":90.0}"
Data / BI Analyst,Robert Half,"Burlington, Ontario, Canada",June,2024,"Description

We are looking for a certified Data Analyst. To be successful in this role, you should be able to turn data into information, information into insight and insight into business decisions. Some responsibilities of the Data Analyst include conducting full lifecycle analysis to include requirements, activities and design, as well as developing analysis and reporting capabilities. The Data Analyst will also monitor performance and quality control plans to identify improvements.

Your responsibilities

Regularly examine data reports to identify and resolve mistakes throughout
Help various departments, including marketing and sales, reach their goals through analysis
Assemble data recording systems and business analysis for the department to use
Identify changes in financial and business trends by monitoring data
Assemble business reports that provide insight into key data points
Accurately analyze and collect data for various types of business reports
Communicate data analysis findings to managers in written and verbal form
Own the maintenance of databases and perform updates as necessary for accuracy

Requirements

Analytical skills that allow for the development of data-driven reports
Knowledge of object-oriented programming and other data analysis programs
Strong written and verbal communication skills to effectively relate data to coworkers
Able to notice small details that could impact results
Time management and prioritization skills to meet project deadlines
General knowledge of business operations, objectives, strategies, process and information flow
1 to 3 years of experience as a financial or business analyst
Superb critical thinking skills to make decisions and solve business problems
Skilled in creating pivot tables, graphs, and charts using data tools

Robert Half is the world’s first and largest specialized talent solutions firm that connects highly qualified job seekers to opportunities at great companies. We offer contract, temporary and permanent placement solutions for finance and accounting, technology, marketing and creative, legal, and administrative and customer support roles.

Robert Half works to put you in the best position to succeed. We provide access to top jobs, competitive compensation and benefits, and free online training. Stay on top of every opportunity - whenever you choose - even on the go.

Questions? Call your local office at 1.888.490.4429. All applicants applying for Canadian job openings must be authorized to work in Canada.

© 2024 Robert Half. By clicking “Apply Now,” you’re agreeing to","{""role_summary"":""The Data Analyst role is responsible for turning data into information, information into insight, and identifying improvements through monitoring performance and quality control plans."",""key_terms"":[{""term"":""Object-oriented programming"",""explanation"":""A programming paradigm that organizes software design around objects and their interactions.""},{""term"":""Pivot tables"",""explanation"":""A data analysis tool used to summarize and analyze large datasets.""}],""skill_priorities"":{""must_have"":[""Analytical skills"",""Knowledge of data analysis programs"",""Strong written and verbal communication skills"",""Time management and prioritization skills"",""General knowledge of business operations""],""nice_to_have"":[""Experience as a financial or business analyst"",""Skilled in creating pivot tables, graphs, and charts""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure data accuracy in your reports?"",""example_answer"":""I use data validation techniques and cross-check data against multiple sources to ensure accuracy.""},{""question"":""Can you give an example of a business problem you solved using data analysis?"",""example_answer"":""I analyzed customer purchase data to identify opportunities to increase sales revenue by 10%.""}],""red_flags"":[""Lack of experience in data analysis programs"",""Inability to communicate complex data insights effectively""],""confidence_score"":85.0}"
Analista de Datos Junior,NOUS LATAM,"Prince Edward Island, Canada",June,2024,"Analista de Datos Junior Estamos en busca de un profesional motivado para formar parte de un nuevo proyecto en nuestro equipo. Tu principal función será colaborar con analistas más experimentados para recopilar, organizar y analizar datos, con el objetivo de obtener información valiosa que respalde la toma de decisiones estratégicas por parte del equipo de gerencia. En este rol, tendrás la oportunidad de utilizar herramientas y tecnologías de vanguardia para el análisis y visualización de datos y trabajar en un entorno dinámico y colaborativo, donde tu voz será escuchada y tus ideas valoradas. Responsabilidades: Ayudar en la recopilación y limpieza de datos de diversas fuentes. Asistir en la preparación de conjuntos de datos para análisis mediante la identificación y corrección de errores. Realizar análisis exploratorio de datos para descubrir patrones, tendencias y relaciones significativas. Apoyar en la creación de informes y visualizaciones para comunicar hallazgos a diferentes audiencias. Generar reportes automatizados que permitan analizar performance de los indicadores. Identificar tendencias, patrones y correlaciones dentro de los datos para respaldar los objetivos comerciales. Colaborar con otros miembros del equipo en proyectos de análisis de datos, proporcionando soporte y contribuyendo con ideas. Mantenerse al tanto de las últimas tendencias y herramientas en análisis de datos y participar en actividades de desarrollo profesional para mejorar habilidades. Requisitos: Título universitario en estadística, matemáticas, informática, economía u otro campo relacionado. Inglés B2-C1 (Requerido). Portugués básico (Preferible, no excluyente) Manejo intermedios / avanzados de herramientas de visualización, tales como Tableau, Power BI o DataStudio Conocimiento básico de técnicas de análisis de datos y herramientas como Excel, SQL, Python o R. Fuertes habilidades analíticas y capacidad para interpretar datos de manera efectiva. Capacidad de adaptación para trabajar de manera colaborativa en un entorno de equipo. Powered by JazzHR","{""role_summary"":""Collaborate with experienced analysts to collect, organize, and analyze data to support strategic decision-making."",""key_terms"":[{""term"":""Análisis exploratorio"",""explanation"":""A method to discover patterns, trends, and significant relationships in data.""},{""term"":""Visualización de datos"",""explanation"":""The process of creating graphical representations to communicate data insights.""},{""term"":""Técnicas de análisis de datos"",""explanation"":""Methods and tools used to extract insights from data, such as Excel, SQL, Python, or R.""}],""skill_priorities"":{""must_have"":[""Título universitario en estadística, matemáticas, informática, economía u otro campo relacionado"",""Inglés B2-C1"",""Manejo intermedios / avanzados de herramientas de visualización"",""Conocimiento básico de técnicas de análisis de datos""],""nice_to_have"":[""Portugués básico"",""Fuertes habilidades analíticas""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to analyze a complex data set and present your findings to a non-technical audience?"",""example_answer"":""I used Tableau to create interactive dashboards that effectively communicated insights to stakeholders.""},{""question"":""How do you stay up-to-date with the latest trends and tools in data analysis?"",""example_answer"":""I regularly attend webinars, participate in data analysis forums, and take online courses to improve my skills.""}],""red_flags"":[""Lack of experience with data visualization tools"",""Inability to communicate complex data insights effectively""],""confidence_score"":85.0}"
Data Analyst - Entry Level,J.D. Power,"London, Ontario, Canada",June,2024,"Title: Data Analyst - Entry Level

Location: Remote Canada

Reports To: Supervisor



J.D. Power is a global leader in consumer insights, advisory services and data and analytics. A pioneer in the use of big data, artificial intelligence (AI) and algorithmic modeling capabilities to understand consumer behavior, J.D. Power has been delivering incisive industry intelligence on customer interactions with brands and products for more than 50 years. The world's leading businesses across major industries rely on J.D. Power to guide their customer-facing strategies.

Position Overview

The primary function of the Automotive Data Analyst 1 is to obtain, compile, analyze, interpret, research, code, and test for presentation all ordering, pricing, and technical information needed by JDP Systems from the Automotive Industry. The Automotive Data Analyst 1 must apply highly specialized knowledge of automotive vehicles and the variations of each manufacturer, as well as keep track of numerous details and their inter-relationships to develop a coding structure that makes the JDP products display accurate information with every possible set of variables. Each Data Analyst is ultimately responsible to ensure the JDP content “Gold Standard”.

Core Job Duties And Responsibilities

During the introductory training period, the Automotive Data Analyst 1 is responsible to access training tools and participate in practice content assignments in preparation to take the final assessment.
Gain an understanding of the department and automotive industry.
Develop personal priorities and timelines and hit deadlines within departmental schedule.
Participate in entry and testing updates to company products
Review and analyze source documents from the manufacturer to identify discrepancies, inaccuracies, or missing content.
Accurately enter and/or test incentive vehicle data
Enter and test up to mid-level complexity vehicles for multiple OEM’s
Responsible to help the team achieve established goals, as well as completing individual responsibilities in a timely manner
May work on special projects, depending upon available resources and appropriate skill levels
Receive and respond to customer reports of errors and proactively respond with corrections and status updates in a professional manner
Act as a positive team player
Perform other duties as assigned

Education, Experience And Qualifications

Excellent verbal and written communication skills
Post-secondary education or related work experience
Able to work well under pressure and to excel in a constantly changing environment
Strong self-management and analytical abilities
Very high accuracy and attention to detail is required
Self-motivated and able to work within a team
Computer skills – MS office tool suite
Time management skills, organized and able to meet deadlines
This role requires flexible hours (including OT) which may at times include early mornings, late nights and weekends

Company Mission

J.D. Power is clear about what we do to ensure our success into the future. We unite industry leading data and insights with world-class technology to solve our clients’ toughest challenges.

Our Values

At J.D. Power, we strive to be Truth Finders, Change Makers and Team Driven - the distinct behaviors that, together, define our unique culture.

Truth Finders - At J.D. Power, we are proud of the unbiased data and findings we provide. As individuals, each and every member of our team is dedicated to living this same objectivity and embodying the highest ethical and professional standards – the only ‘favorite’ we have is the truth.

Change Makers - At J.D. Power, we never stand still. We constantly seek better ways – innovating and evolving in everything we do to support our colleagues and our clients alike – and all in service of delivering data and insights that drive meaningful business impact.

Team Driven - At J.D. Power, we are one team and we are activated. Regardless of individual role, every member of our team is dedicated to supporting their immediate colleagues and our broader J.D. Power family to deliver on our collective purpose and make us greater than the sum of our parts. At J.D. Power, these values are more than words.

J.D. Power is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.

J.D. Power is an equal-opportunity employer and compliant with AODA/ADA legislation. Should you require accommodations during the recruitment and selection process, please reach out to tarecruitment@jdpa.com.



To all recruitment agencies: J.D. Power does not accept unsolicited agency resumes and we are not responsible for any fees related to unsolicited resumes.","{""role_summary"":""The Data Analyst - Entry Level role is responsible for obtaining, compiling, and interpreting automotive industry data to ensure accurate information in JDP products.  The role requires strong analytical and communication skills, with the ability to work well under pressure and meet deadlines."",""key_terms"":[{""term"":""Automotive Industry"",""explanation"":""The automotive industry refers to the manufacturing and sales of vehicles, including cars, trucks, and motorcycles.""},{""term"":""JDP Systems"",""explanation"":""JDP Systems refers to the technology and data analytics platforms used by J.D. Power to provide insights to the automotive industry.""},{""term"":""Coding structure"",""explanation"":""A coding structure refers to the organized system of codes and categories used to classify and analyze data in the automotive industry.""}],""skill_priorities"":{""must_have"":[""Analytical skills"",""Communication skills"",""Attention to detail"",""Time management skills"",""MS Office tool suite""],""nice_to_have"":[""Post-secondary education"",""Related work experience"",""Self-motivation""]},""proposed_screening_questions_with_answers"":[{""question"":""What experience do you have working with automotive industry data?"",""example_answer"":""I have worked with automotive industry data in my previous role, where I was responsible for analyzing and interpreting data to inform business decisions.""},{""question"":""How do you ensure accuracy and attention to detail in your work?"",""example_answer"":""I use a combination of quality control checks and attention to detail to ensure accuracy, and I am proactive in identifying and correcting errors.""}],""red_flags"":[""Lack of experience working with automotive industry data"",""Inability to work well under pressure"",""Poor communication skills""],""confidence_score"":90.0}"
Lead Data Analyst,Zortech Solutions,Canada,February,2024,"Role: Lead Data Analyst

Location: Remote/Canada

Duration: 6+ Months

Job Description

Lead Data Analyst minimum 15+ – 4 years lead exp

We are looking for Strong expereince on the following .

Total years of exp should be more tha

Expert in SQL (Most Advanced level) – SQL – Azure cloud migration
Data Models – expert level
Data Analysis (data identification, querying, cleaning, wrangling, checking quality)
Market Data Analysis background
Cloud Migration – Azure
On Premises Migration
data visualization tools such as Power BI, Tableau etc.

Write Up From Candidate Required .

What is the most complex Source to target mapping exercise that you have done?
What is the most complex SQL query you have done- is this for Data analyst?

This is a combination of (Data + Strong SQL background + On Perm and Cloud migration (Azure

The senior data analyst is responsible for analysing business requirements and converting them into data requirements such as reports, data lifecycle management. They will analyse and interpret complex data sets to inform business decisions. The senior data analyst will also be expected to lead and mentor junior data analysts as well as communicate findings and recommendations to stakeholders and management .

SQL/NoSQL databases, social media, surveys within organization, and additional, public domain, market data sources.
Collaborate with Business SMEs, Product owners, Data Stewards, and Data Architects to identify critical data elements, define business terms, capture metadata, define data schema, clean, and prepare data in an appropriate format to perform analysis.
Analyse data using statistical techniques to identify trends and patterns (e.g. growth/decline in key metrics) and create visualizations and reports to present findings to business stakeholders and/or data scientists for further actions.
Build expert knowledge of products, systems, data and data quality in order to provide high business impact analysis and consultation. Provide robust, data-driven customer insights and recommendations for strategic decision-making purposes by performing deep dives and providing meaningful analysis to the business units .
Assess and monitor the quality of data by working with the Data stewards, Data quality leads, and internal stakeholders and support the implementation of data quality rules and remediation of issues.
Provide guidance and mentorship to junior members of the team.
Build a culture of collaboration and innovation. Proactively identify pain points through the data and
formulate potential opportunities that can be pursued by the business units.
Collaborate/Partner with product owner and delivery teams to ensure that the project/product is
delivered with quality and in time. Assist the scrum master to provide estimate and impact assessment.
Interpret data models (Logical and Physical) and ensuring they align with the solution design. Design
reusable and scalable frameworks to achieve standardization and efficiency. Convert user requirement into technical specifications and design documents and identifying new data sources for the data warehouse.
Also responsible for other Duties/Projects as assigned by business management as needed.
Also responsible for other Duties/Projects as assigned by business management as needed.

Mandatory Skill set .

Experience in data identification, querying, cleaning, wrangling, checking quality, working with common relational and non-relational databases in big data environments on both on prem and cloud such as Azure .
Experience working with relational databases using SQL.
Experience with Data querying, cleaning, wrangling, working with common relational and non-relational databases in big data environments such as Azure .
Experience articulating and translating business questions and using statistical techniques to arrive
at an answer using data.
Experience writing and speaking about technical concepts to business, technical, and lay audiences and giving data-driven presentations .
Experience working with relational databases using SQL .
Experience with data visualization tools such as Power BI, Tableau etc.
Excellent presentation, communication, and organizational skills","{""role_summary"":""Lead a team of data analysts to analyze business requirements, convert them into data requirements, and inform business decisions through complex data analysis and visualization."",""key_terms"":[{""term"":""Azure cloud migration"",""explanation"":""The process of moving data and applications from on-premises environments to Microsoft Azure cloud infrastructure.""},{""term"":""Data Models"",""explanation"":""Conceptual representations of data structures and relationships, used to organize and standardize data.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and manipulating data in relational databases.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to facilitate understanding and decision-making.""},{""term"":""Cloud Migration"",""explanation"":""The process of moving data, applications, and other business elements from on-premises environments to cloud infrastructure.""},{""term"":""On Premises Migration"",""explanation"":""The process of moving data, applications, and other business elements from one on-premises environment to another.""}],""skill_priorities"":{""must_have"":[""Expert-level SQL skills"",""Experience with data analysis, querying, cleaning, and visualization"",""Cloud migration experience (Azure)"",""Strong communication and presentation skills""],""nice_to_have"":[""Experience with Power BI, Tableau, or other data visualization tools"",""Knowledge of NoSQL databases and social media data sources"",""Familiarity with data quality rules and remediation""]},""proposed_screening_questions_with_answers"":[{""question"":""What is the most complex SQL query you have written, and how did you optimize its performance?"",""example_answer"":""I once wrote a query that joined multiple large tables and optimized it by using indexing and subqueries, resulting in a 50% reduction in execution time.""},{""question"":""Can you describe a time when you had to communicate complex data insights to a non-technical stakeholder?"",""example_answer"":""I once presented data-driven recommendations to a product owner, using visualizations and clear explanations to ensure they understood the insights and could make informed decisions.""}],""red_flags"":[""Avoid candidates without cloud experience (Azure)"",""Be cautious of candidates with limited experience in data analysis, querying, cleaning, and visualization""],""confidence_score"":90.0}"
Partnershipstaffing,"Abbotsford, British Columbia, Canada",1 month ago,June,2024,"Our expertise has made us the preferred video agency and partner for a diverse range of clients, both nationally and internationally. We have valued partnerships with media and advertising agencies, publishers, and influential broadcasters, solidifying our position as a trusted name in the industry.

As part of our continued growth, we are excited to announce the opening of our new office in North America. We invite talented job candidates to join us on this journey and be at the forefront of our expanding operations

About The Role

As an Entry-Level Data Analyst you will have the chance to learn and develop essential data analysis skills while contributing to meaningful projects. You will work closely with experienced data analysts and collaborate with cross-functional teams to support our data-driven decision-making process.

Responsibilities

Data Collection and Analysis:

Assist in collecting, cleaning, and organizing data from various sources.

Learn to use data analysis tools and techniques to ensure data accuracy.

Reporting and Visualization:

Support the creation of reports and dashboards using tools like [Excel, Power BI].

Assist in visualizing data to communicate insights effectively.

Data Analysis

Work under the guidance of senior analysts to perform data analysis and generate insights.

Learn to use statistical methods to identify trends and patterns.

Collaborative Approach:

Collaborate with team members to understand data-related needs and provide assistance.

Communicate findings and insights to colleagues and stakeholders.

Continuous Learning:

Engage in ongoing training and development to enhance your data analysis skills.

Stay updated on industry best practices and emerging trends.

About You

Bachelor's degree in a related field (e.g., Data Science, Statistics, Mathematics, Computer Science) or relevant coursework.

Strong interest in data analysis and a desire to learn and grow in this field.

Basic knowledge of data analysis tools or programming languages is a plus (e.g., Excel, SQL, Python).

Excellent problem-solving skills and attention to detail.

Effective communication and a willingness to work collaboratively.

Eagerness to take on new challenges and a strong desire to develop as a data analyst.

What we offer

A Highly Competitive Remuneration

Comprehensive medical, dental, and vision insurance

401(k)

Paid parental leave

Flexible Work Arrangements

Gym memberships/yoga & meditation classes

How to apply

Please note that we prefer direct communication with candidates and have not engaged any recruitment agency for this position. Therefore, we will not accept CVs or applications submitted through any recruitment agency.

We are committed to providing equal employment opportunities to all individuals, regardless of race, gender, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information, or any other characteristic protected by applicable law. We value and celebrate the unique qualities that each team member brings to our organization, and we encourage all employees to embrace their true selves. We believe that diversity and individual differences enrich our team and contribute to our success. Join ustoday, and we are confident it will be a transformative experience!

Powered by Webbtree","{""role_summary"":""Assist in data collection, analysis, and visualization to support data-driven decision-making, while learning and growing as a data analyst."",""key_terms"":[{""term"":""Data Analysis"",""explanation"":""The process of extracting insights from data to inform business decisions.""},{""term"":""Data Visualization"",""explanation"":""The presentation of data in a clear and concise manner to facilitate understanding.""},{""term"":""Statistical Methods"",""explanation"":""Mathematical approaches used to identify trends, patterns, and correlations within data.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in a related field"",""Strong interest in data analysis"",""Excellent problem-solving skills"",""Effective communication""],""nice_to_have"":[""Basic knowledge of data analysis tools or programming languages"",""Experience with Excel, SQL, Python""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a time when you had to collect and analyze data to inform a business decision?"",""example_answer"":""In my previous internship, I was tasked with analyzing customer purchase patterns to identify trends and opportunities. I used Excel to collect and clean the data, and presented my findings to the marketing team, which led to a 10% increase in sales.""},{""question"":""How do you stay updated on industry trends and emerging technologies in data analysis?"",""example_answer"":""I regularly read industry blogs and attend webinars on topics like machine learning and data visualization. I also participate in online forums to stay current on best practices and network with other professionals in the field.""}],""red_flags"":[""Lack of enthusiasm for learning and growing in the field of data analysis"",""Inability to communicate complex data insights effectively to non-technical stakeholders""],""confidence_score"":85.0}"
Data Analyst – Information Management,NES Fircroft,"Calgary, Alberta, Canada",June,2024,"NES Fircroft is a leading global technical recruitment company providing professional contract and permanent staff to a diverse world-wide client base within the oil & gas Industry.

Job Title: Data Analyst – Information Management
Location: Calgary
Length: 12 Month contract to start
Rotation: Mon - Fri

Description:
We are looking for an experienced and detail-oriented IM Data Analyst. This position will be responsible for the management & control of the Superior Refinery master process safety data / drawings to be compliant with and support the Operational Integrity Management Element 4 Information Management (IM) practices and OSHA Process Safety Information requirements, including Management of Change (MOC).

Successful applicants will have a strong background in information management to provide quality control on project engineering drawing deliverables metadata handed over from projects to ensure company expectations are met and the drawings represent the asset engineering information expected.

Applicants must be passionate, dynamic, energetic, and persistent to drive change and transition refinery to modern data driven systems, including development of methodology and procedures.

Responsibilities
Review and quality check incoming process safety information and drawings packages to ensure all required drawings/technical/ safety / operations documents are received contain accurate information
Manage equipment & instrument databases, assign equipment & instrument numbers as requested
Ensure equipment tags contain the consistent and correct metadata, providing a way to quickly get process/asset/equipment documents in a timely manner for refinery’s daily operations.
Maintain control of Process Safety Information master copies of drawings, technical / operations / safety documents and technical documents issued to internal/external users.
Collaborate with technical services, maintenance, and operations function of the Superior Refinery.
Work effectively with staff at various levels, within the refinery and with the corporate head office with tact and diplomacy
Ensure current revision of all Process Safety Information, including Safe Operating Procedures, drawings, technical / operations / safety documents are available, issued and tracked. Assign document numbers as requested. Support management of concurrent engineering & redline processes
Maintain control of Process Safety Information master copies of drawings, technical / operations / safety documents and technical documents issued to internal/external users.
Review and quality check incoming process safety information and drawings packages to ensure all required drawings/technical/ safety / operations documents are received contain accurate information
Manage equipment & instrument databases, assign equipment & instrument numbers as requested
Provide training to Site team when required for Process Safety Information management. Collaborate with internal stakeholders and team members to identify and change current processes for more efficient working activities
Create value-add dashboards to track data quality across departments for accurate, timely information. Good data will help increase production time by limited asset downtime, Process Safety incidents which will ultimately reduce operational and incident costs

Required Skills and Experience
Understanding of taxonomy, metadata, and document management practices
Tracking record managing KPI and records retention compliance. Managing documents in a controlled environment, revision tracking
Demonstrated experience in writing and implementing information management standards, procedures, and processes
Understanding of various systems such as MSDP (procedural documents), SAP PM (Plant Maintenance data) and TechDocs (Engineering documents)
Demonstrated understanding of engineering and supporting documentation, revision control, review & approval process, understanding Project life cycle
Proficiency in identifying Engineering Drawing document types
Detail attention to data and the ability to create comparative analysis to identify and correct integrity issues
Proficient in MS Office and Livelink, and Share Point
Working Knowledge of petroleum/oil& gas industry; Engineering disciplines, Terminology/industry accepted file types (.dgn, .tif, etc)
Related Bachelor's or Technical College Diploma (information science, records management, archival science, engineering, science, process safety etc.) is an asset
ECMS, ECMM, RM or AIIM certification is a strong asset
Experience in process safety, records management, information management or document control (3-5 years)
Experience in oil and gas, Owner Operator, large Contractor, or EPC industry related experience (3-5 years)

Apply here or send your resume to trevor.parlee@nesfircroft.com","{""role_summary"":""Manage and control process safety data and drawings to ensure compliance with operational integrity management element 4 information management practices and OSHA process safety information requirements."",""key_terms"":[{""term"":""Operational Integrity Management Element 4 Information Management (IM) practices"",""explanation"":""A set of guidelines for managing process safety information to ensure operational integrity.""},{""term"":""OSHA Process Safety Information requirements"",""explanation"":""Regulatory requirements for managing process safety information to ensure a safe working environment.""},{""term"":""Management of Change (MOC)"",""explanation"":""A process for managing changes to process safety information and drawings.""},{""term"":""Metadata"",""explanation"":""Data that provides information about other data, such as equipment tags and instrument numbers.""},{""term"":""Process Safety Information master copies"",""explanation"":""Authorized copies of process safety information and drawings.""},{""term"":""Safe Operating Procedures"",""explanation"":""Procedures for safely operating equipment and processes.""},{""term"":""Concurrent engineering & redline processes"",""explanation"":""A process for managing multiple versions of process safety information and drawings.""},{""term"":""Taxonomy"",""explanation"":""A system for classifying and organizing process safety information and drawings.""},{""term"":""MSDP (procedural documents)"",""explanation"":""A system for managing procedural documents.""},{""term"":""SAP PM (Plant Maintenance data)"",""explanation"":""A system for managing plant maintenance data.""},{""term"":""TechDocs (Engineering documents)"",""explanation"":""A system for managing engineering documents.""}],""skill_priorities"":{""must_have"":[""Understanding of taxonomy, metadata, and document management practices"",""Demonstrated experience in writing and implementing information management standards, procedures, and processes"",""Understanding of various systems such as MSDP, SAP PM, and TechDocs"",""Proficiency in identifying Engineering Drawing document types"",""Proficient in MS Office and Livelink, and Share Point""],""nice_to_have"":[""ECMS, ECMM, RM or AIIM certification"",""Experience in oil and gas, Owner Operator, large Contractor, or EPC industry related experience (3-5 years)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with managing process safety information and drawings?"",""example_answer"":""I have 3-5 years of experience in managing process safety information and drawings in the oil and gas industry.""},{""question"":""How do you ensure data quality and integrity in your work?"",""example_answer"":""I use comparative analysis to identify and correct integrity issues, and I have a strong attention to detail.""},{""question"":""Can you describe your experience with information management standards, procedures, and processes?"",""example_answer"":""I have demonstrated experience in writing and implementing information management standards, procedures, and processes in my previous roles.""}],""red_flags"":[""Lack of experience in managing process safety information and drawings"",""Inability to work in a fast-paced environment with multiple stakeholders""],""confidence_score"":90.0}"
"Staff Data Analyst, Growth",Stripe,"Toronto, Ontario, Canada",June,2024,"Who we are

About Stripe

Stripe is a financial infrastructure platform for businesses. Millions of companies—from the world’s largest enterprises to the most ambitious startups—use Stripe to accept payments, grow their revenue, and accelerate new business opportunities. Our mission is to increase the GDP of the internet, and we have a staggering amount of work ahead. That means you have an unprecedented opportunity to put the global economy within everyone’s reach while doing the most important work of your career.

About The Team

Our GTM (Go-To-Market) Analytics team is on the mission to maximize revenue by providing actionable insights and reporting to our partners across Sales, Marketing, and Growth. GTM Analytics is situated within the broader Data Science organization at Stripe, which is home to a diverse team of data analysts and scientists, product managers, and engineers that span their focus across sales, marketing, and product-led growth. GTM Analytics leverages sales, marketing, and product data to build and provide a wide variety of tools that are utilized across the company to drive business decisions.

What you’ll do

As a senior member of the GTM Analytics team, you will lead analytical projects that shed light on our self-service business. You will increase our understanding of growth drivers and influence business outcomes by recommending solutions rooted in analyses and your deep understanding of Stripe’s users. You will partner closely with cross-functional Growth pods of product managers, marketers, engineers, and data analysts and scientists that obsess over the experience Stripe users have on their journey to become customers – from initial signup through onboarding and retention.

Responsibilities

Collaborate with Growth stakeholders to ideate, scope, and develop data products that shed light on Stripe’s self-service business.
Influence Stripe’s Growth roadmap by proactively identifying opportunities and emerging trends in Stripe’s Growth business in ongoing forums.
Develop frameworks that allow for analysis at scale across Stripe’s self-service experience.
Build and maintain data pipelines and dashboards that provide consistent and timely data and insights.
Work with finance partners on forecasting and planning models that provide visibility into the future of Stripe’s self-service business.
Define key Growth metrics, gain consensus around their definitions, and drive adoption of their usage.


Who you are

We’re looking for someone who meets the minimum requirements to be considered for the role. If you meet these requirements, you are encouraged to apply. The preferred qualifications are a bonus, not a requirement.

Minimum Requirements

8+ years of experience in analytical roles working with large datasets
Bachelor’s degree in Statistics, Economics, Mathematics, Engineering, Sciences or a related quantitative field
Proficiency in SQL and Python
Experience building self-serve dashboards or other scalable analytical tools for partner teams
Strong knowledge of statistics
Expertise in data storytelling and visualization, using data-driven insights to deliver actionable recommendations and drive business goals
Demonstrated ability to lead and deliver on multiple projects with a high attention to detail
Outstanding written and verbal communication skills


Preferred Qualifications

Master’s degree in Statistics, Economics, Mathematics, Engineering, Sciences or a related quantitative field and/or experience in working on data analytics in the tech field
Experience developing data-informed narratives and visualizations for external publication
Experience working with institutions that are respected by policymakers and the wider public for their economic insight
Experience building and maintaining data pipelines using a distributed data framework (e.g. Hadoop, Spark)


Hybrid work at Stripe

This role is available either in an office or a remote location (typically, 35+ miles or 56+ km from a Stripe office).

Office-assigned Stripes spend at least 50% of the time in a given month in their local office or with users. This hits a balance between bringing people together for in-person collaboration and learning from each other, while supporting flexibility about how to do this in a way that makes sense for individuals and their teams.

A remote location, in most cases, is defined as being 35 miles (56 kilometers) or more from one of our offices. While you would be welcome to come into the office for team/business meetings, on-sites, meet-ups, and events, our expectation is you would regularly work from home rather than a Stripe office. Stripe does not cover the cost of relocating to a remote location. We encourage you to apply for roles that match the location where you currently or plan to live.

Pay and benefits

The annual US base salary range for this role is $179,000 - $268,400. For sales roles, the range provided is the role’s On Target Earnings (""OTE"") range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. This salary range may be inclusive of several career levels at Stripe and will be narrowed during the interview process based on a number of factors, including the candidate’s experience, qualifications, and location. Applicants interested in this role and who are not located in the US may request the annual salary range for their location during the interview process.

Additional benefits for this role may include: equity, company bonus or sales commissions/bonuses; 401(k) plan; medical, dental, and vision benefits; and wellness stipends.","{""role_summary"":""Lead analytical projects to shed light on Stripe's self-service business, influencing business outcomes through data-driven insights and recommendations."",""key_terms"":[{""term"":""GTM Analytics"",""explanation"":""A team that provides actionable insights and reporting to partners across Sales, Marketing, and Growth.""},{""term"":""Self-service business"",""explanation"":""Stripe's business model where customers sign up and onboard without direct sales involvement.""},{""term"":""Data pipelines"",""explanation"":""Systems that extract, transform, and load it into a target system for analysis and reporting.""}],""skill_priorities"":{""must_have"":[""8+ years of experience in analytical roles"",""Proficiency in SQL and Python"",""Experience building self-serve dashboards"",""Strong knowledge of statistics"",""Expertise in data storytelling and visualization""],""nice_to_have"":[""Master's degree in a quantitative field"",""Experience working on data analytics in the tech field"",""Experience building and maintaining data pipelines""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach building a data pipeline for Stripe's self-service business?"",""example_answer"":""I would start by identifying the key data sources, then design a scalable pipeline using a distributed data framework like Hadoop or Spark, ensuring data quality and integrity.""},{""question"":""Can you give an example of a data-driven insight you've delivered to drive business goals?"",""example_answer"":""In my previous role, I analyzed customer behavior and identified a trend that led to a 15% increase in sales. I presented the findings to the product team, and we implemented changes that resulted in a 20% revenue growth.""}],""red_flags"":[""Lack of experience working with large datasets"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
Functional Data Analyst ,Matrix,"Montreal, Quebec, Canada",June,2024,"A cybercrime investigator or a functional data analyst

The IT Delivery group supporting the Fight against Financial Crimes sector is currently looking for an analyst who wishes to contribute to the evolution of the sector's processes and application base and its business partners. This position is part of a sector transformation framework, including new working practices (agility) and various initiatives of all sizes.

Act as a functional analyst in the field of cybercrimes
Participate in highly strategic initiatives for the Bank relating to the prevention of money laundering and fraud
Understand the strategy, issues, and operational reality of business sectors to properly guide IT teams in developing innovative and efficient solutions
Identify and mitigate impacts in transformation projects, current programs as well as new initiatives
Ensure the link between business requirements and the development team

Requirements:
Minimum five years of experience in functional analysis for large-scale projects.
Experience in Agile Scrum delivery.
Knowledge of fraud and compliance areas is beneficial.
Strong communication skills and ability to simplify complex IT concepts.
Bilingualism (French and English) is essential.
Contribute to strategic planning and Agile transformation.
Participate in testing phases.

Matrix Global Services is a leading multinational corporation providing innovative and comprehensive technology, consulting, and outsourcing solutions. For over thirty years, Matrix has established itself as a trusted partner for businesses across various industries, consistently delivering exceptional results.
We're a network of firms in 10+ countries with over 13,000 people. At Matrix, we pride ourselves on our commitment to excellence and our ability to adapt to our clients' ever-changing needs. Our team of highly skilled professionals is adept at understanding complex business challenges and tailoring solutions that drive sustainable growth and profitability.
Our wide range of services includes cutting-edge technology solution services, strategic consulting, digital transformation, cloud computing, cybersecurity, and managed services. Whether it's developing customized software applications, streamlining business processes, implementing robust IT infrastructure, or managing complex projects, our expertise and industry knowledge enable us to deliver value-added solutions that meet each client's unique requirements.
Come and join a winning team! You'll be challenged, have fun, and be part of a highly respected organization! Matrix offers a competitive base salary and a complete benefit package. Benefits include medical, dental, 401 (k), STD, HSA, and PTO.

EQUAL OPPORTUNITY EMPLOYER: Matrix is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind. Matrix is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Matrix are based on business needs, job requirements, and individual qualifications, without regard to race, color, religion or belief, family or parental status, or any other status protected by the laws or regulations in our locations. Matrix will not tolerate discrimination or harassment based on any of these characteristics. Matrix encourages applicants of all ages.","{""role_summary"":""Support the Fight against Financial Crimes sector by contributing to process and application evolution as a functional analyst, focusing on cybercrime prevention and mitigation."",""key_terms"":[{""term"":""Agile Scrum delivery"",""explanation"":""A project management approach that emphasizes flexibility and collaboration.""},{""term"":""Functional analysis"",""explanation"":""A method to identify and document business needs and requirements.""},{""term"":""Cybercrime prevention"",""explanation"":""Efforts to stop or reduce illegal activities involving computers or digital systems.""},{""term"":""Fraud and compliance"",""explanation"":""Regulations and measures to prevent and detect fraudulent activities.""}],""skill_priorities"":{""must_have"":[""Five years of experience in functional analysis for large-scale projects"",""Experience in Agile Scrum delivery"",""Strong communication skills"",""Bilingualism (French and English)""],""nice_to_have"":[""Knowledge of fraud and compliance areas""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with Agile Scrum delivery in a large-scale project?"",""example_answer"":""In my previous role, I worked on a project with multiple teams, and we used Agile Scrum to deliver the project on time.""},{""question"":""How do you ensure effective communication between business stakeholders and IT teams?"",""example_answer"":""I use simple language to explain complex IT concepts, and I involve stakeholders in the development process to ensure their needs are met.""}],""red_flags"":[""Lack of experience in Agile Scrum delivery"",""Inability to communicate complex IT concepts to non-technical stakeholders""],""confidence_score"":85.0}"
"Analyst, Contact Centre Reporting & Analytics",SiriusXM Canada,"Toronto, Ontario, Canada",June,2024,"JOB SUMMARY

This position will be accountable for the day-to-day analytics of inbound, chat and outbound 3rd party vendor performance, including performance management and incentives. The role will focus on the analysis of performance metrics.

JOB DETAILS

Accountabilities

Provide meaningful analysis and performance insights to support business plans and maximize performance. Fosters a customer-centric attitude and builds effective relationships with anyone connected to the customer (support or front-line).
Critically evaluating information gathered from multiple sources, reconciling conflicts, interpreting high-level information to glean details, and abstracting upwards from low-level information to assemble a general understanding.
Support the launch of new programs through incentive models, business flow updates, and updating reporting dashboards and SQL tables.
Analyzes vendor performance (cost, quality, productivity, satisfaction), and identifies trends and opportunities, issues, concerns, and successes.
Provide feedback and market intelligence to Operations, CRM, Workforce Training, and Quality to improve tools and resources as it relates to support, pricing, and marketing initiatives.
Create and monitor Call Centre performance reports (aftermarket, conversion, OTM, etc.)
Analyses incentive programs, delivering key insights and strategic recommendations to the vendor management team.
Prepare detailed reports and trend analysis so that decision-makers can quickly react.
Provide qualitative and quantitative reporting on all issues identified.
Create reporting to clearly display insights and communicate findings to business partners.
Act as a liaison with Call Centre Operations, Aftermarket, Conversion, and Information Technology teams on system enhancement requirements
On-going auditing of systems to ensure data accuracy and agent compliance to processes.
Provide weekly recap of forecast based on planned activities through the issuance of dashboards and performance metrics.
Provide ad-hoc analysis reports to business units as required.

KNOWLEDGE AND SKILL REQUIREMENTS

Level of Education
Bachelor’s degree in data science, computer science, statistics, mathematics, or a related field.

Job Related Experience
2+ years of experience in data analysis, modelling, or governance. Prior experience with subscription-based services or call center analytics is highly beneficial.

Skills and Background
Proficiency in SQL and Python within cloud environments.
Experience with ETL processes, data modelling, and database querying.
Advanced proficiency in Excel and BI tools such as Power BI or Tableau.
Familiarity with machine learning and AI techniques as a strong asset.
Knowledge of automation tools and methodologies to streamline data processes.
Strong analytical and quantitative skills, including a thorough understanding of interpreting business needs and translation into application and operational requirements.
Working knowledge of database marketing mechanics.
Strong presentation skills.
Ability to simultaneously manage multiple analytics projects and deliverables.
Excellent communication skills (written and verbal).
Bilingual Spoken (English and French) is a definite asset.

COMMUNICATIONS

This position is frequently called upon to reach agreement with others in order to complete work activities; requires presenting a point of view at times and influence others to adopt a course of action.

SiriusXM Canada is committed to equity in employment and programming.","{""role_summary"":""This role is responsible for analyzing vendor performance, providing insights to support business plans, and maximizing performance. It involves fostering a customer-centric attitude, and building effective relationships with stakeholders."",""key_terms"":[{""term"":""ETL processes"",""explanation"":""Extract, Transform, Load - a method of data integration""},{""term"":""Data modelling"",""explanation"":""The process of creating a conceptual representation of data structures""},{""term"":""Machine learning and AI techniques"",""explanation"":""Methods used to enable machines to learn from data and make predictions or decisions""},{""term"":""Automation tools and methodologies"",""explanation"":""Techniques used to streamline data processes""},{""term"":""Database marketing mechanics"",""explanation"":""The process of using data to target and personalize marketing efforts""}],""skill_priorities"":{""must_have"":[""SQL"",""Python"",""ETL processes"",""Data modelling"",""Advanced proficiency in Excel"",""Strong analytical and quantitative skills""],""nice_to_have"":[""Familiarity with machine learning and AI techniques"",""Knowledge of automation tools and methodologies"",""Bilingual Spoken (English and French)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would analyze vendor performance and identify trends and opportunities?"",""example_answer"":""I would use SQL to extract data, then apply data modelling techniques to identify trends and opportunities. I would also use Excel to create reports and present my findings.""},{""question"":""How do you stay current with new tools and methodologies in data analysis?"",""example_answer"":""I regularly read industry blogs and attend webinars to stay up-to-date on the latest tools and methodologies.""}],""red_flags"":[""Lack of experience with subscription-based services or call center analytics"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
Mixedstaffingandrecruiting,Canada,1 month ago,June,2024,"We are seeking a motivated and analytic individual to join our team as a Remote Digital Data Analyst. As a Data Analyst, you will be responsible for interpreting and analysing large data sets, making data-driven decisions, and presenting findings to management.

Responsibilities

Collect and analyse large data sets from various sources
Interpret data and identify trends and patterns
Create reports and visualisations to communicate findings
Collaborate with cross-functional teams to provide data-driven insights
Continuously monitor data for accuracy and completeness
Identify areas for improvement and make recommendations

Requirements

Proficient in SQL, Excel, and data visualisation tools such as Tableau or Power BI
Strong analytic skills with the ability to interpret complex data
Excellent communication and presentation skills
Ability to work independently and as part of a team
Attention to detail and accuracy

If you are a self-starter who is passionate about data and enjoys problem-solving, we encourage you to apply. This is an entry-level position with room for growth within the company.

To apply, please submit your resume and cover letter highlighting your qualifications and why you would be a great fit for this position. We look forward to hearing from you!

Powered by Webbtree","{""role_summary"":""Analyse large data sets, make data-driven decisions, and present findings to management as a Remote Digital Data Analyst."",""key_terms"":[{""term"":""SQL"",""explanation"":""A programming language used for managing and manipulating data in relational database management systems.""},{""term"":""Data Visualisation"",""explanation"":""The process of creating graphical representations of data to better understand and present information.""},{""term"":""Tableau or Power BI"",""explanation"":""Data visualisation software used to create interactive dashboards and reports.""}],""skill_priorities"":{""must_have"":[""SQL"",""Excel"",""Data Visualisation"",""Analytic skills"",""Communication and presentation skills"",""Attention to detail and accuracy""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to interpret complex data and present your findings to a non-technical audience?"",""example_answer"":""In my previous role, I had to analyse customer purchase data and present my findings to the marketing team. I created a dashboard in Tableau to visualise the trends and patterns, and then presented my recommendations to the team.""},{""question"":""How do you ensure the accuracy and completeness of large data sets?"",""example_answer"":""I use a combination of data validation rules and data quality checks to ensure the accuracy and completeness of the data. I also continuously monitor the data for any discrepancies or errors.""}],""red_flags"":[""Lack of experience with data visualisation tools"",""Poor communication and presentation skills""],""confidence_score"":90.0}"
"Analyst, Data",Aecon Group Inc.,"Toronto, Ontario, Canada",June,2024,"Build Your Career at Aecon

Aecon is proud to build some of the most impactful infrastructure projects of this generation. From the roads and transit systems that connect our communities, to the communication networks that link us from coast-to-coast, and the water infrastructure that supplies our businesses and homes. Our integral work includes constructing the pipelines that join provinces with the energy that fuels the nation, and the airports and ports that connect us all. Aecon is there, safely and sustainably building the future.

We lead the infrastructure industry with purpose, and our people are at the heart of everything we do. Our business success relies on strong execution and continuous improvement – driven by the diversity, expertise and teamwork of our employees. We are always searching the globe for exceptional candidates to join the Aecon family and be a part of our forward-thinking, innovative, best-in-class organization!

What is the Opportunity?

Aecon Civil is a market leader with a self-perform competitive advantage and core local strength in key markets. We’re proud of our work helping to expand and improve Canada’s infrastructure and transportation networks, and we’re ready to build the future of our country.

We are currently seeking a Data Analyst to join our head office.

What You'll Do Here

Establish and maintain KPIs and supporting metrics to be used across the project to track performance
Develop reporting requirements with functional leads and utilize a standardized approach to performance reporting
Communicate with internal stakeholders to gather performance reporting data and share updates relevant to performance reporting and its processes
Support the use of reporting, cost, scheduling, and financial and other operational systems; develop reporting dashboards to inform performance of the project; and enable fast, easy, meaningful operational and business insights
Support the implementation and continuous improvement
Develop and maintain a comprehensive Performance Management Framework, including development of dashboards to monitor and analyze performance trends
Analyze, measure, and report on project goals and objectives, engineering and design performance, construction progress, schedule, financial performance, and other essential KPIs and metrics
Develop periodic and ad hoc performance reporting packages
Contribute to evidence-based decision-making to maximize the performance of the project
Analyze data from different sources (including SAP, Primavera P6, InEight (Hard Dollar) Estimating, Designers, Subcontractors, Aconex, etc.) to identify our challenges and opportunities
Experience with various data platforms such as Microsoft Power BI, Databricks, Apache Spark, Snowflake
Familiarity with data integration, ETL, visualization tools and technologies
Strong understanding of data governance, data quality and security best practices
Strong analytical and problem-solving skills, with the ability to troubleshoot complex issues
Ability to work in a fast-paced environment and managed multiple tasks simultaneously


What You Bring To The Team

Minimum of six (6) years’ related experience; or equivalent combination of education and experience in construction projects, including performance monitoring; information systems, financial systems, other construction performance management systems
Completion of a degree in Business Administration, Engineering, Science, Computer Science, Statistics, Economics, or Information Systems, or a related discipline, or a combination of education, training and experience deemed equivalent
Organizational skills to handle multiple tasks within a high-pressure work site environment
Excellent interpersonal and communication skills (written and oral)
Minimum 4 years experience with Power BI, Tableau, Qlik Sense
Experience with SQL, DAX, Python, R, SAP Webi, or other reporting and data analytics tools, an asset
Knowledge of Earned Value Management (EVM) Industry best practices: PMI, AACEI, etc.
Effective inter-personal communication and presentation skills to communicate effectively with stakeholders across different business units
Ability to work effectively with all levels of management and employees
Willingness for continuous learning and advancement of technical knowledge
Detail oriented
Must be able to travel to projects
Must possess valid G driver's license and have access to a vehicle


What Makes Us Aecon Proud

Engaging and agile workplace culture, collaborative and inclusive teams
Commitment to sustainability and to becoming a net-zero company by 2050
Investing in our people through a variety of learning and development programs such as Aecon University, BluePrint leadership program, and Project Management Academy
Variety of wellness benefits, access to virtual health care, 100% employer-paid health and dental premiums, Employee Assistance Program, Best Doctors Program, and more.
Tuition reimbursement opportunities
Recognition and rewards through Aecon Accolades, Aecon Achievement Awards and more
Employee Stock Options, Short Term Incentive Program, Retirement Savings and Pension Plan


Aecon fosters diversity , inclusion and belonging within and across our organization. We welcome all to apply including, women, visible minorities, Indigenous peoples, persons with disabilities, and persons of any sexual orientation or gender identity. If you require accommodation during any step of the application process, please click here.","{""role_summary"":""A Data Analyst responsible for establishing and tracking performance metrics, developing reporting dashboards, and analyzing data to inform project decisions."",""key_terms"":[{""term"":""KPIs"",""explanation"":""Key Performance Indicators used to track project performance.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process used to integrate data from different sources.""},{""term"":""Data Governance"",""explanation"":""Policies and procedures to ensure data quality, security, and integrity.""},{""term"":""Earned Value Management (EVM)"",""explanation"":""A method to measure project progress and performance.""}],""skill_priorities"":{""must_have"":[""Experience with data platforms (Microsoft Power BI, Databricks, Snowflake)"",""Familiarity with data integration, ETL, visualization tools and technologies"",""Strong analytical and problem-solving skills"",""Ability to work in a fast-paced environment and manage multiple tasks simultaneously"",""Minimum of six (6) years' related experience""],""nice_to_have"":[""Experience with SQL, DAX, Python, R, SAP Webi, or other reporting and data analytics tools"",""Knowledge of Earned Value Management (EVM) Industry best practices"",""Minimum 4 years experience with Power BI, Tableau, Qlik Sense""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would develop a comprehensive Performance Management Framework for a construction project?"",""example_answer"":""I would start by identifying key performance indicators, developing dashboards to monitor and analyze performance trends, and establishing a standardized approach to performance reporting.""},{""question"":""How do you ensure data quality and security in your work?"",""example_answer"":""I follow best practices for data governance, ensuring data integrity, and implementing security measures to protect sensitive data.""}],""red_flags"":[""Lack of experience with data platforms (Microsoft Power BI, Databricks, Snowflake)"",""Inability to work in a fast-paced environment""],""confidence_score"":90.0}"
"Analyst, Business Intelligence and Reporting",Toronto Parking Authority,"Toronto, Ontario, Canada",June,2024,"Position Summary

Reporting to the Senior Specialist, Operations Business Intelligence, the Analyst, Business Intelligence and Reporting is integral to TPA’s success as a data informed organization. The Analyst works closely with all departments to maintain, implement, and drive a business intelligence and revenue management culture within the organization, while driving revenue growth, internal efficiencies and ensuring the continued growth of BI services. Key responsibilities of this position include analyzing complex business problems and providing strategic insight using internal and external data, identifying, and interpreting data trends, and producing reports. Through the use of BI tools, the Analyst uses data to provide insight, drive results and influence change across the organization.

Responsibilities

Data Analysis and Analytics

Analyze, manipulate, review and present large amounts of data to business partners and leaders
Ensure data quality throughout all stages, including data collection, normalization, and transformation
Develop and maintain key performance indicators, measuring performance of the business and relating findings to individual positions on various organizational levels
Maintain and create advanced dynamic data integrations to enable regular real time KPI reporting
Analyze performance results, identifying options of action and establish corrective initiatives to achieve better results.
Maintain and ensure accuracy of master data library, the one source of truth for entire organization, including inventory, pricing tables, pricing structures and hierarchies.
Increase revenue across the organization by analyzing and extracting insight from multiple sources of data

Data Mining and Statistical Modeling

Utilize machine learning and program languages to build mathematical models that apply to real-world scenarios in parking management. Document processes and outcomes
Generate revenue and transaction projections in collaboration with management, considering various data inputs. Ensure the integrity of data used for analysis through diligent processing and cleansing
Maintain and build occupancy, demand, and seasonality models to optimize pricing strategies for different customer segments.
Conduct dynamic competitor, venue, and sentiment analysis

Reporting

Create and maintain analytical reports and dashboards to monitor trends and detect outliers.
Responsible for the accuracy, quality & timeliness of fixed/ad hoc reporting and dashboards.
Monitor and analyze KPI results and help propose corrective actions for areas lagging behind targets
Explain insights, complex problems, solutions, or the essence of a quantitative model to non-technical staff
Leverage strong business acumen, presentation, and communication skills to create and present analysis in a relevant, consumable, meaningful and insightful ways.
Perform ad-hoc analysis and participate in special projects as necessary

Drive a Data Driven Culture

Build trust and adoption in Business Intelligence tools
Meet with internal BI stakeholders to provide coaching and onboarding. Motivate others; build commitment and excitement around shared goals and achievements.
Create organization impact and influence by leveraging networks and cross-functional partnerships.
Assist in the on-going development and deployment of advanced analytical tools within TPA, support training to all levels of competence
Other duties as assigned

QUALIFICATIONS:

Bachelor’s degree in business, Computer Science, Math, Statistics or Economics
1-3 years + of experience in a business intelligence, data science or revenue/yield management role
Experience converting large amounts of multi-faceted data into meaningful reports
Strong data visualization skills and experience using various visualization tools like PowerBI/Tableau/Looker or similar is required
Proficiency in open-source languages (R, Python), Excel, SQL, and relational databases is required
Advanced MS Office user, with a particular emphasis on advanced Excel skills (look-up functions, VBA macros, complex logical statements, charts pivot tables, etc.)
Experience using PHP, SAP, MS Fabric, Dax, and Google Analytics, considered an asset
Experience collecting large data from multiple sources including API and SFTP, considered an asset
Dynamic pricing experience and revenue management from parking, hotel, airline, or retail industries, considered an asset.
Experience designing, developing, implementing and maintaining a database, and programs to manage data analysis efforts
Strong project management skills with the ability to work on multiple concurrent projects
Ability to articulate analyses and communicate effectively with all levels of the organization
High level of curiosity and investigative mind-set with an attention to detail and accuracy
Team player with excellent organizational, evaluation and interpersonal skills
Internal candidates: No new or reclassified employee with less than one (1) year’s continuous on the job service may apply

Powered by JazzHR

x9m87GFSuc","{""role_summary"":""The Analyst, Business Intelligence and Reporting drives revenue growth, internal efficiencies, and BI services growth by analyzing complex business problems, identifying data trends, and producing reports."",""key_terms"":[{""term"":""Business Intelligence"",""explanation"":""Using data to inform business decisions and drive results.""},{""term"":""Management"",""explanation"":""Optimizing pricing strategies for different customer segments.""},{""term"":""Machine Learning"",""explanation"":""Building mathematical models to apply to real-world scenarios.""},{""term"":""Data Mining"",""explanation"":""Extracting insights from multiple sources of data.""},{""term"":""Statistical Modeling"",""explanation"":""Building models to optimize pricing strategies and predict revenue.""}],""skill_priorities"":{""must_have"":[""Experience with business intelligence tools"",""Strong data visualization skills"",""Proficiency in open-source languages (R, Python)"",""Experience with Excel, SQL, and relational databases"",""Strong project management skills""],""nice_to_have"":[""Experience with SAP, MS Fabric, Dax, and Google Analytics"",""Dynamic pricing experience and revenue management"",""Experience collecting large data from multiple sources"",""Experience designing, developing, implementing and maintaining a database""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure data quality throughout all stages of data analysis?"",""example_answer"":""I review and validate data at each stage, and perform regular audits to ensure accuracy.""},{""question"":""Can you explain a complex data trend to a non-technical stakeholder?"",""example_answer"":""I would use simple language and visualizations to explain the trend and its implications for the business.""}],""red_flags"":[""Lack of experience with business intelligence tools and data visualization"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
Data Analyst (Johnmaxwell Team),BCJobs,"Fort Langley, British Columbia, Canada",June,2024,"The Johnmaxwell Team is seeking a talented Data Analyst to join our team. The ideal candidate will be responsible for analyzing data to help drive key business decisions and improve overall performance. If you have a passion for data and a keen eye for detail, we want to hear from you!

Major Responsibilities And Objectives

Collect, clean, and analyze data from various sources
Identify trends and patterns in data to provide insights for decision-making
Create reports and visualizations to communicate findings to stakeholders
Collaborate with cross-functional teams to support data-driven initiatives
Develop and maintain databases for data storage and retrieval

Qualifications, Skills, and Experience:

Bachelor's degree in Data Science, Statistics, Computer Science, or related field
2+ years of experience in data analysis or a related role
Proficiency in data visualization tools such as Tableau or Power BI
Strong analytical and problem-solving skills
Excellent communication and presentation abilities
Experience working with SQL and Python

Value","{""role_summary"":""The Data Analyst role is responsible for analyzing data to drive business decisions and improve performance, with a focus on data collection, analysis, and communication of insights."",""key_terms"":[{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to communicate insights and trends.""},{""term"":""SQL"",""explanation"":""A programming language used to manage and analyze data in relational databases.""},{""term"":""Python"",""explanation"":""A programming language used for data analysis, machine learning, and automation.""}],""skill_priorities"":{""must_have"":[""Data analysis"",""Data visualization tools (e.g., Tableau, Power BI)"",""SQL"",""Python"",""Analytical and problem-solving skills"",""Communication and presentation abilities""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for identifying trends and patterns in data?"",""example_answer"":""I use a combination of statistical methods and data visualization tools to identify trends and patterns. For example, I might use Tableau to create interactive dashboards that help stakeholders understand complex data insights.""},{""question"":""How do you ensure data quality and integrity in your analysis?"",""example_answer"":""I follow a rigorous data cleaning and validation process to ensure that my analysis is based on accurate and complete data. This includes data profiling, data transformation, and data quality checks.""}],""red_flags"":[""Lack of experience with data visualization tools"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
Junior Business Data Analyst,Nuclear Promise X,"Kincardine, Ontario, Canada",June,2024,"Role Overview

We have an exciting opportunity for a Business Data Analyst to join our Data team. In this role, you will have the opportunity to be at the forefront of applying data and analytics to tackle business problems. This role is a unique opportunity to join a dynamic team of analytical professionals that partners with business and Technology to design innovative, value-adding customer engagement solutions for our clients.

This position is a full-time opportunity and is primarily a remote role, with the ability to go onsite at Bruce Power if needed. You possess a specialty/background with business intelligence or data analysis and will work heavily with the Power Platform (Power BI, Power Apps, and Power Automate) and have proficiency with SQL, while working with an innovative and collaborative team.

Responsibilities

Constantly look for new and innovative approaches to provide customers with a point of view on their data.
Examine customer reporting requirements and develop proposals of technical solutions and build the report that supports the requirements.
Manage the balance between customer expectations and delivering projects to their original specification.
Collaborate with Customer Success to identify needs and opportunities for improving reports and dashboards.
Analyze data and synthesize raw information into insights, and recommendations on how our customers are using our reports and dashboards.
Design and develop data pipelines and Power BI dashboarding solutions to deliver insights and actionable intelligence based on the client's data.
Mentor other Developers on technical solutions and/or escalated matters.
Monitor new developments in the Power Platform and Power BI space.
Work as part of a multidisciplinary team, including product owners, product managers, UX designers, and IT.
Prepare technical documentation.

What you bring to the table?

Bachelor's degree in Computer Science, Information Technology, Business Analytics, or related field, or an equivalent combination of education and experience.
Experience with performing data analysis, developing data warehouse models, and deploying business intelligence dashboards and solutions.
2-3 years of experience with Power BI or other visualization tools.
Skilled in client requirements gathering, process analysis, and testing.
Highly proficient in reading and writing SQL queries.
Proficiency in SQL, Microsoft SSMS and SSDT, and Databricks.
Ability to develop high-quality documentation and provide user guidance and assistance.
Effective analytical and communication skills.
Strong track record of being able to develop relationships with a multitude of stakeholders/peers.
Knowledge of Maximo/P6.
Previous experience within the nuclear industry would be a plus.
Must be eligible to work in Canada.

Is NPX right for you?

Do you have an intellectual curiosity that causes you to explore, experiment and build?
Do you like working with cutting edge technology to find solutions or opportunities that push up the innovation curve?
Do you enjoy working in an open-concept start-up environment where collaboration, diversity, and knowledge sharing are key values?
Are you seriously passionate about giving back and supporting your community?

About us

NPX was founded on the premise that innovation is the most important key to sustaining the nuclear energy industry. We source, implement, and integrate innovative technologies to make things better at nuclear power plants. We think differently and work differently. We are customer obsessed rather than competitor focused, passionate for innovation, long-term thinking and committed to operational excellence. We are a family, driven by the excitement of building technologies, inventing products, and providing services that change lives and give back to our community.

At NPX we are committed to building a warm, inclusive, and diverse environment. We believe that people do their best work when they feel safe, empowered, and supported.

To this end, we offer an excellent compensation and benefits package including:

High-growth position in the early stage of a scaling company
Competitive salary + benefits package 💸
Career Growth & Development Program 🌱
Flexible vacation and work model 🌴
NPX Days Off
Company-wide days off to reset and recharge
Professional Development Fund 📈
Competitive Maternity & Parental Leave 🍼
Focus on Mental Health ❤️‍🩹
Investing in your Future with a RRSP Plan 💵
A company culture built on trust, autonomy, and independence🤝
Volunteer and Fun Events ❣️
Referral Rewards 👋
Enjoy our welcome NPX Swag 🎁","{""role_summary"":""A Business Data Analyst role that applies data and analytics to business problems, partnering with business and Technology team to design innovative solutions."",""key_terms"":[{""term"":""Power Platform"",""explanation"":""A suite of Microsoft tools including Power BI, Power Apps, and Power Automate.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and manipulating data in relational database management systems.""},{""term"":""Data Pipelines"",""explanation"":""A series of processes that extract, transform, and load it into a target system for analysis and reporting.""},{""term"":""Business Intelligence"",""explanation"":""The process of gathering, analyzing, and presenting business data to inform business decisions.""}],""skill_priorities"":{""must_have"":[""Experience with Power BI or other visualization tools"",""Highly proficient in reading and writing SQL queries"",""Ability to develop high-quality documentation and provide user guidance and assistance""],""nice_to_have"":[""Previous experience within the nuclear industry"",""Knowledge of Maximo/P6""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to design and develop a data pipeline?"",""example_answer"":""In my previous role, I created a data pipeline using Power BI to analyze customer data and provide actionable insights.""},{""question"":""How do you stay current with new developments in the Power Platform and Power BI space?"",""example_answer"":""I regularly attend webinars and conferences, and participate in online forums to stay up-to-date with the latest developments.""}],""red_flags"":[""Lack of experience with Power BI or other visualization tools"",""Inability to write complex SQL queries""],""confidence_score"":90.0}"
Business Analyst/Data Analyst,J&M Group,"Toronto, Ontario, Canada",June,2024,"10+ years previous work experience as a Business or Data Analyst, or in a technical/functional Role

Experience working on Risk Data projects (Agile methodologies), sourcing, standardization, and aggregation of risk in one of the functional risk areas such as Counterparty/Credit Risk

Understanding of financial Instruments including several types of Fixed Income and Equity Instruments and their valuation; Exposure to Banking Loan Book and other products

Skills acquired in a market and/or counterparty risk management environment are transferable

Documentation skills ability to succinctly articulate requirements, summarize data analysis and present to business users and development team

Use of Python, Anaconda, Pandas, Jupyter and support of Developers working with a technology stack including Linux, Hadoop, Hive, Spark, and other big data technologies

Strong data analysis skills are required including analyzing large data sets in using SQL queries and other modelling tools

Producing and using Data Catalogues, understanding data models and business process modeling

Experience building enterprise scale applications involving large data volumes and computations

Bachelor's degree in Sciences, Information Technology, Computer Science or other quantitative discipline","{""role_summary"":""A Business or Data Analyst responsible for managing risk data projects, analyzing large datasets, and developing enterprise-scale applications."",""key_terms"":[{""term"":""Agile methodologies"",""explanation"":""A project management approach that emphasizes flexibility and collaboration.""},{""term"":""Financial Instruments"",""explanation"":""Types of investments, such as bonds and stocks, and their valuation.""},{""term"":""Counterparty/Credit Risk"",""explanation"":""The risk of loss due to a borrower's failure to meet their obligations.""},{""term"":""Big data technologies"",""explanation"":""Tools like Hadoop, Hive, and Spark used to process and analyze large datasets.""},{""term"":""Data Catalogues"",""explanation"":""A centralized repository of data assets, making it easier to find and use data.""}],""skill_priorities"":{""must_have"":[""Python"",""Data analysis skills"",""SQL"",""Experience with big data technologies""],""nice_to_have"":[""Anaconda"",""Hive"",""Spark"",""Linux"",""Hadoop"",""Business process modeling""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you've applied Agile methodologies in a previous project?"",""example_answer"":""In my previous role, I worked on an Agile team to develop a risk management application. We followed Scrum principles, holding daily stand-ups and sprint planning meetings.""},{""question"":""How do you stay up-to-date with new financial instruments and their valuation?"",""example_answer"":""I regularly read industry publications and attend webinars to stay current on new financial instruments and their valuation.""}],""red_flags"":[""Lack of experience with big data technologies"",""Inability to articulate technical requirements to non-technical stakeholders""],""confidence_score"":85.0}"
Research Data Analyst,Michael Garron Hospital,"Toronto, Ontario, Canada",June,2024,"Overview

Reporting to the Research Business Manager, the Research Data Analyst will be an integral part of the Department of Research & Innovation’s core services team, responsible for facilitating data access and analysis for research and quality improvement projects.

Additionally reporting to the Manager, Information Technology, the incumbent will closely partner with the Michael Garron Hospital (MGH) Information Technology Services (ITS) team to ensure alignment with MGH policies and practices.

The Research Data Analyst will be responsible for creating Cerner Command Language (CCL) reports to extract data from Cerner PowerChart (MGH’s electronic medical record); consult with research scientists and improvement leads to develop data analysis plans and ensure swift execution of data requests; interpret, identify, and analyze relevant variables from internal and external datasets; and prepare datasets for analysis and publication. Additional responsibility will include ad hoc report generation and data visualization to support data management activities, which may also include database validation, data review and quality control.

This is a contract position until March 31, 2026, with the potential to renew.

EDUCATION

A Bachelor’s degree in Statistics, Data Science, Computer Science, Industrial Engineering, Mathematics, Health Sciences or equivalent field.
Master’s degree, preferred.

Qualifications

Minimum of five (5) years of data analysis within a healthcare or research setting.
Minimum of five (5) years of programming experience in Microsoft SQL Server and Oracle environment.
Proficiency using SQL language, and experience using CCL and DA2; or a commitment to learn CCL.
Highly competent in computer programming using R or Python to perform data abstraction and reorganization.
Solid understanding of workflow analysis, requirements gathering, documentation and system design.
Knowledge and experience with Hospital Information Systems, (experience with Cerner HIS is preferred).
Experience using key software and databases such as: Oracle or SQL.
Solid understanding of testing methodologies and change management control.
Demonstrated ability to work independently and in a team environment.
Demonstrated flexibility with the ability to effectively and efficiently multi-task and prioritize work.
Must be able to maintain a high level of confidentiality with respect to all aspects of work being performed.
Familiarity with health care administrative datasets such as CIHI-DAD or NACRS is preferred.
Ability to work as part of a team and assist team members with tasks to keep projects on schedule.
Good interpersonal and communications skills, including the ability to express technical ideas that can be easily understood.
Good judgment and problem-solving skills, with the ability to make timely and sound decisions.
Able to prioritize responsibilities and organize workload to ensure that timeframes are met.
Strong interpersonal skills, proven leadership skills and exhibit a high level of professionalism.
Interest in the principles of Equity, Diversity, Inclusion, and Anti-racism.
All employees of Michael Garron Hospital (MGH), a division of Toronto East Health Network (TEHN) [formerly Toronto East General Hospital (TEGH)] agree to work within the legislated practices of the Occupational Health and Safety Act of Ontario.
All employees of MGH are responsible for contributing to a transparent culture of patient and staff safety by adhering to and abiding by patient and staff safety policies and procedures set by MGH.
All employees are accountable for protecting the psychological health and safety of themselves and their co-workers through adherence to MGH's policies and practices.

Vaccines (COVID-19 and others) are a requirement of the job unless you have an exemption pursuant to the Ontario Human Rights Code.","{""role_summary"":""The Research Data Analyst facilitates data access and analysis for research and quality improvement projects, partnering with the IT team to ensure alignment with hospital policies and practices."",""key_terms"":[{""term"":""Cerner Command Language (CCL)"",""explanation"":""A programming language used to extract reports from Cerner PowerChart, an electronic medical record system.""},{""term"":""Cerner PowerChart"",""explanation"":""An electronic medical record system implemented at Michael Garron Hospital.""},{""term"":""SQL"",""explanation"":""A standard programming language used for managing and analyzing relational databases.""},{""term"":""R or Python"",""explanation"":""Programming languages used for data abstraction, reorganization, and analysis.""},{""term"":""Hospital Information Systems (HIS)"",""explanation"":""A comprehensive system used to manage hospital operations, including patient data and administrative tasks.""},{""term"":""CIHI-DAD or NACRS"",""explanation"":""Healthcare administrative datasets used for research and analysis.""}],""skill_priorities"":{""must_have"":[""5+ years of data analysis experience in a healthcare or research setting"",""5+ years of programming experience in Microsoft SQL Server and Oracle environment"",""Proficiency in SQL language"",""Experience using CCL or commitment to learn"",""Highly competent in programming using R or Python""],""nice_to_have"":[""Master's degree"",""Experience with Hospital Information Systems (HIS), especially Cerner HIS"",""Familiarity with healthcare administrative datasets such as CIHI-DAD or NACRS""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to extract data from an electronic medical record system like Cerner PowerChart?"",""example_answer"":""In my previous role, I extracted patient data from Cerner PowerChart to analyze treatment outcomes. I used CCL to create custom reports and ensured data quality control.""},{""question"":""How do you ensure data quality and integrity when working with large datasets?"",""example_answer"":""I implement data validation checks and perform regular data reviews to ensure accuracy and consistency. I also document my processes to maintain transparency and reproducibility.""}],""red_flags"":[""Lack of experience with Cerner PowerChart or similar electronic medical record systems"",""Inability to work independently and efficiently in a fast-paced setting""],""confidence_score"":90.0}"
Toyandsons,"Pickering, Ontario, Canada",7 months ago,December,2023,"Summary:

The Data Analyst Full Time will be responsible for analyzing and interpreting large datasets to provide valuable insights and recommendations to the business. They will work closely with cross-functional teams to gather and analyze data, develop reports, and provide customized solutions to help the organization gain a competitive edge.

Responsibilities:

Analyze large data sets using advanced statistical techniques and tools to uncover trends, opportunities, and insights.
Develop, maintain and analyze performance metrics and reports that support data-driven decision-making processes.
Collaborate with stakeholders to identify business questions and translate them into data and analysis requirements.
Develop models and algorithms to help optimize business processes and drive efficiencies.
Design and execute A/B tests and experiments to identify opportunities for optimization.
Identify data quality issues and help to develop solutions to improve data integrity, accuracy, and completeness.
Manage data collection, cleansing, and manipulation processes to ensure data is readily accessible and easy to work with.
Prepare and present data-driven reports and insights to stakeholders, highlighting key findings and recommendations.

Qualifications:

1+ years of relevant experience in data analysis, preferably in the Internet and New Media industry.
Proven experience in analyzing large and complex datasets using SQL, R, Python, or related tools.
Strong analytical, critical thinking, and problem-solving skills.
Excellent communication and collaboration skills, with the ability to work effectively in a team environment.
Experience with data visualization tools such as Tableau, Power BI, or related tools.
Knowledge of statistical modeling, hypothesis testing, and A/B testing methodologies.
Familiarity with data management and ETL processes.
If you are interested in this position, please send your resume, contact information and salary requirements to : hiring@jobsai.live

Powered by Webbtree","{""role_summary"":""The Data Analyst is responsible for analyzing large datasets to provide insights and recommendations, working closely with teams to develop reports and solutions to drive business growth."",""key_terms"":[{""term"":""A/B testing"",""explanation"":""A method to compare two versions of a product or process to determine which one performs better.""},{""term"":""ETL"",""explanation"":""Extract, Transform, and Load data processes to manage and prepare data for use.""},{""term"":""Hypothesis testing"",""explanation"":""A statistical method to test a hypothesis about a population based on a sample of data.""},{""term"":""SQL"",""explanation"":""A programming language used to manage and analyze relational databases.""}],""skill_priorities"":{""must_have"":[""Experience with data analysis and statistical techniques"",""Strong analytical and problem-solving skills"",""Excellent communication and collaboration skills"",""Experience with data management and ETL processes""],""nice_to_have"":[""Experience in the Internet and New Media industry"",""Knowledge of data visualization tools such as Tableau or Power BI""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to analyze a complex dataset to inform business decisions?"",""example_answer"":""In my previous role, I analyzed customer purchase data to identify trends, which led to a 10% increase in sales.""},{""question"":""How do you ensure data quality and integrity in your analysis?"",""example_answer"":""I use data validation techniques and data profiling to identify errors and inconsistencies, and then develop processes to correct them.""}],""red_flags"":[""Lack of experience with data analysis and visualization tools"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
Mbstaffingservicesllc,"Cambridge, Ontario, Canada",1 month ago,June,2024,"We are seeking a highly motivated and detail-oriented Virtual Data Analyst to join our team. The Virtual Data Analyst will be responsible for analyzing large datasets, generating insights, and communicating findings to stakeholders. This is an entry-level position that offers the opportunity to work remotely and make a meaningful impact on our organization.

Responsibilities

Collect and analyze large datasets using a variety of tools and techniques

Identify trends, patterns, and anomalies in data and communicate findings to stakeholders

Develop and maintain dashboards and visualizations to provide stakeholders with a clear understanding of data trends

Assist with the development of data-driven strategies to improve business outcomes

Collaborate with cross-functional teams to support business needs and provide insights

Qualifications

Bachelor's degree in a related field such as Mathematics, Statistics, Economics, or Computer Science

Strong analytical and problem-solving skills

Proficiency in SQL, Python, and/or R

Knowledge of data visualization tools such as Tableau or Power BI

Excellent communication skills, both written and verbal

Ability to work independently and as part of a team

Benefits

Competitive salary and benefits package

Flexible work schedule

Opportunity for growth and advancement within the organization

Collaborative and inclusive work environment

Work from the comfort of your own home

Access to professional development and training opportunities

At our organization, we value diversity and are committed to creating an inclusive environment for all employees. We believe that everyone has a unique perspective to bring to the table and that our differences make us stronger. If you are a data-driven individual with a passion for problem-solving and a desire to make a meaningful impact, we encourage you to apply for this exciting opportunity.

Powered by Webbtree","{""role_summary"":""The Virtual Data Analyst analyzes large datasets, identifies trends, and communicates findings to stakeholders, contributing to data-driven strategies and business growth."",""key_terms"":[{""term"":""SQL"",""explanation"":""A programming language used for managing and analyzing relational databases.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to help stakeholders understand trends and patterns.""},{""term"":""Python"",""explanation"":""A popular programming language used for data analysis, machine learning, and automation.""},{""term"":""R"",""explanation"":""A programming language and environment for data analysis, statistical computing, and graphics.""},{""term"":""Tableau"",""explanation"":""A data visualization tool used to create interactive dashboards and reports.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in a related field"",""Strong analytical and problem-solving skills"",""Proficiency in SQL, Python, and/or R"",""Knowledge of data visualization tools such as Tableau or Power BI""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you identified a trend in a large dataset and how you communicated your findings to stakeholders?"",""example_answer"":""In my previous role, I analyzed customer purchase data and discovered a correlation between product categories. I created a dashboard in Tableau to visualize the trend and presented my findings to the marketing team, which led to a change in their targeting strategy.""},{""question"":""How do you approach data visualization, and what tools do you use to create effective dashboards?"",""example_answer"":""I follow a user-centered approach to data visualization, focusing on simplicity and clarity. I use a combination of Tableau and Power BI to create interactive dashboards that provide actionable insights to stakeholders.""}],""red_flags"":[""Lack of experience with data visualization tools"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
Senior Data Analyst - Canada,KTI Talent Indicator,Canada,June,2024,"We have an immediate need for Senior Data Specialists*** who can work the full life cycle, from requirement gathering to reporting data. The business has continued to evolve, and this growing group is the central hub for analytics and reporting for the entire company.

Skills And Attributes Needed

MS SQL, Power BI and Azure skills.
Ability to work with the business and to get an understanding and what is needed and then produce
Ability to work with multiple stake holders.
Strong analytical and problem-solving skills.
The title is Senior Data Analyst though we have a few people on the team and they tell is it’s all encompassing… Data Analyst, Business Analyst, Data Scientist, Data Engineer, ect…","{""role_summary"":""Work as a central hub for analytics and reporting, handling the full life cycle from requirement gathering to reporting data."",""key_terms"":[{""term"":""MS SQL"",""explanation"":""A database management system used for storing and retrieving data.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft for interactive visualizations and business intelligence.""},{""term"":""Azure"",""explanation"":""A cloud computing platform by Microsoft for building, deploying, and managing applications.""}],""skill_priorities"":{""must_have"":[""MS SQL"",""Power BI"",""Azure""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a project where you had to gather requirements from stakeholders and deliver a reporting solution?"",""example_answer"":""In my previous role, I worked with cross-functional teams to gather requirements and developed a reporting dashboard using Power BI, which improved business decision-making.""},{""question"":""How do you approach analytical problem-solving in a data-intensive environment?"",""example_answer"":""I use a structured approach to break down complex problems, identify key metrics, and develop data-driven solutions. I'm proficient in MS SQL and have experience working with large datasets.""}],""red_flags"":[""Lack of experience with MS SQL, Power BI"",""Inability to work with multiple stakeholders""],""confidence_score"":90.0}"
Senior Marketing Data Analyst,KOHO,Canada,June,2024,"About KOHO

KOHO’s purpose is to empower Canadians to build a great financial foundation with products that are radically transparent and easy to manage. We first launched in 2017, and we have since built a community of over 1 million users . Leading investors around the globe believe in our vision, and we’ve successfully raised over $320M to make our vision a reality.

Discover our culture here and get the inside scoop from our team here !

About The Role

KOHO is seeking a highly motivated Senior Data Analyst to collaborate with various departments in leveraging data for informed decision-making. If you thrive on automating reports, crafting insightful dashboards, and extracting actionable insights from financial data, this role is tailored for you. As part of our team, you will immerse yourself in writing SQL queries, crafting Python scripts, and engaging in consultative sessions with stakeholders across the business.

What You'll Do

Analyze existing data sources to develop accurate and insightful reports.
Create and deliver visually compelling dashboards to showcase key findings and emerging trends.
Perform in-depth analysis of marketing data to drive strategic decision-making.
Prioritize and manage incoming data requests effectively within your workflow.
Collaborate closely with other members of the data team to execute projects and uphold the integrity of our data warehouse as the cornerstone of truth at KOHO.

Who You Are

Proven experience in a data or marketing analyst role.
Proficiency in SQL for data manipulation, including self-joins, window functions, and parameter usage.
Intermediate proficiency in Python, including user-defined functions, API requests, and writing efficient loops.
Demonstrated experience with dbt from previous roles.
Basic proficiency in Python.
Strong quantitative and analytical skills, coupled with adept data gathering abilities.
Quick grasp of business concepts, metrics, and KPIs.
Ability to effectively multitask and prioritize assignments.
Well-organized with excellent time management skills.

At KOHO, we are dedicated to providing pay transparency to all candidates. Compensation at KOHO is determined through various factors including but not limited to: comparable salary market data within Canada, technical skill assessment, a holistic view of previous work history, and internal pay equity with other KOHO team members.

Target Base Salary Range

$80,500 — $105,000 CAD

What's In It For You?

We Invest Time And Resources Into Making Sure KOHO Is As Good As The People We Hire. Here Are Some Of The Reasons We Attract The Best People

🧘‍♂️ Balance Your Life - Company-wide summer wellness days, winter holiday closure, personal days, a wellness spending account, and maternity & parental leave top-up

💻 Remote First - Work from anywhere in Canada with a budget to set up your home office

🆙 Level Up - Access to an in-house certified performance coach and an annual training budget

🥅 Reach Your Goals - Salary assessments twice per year

🙌 The KOHO Culture - We have won 7 ""Great Place to Work ®"" awards since 2019

🤝 Be an Owner - Every KOHO employee gets a generous amount of equity with a 10 year exercise window

The KOHO culture is one of collaboration, creativity, and diverse perspectives. We are committed to building and fostering an inclusive, accessible environment for everyone. If you have any questions, concerns, or requests regarding accessibility needs, please contact peopleaccessibility@koho.ca and the People and Culture team will be happy to help.","{""role_summary"":""Collaborate with various departments to leverage data for informed decision-making, automating reports, crafting insightful dashboards, and extracting actionable insights from financial data."",""key_terms"":[{""term"":""SQL"",""explanation"":""A programming language used for managing and manipulating data in relational database management systems.""},{""term"":""Python"",""explanation"":""A high-level programming language used for general-purpose programming, data analysis, and more.""},{""term"":""dbt"",""explanation"":""A software tool used for data transformation and loading data into a data warehouse.""}],""skill_priorities"":{""must_have"":[""Proven experience in a data or marketing analyst role"",""Proficiency in SQL"",""Intermediate proficiency in Python"",""Demonstrated experience with dbt"",""Strong quantitative and analytical skills""],""nice_to_have"":[""Basic proficiency in Python"",""Ability to effectively multitask and prioritize assignments"",""Well-organized with excellent time management skills""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing existing data sources to develop accurate and insightful reports?"",""example_answer"":""I would start by identifying the key stakeholders and their requirements, then use SQL queries to extract the data, and finally, use data visualization tools to present the findings.""},{""question"":""How do you stay organized when managing multiple projects with competing deadlines?"",""example_answer"":""I prioritize tasks based on urgency and importance, break down larger tasks into smaller ones, and maintain a task list to track progress.""}],""red_flags"":[""Lack of experience with dbt"",""Inability to multitask and prioritize assignments""],""confidence_score"":90.0}"
"Consumer Insights, Analyst",Adecco,"New York, NY",March,2025,"Adecco Creative is partnering with one of NYC’s most iconic fashion brands to recruit for an Analyst, Brand Insights role. This position will be temp to perm and a hybrid schedule in Midtown Manhattan. This role will start immediately and relocation is not available.

Primary Purpose:
The Global Brand Analytics team is responsible for providing the insights, measurement frameworks, and self-serve tools to enable the Brand team to deliver its ambitious growth strategy.

As the Sr. Analyst, Brand Insights, you will play a critical role in supporting data driven decision-making through post-purchase surveys, brand lift studies, and creative pre-testing globally.

The successful individual will leverage their proficiency in Marketing Analytics to:
Design, implement, and analyze brand & campaign lift studies and creative pre-testing to assess marketing effectiveness and consumer sentiment in a timely manner.
Interpret survey results, identify trends, and generate actionable insights that inform marketing strategies, media planning, and creative optimizations.
Work closely with cross-functional teams to integrate marketing and consumer insights into campaign planning and brand strategy.
Develop and refine testing methodologies to assess creative impact, messaging effectiveness, and consumer engagement.
Create compelling reports and presentations that communicate insights and recommendations to stakeholders, including senior leadership.
Stay updated on post-purchase survey program, industry trends, emerging research methodologies, and best practices in marketing, creative and consumer insights.
Leverage marketing analytics tools, testing platforms, and data visualization tools to streamline processes and improve efficiency.

The accomplished individual will possess:
Bachelor’s degree in Marketing, Statistics, Business Analytics, or a related field
3+ years of experience in consumer insights, marketing analytics, or market research
Proficiency in survey tools (e.g., Medallia).
Familiarity with media measurement and brand tracking methodologies.
Strong knowledge of experimental design, A/B testing, and data interpretation.
Knowledge of statistical analysis and data visualization tools (Excel, SQL, Python, R, Tableau, Power BI).
Exceptional project management, analytical and problem-solving skills with keen attention to detail.
Excellent communication skills with the ability to convey complex findings to non-technical stakeholders.
Knowledge of ad effectiveness metrics and brand health tracking.
Experience working cross-functionally with marketing, data science/analytics, and creative teams","{""role_summary"":""Support data-driven decision-making by analyzing brand lift studies, creative pre-testing, and post-purchase surveys to inform marketing strategies and optimize campaigns."",""key_terms"":[{""term"":""Brand lift studies"",""explanation"":""Measuring the effectiveness of marketing campaigns on brand awareness and perception.""},{""term"":""Creative pre-testing"",""explanation"":""Assessing the impact of marketing creative on consumer sentiment and behavior before launching a campaign.""},{""term"":""Post-purchase surveys"",""explanation"":""Gathering feedback from customers after a purchase to understand their experience and sentiment.""},{""term"":""Marketing Analytics"",""explanation"":""Using data and statistical methods to measure and optimize marketing campaigns and strategy.""},{""term"":""Experimental design"",""explanation"":""A methodology for designing and analyzing experiments to measure the impact of marketing interventions.""},{""term"":""A/B testing"",""explanation"":""Comparing two versions of a marketing campaign to determine which performs better.""},{""term"":""Data visualization"",""explanation"":""Presenting data in a graphical format to facilitate understanding and insights.""},{""term"":""Ad effectiveness metrics"",""explanation"":""Measuring the performance of advertising campaigns in terms of reach, engagement, and conversion.""},{""term"":""Brand health tracking"",""explanation"":""Monitoring key performance indicators to assess its overall brand performance and reputation.""}],""skill_priorities"":{""must_have"":[""Marketing Analytics"",""Survey tools (e.g., Medallia)"",""Experimental design"",""A/B testing"",""Data interpretation"",""Statistical analysis"",""Data visualization tools (Excel, SQL, Python, R, Tableau, Power BI)""],""nice_to_have"":[""Familiarity with media measurement and brand tracking methodologies"",""Knowledge of ad effectiveness metrics and brand health tracking"",""Experience working cross-functionally with marketing, data science/analytics, and creative teams""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for designing and analyzing a brand lift study?"",""example_answer"":""I would start by defining the research objectives and identifying the key metrics to measure. Then, I would design the study, collect and analyze the data, and finally, present the findings and recommendations to stakeholders.""},{""question"":""How do you stay updated on industry trends and emerging research methodologies?"",""example_answer"":""I regularly read industry publications, attend conferences, and participate in online forums to stay current on the latest developments and best practices.""}],""red_flags"":[""Lack of experience in consumer insights, marketing analytics, or market research"",""Inability to communicate complex findings to non-technical stakeholders""],""confidence_score"":90.0}"
Senior BI Analyst,Safeway,"Denver, CO",March,2025,"About The Company

Albertsons Companies is at the forefront of the revolution in retail. With a fixation on raising the bar with innovation and building belonging through our culture, our team is rallying our company around a unique purpose: to create joy around each table and inspire a healthier tomorrow for every community.

Albertsons Companies is one of the largest food and drug retailers in the United States, with over 2,200 stores in 34 states and the District of Columbia. Our well-known banners include Albertsons, Safeway, Vons, Jewel-Osco, Shaw's, Acme, Tom Thumb, Randalls, United Supermarkets, Pavilions, Star Market, Haggen, Carrs, Kings Food Markets, and Balducci's Food Lovers Market. We support our stores with 22 distribution centers and 19 manufacturing plants.

Placing a premium on adaptability, safety and family well-being, our work model, Presence with a Purpose, offers a hybrid work environment between remote work and office time. A one-size-fits-all approach does not apply to everyone, and teams are empowered to make decisions best for them.

Bring your flavor

Building the future of food and well-being starts with you. Join our team and bring your best self to the table.

#bringyourflavor

What You Will Be Doing

The Own Brands Strategic Sourcing Department has an opening for a Senior BI Analyst.

The BI Analyst is responsible for delivering business solutions that collect, transform, analyze, and interpret data to draw key insights to support Strategic Sourcing in making an informed data-based and strategic decisions on category review and negotiations. Has a keen ability to extract data from a variety of sources across the Albertsons enterprise and use quantitative skill set to create dashboards, reports, metrics using a variety of business intelligence tools, techniques, and technology. This individual must have a unique combination of technical and business operations acumen and experience, coupled with strong emotional intelligence.

The position will be based in Boise, Idaho, or one of our main regional offices (Seattle, WA, Portland, OR, Pleasanton CA, Denver CO, Dallas TX, Chicago, IL, or Fullerton, CA, Phoenix, AZ).

Main Responsibilities

Partner with Own Brands Strategic Sourcing Team with business needs and provide solutions for data insights.
Analyze large and complex data sets and create optimized solutions to present actionable recommendations to Sourcing Managers.
Ability to take data with different ranges of complexity level from disparate sources across the enterprise and synthesize into meaningful business insights for Sourcing Managers.
Provide in-depth analytical support for a variety of sourcing initiatives including category reviews, new item cost analysis, and logistic assessments.
Aggregate data from RFI/RFP submissions and help create a decision matrix.
Prepare and present analytics results and recommendations to leaders by building visual charts, graphs, and process flows.
Create ad-hoc customized reports for a variety of needs/functions through platforms such as Power BI dashboard.
Lead creating training content for Strategic Sourcing Team such as excel tips and tricks.
Mentor BI Analysts.

The salary range is $82,900 to $115,000 annually. Starting salary will vary based on criteria such as location, experience, and qualifications. There may be flexibility for exceptional candidates.

What We Are Searching For

Preferred degree in: Business, Accounting, Supply Chain, Finance or equivalent.MBA preferred.
3- 5 years experience and /or the education listed above.
3+ years in business analytics and retail or backstage/corporate experience.
Knowledge in formal strategic sourcing processes and methodologies.
Excellent understanding of manufacturing, distribution and logistics.
Advanced ability to strategically plan data architecture and information needed to ensure relevant information is accessible.
Experience with Business intelligence visualization process Power BI or equivalent to create impactful reports and interactive dashboards
Ability to multi-task and manage a variety of business programs/initiatives in response to changing priorities
Ability to explain complicated or technical information in a streamlined manner to non-technical audiences
Strong analytical, quantitative, and problem-solving skills
Advanced computer skills including SQL, VBA, Excel, and PowerPoint. Ability to understand and work with multiple enterprise wide systems.
Experience pulling information or modifying/creating queries from database such as Snowflake, SSIMS and EDM.
Excellent oral, written and presentation communication skills.
Excellent relationship building and collaboration skills
High energy level and sense of urgency on executing initiatives.

What is it like at Albertsons?

Our 290,000 associates have a passion for great service and building lasting relationships with our customers. Through a companywide focus on innovation, we are continually enhancing our digital and product offerings, making it easy for customers to get what they need, wherever they are.

Albertsons is an Equal Opportunity Employer

This Company is an Equal Opportunity Employer, and does not discriminate on the basis of race, gender, ethnicity, religion, national origin, age, disability, veteran status, gender identity/expression, sexual orientation, or on any other basis prohibited by law. Consistent with applicable state and local law, the Company will consider for employment qualified applicants with arrest and conviction records.

We endeavor to make this site accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at 1-888-255-2269(option #4).","{""role_summary"":""The Senior BI Analyst will provide data insights to inform strategic sourcing decisions, analyzing complex data sets and presenting actionable recommendations to Sourcing Managers."",""key_terms"":[{""term"":""Business Intelligence"",""explanation"":""The practice of collecting, analyzing, and interpreting data to inform business decisions.""},{""term"":""Strategic Sourcing"",""explanation"":""The process of identifying and acquiring goods, services, or works from an external source, often involving category reviews and negotiations.""},{""term"":""Power BI"",""explanation"":""A business intelligence tool used to create interactive dashboards and reports.""}],""skill_priorities"":{""must_have"":[""3-5 years of experience in business analytics and retail"",""Knowledge of formal strategic sourcing processes and methodologies"",""Advanced ability to strategically plan data architecture and information"",""Experience with business intelligence visualization process"",""Strong analytical, quantitative, and problem-solving skills"",""Advanced computer skills including SQL, VBA, Excel, and PowerPoint""],""nice_to_have"":[""MBA"",""Experience with Snowflake, SSIMS, and EDM"",""Experience pulling information or modifying/creating queries from database""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a complex data set you've analyzed and the insights you drew from it?"",""example_answer"":""I analyzed a large dataset of customer purchasing behavior and identified a correlation between product placement and sales. I presented my findings to the marketing team, and we implemented a new product placement strategy, resulting in a 10% increase in sales.""},{""question"":""How do you stay current with new tools and technologies in business intelligence?"",""example_answer"":""I regularly attend industry conferences and webinars, and I participate in online forums and communities to stay up-to-date on the latest developments in business intelligence.""}],""red_flags"":[""Lack of experience with business intelligence tools such as Power BI"",""Inability to explain complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
Customer Data Analyst Intern (Summer 2025),L'OCCITANE Group (B Corp™),"New York, NY",March,2025,"Job Summary

As an Intern with L’Occitane en Provence North America you will undertake work on our different Data projects. L'Occitane group has built an ambitious Datahub program with the set up of a Datalake (Snowflake solution) to cover the analytical needs and different Master data platforms for operational needs around referential data (customers, products, stores). To drive the development of our data, the Data Intern will have the role to develop diversified projects on different business domains : Customers, Supply, and Finance. The Data Intern will work on projects such as data information capture and extraction using ETL, data quality and monitoring and/or build Finance/Supply reporting.

Job Responsibilities

The candidate will work on the Snowflake platform to monitor and improve the Data Quality in our different channels (Retail, Clienteling, E-commerce, CRM) on customer, finance and supply domains
Build and maintain Data flow to capture and propagate data in Customers, Finance and Supply domains using SQL language, ETL solution such as DBT, SSIS or Knime
Build and maintain Datamart using SQL language and DBT
Analyze data sets using SQL language
Build reports using PowerBI
In Data Science, if the candidate is skilled and autonomous, she/he can propose use cases using Machine learning scores and Large Language Model to improve our customer knowledge and KPI, create actionable data and automate process using Python, PowerBI report, Knime or OpenAI. For this expertise area, we are expecting the candidate to be autonomous and bring his/her expertise to the company

Key Performance Indicators

Data accuracy
Project completion in timely manner
Project deliverables
Fast learning curve
Accuracy of data
Autonomy
Curious

Requirements

EDUCATION:

Currently pursuing a bachelor's / master's degree in Computer Science

EXPERIENCE:

Prior internship experience or students projects with data projects and development

Skills

SQL (good knowledge and experience)
Data Modelization
Data flows (ETL, API)
Data Science
Python
Reporting

Physical & Travel Requirements

Hybrid or on site at NY office

Benefits Include

Competitive Compensation at $19/hour
School Credit Offered
A warm, open, fun, and friendly work environment
Generous L’Occitane employee discounts

All Applicants

L'Occitane's Privacy Statement

United States Applicants Only

Employee Rights

FMLA: Posters

FMLA Special Rules for Returning Military Members (USERRA)","{""role_summary"":""Assist in L'Occitane's Datahub program, developing projects on data quality, monitoring, and reporting across customer, finance, and supply domains."",""key_terms"":[{""term"":""Datahub"",""explanation"":""A centralized data management system for L'Occitane.""},{""term"":""Datalake"",""explanation"":""A storage repository for structured and unstructured data, used for analytics.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process for data integration and data migration.""},{""term"":""SQL"",""explanation"":""Structured Query Language - a standard language for managing relational databases.""},{""term"":""Machine learning scores"",""explanation"":""Predictive models that enable data-driven decision-making.""},{""term"":""Large Language Model"",""explanation"":""AI-powered models for natural language processing and understanding.""}],""skill_priorities"":{""must_have"":[""SQL"",""Data Modelization"",""Data flows (ETL, API)""],""nice_to_have"":[""Python"",""Reporting"",""Data Science""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would improve data quality in our customer channel using Snowflake?"",""example_answer"":""I would use Snowflake's data quality features to identify and correct errors, and then create a data validation process to ensure data accuracy.""},{""question"":""How would you build a data mart using SQL and DBT?"",""example_answer"":""I would design a data mart schema, create the necessary tables and relationships, and then use DBT to populate the data mart with data from our source systems.""}],""red_flags"":[""Lack of experience with data projects and development"",""Limited knowledge of SQL and data modeling""],""confidence_score"":85.0}"
Data Customer Insights Analyst,CAVA,United States,March,2025,"About CAVA:
At CAVA we make it deliciously simple to eat well and feel good every day. We are guided by a Mediterranean heritage that’s been perfecting how to eat and live for four thousand years. We prioritize authenticity, curiosity and the pursuit of excellence in everything we do. We are working towards something big, together.

We foster a culture built on five core values:
Generosity First, Always: We lead with kindness. Our best work happens when we act in service of others.
Constant Curiosity: We are eager to learn, grow, and explore beyond the obvious.
Act with Agility: We welcome change; it’s the only constant. We embrace, adjust, adapt.
Passion for Positivity: We greet each day with warmth and possibility.
Collective Ambition: We have high aspirations that are achieved when we work together with a shared purpose.

The Role:
We are seeking a highly motivated and analytical Customer Insights Analyst to help drive analysis, strategy, and reporting – fueling customer related initiatives across the business. This position will report to the Customer Analytics Manager and requires a unique balance of strong technical skills and ability to synthesize results + creatively propose business solutions.

What You’ll Do:
Play a technical and strategic role in driving all things customer insights and analytics while partnering internally to evaluate the success of customer initiatives
Own discrete analyses focused on but not limited to: CAVA’s loyalty program, personalization tactics, customer lifecycle (CLV, churn, etc.), customer preferences, and much more
Develop and apply research methodologies that align with key strategic goals across different stages of the customer lifecycle
Support design, creation, and publication of reports and dashboards for enterprise consumption
Create compelling visualizations using advanced analytics tools and tell revealing stories about the CAVA customer
Support the development and calculation of key KPIs to evaluate the success of customer initiatives and campaigns
Get to know the customer inside and out and generate creative ideas on how to better serve the customer that can be tested empirically through data
Advise on data-driven ways to segment the customer base in order to track and measure success of initiatives by customer cohort
Package strategic and analytical insights into clear, concise, and stakeholder ready presentations
Abide by policies and procedures that support the service mindset
Manage timeline expectations within and across teams, deliver on our responsibilities accordingly
Earn the trust of Team Members and Managers by consistently embracing CAVA’s values
Show discipline in bringing consistent performance, communication, and attitude to the job every day
Actively contribute to your department in order to complete tasks and meet company goals
Recognize the emotional stake each Team Member has in personal and organizational success of this business

The Qualifications:
1-3 years of professional experience working as a data analyst with a focus on strategic insights, either in consulting or at a consumer-facing company
Hands on and demonstrable experience working with large-scale data sets
Highly proficient in Excel – both manipulation and presentation of data
Highly proficient in SQL – data manipulation, aggregation, calculations
Highly proficient in PowerPoint – efficient and compelling slide creation
Experience with popular data visualization tools such as Tableau, Power BI, and Looker
Experience with common relational databases such as SQL DB, Redshift, Snowflake
Preferred: proficiency in Python or R for automation, statistical analysis, and data manipulation
Preferred: Bachelor’s Degree


Physical Requirements:
Ability to maintain stationary position to be able to operate a computer and other office equipment
Must be able to identify, analyze and assess details
For certain positions, must be able to occasionally move or transport items up to 50 pounds
Ability to communicate with others and exchange information accurately and effectively
Constantly positions self and move about to support ordinary restaurant or food production support or office operations, as applicable
Ability to work in a constant state of alertness and in a safe manner

What we offer:
Competitive salary, plus bonus and long-term incentives*
Early Wage Access!
Unlimited PTO, paid parental leave, plus paid opportunities to give back to the community
Health, Dental, Vision, Telemedicine, Pet Insurance plus more!
401k enrollment with CAVA contribution
Company-paid STD, LTD, Life and AD&D coverage for salaried positions*
Free CAVA food
Casual work environment
The opportunity to be on the ground floor of a rapidly growing brand
All exempt and non-exempt employees are eligible for benefits. Benefits are effective the 1st of the month following 30 days of service and you have until the day before the effective date to enroll. A new hire can enroll in our benefit program by selecting a link that is emailed directly to the new hire at their personal email address once hired.
Please note that visa sponsorship is not available. The compensation range posted includes total cash.


*Indicates qualifying eligible positions only

CAVA – Joining “A culture, not a concept”

This job description is not intended to be a comprehensive list of all the duties and responsibilities of the position and such duties and responsibilities may change without notice.As an equal opportunity employer, CAVA considers applicants for all positions without regard to race, color, sex, religion, national origin, disability, age, height, weight, marital status, sexual orientation, familial status, genetic information or any other characteristic or protected classes as defined by federal, state, or local law.","{""role_summary"":""The Customer Insights Analyst plays a technical and strategic role in driving customer insights and analytics, partnering internally to evaluate the success of customer initiatives."",""key_terms"":[{""term"":""Customer lifecycle (CLV, churn, etc.)"",""explanation"":""The stages a customer goes through from initial purchase to eventual churn, including customer lifetime value and churn rate.""},{""term"":""Personalization tactics"",""explanation"":""Methods used to tailor the customer experience to individual preferences and behaviors.""},{""term"":""Customer preferences"",""explanation"":""The likes, dislikes, and behaviors of customers that influence their purchasing decisions.""},{""term"":""Advanced analytics tools"",""explanation"":""Software used to analyze complex data, including data visualization tools like Tableau, Power BI, and Looker.""},{""term"":""Relational databases"",""explanation"":""Databases that organize and store data in a structured way, such as SQL DB, Redshift, and Snowflake.""}],""skill_priorities"":{""must_have"":[""Hands-on experience with large-scale data sets"",""High proficiency in Excel, SQL, and PowerPoint"",""Experience with data visualization tools like Tableau, Power BI, and Looker""],""nice_to_have"":[""Proficiency in Python or R for automation, statistical analysis, and data manipulation"",""Bachelor's Degree""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a time when you had to analyze a large dataset to inform business decisions?"",""example_answer"":""In my previous role, I analyzed customer purchase data to identify trends and opportunities for growth. I presented my findings to the marketing team, and we were able to increase sales by 15%.""},{""question"":""How do you stay current with new tools and technologies in the field of data analysis?"",""example_answer"":""I regularly attend industry conferences and webinars to stay up-to-date on the latest tools and methodologies. I also participate in online forums and communities to network with other professionals in the field.""}],""red_flags"":[""Lack of experience working with large-scale data sets"",""Inability to effectively communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
Data Analyst Intern,Farmer's Fridge,"Chicago, IL",March,2025,"Farmer’s Fridge is on a mission to make it simple for everyone to eat well. We serve healthy, handcrafted meals and snacks from our growing network of 1700+ Smart Fridges (software-enabled vending machines). We are striving to change the food system from the ground up – one Fridge or delivery at a time.

We are a team that cares -– about the business, the impact our product makes, and each other. We are data-driven, innovative, and quick to move on a good idea. We are looking for people who want to collaborate in an entrepreneurial, inclusive culture and have a passion to succeed.

Farmer’s Fridge is entering a period of rapid growth, and we are looking for a a motivated Data Analyst Intern with strong technical skills and business acumen to help turn millions of potential data points into models and actionable insights that can drive product improvements, make our customer acquisition more efficient, improve our customer retention rates, and drive operating efficiencies on our production and logistics teams.

In a Typical Week/month, You Will

Develop and maintain dashboards and reports using Tableau and Hex
Assist Farmer’s Fridge in FAQ about our data structure
Pull ad-hoc reports via SQL for stakeholders
Assist in SQL and Python code reviews to improve query efficiency and maintainability
Help clean, validate, and organize datasets to ensure data accuracy and consistency.
Document data processes and best practices for internal knowledge sharing.

What are we looking for in a Data Analyst intern?

You are creative, flexible, and supremely detail-oriented but never lose sight of the big picture. It would never occur to you to say, “that’s not my job”.
You are comfortable in an environment of high-growth and ambiguity.
You strive for optimization, automation, and continuous improvement, knowing that what is currently being done can always be improved.
You believe learning should be fun and seek to empower each employee at Farmer’s Fridge with the information, benchmarks, metrics, and insights that they need to be independently successful in their roles.

What background are we seeking for a Data Analyst intern?

Currently pursuing or recently completed a degree in Data Science, Computer Science, Statistics, or a related field.
Experience in SQL for querying and manipulating large datasets.
Experience with Python for data analysis and scripting (Pandas, NumPy, etc.).
Familiarity with data visualization tools such as Looker, Tableau, or Power BI.
Familiarity with or willing to learn: version control systems, cloud platforms, and exposure to data warehousing or data pipeline concepts
Understanding of basic analytics engineering concepts (e.g., data modeling, ETL processes).
Strong analytical mindset and problem-solving skills.
Ability to work independently and manage multiple tasks in a fast-paced environment.
Detail oriented, organized, and able to effectively communicate
Minimal supervision needed

What You’ll Gain

Hands-on experience in a real-world analytics environment.
Exposure to cutting-edge data tools and methodologies.
Opportunity to collaborate with experienced analysts and engineers.
Potential for future full-time opportunities based on performance.

Farmer’s Fridge Diversity Statement

""Don’t meet every single requirement? Studies have shown that women and people of color are less likely to apply for jobs unless they meet every single qualification. At Farmer’s Fridge, we are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyways. You may be just the right candidate for this or other roles.”

Farmer’s Fridge is an equal-opportunity employer. We are committed to providing equal employment opportunity in all employment practices, including hiring, without regard to race, color, religion, national origin, sex, gender identity, sexual orientation, age, disability status, veteran status, or any other characteristic protected by federal, state or local law. View our disclosures related to External Agencies and Applicants below: https://www.farmersfridge.com/careerdisclosures","{""role_summary"":""Assist in turning millions of data points into models and actionable insights to drive product improvements, customer acquisition, customer retention, and operating efficiencies."",""key_terms"":[{""term"":""SQL"",""explanation"":""Structured Query Language used for querying and manipulating large datasets.""},{""term"":""Python"",""explanation"":""Programming language used for data analysis and scripting with libraries like Pandas and NumPy.""},{""term"":""Tableau"",""explanation"":""Data visualization tool used for creating dashboards and reports.""},{""term"":""Data Warehousing"",""explanation"":""Concept of storing and managing data in a centralized repository for reporting and analysis.""},{""term"":""Data Modeling"",""explanation"":""Process of creating a conceptual representation of data structures and relationships.""}],""skill_priorities"":{""must_have"":[""SQL"",""Python"",""Data Visualization tools (e.g., Tableau)"",""Analytical mindset and problem-solving skills""],""nice_to_have"":[""Familiarity with version control systems, cloud platforms, and data warehousing or data pipeline concepts"",""Experience with Looker or Power BI""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach optimizing a slow-performing SQL query?"",""example_answer"":""I would use EXPLAIN to analyze the query plan, identify performance bottlenecks, and consider indexing or rewriting the query for better performance.""},{""question"":""Can you walk me through your process for data visualization in Tableau?"",""example_answer"":""I would start by identifying the key insights to convey, then choose an appropriate visualization, and finally ensure the dashboard is intuitive and interactive.""}],""red_flags"":[""Lack of experience with SQL or Python"",""Inability to work independently in a fast-paced environment""],""confidence_score"":90.0}"
Data Analysts,Kforce Inc,"Tampa, FL",March,2025,"Responsibilities

Kforce in Tampa, Florida is looking for Data Analysts. Qualified candidates will be analyzing user requirements, current business intelligence or trend data and defining functional specifications using Agile methodologies; Designing, building, and rolling out of high performing business intelligence tools or systems, including design of related master data management sets and maps for mining in a cloud (AWS/GCP) environment; Design and develop robust extract, transform, load (ETL) processes using Tableau, SQL, R, JavaScript, C#, Python, Jupyter, SAS, and SPSS; Developing and implementing complex business intelligence tools or data warehouse and systems using ETL tools, SQL, SQL Server, SQL Server Integration Services (SSIS) and SQL Server Reporting Services (SSRS) with Azure components; Creating dashboards using Snowflake SQL, Power BI and Visual Studio; Cleaning and analyzing large datasets for forecasting application usage utilizing Python, R and SQL; Maintaining or updating business intelligence tools, dashboards, or pipelines; Extracting and loading data between legacy systems; Building source-to-source target mapping to extract, transform and load (ETL) data into the data warehouse and cloud platforms; Designing reports and dashboards for the business intelligence solutions using Tableau; Deploying applications in Informatica and migrating the applications to different environments; and Documenting modifications and enhancements made to the applications, systems and databases as required by the project. Salary: $46.00 to $90.00/hr.

Requirements

Requirements: Bachelor's Degree or foreign degree equivalent in Computer Science, Computer Information Systems, Computer Applications, Information Technology, Information Systems and Technology or Engineering and six month's experience in position or six month's experience in IT or Data Analysis field. Special requirements: Experience with Tableau, SQL, R, JavaScript, C#, Python, Jupyter, SAS and SPSS. Up to 100% travel to various unanticipated domestic client sites in US required. Qualified candidates should apply online at: https://www.kforce.com/find-work/search-jobs and enter the Ref #16465 in Search field. Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.

We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.

Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.

This job is not eligible for bonuses, incentives or commissions.

Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.

By clicking “Apply Today” you agree to receive calls, AI-generated calls, text messages or emails from Kforce and its affiliates, and service providers. Note that if you choose to communicate with Kforce via text messaging the frequency may vary, and message and data rates may apply. Carriers are not liable for delayed or undelivered messages. You will always have the right to cease communicating via text by using key words such as STOP.","{""role_summary"":""The Data Analyst is responsible for analyzing user requirements, designing and building business intelligence tools, and implementing complex data warehouse systems. The role involves creating dashboards, extracting and loading data, and maintaining business intelligence tools."",""key_terms"":[{""term"":""Agile methodologies"",""explanation"":""A project management approach that emphasizes collaboration, flexibility, and continuous improvement.""},{""term"":""Cloud (AWS/GCP) environment"",""explanation"":""A cloud computing platform that provides on-demand access to a shared pool of computing resources.""},{""term"":""ETL (Extract, Transform, Load) processes"",""explanation"":""A data integration process that extracts data from multiple sources, transforms it into a standardized format, and loads it into a target system.""},{""term"":""Master data management sets and maps"",""explanation"":""A process that creates a single, unified view of an organization's data, ensuring consistency and quality.""},{""term"":""Business intelligence tools or systems"",""explanation"":""Software applications that analyze and present complex business data to support better decision-making.""}],""skill_priorities"":{""must_have"":[""Tableau"",""SQL"",""R"",""JavaScript"",""C#"",""Python"",""Jupyter"",""SAS"",""SPSS""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement a complex business intelligence tool using ETL processes and SQL?"",""example_answer"":""I would start by analyzing the business requirements, then design an ETL process using SQL to extract and transform the data. Next, I would load the data into a data warehouse and create reports using Tableau.""},{""question"":""How do you ensure data quality and consistency in a cloud-based data warehouse?"",""example_answer"":""I would implement data quality checks and validation rules during the ETL process, and also perform regular data audits to ensure consistency and accuracy.""}],""red_flags"":[""Lack of experience with cloud-based data warehousing"",""Inability to design and implement complex ETL processes""],""confidence_score"":90.0}"
Customer Relationship Management Analyst,Bvlgari,New York City Metropolitan Area,March,2025,"Job Overview:
We are looking for a highly skilled and detail-oriented CRM Data Analyst to join the Bulgari North America CRM team. The ideal candidate will have a strong background in data analysis, CRM systems, and a passion for using data to drive business decisions. The CRM Analyst is vital to optimizing CRM strategies and identifying areas where the company can improve acquisition and retention of clients. This role will design, maintain, and analyze reporting that offers insights into customer behavior and that identifies trends and patterns to improve customer engagement. You will work closely with stores, merchandising, marketing, High-End and e-Commerce departments to ensure that our CRM system is effectively utilized to meet business objectives. The successful candidate will have excellent analytical skills and the ability to communicate complex data insights in a clear and concise manner.

Key Responsibilities:
Conduct analysis of customer data to identify trends, insights and opportunities that can inform customer acquisition and retention strategies and improve customer engagement.
Create and maintain comprehensive reports and visualizations on customer behavior and purchasing patterns, presenting findings to management to support strategic planning.
Analyze data to measure the effectiveness of CRM channels and provide actionable insights to drive continuous improvement and customer lifetime-value.
Monitor and report on key CRM metrics.
Identify opportunities for CRM system improvements and support the implementation of CRM-related projects.
Deliver timely and accurate reporting to stakeholders.
Work collaboratively with cross-functional teams to support identification of opportunities in customer engagement and loyalty.
Knowledge of data governance practices and a strong understanding of data privacy and ethical considerations, especially related to customer data.
Feed performance media product owners with key insights to ensure optimal journeys & Brand experience for brand.com and offline channels.
Execute ad hoc weekly, monthly, quarterly, and yearly reporting, with thoughtful analysis and recommendations.
Assist with CRM database hygiene as well as report maintenance and store portfolio rebalancing.
Manage client reallocation project using CRM tools.
Develop & manage reporting based on consumer profiles & shopping patterns and share insights to enhance the customer experience at every stage of the journey.
Develop and maintain process documentation for CRM reporting.
Stay up-to-date with industry trends, competitive landscape, and emerging technologies to recommend new approaches for customer engagement
Qualifications:
Bachelor's degree in business, marketing, data science, statistics or related field
Minimum of 3 years of experience in a customer analytics or CRM-related role within a corporate environment
Expertise in data analytics tools, such as PowerBI, SAP, BW, or similar reporting platforms
Advanced Excel skills, including pivot tables, dashboards, etc. with strong knowledge of all other Microsoft Office 365 programs (PowerPoint, Outlook)","{""role_summary"":""The CRM Data Analyst is responsible for analyzing customer data to inform customer acquisition and retention strategies, creating reports to support strategic planning, and identifying opportunities for CRM system improvements."",""key_terms"":[{""term"":""CRM"",""explanation"":""Customer Relationship Management, a system used to manage customer interactions and data.""},{""term"":""PowerBI"",""explanation"":""A business analytics service by Microsoft that provides interactive visualizations and business intelligence capabilities.""},{""term"":""SAP"",""explanation"":""Systems, Applications, and Products in Data Processing, an enterprise software to manage business operations and customer relations.""},{""term"":""BW"",""explanation"":""Business Warehouse, a data warehousing and reporting platform used for business intelligence.""}],""skill_priorities"":{""must_have"":[""Data analytics tools (PowerBI, SAP, BW, or similar)"",""Advanced Excel skills (pivot tables, dashboards, etc.)"",""Strong knowledge of Microsoft Office 365 programs (PowerPoint, Outlook)""],""nice_to_have"":[""Experience with CRM database hygiene and report maintenance""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would analyze customer data to inform customer acquisition and retention strategies?"",""example_answer"":""I would use data analytics tools to identify trends and patterns in customer behavior, and then create reports to present findings to management.""},{""question"":""How do you stay up-to-date with industry trends and emerging technologies in customer engagement?"",""example_answer"":""I regularly read industry publications and attend conferences to stay current with the latest developments in customer engagement and analytics.""}],""red_flags"":[""Lack of experience with CRM systems and data analytics tools"",""Inability to communicate complex data insights in a clear and concise manner""],""confidence_score"":90.0}"
Junior Data Analyst,CGI,"Arlington, VA",March,2025,"Position Description

This is an exciting full-time opportunity to work in a fast-paced environment with a team of passionate technologists. We take an innovative approach to supporting our client, working side-by-side in an agile environment using emerging technologies. As a solution builder, you will be working to support the client’s mission and goals of growing an enterprise analytics platform

This position is located in our Fairfax, VA office with work performed at client site in Arlington, VA; however, a hybrid working model is acceptable.

Your future duties and responsibilities

As a solution builder, you will be working to support the client’s mission and goals of building an enterprise analytics platform
Demonstrate in-depth technical capabilities with the ability to support multiple work streams and drive assimilation of new techniques and solutions
Apply data and technical expertise in analysis, data mining and visualization of data using Business Intelligence tools and data development platforms
Evaluate data quality using SQL and data analysis techniques that improve client-reporting capabilities
Follow technology trends in data science and inform clients how this technology will benefit the future development platform
Participate in team problem solving efforts and offer ideas to solve client issues
Understand data needs and construct data pipelines for automating and accelerating data preparation

Required Qualifications To Be Successful In This Role

An interim Secret clearance is required to begin working onsite with our client, and a Secret clearance must be maintained throughout the project duration. Due to the nature of the government contract requirements and/or clearance requirements, US citizenship is required.

Basic Qualifications:

Bachelor’s degree or master’s degree in Computer Science, Mathematics or STEM related discipline
1+ Years of Experience working on Analytics and Business Intelligence focused initiatives, preferably in a consulting capacity
1+ Years of Experience using Python, R, or other languages to build statistical models or analyze data
1+ Years of Experience in creating complex SQL queries and functions, data structures and strong analytical problem solving skills
Experience working with various self-service business intelligence and data visualization tools such as Tableau, Power BI, Business Objects, etc
Strong technical troubleshooting techniques and analytical problem-solving skills
Experience working in an Agil

CGI is required by law in some jurisdictions to include a reasonable estimate of the compensation range for this role. The determination of this range includes various factors not limited to skill set, level, experience, relevant training, and license and certifications. To support the ability to reward for merit-based performance, CGI typically does not hire individuals at or near the top of the range for their role. Compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range for this role in the U.S. is $50,800.00 - $119,200.00.

CGI Federal's benefits are offered to eligible professionals on their first day of employment to include:

Competitive compensation
Comprehensive insurance options
Matching contributions through the 401(k) plan and the share purchase plan
Paid time off for vacation, holidays, and sick time
Paid parental leave
Learning opportunities and tuition assistance
Wellness and Well-being programs

Due to the nature of this government contract, US Citizenship is required.

#CGIFederalJob

Together, as owners, let’s turn meaningful insights into action.

Life at CGI is rooted in ownership, teamwork, respect and belonging. Here, you’ll reach your full potential because…

You are invited to be an owner from day 1 as we work together to bring our Dream to life. That’s why we call ourselves CGI Partners rather than employees. We benefit from our collective success and actively shape our company’s strategy and direction.

Your work creates value. You’ll develop innovative solutions and build relationships with teammates and clients while accessing global capabilities to scale your ideas, embrace new opportunities, and benefit from expansive industry and technology expertise.

You’ll shape your career by joining a company built to grow and last. You’ll be supported by leaders who care about your health and well-being and provide you with opportunities to deepen your skills and broaden your horizons.

Come join our team—one of the largest IT and business consulting services firms in the world.

Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, pregnancy, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status or responsibilities, reproductive health decisions, political affiliation, genetic information, height, weight, or any other legally protected status or characteristics.

CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com. You will need to reference the Position ID of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a Position ID will not be returned.

We make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members.

All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held. Dependent upon role and/or federal government security clearance requirements, and in accordance with applicable laws, some background investigations may include a credit check. CGI will consider for employment qualified applicants with arrests and conviction records in accordance with all local regulations and ordinances.

CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI’s legal duty to furnish information.","{""role_summary"":""Work as a solution builder to support a client's mission and goals of building an enterprise analytics platform, applying technical expertise in data analysis, visualization, and mining using various tools and platforms."",""key_terms"":[{""term"":""Agile environment"",""explanation"":""A collaborative approach to project management that emphasizes iterative progress and flexibility.""},{""term"":""Business Intelligence tools"",""explanation"":""Software applications used to analyze and present data to support business decisions.""},{""term"":""Data science"",""explanation"":""The study of extracting insights from data using various techniques and tools.""},{""term"":""Data visualization"",""explanation"":""The process of creating graphical representations of data to facilitate understanding.""},{""term"":""Emerging technologies"",""explanation"":""New and developing technologies that are expected to have a significant impact.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and analyzing relational databases.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree or master's degree in Computer Science, Mathematics, or STEM-related discipline"",""1+ years of experience working on Analytics and Business Intelligence focused initiatives"",""1+ years of experience using Python, R, or other languages to build statistical models or analyze data"",""1+ years of experience in creating complex SQL queries and functions, data structures, and strong analytical problem-solving skills""],""nice_to_have"":[""Experience working with various self-service business intelligence and data visualization tools such as Tableau, Power BI, Business Objects, etc."",""Strong technical troubleshooting techniques and analytical problem-solving skills""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building an enterprise analytics platform?"",""example_answer"":""I would start by understanding the client's requirements and goals, then identify the necessary tools and technologies to support the platform. I would also ensure that the platform is scalable and flexible to accommodate future growth.""},{""question"":""How do you stay current with emerging technologies in data science?"",""example_answer"":""I regularly read industry publications and attend conferences to stay informed about the latest developments in data science. I also participate in online forums and discussions to learn from others in the field.""}],""red_flags"":[""Lack of experience working with government contracts or clearances"",""Inability to obtain a Secret clearance""],""confidence_score"":85.0}"
Data Analyst I,GM Financial,"Dallas, TX",March,2025,"Overview

Why GM Financial?

GM Financial is the wholly-owned captive finance subsidiary of General Motors and is headquartered in Fort Worth, U.S. We are a global provider of auto finance solutions, with operations in North America, South America, and the Asia Pacific region. Through our long-standing relationships with auto dealers, we offer attractive retail financing and lease programs to meet the needs of each customer. We also offer commercial lending products to dealers to help them finance and grow their businesses. At GM Financial, our team members define and shape our culture — an environment that welcomes new ideas, fosters integrity and creates a sense of community and belonging. Here we do more than work — we thrive.

Our Purpose: We pioneer the innovations that move and connect people to what matters

About The Role

The Data Analyst I is responsible for assisting in data collection, research, analysis, and presentation of trends and anomalies to support GM Financial audits, continuous business monitoring, and participation in corporate projects. This position will perform analyses and generate reports using advanced analytics tools to assist auditors in identify risks and control deficiencies. The Data Analyst I will work alongside Audit Data Analytics team members and auditors to develop and implement streamlined data analytics and decision-support solutions. This position will interact with other departments in the interest of achieving the overall company objectives.

Responsibilities

In this role you will:

Uses appropriate programming languages (Python, R, SQL, SAS) to develop reporting and data visualizations
Builds technical knowledge to support research and analytic responsibilities through independent learning
Maintains thorough understanding of relevant data sources and analytic tools
Document data analysis processes and methodologies to ensure clarity and reproducibility
Assists in developing data analytics to summarize results, assumptions, and conclusions for internal audit team members and audit clients
Support Continuous Audit in enhancing Continuous Business Monitoring by implementing effective processes, technologies, and strategies
Collaborates with Audit Data Analytic team members to provide recommendations on the appropriate application of analytics to enhance and expand the existing data analytics framework
Design and implement dashboards, reports, and visualizations to help the Internal Audit team identify risks and exceptions during audits
Ensures that the delivered products meet the auditors needs
Perform other duties as assigned
Conform with all company policies and procedures

Qualifications

What makes you a dream candidate?

Ability to wrangle large datasets, structured and non-structured data, including data mining and manipulation
Demonstrated understanding and experience with technical systems, datasets, data warehouses, data analysis techniques and data visualization
Knowledge of consumer auto lending / leasing portfolio preferred
Ability to design and implement process documentation and monitoring protocols, demonstrated understanding and experience with technical systems, relational and dimensional datasets, data warehouses, and data analysis techniques
Strong quantitative, analytical and data interpretation skills
Ability to summarize complex data into digestible information for management
Proficient in programming languages such as Python, SAS, R or similar preferred
Proficient in data visualization best practices and tools such as Power BI, Tableau, SAS Visual Analytics etc preferred
Ability to identify and seek needed information/research skills
Strong written and verbal presentation skills with an ability to communicate effectively with Management by making complex concepts easy to understand
Ability to be curious, ask questions, explore, and be creative when analyzing data and business problems
Ability to interact collaboratively with internal customers and external vendors
Capable of supporting multiple projects, including the ability to coordinate and balance numerous tasks in a time-sensitive environment, under pressure and meeting deadlines

Experience

Bachelor’s Degree in Economics, Mathematics, Business Analytics, Computer Science, Statistics or other quantitative field required
Master’s Degree in Economics, Mathematics, Business Analytics, Computer Science, Statistics or other quantitative field preferred
0-2 years of data mining and query tool experience preferred
0-2 years experience in auto finance preferred
0-2 years of experience in similar role preferred

What We Offer: Generous benefits package available on day one to include: 401K matching, bonding leave for new parents (12 weeks, 100% paid), tuition assistance, training, GM employee auto discount, community service pay and nine company holidays.

Our Culture: Our team members define and shape our culture — an environment that welcomes innovative ideas, fosters integrity, and creates a sense of community and belonging. Here we do more than work — we thrive.

Compensation: Competitive pay and bonus eligibility

Work Life Balance: Flexible hybrid work environment, 2-days a week in office","{""role_summary"":""Assist in data collection, and presentation of trends and anomalies to support GM Financial audits, continuous business monitoring, and corporate projects."",""key_terms"":[{""term"":""Data Analytics"",""explanation"":""Using advanced analytics tools to identify risks and control deficiencies.""},{""term"":""Continuous Business Monitoring"",""explanation"":""Implementing effective processes, technologies, and strategies to enhance business monitoring.""},{""term"":""Data Visualization"",""explanation"":""Presenting complex data in a clear and concise manner using tools like Power BI, Tableau, SAS Visual Analytics.""}],""skill_priorities"":{""must_have"":[""Python"",""R"",""SQL"",""SAS"",""Strong quantitative, analytical and data interpretation skills""],""nice_to_have"":[""Knowledge of consumer auto lending / leasing portfolio"",""Data visualization best practices and tools"",""Experience in auto finance""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach analyzing a large dataset to identify trends and anomalies?"",""example_answer"":""I would use Python and SQL to extract and manipulate the data, and then apply data mining techniques to identify patterns and trends.""},{""question"":""Can you give an example of a complex data concept you had to communicate to a non-technical audience?"",""example_answer"":""I had to explain the results of a regression analysis to a group of business stakeholders. I used simple language and visualizations to convey the key findings.""}],""red_flags"":[""Lack of experience in data mining and query tool experience"",""Inability to communicate complex data concepts to non-technical audience""],""confidence_score"":90.0}"
People Data Analyst,Coinbase,United States,March,2025,"Ready to be pushed beyond what you think you’re capable of?

At Coinbase, our mission is to increase economic freedom in the world. It’s a massive, ambitious opportunity that demands the best of us, every day, as we build the emerging onchain platform — and with it, the future global financial system.

To achieve our mission, we’re seeking a very specific candidate. We want someone who is passionate about our mission and who believes in the power of crypto and blockchain technology to update the financial system. We want someone who is eager to leave their mark on the world, who relishes the pressure and privilege of working with high caliber colleagues, and who actively seeks feedback to keep leveling up. We want someone who will run towards, not away from, solving the company’s hardest problems.

Our work culture is intense and isn’t for everyone. But if you want to build the future alongside others who excel in their disciplines and expect the same from you, there’s no better place to be.
Data-backed decision making is core to Coinbase’s culture, and our People Analytics team strives to introduce data to inform, and ultimately drive, every people-related decision we make. We are looking for a People Data Analyst to realize this vision by building and enabling exceptional reporting on people data. , expanding the team’s We are looking for candidates who are builders: to define and build toward a best-in-class future, build our foundations (from the weeds to the clouds), and support in the scaling of our People Analytics practices for the next phase of Coinbase’s growth.

People Analytics works closely with our Executive Team, functional business leaders, and People leaders to ensure people data is accessible, valuable, and actionable. 

What you’ll be doing (ie. job duties): To be completed by all business teams except Eng.


Develop and maintain self-service reporting and analytics capabilities within Looker.

Respond to ad hoc report requests in support of BAU activities and special projects (e.g., executive dashboards)

Maintain and audit custom report and calculated field catalogs, ensuring cleanliness of dashboards across our Workday, Greenhouse, and Qualtrics datasets

Design, own, and deliver complex reporting and analysis solutions to provide rich insights on people challenges (e.g., performance, org health)

Collaborate with people leadership / teams to improve data quality and consistency within various HR platforms (especially Workday)

Maintain awareness of key HR platform feature releases/roadmap and the potential impact of those plans on current and future analytics functionality

Lead testing and analysis of new Looker reporting and analytics features

Manage cross-functional relationships with our partners in data engineering, data platform, and enterprise architecture

Provide excellent customer service in response to report requests and resolve requests accurately and in a timely manner


What we look for in you (ie. job requirements): To be completed by all business teams except Eng. 


Experience with various data analysis and visualization tools (Looker preferred)

Experience with Workday reporting

Proven expertise in building robust data models from complex data sources to generate insights

Experience interpreting and transforming business user requirements into dashboards to drive actionable insights

Hands-on experience querying with SQL 

Understanding of foundational statistical concepts and methods

Customer orientation and track record of delivering results against time tight timelines in a heavily XFN environment

Exterme attention to detail


Nice to haves:




Experience with other HR specific platforms and visualization tools (e.g., Qualtrics, Greenhouse, OneModel)




Job #: P68408
Pay Transparency Notice: Depending on your work location, the target annual salary for this position can range as detailed below. Full time offers from Coinbase also include target bonus + target equity + benefits (including medical, dental, vision and 401(k)).
Pay Range: : $130,900 USD - $154,000 USD
Please be advised that each candidate may submit a maximum of four applications within any 30-day period. We encourage you to carefully evaluate how your skills and interests align with Coinbase's roles before applying.

Commitment to Equal Opportunity
Coinbase is committed to diversity in its workforce and is proud to be an Equal Opportunity Employer.  All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, sex, gender expression or identity, sexual orientation or any other basis protected by applicable law. Coinbase will also consider for employment qualified applicants with criminal histories in a manner consistent with applicable federal, state and local law.  For US applicants, you may view the Know Your Rights notice here.  Additionally, Coinbase participates in the E-Verify program in certain locations, as required by law. 

Coinbase is also committed to providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please contact us at accommodations[at]coinbase.com to let us know the nature of your request and your contact information.  For quick access to screen reading technology compatible with this site click here to download a free compatible screen reader (free step by step tutorial can be found here).

Global Data Privacy Notice for Job Candidates and Applicants
Depending on your location, the General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA) may regulate the way we manage the data of job applicants. Our full notice outlining how data will be processed as part of the application procedure for applicable locations is available here. By submitting your application, you are agreeing to our use and processing of your data as required. For US applicants only, by submitting your application you are agreeing to arbitration of disputes as outlined here.    

 ","{""role_summary"":""The People Data Analyst will build and enable exceptional reporting on people data, working closely with the Executive Team, functional business leaders, and People leaders to ensure people data is accessible, valuable, and actionable."",""key_terms"":[{""term"":""People Analytics"",""explanation"":""The practice of using data to inform and drive people-related decisions within an organization.""},{""term"":""Looker"",""explanation"":""A data analytics and visualization tool used to develop and maintain self-service reporting and analytics capabilities.""},{""term"":""Workday"",""explanation"":""A human resources platform that provides data for people analytics and reporting.""}],""skill_priorities"":{""must_have"":[""Experience with data analysis and visualization tools"",""Proven expertise in building robust data models from complex data sources"",""Hands-on experience querying with SQL"",""Understanding of foundational statistical concepts and methods"",""Customer orientation and track record of delivering results against tight timelines""],""nice_to_have"":[""Experience with other HR specific platforms and visualization tools"",""Experience with Qualtrics, Greenhouse, OneModel""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a data model from complex data sources to generate insights?"",""example_answer"":""I would start by identifying the key stakeholders and their requirements, then design a data model that incorporates relevant data sources and ensures data quality and consistency.""},{""question"":""How do you ensure data quality and consistency within various HR platforms?"",""example_answer"":""I would collaborate with people leadership and teams to improve data quality, and maintain awareness of key HR platform feature releases and roadmaps to ensure analytics functionality.""}],""red_flags"":[""Lack of experience with data analysis and visualization tools"",""Inability to work in a fast-paced environment with tight timelines""],""confidence_score"":90.0}"
Data Analyst III,Fanatics,"New York, NY",March,2025,"Overview

JOB DESCRIPTION

Fanatics Betting & Gaming is seeking a Senior Data Analyst to play a key role in optimizing and scaling our VIP program through data-driven insights. This position will focus on performance tracking, reporting, and ad-hoc analysis to drive strategic decision-making and enhance customer engagement. You will be responsible for building and maintaining Tableau dashboards, writing SQL queries, and leveraging automation and data engineering best practices to extract and analyze large datasets in a scalable fashion. Your insights will directly impact sales operations, customer reinvestment strategies, and VIP journey optimization, helping to create a seamless, high-value experience for our most engaged users.

Key Responsibilities

Build and maintain Tableau dashboards to visualize VIP program performance and key business metrics.
Develop SQL queries to extract, analyze, and manipulate large datasets, driving customer engagement insights.
Collaborate with data engineering teams to optimize pipelines and ensure data integrity and scalability.
Analyze sales operations, customer reinvestment trends, and engagement behaviors to inform VIP program strategy.
Develop predictive models to optimize customer segmentation, routing, and personalized VIP journeys.
Provide data-driven recommendations to improve customer relationships, maximize engagement, and enhance the VIP experience.
Automate reporting processes and streamline data workflows for efficiency and scalability.
Effectively communicate insights to commercial, marketing, operations, and executive leadership teams to drive strategic initiatives.

Experience & Skills

4+ years of experience in data analytics, business intelligence, or data engineering.
Advanced SQL proficiency, with experience handling large-scale datasets and optimizing queries.
Strong expertise in Tableau for dashboard development, visualization, and performance tracking.
Understanding of data engineering best practices, pipeline optimization, and automation.
Ability to think strategically and translate data into business insights and revenue-driving recommendations.
Experience with customer loyalty programs, engagement analytics, or VIP strategy is a plus.
Self-motivated, highly detail-oriented, and strong problem-solving mindset with the ability to work independently.
Excellent communication skills, with the ability to present data insights to both technical and non-technical stakeholders.

Salary range is listed in USD; ranges will change based on country and state of residence, which are reflected in Geographical Zones defined by Fanatics Betting and Gaming. *Salary Range: $130,000 to $160,000 (Salary range incorporates all of our Geographical Compensation Zones and is subject to change as the Zone associated with the actual Offer is confirmed). In addition to the base and bonus, full-time employees are eligible for Medical, Dental, Vision, 401K, paid time off, and other benefits like GymPass, Pet Insurance, Family Care Benefits, Free Shipt deliveries, and more. For information about our benefits, please visit https://benefitsatfanatics.com/

About Us

Fanatics is building a leading global digital sports platform. We ignite the passions of global sports fans and maximize the presence and reach for our hundreds of sports partners globally by offering products and services across Fanatics Commerce, Fanatics Collectibles, and Fanatics Betting & Gaming, allowing sports fans to Buy, Collect, and Bet. Through the Fanatics platform, sports fans can buy licensed fan gear, jerseys, lifestyle and streetwear products, headwear, and hardgoods; collect physical and digital trading cards, sports memorabilia, and other digital assets; and bet as the company builds its Sportsbook and iGaming platform. Fanatics has an established database of over 100 million global sports fans; a global partner network with approximately 900 sports properties, including major national and international professional sports leagues, players associations, teams, colleges, college conferences and retail partners, 2,500 athletes and celebrities, and 200 exclusive athletes; and over 2,000 retail locations, including its Lids retail stores. Our more than 22,000 employees are committed to relentlessly enhancing the fan experience and delighting sports fans globally.

About The Team

Launched in 2021, Fanatics Betting and Gaming is the online and retail sports betting subsidiary of Fanatics Holdings Inc., a global digital sports platform. The Fanatics Sportsbook is available to nearly 93% of the addressable online sports bettor market in the U.S. in the following states: Arizona, Colorado, Connecticut, Illinois, Indiana, Iowa, Kansas, Kentucky, Maryland, Massachusetts, Michigan, New Jersey, New York, North Carolina, Ohio, Pennsylvania, Tennessee, Vermont, Virginia, West Virginia and Wyoming. Fanatics Casino is currently available online in Michigan, New Jersey, Pennsylvania and West Virginia. Fanatics Betting and Gaming operates nineteen retail locations including retail sportsbooks outside of Progressive Field and Nationwide Arena and the only sportsbook inside an NFL stadium at Commanders Field. Fanatics Betting and Gaming is headquartered in New York with offices in Denver and Dublin, Ireland.","{""role_summary"":""A Senior Data Analyst will optimize and scale the VIP program through data-driven insights, focusing on performance tracking, reporting, and ad-hoc analysis to drive strategic decision-making and enhance customer engagement."",""key_terms"":[{""term"":""VIP program"",""explanation"":""A loyalty program for high-value customers, offering personalized experiences and rewards.""},{""term"":""Tableau dashboards"",""explanation"":""Visual representations of data to track key business metrics and performance.""},{""term"":""Data engineering"",""explanation"":""Best practices for designing, building, and maintaining large-scale data systems.""},{""term"":""Predictive models"",""explanation"":""Statistical models that forecast customer behavior and optimize engagement strategies.""}],""skill_priorities"":{""must_have"":[""Advanced SQL proficiency"",""Strong expertise in Tableau"",""Understanding of data engineering best practices""],""nice_to_have"":[""Experience with customer loyalty programs"",""Engagement analytics or VIP strategy""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize a large-scale dataset for analysis?"",""example_answer"":""I would use data engineering best practices to design an efficient pipeline, and then leverage automation to extract and analyze the data.""},{""question"":""Can you explain how you would develop a predictive model to optimize customer segmentation?"",""example_answer"":""I would use statistical techniques to identify key customer characteristics, and then develop a model that forecasts customer behavior and optimizes engagement strategies.""}],""red_flags"":[""Lack of experience with large-scale datasets"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
Customer Data Analyst,Penn Foster Group,United States,March,2025,"Position Summary:
The Customer Data Analyst will partner closely with the product team to optimize the learner experience and journey through testing, monitoring, and innovation. The primary measures of success for this role are improvements to learner persistence, progression and satisfaction. This analyst will join a highly skilled team focused on building Penn Foster’s next-generation analytics platform centered on learner needs.

Essential Job Functions:
Build and maintain analytics tools to continuously monitor and improve learner persistence
Advance the goal of ‘democratizing data’ by developing intuitive data visualizations and models that provide insights into learner experience
Perform A/B and multivariate tests for product course revisions and optimizations
Develop and test new features informed by learner research, feedback, and behavior data to enhance the learner journey
Summarize and present recommendations to optimize learner success based on customer research, product data and insights
Ensure integrity and accuracy of all analytics data by continually assessing and enhancing data quality

Knowledge, Skills, Abilities:
Undergraduate degree in business, data science or analytics
2+ years of experience in analytics roles optimizing digital products
Curiosity and problem-solving skills to uncover insights from user data
High-energy, collaborative, creative, and strategic
Strong communication skills
Experience with A/B Testing and statistical analysis
Technical Skills:
Proven experience using SQL or Python to pull and organize data from large databases
Proficient in Tableau or other data visualization tools

About Us: At Penn Foster Group, we are transforming online learning to help learners by bringing together Penn Foster, CareerStep, Ashworth College, James Madison High School, the New York Institute of Photography, the New York Institute of Art and Design, and other education platforms. Together, we create an accelerated path to greater economic mobility through real-world skills and knowledge that enable learners to achieve long-term success in the workplaces of the future. Our history dates back to 1890 when our founder, Thomas Foster, pioneered distance education by offering training by mail for coal miners to get the necessary skills for safer jobs. Today, with the partners who use our education and training programs, we continue that mission of providing accessible training and education for in-demand skills and are building a workforce that’s prepared for the future job market.

Equal Employment Opportunity: We strive toward Diversity, Equity, and Inclusion at Penn Foster Group by intentionally building diverse teams – in identities, lived experiences, and ideas to create a culture where people feel connected to each other and have a sense of belonging. We value diversity, equity, and inclusion because it is the foundation that enables us to achieve what we set out to do as an organization – from maximizing the number of learners who can reach their goals while giving them the kinds of experiences we want them to have, to becoming the type of company we want to work in.

What We Offer: We offer a robust benefits package that includes medical, dental, vision, flexible spending, generous paid time off, sponsored volunteer opportunities, a 401K with a company match, and free access to our online programs.

This position is fully remote in AL, AZ, CO, CT, DC, FL, GA, IA, ID, IL, IN, KS, KY, LA, MA, MD, MI, MN, MO, NC, NE, NH, NJ, NY, OH, OK, PA, SC, TN, TX, UT, VA, WA, WI only.","{""role_summary"":""The Customer Data Analyst collaborates with the product team to optimize the learner experience and journey through testing, monitoring, and innovation, focusing on improving learner persistence, progression, and satisfaction."",""key_terms"":[{""term"":""A/B Testing"",""explanation"":""A method of comparing two or more versions of a product to determine which one performs better.""},{""term"":""Multivariate Testing"",""explanation"":""A method of testing multiple variables to determine which combination performs better.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to better understand and communicate insights.""},{""term"":""SQL"",""explanation"":""A programming language used to manage and analyze data in relational databases.""},{""term"":""Python"",""explanation"":""A programming language used for data analysis, machine learning, and automation.""},{""term"":""Tableau"",""explanation"":""A data visualization tool used to create interactive dashboards and reports.""}],""skill_priorities"":{""must_have"":[""2+ years of experience"",""Experience with A/B Testing and statistical analysis"",""Proven experience using SQL or Python to pull and organize data from large databases"",""Proficient in Tableau or other data visualization tools""],""nice_to_have"":[""Curiosity and problem-solving skills to uncover insights from user data"",""High-energy, collaborative, creative, and strategic"",""Strong communication skills""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach A/B testing for product course revisions and optimizations?"",""example_answer"":""I would start by identifying the key metrics to be tested, then create multiple versions of the product course, and finally analyze the results to determine which version performs better.""},{""question"":""How do you ensure the integrity and accuracy of analytics data?"",""example_answer"":""I continually assess and enhance data quality by monitoring data sources, performing regular data audits, and implementing data validation rules.""}],""red_flags"":[""Lack of experience with A/B testing and statistical analysis"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
Business Intelligence Specialist,CDW,United States,March,2025,"BI Developer (CRM Analytics & Power BI)
100% Remote
1 year contract (CDW Direct)
CDW is seeking a talented BI Developer with experience in CRM Analytics (formerly Tableau CRM) and Power BI to join our Data & Analytics team. In this role, you will develop, maintain, and optimize data visualizations and reports, leveraging both Salesforce-native CRM Analytics and Power BI platforms. You will work closely with business stakeholders to translate complex data into actionable insights and empower data-driven decision-making across the organization.

Key Responsibilities:
CRM Analytics (CRMA) Development:
Design, develop, and optimize data visualizations and dashboards using CRM Analytics (Tableau CRM).
Work with Salesforce data to create actionable insights that drive business outcomes.
Customize and enhance CRM Analytics features to meet evolving business needs.
Power BI Development:
Create and manage Power BI reports and dashboards, ensuring consistency with business objectives and KPIs.
Integrate Power BI with various data sources for comprehensive analysis.
Optimize Power BI performance and implement best practices for data modeling and visualization.
Data Integration & Transformation:
Collaborate with data engineers and IT teams to ensure proper data integration across systems.
Ensure data accuracy, consistency, and reliability across all reporting platforms.
Design and implement ETL processes to feed data into CRM Analytics and Power BI.
Stakeholder Collaboration:
Work closely with business units to understand requirements and translate them into effective visualizations.
Provide training and support to end-users for both CRM Analytics and Power BI tools.
Assist in the development of ad-hoc reports and dashboards as needed.
Continuous Improvement:
Stay updated with new features and best practices for both CRM Analytics and Power BI.
Recommend and implement improvements to reporting processes, dashboard design, and data flows.
Monitor and troubleshoot dashboard/reporting performance issues.

Qualifications:
Experience:
3+ years of experience as a BI Developer or Data Analyst with strong expertise in CRM Analytics (formerly Tableau CRM) and Power BI.
Proven experience working with Salesforce data and reporting tools.
Strong understanding of data modeling, ETL processes, and BI best practices.
Skills & Competencies:
Expertise in CRM Analytics (Tableau CRM) for Salesforce, including dashboard creation, custom queries, and app development.
Advanced knowledge of Power BI, including data modeling, DAX, and report/dashboard development.
Strong SQL skills and experience with data integration from multiple sources.
Excellent problem-solving and analytical skills with a focus on business insights.
Strong communication and collaboration skills to work with business stakeholders.

If you're passionate about leveraging CRM Analytics and Power BI to drive business insights and empower data-driven decision-making, we'd love to hear from you!","{""role_summary"":""Develop and maintain data visualizations and reports using CRM Analytics and Power BI, working closely with business stakeholders to drive data-driven decision-making."",""key_terms"":[{""term"":""CRM Analytics"",""explanation"":""A Salesforce-native platform for creating data visualizations and reports.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft for creating interactive visualizations and business intelligence reports.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process for integrating data from multiple sources into a single platform.""},{""term"":""DAX"",""explanation"":""A formula language used in Power BI for data modeling and calculations.""}],""skill_priorities"":{""must_have"":[""CRM Analytics (Tableau CRM) for Salesforce"",""Power BI"",""SQL"",""Data modeling"",""ETL processes"",""BI best practices""],""nice_to_have"":[""Data integration from multiple sources"",""App development in CRM Analytics""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize a Power BI report for better performance?"",""example_answer"":""I would review the data model, check for unnecessary calculations, and apply best practices for data visualization to improve the report's performance.""},{""question"":""How do you ensure data accuracy and consistency across all reporting platforms?"",""example_answer"":""I collaborate with data engineers and IT teams to ensure proper data integration, and implement data quality checks to ensure accuracy and consistency.""}],""red_flags"":[""Lack of experience with CRM Analytics and Power BI"",""Inability to work closely with business stakeholders""],""confidence_score"":90.0}"
Data Analyst (various levels open),"HRCap, Inc.",United States,March,2025,"About the Job
[VVIP HRCap Clients] Start-ups, PEs, JVs, Global SMBs, Fortune 500s
[Industries] AI, Automotive, Beauty, Consumer Electronics, Cosmetics, Construction, E-Commerce, Energy, EV, Fashion, Financial Services, Healthcare, Investment, Manufacturing, Technology, and more.
[Location] CA, TX, MI, IL, GA, NJ, NY, PA, CT, and more (remote included)


Role Description
Our clients are seeking Data Analysts (various levels open depending on experience and relevant skills) to join their U.S. teams.

The ideal candidate will use their passion for big data and analytics to provide insights to the business covering a range of topics. They will be responsible for conducting both recurring and ad hoc analysis for business users.


Responsibilities
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and mine data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Compile and analyze data specifically related to business' issues
Develop clear visualizations to convey complicated data in a straightforward fashion


Qualifications
Bachelor's or Master's degree in Statistics or Applied Mathematics or equivalent experience
Relevant Data Analysis experience
Proficient in SQL


===

About us
HRCap, Inc. is a Top 10 Executive Search & HR Consulting Company and the largest Global Asian American Search Firm in the world. Established in 2000, we partner with over 1500 VIP client organizations ranging across Fortune 500s, global medium-sized businesses, PE firms, venture capitals, and tech start-ups across all industries and operate globally with a focus in North America, Europe, and APAC regions. We offer customized workforce strategies, executive search, technical recruiting, succession planning, HR training & development, and executive coaching for effective globalization and localization. We are trusted HR advisors, strategic business partners, and cultural ambassadors to our clients, candidates, and community. www.hrcap.com","{""role_summary"":""The Data Analyst role involves using big data and analytics to provide insights to the business, conducting recurring and ad hoc analysis, and developing clear visualizations to convey complex data."",""key_terms"":[{""term"":""Big Data"",""explanation"":""The process of analyzing large and complex data sets to extract insights and patterns.""},{""term"":""Data Mining"",""explanation"":""The process of automatically discovering patterns or relationships in large data sets.""},{""term"":""SQL"",""explanation"":""A programming language used to manage and analyze data in relational database management systems.""}],""skill_priorities"":{""must_have"":[""Data Analysis experience"",""Proficient in SQL"",""Bachelor's or Master's degree in Statistics or Applied Mathematics""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to analyze a complex data set and present your findings to a non-technical audience?"",""example_answer"":""In my previous role, I analyzed customer purchase data to identify trends and opportunities for growth. I presented my findings to the marketing team, and they were able to use the insights to inform their marketing strategy.""},{""question"":""How do you stay current with new tools and technologies in data analysis?"",""example_answer"":""I regularly read industry blogs and attend webinars to stay up-to-date on the latest developments in data analysis. I also participate in online forums to learn from other professionals in the field.""}],""red_flags"":[""Lack of experience working with large data sets"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
"Data Analyst, Sr",Qualcomm,"San Diego, CA",March,2025,"Company

Qualcomm Technologies, Inc.

Job Area

Miscellaneous Group, Miscellaneous Group > Data Analyst

General Summary

General Summary The Master Data Analyst is responsible for developing processes, governance, policies, standards, and tools to consistently define and manage critical business data. This role ensures a single point of reference across all systems, streamlining data sharing among business functions, and linking records across systems. The objective is to harmonize data elements to provide quality and high-integrity data from a trusted single version of truth for decision-making.

Data Management

Principal Duties & Responsibilities

Manage product data by developing the ability and knowledge of creating and changing Oracle ERP master data in areas such as Item Master, BOMs, Routes, Sourcing, Attributes, and other required areas as defined through documented processes.
Identify data discrepancies, communicate with business partners, research discrepancies, and facilitate/coordinate resolution.
Ensure data accuracy to enable appropriate supply, demand, and capacity planning.
Understand how to gather, interpret, and interact with large and complicated datasets.
Collaborate and share knowledge with stakeholders to integrate information and drive better-informed data decision-making.
Perform manufacturing cost roll-ups to support PO placement, inventory transactions, WIP visibility, supplier and DC shipments to customers, quarterly re-quoting process, financial reconciliations, and inventory valuation.
Knowledge of B2B Messaging and Shop Floor Manufacturing with an understanding of data elements that impact these functions.
Maintain and monitor supplier attribute data to ensure accurate lot genealogy and traceability for quality control and customer-specific requirements.


Project Support/Identification Of Process Improvements

Participate in solution design and architect master data-related solutions for setup and data collection requirements.
Provide data for testing in IT Test Environments and participate in project readiness from POC to go-live.
Expected tasks include specification and IT case creation, script testing, and internal training, cross-functional collaboration, and documentation.
Act as an SME to assist in troubleshooting and performing corrective actions to support cross-functional teams throughout the organization.
Develop a working knowledge of multiple business processes and work as a system liaison for problem resolutions.
Understand upstream source of truth systems, such as PLM, Cognos, Program Management databases, to provide feedback and expertise on how they impact Oracle ERP data elements.
Be knowledgeable of key data elements from ERP to other downstream systems such as Rapid Response, Price Management, Salesforce, Model-N, Salesforce, and custom business systems, including knowledge of data hierarchies, data attributes, and data formats.
Develop ad hoc and weekly reporting using ETL processes in systems such as SharePoint, Business Objects, Tableau, Oracle, QlikView, and SharePoint.
Knowledge in New Product Introduction, Engineering Change Order approvals and implementation, Data Mining, and Lifecycle Management from Engineering to Obsolescence.


Required Competencies

IT Core Competencies no standard job description text

2+Years and experience dealing with data analysis, integrity, and reporting with a Bachelor's degree in Business, Supply Chain, Engineering and/or Operations.
Knowledge of manufacturing and Supply Chain and Operations procedures


Additional Competencies

Knowledge in Oracle ERP, Agile, SharePoint, Power Apps and BI tools such as Business Objects, Power BI and Tableau.
Semiconductor industry experience a plus
Self-motivated team contributor with the ability to work on multiple projects simultaneously.
Strong communications, interpersonal and organizational skills in a team environment
Ability to clearly convey technical and non-technical concepts to a wide audience to drive resolution/decisions.
Ability to work with minimal direction and supervision
Detail oriented and highly organized with a high skill level in time management, multi-tasking, and task prioritization.
Capability to provide data driven decisions and solutions.
Creative thinker with a flair for problem solving and out of the box ideas


Minimum Qualifications No Standard Job Description Text

Applicants: Qualcomm is an equal opportunity employer. If you are an individual with a disability and need an accommodation during the application/hiring process, rest assured that Qualcomm is committed to providing an accessible process. You may e-mail disability-accomodations@qualcomm.com or call Qualcomm's toll-free number found here. Upon request, Qualcomm will provide reasonable accommodations to support individuals with disabilities to be able participate in the hiring process. Qualcomm is also committed to making our workplace accessible for individuals with disabilities. (Keep in mind that this email address is used to provide reasonable accommodations for individuals with disabilities. We will not respond here to requests for updates on applications or resume inquiries).

To all Staffing and Recruiting Agencies: Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications.

EEO Employer: Qualcomm is an equal opportunity employer; all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or any other protected classification.

Qualcomm expects its employees to abide by all applicable policies and procedures, including but not limited to security and other requirements regarding protection of Company confidential information and other confidential and/or proprietary information, to the extent those requirements are permissible under applicable law.

Pay Range And Other Compensation & Benefits

$100,800.00 - $151,200.00

The above pay scale reflects the broad, minimum to maximum, pay scale for this job code for the location for which it has been posted. Even more importantly, please note that salary is only one component of total compensation at Qualcomm. We also offer a competitive annual discretionary bonus program and opportunity for annual RSU grants (employees on sales-incentive plans are not eligible for our annual bonus). In addition, our highly competitive benefits package is designed to support your success at work, at home, and at play. Your recruiter will be happy to discuss all that Qualcomm has to offer – and you can review more details about our US benefits at this link.

If you would like more information about this role, please contact Qualcomm Careers.

3072456","{""role_summary"":""The Master Data Analyst is responsible for developing processes, governance, policies, standards, and tools to consistently define and manage critical business data, ensuring a single point of reference across all systems and providing quality data for decision-making."",""key_terms"":[{""term"":""Master Data"",""explanation"":""Critical business data that requires consistent definition and management across all systems.""},{""term"":""Oracle ERP"",""explanation"":""Enterprise Resource Planning system used for managing business operations and data.""},{""term"":""BOMs"",""explanation"":""Bills of Materials, a document used to list the components and materials required to manufacture a product.""},{""term"":""ETL processes"",""explanation"":""Extract, Transform, Load processes used for data integration and migration between systems.""}],""skill_priorities"":{""must_have"":[""Data analysis and reporting"",""Oracle ERP knowledge"",""Supply Chain and Operations procedures"",""Bachelor's degree in Business, Supply Chain, Engineering and/or Operations""],""nice_to_have"":[""Semiconductor industry experience"",""Knowledge of Agile, SharePoint, Power Apps, and BI tools""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure data accuracy and integrity in a complex system?"",""example_answer"":""I use a combination of data validation rules, data profiling, and data quality metrics to identify and correct data discrepancies.""},{""question"":""Can you explain how you would approach data integration between different systems?"",""example_answer"":""I would use ETL processes to extract data from source systems, transform the data into a standardized format, and load it into the target system, ensuring data consistency and quality.""}],""red_flags"":[""Lack of experience with Oracle ERP"",""Inability to work with large and complicated datasets"",""Poor communication and interpersonal skills""],""confidence_score"":90.0}"
Data Analyst - US004,SMASH,"Utah, United States",March,2025,"SMASH, Who we are?

We believe in long-lasting relationships with our talent. We invest time in getting to know them and understanding what they seek as their next professional step.
We aim to find the perfect match. As agents, we pair our talent with our US clients, not only by their technical skills but as a cultural fit. Our core competency is to find the right talent fast.

The Role

We are seeking a Data Analyst who will help support the financial operations. Success in this role hinges on your technical aptitude, quantitative abilities, and business acumen: you know how to plow through data with SQL and other analysis tools such as Excel.

What you’ll do:

Help monthly billing by running queries and ensuring completion.
Review and modify billing and other queries for the financial team.
Build SQL queries or Python code to automate financial process.
Provide support with audits, data validation and other system related needs.
Help investigate billing, reconciliation, and other system related issues needed to support the finance function.

What you’ll need:

1-2 years’ experience in an analytics position or equivalent
Experience with Excel
Proficient with SQL
Ability to meet deliverables under tight deadlines
Ability to work independently, and a strong sense of ownership
Proven experience analyzing, interpreting, and summarizing complex data (ideally related to financial services)
Ability to work in a dynamic, cross-functional environment, with a strong attention to detail
Effective communication and presentation skills and ability to explain complex analyses in simple terms to stakeholders
Strong relationship building and collaborative skills
Exceptional problem-solving skills

Nice to Have:

Experience with Python
VBA
BA/BS Degree required","{""role_summary"":""Support financial operations by analyzing and interpreting complex data, automating financial processes, and providing insights to stakeholders."",""key_terms"":[{""term"":""SQL"",""explanation"":""A programming language used to manage and analyze data in relational databases.""},{""term"":""Python"",""explanation"":""A high-level programming language used for data analysis, automation, and other tasks.""},{""term"":""VBA"",""explanation"":""Visual Basic for Applications, a programming language used to create and automate tasks in Microsoft Office applications.""}],""skill_priorities"":{""must_have"":[""Excel"",""SQL"",""Data analysis"",""Problem-solving"",""Communication"",""Collaboration""],""nice_to_have"":[""Python"",""VBA""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize a complex SQL query for better performance?"",""example_answer"":""I would analyze the query to identify performance bottlenecks, then apply indexing, caching, or other optimization techniques to improve its efficiency.""},{""question"":""How do you ensure data accuracy and integrity in your analysis?"",""example_answer"":""I use data validation techniques, such as data profiling and data quality checks, to ensure accuracy and integrity. I also document my processes to maintain transparency and reproducibility.""}],""red_flags"":[""Lack of experience with SQL or Excel"",""Inability to work independently or meet tight deadlines""],""confidence_score"":90.0}"
Data/BI Analyst,Sage,"Atlanta, GA",March,2025,"Job Description

We are seeking a skilled and detail-oriented Power BI Analyst to join our dynamic team. The ideal candidate will be responsible for designing, developing, and maintaining reports and dashboards using Microsoft Power BI. This role involves transforming raw data into meaningful insights through interactive and user-friendly dashboards and reports.

*This is a hybrid role: 3 days/week in office*

Data Analysis: Proficiency in analyzing complex data sets to derive actionable insights.
Technical Proficiency: Expertise in Power BI, SQL and/or Snowflake, DAX (Data Analysis Expressions).
Data Modeling: Ability to create and manage data models, including relationships, hierarchies, and calculated columns.
ETL Processes: Experience with Extract, Transform, Load (ETL) processes to integrate data from various sources.
Data Visualization: Skills in designing and developing interactive and visually compelling reports and dashboards.
Problem-Solving: Strong analytical and problem-solving abilities to address business challenges.
Communication: Excellent verbal and written communication skills to present data findings clearly to stakeholders.
Business Acumen: Understanding of business operations and the ability to translate data insights into business strategies.





Requirements:

Minimum of 4+ years using PowerBI or Tableau
Experience with R or Python programming is a huge plus
Experience in the following:
Data Collection and Preparation: Extracting, cleaning, and transforming data from various sources to ensure it's ready for analysis.
Report and Dashboard Development: Designing and creating interactive reports and dashboards using Power BI.
Data Modeling: Developing and maintaining complex data models to support business analysis.
Performance Optimization: Optimizing the performance of reports and dashboards by improving data queries and model efficiency.
Data Analysis: Performing advanced data analysis using DAX functions to create calculated measures and solve business problems.
Collaboration: Working closely with business analysts, stakeholders, and end-users to gather and refine requirements for reports and dashboards.
Data Governance: Implementing data governance practices, including data access controls and ensuring data quality and integrity.
Documentation: Maintaining documentation for reports, data sources, and data transformation processes.





Your benefits at Sage:

Comprehensive health, dental, and vision coverage
401(k) retirement match (100% matching up to 4%)
21 days paid time off (+1 floating holiday)
5 days paid yearly to volunteer (through Sage Foundation)
Sage Wellness Rewards Program (flexible ways to use wellness credit and fitness reimbursement)
A library of on-demand career development options and ongoing training offerings





Dig deeper about who we are:

Who is Sage: https://www.sage.com/en-us/company/about-sage/

Life at Sage: https://www.sage.com/en-us/company/careers/

Our Values & Behaviors: https://www.youtube.com/watch?app=desktop&v=vt5JXf-Gwno&feature=youtu.be

How we make a difference: https://www.sage.com/en-us/company/sage-foundation/

Sage Business Cloud - SaaS for Every Business: https://www.sage.com/en-us/products/","{""role_summary"":""Design, develop, and maintain reports and dashboards using Microsoft Power BI, transforming raw data into meaningful insights for stakeholders."",""key_terms"":[{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""},{""term"":""DAX"",""explanation"":""Data Analysis Expressions, a formula language used in Power BI to create calculated columns and measures.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load, a process used to integrate data from various sources into a single, unified view.""},{""term"":""SQL"",""explanation"":""Structured Query Language, a programming language used to manage and manipulate data in relational database management systems.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform that allows users to store, process, and analyze large amounts of data.""}],""skill_priorities"":{""must_have"":[""Power BI"",""SQL"",""DAX"",""Data Analysis"",""Data Visualization"",""Problem-Solving"",""Communication""],""nice_to_have"":[""R or Python programming"",""Tableau""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize the performance of a slow-performing report in Power BI?"",""example_answer"":""I would first identify the root cause of the performance issue, then apply techniques such as data aggregation, filtering, and caching to improve the report's performance.""},{""question"":""How do you ensure data quality and integrity in your reports and dashboards?"",""example_answer"":""I implement data governance practices, including data access controls, data validation, and data cleansing to ensure the accuracy and reliability of the data.""}],""red_flags"":[""Lack of experience with Power BI or similar business intelligence tools"",""Inability to communicate complex data insights effectively to stakeholders""],""confidence_score"":90.0}"
Analista de Datos - Mercado Pago,Mercado Libre,"Mexico City, Mexico",March,2025,"En Mercado Libre estamos democratizando el comercio y los servicios financieros para transformar la vida de las personas de América Latina. ¡Súmate a este propósito!

En el área de Risk & Compliance desarrollamos acciones para fortalecer la confianza de nuestros stakeholders. Desafiamos enfoques tradicionales mediante soluciones innovadoras y promovemos una cultura de excelencia y cumplimiento de las normas.
Nuestro equipo interdisciplinario trabaja #CodoACodo en la gestión integral de riesgos y compliance, y en el desarrollo de la resiliencia de nuestro negocio, cuidando a nuestro ecosistema emprendedor en cada uno de los países en los que estamos presentes.

Tenemos un desafío para quienes:

Vibran energía emprendedora: se mueven por la curiosidad, nunca se rinden y se enfocan en superar sus propios límites.
Dan el máximo porque les gusta trabajar con compromiso y dedicación.
Viven los cambios como oportunidades y aprenden de sus errores.
La excelencia y la ejecución son claves en su forma de hacer las cosas.
Promueven el buen clima, aportan alegría y diversión.
Saben cómo construir con otras personas y disfrutan trabajando en equipo.

Imagínate emprendiendo proyectos desafiantes, dinámicos e innovadores y siendo responsable de:

Desarrollar e implementar modelos analíticos para detectar patrones de lavado de dinero y financiamiento del terrorismo.
Realizar análisis de datos para identificar transacciones sospechosas y tendencias emergentes.
Investigar alertas generadas por los sistemas de monitoreo, determinando la naturaleza de la actividad.
Realizar pruebas de desempeño al ecosistema de controles de monitoreo transaccional, para identificar oportunidades de mejora, creación de nuevos controles, entre otros.
Brindar soporte al equipo de monitoreo con procesos de ETL.
Implementar automatizaciones que permitan mejorar la eficiencia de los procesos actuales.

Requisitos:
Ser profesional de Matemáticas, Estadística, Economía, Ciencias de la Computación o un campo relacionado.
Contar con 3 años de experiencia en análisis de datos en el sector financiero.
Tener experiencia en el uso de herramientas SQL, Python o R.
Capacidad para trabajar con grandes conjuntos de datos y extraer información relevante.
Tener algún conocimiento en PLD.

Te proponemos:

Ser parte de una compañía con espíritu emprendedor en la que nos encanta pensar en grande y a largo plazo.
Ser protagonista de tu desarrollo en un ambiente de oportunidades, aprendizaje, crecimiento, expansión y proyectos desafiantes.
Compartir y aprender en equipo junto a grandes profesionales y especialistas.
Un excelente clima de trabajo, con todo lo necesario para que vivas una gran experiencia. :)","{""role_summary"":""Develop and implement analytical models to detect money laundering and terrorist financing patterns, and perform data analysis to identify suspicious transactions and emerging trends."",""key_terms"":[{""term"":""Lavado de dinero"",""explanation"":""Money laundering, the criminal process of concealing the source of illegally obtained funds to make them appear legitimate.""},{""term"":""Financiamiento del terrorismo"",""explanation"":""Terrorist financing, the provision or collection of funds to support terrorist activities.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load, a process used to extract data from multiple sources, transform it into a standardized format, and load it into a target system for analysis.""},{""term"":""PLD"",""explanation"":""Probably referring to 'Prevención de Lavado de Dinero' (Money Laundering Prevention), a set of regulations and guidelines to prevent money laundering.""}],""skill_priorities"":{""must_have"":[""Professional degree in Mathematics, Statistics, Economics, Computer Science, or a related field"",""3 years of experience in data analysis in the financial sector"",""Experience with SQL, Python, or R"",""Ability to work with large datasets and extract relevant information""],""nice_to_have"":[""Knowledge of PLD""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would develop an analytical model to detect money laundering patterns?"",""example_answer"":""I would use machine learning algorithms and data visualization techniques to identify suspicious transaction patterns and trends. I would also consider implementing a risk-based approach to prioritize transactions for further review.""},{""question"":""How do you stay up-to-date with emerging trends and regulations in the financial sector?"",""example_answer"":""I regularly read industry publications and attend conferences to stay informed about new developments and best practices. I also participate in online forums and discussion groups to network with other professionals in the field.""}],""red_flags"":[""Lack of experience with data analysis in the financial sector"",""Inability to work with large datasets"",""No knowledge of PLD regulations""],""confidence_score"":90.0}"
Data Analyst - Remote,Siemens Healthineers,"Norwood, MA",March,2025,"Join us in pioneering breakthroughs in healthcare. For everyone. Everywhere. Sustainably.

Our inspiring and caring environment forms a global community that celebrates diversity and individuality. We encourage you to step beyond your comfort zone, offering resources and flexibility to foster your professional and personal growth, all while valuing your unique contributions.

Conducts analyses of data using various methods and tools to extract information as basis for decision making.

As a Data Analyst you will be a foundational member in the creation of analytics that power our Service Operations. You will work cross-functionally with established analysts and developers within DX Global and SHS. This role requires you to work closely with leadership teams to understand and implement solutions.

Responsibilities

This role is well suited to an ambitious professional, looking for the next step in their career. As a Data Analyst your responsibilities include:

Researches, analyzes, consolidates and interprets data using statistical and data analytics methods to create information on business-relevant topics, e.g. market environment, operational process and equipment performance etc.
Acquires data from primary or secondary data sources and maintain databases/data systems.
Operates and optimizes pre-defined tools, applications and data bases/data management systems.
Creates reports and communicates results to various internal and/or external stakeholders (e.g. management, customers).

This position may suit you best if you are familiar with:

Python
Snowflake
Qlik
Power BI
Genesys Cloud, SAP, PEAK

Required skills to have for the success of this role

Exceptional Communication skills to support collaboration with our internal partners
Proficiency with programming languages such as Python
Ability to grow strong working relationships
Comfortable with flexible work environments and changing priorities
Strong Time and Priority management ability

The pay range for this position is $86,700 - $100,000 annually; however, base pay offered may vary depending on job-related knowledge, skills, and experience. The annual incentive target is 8% of base pay. Siemens Healthineers offers a variety of health and wellness benefits including paid time off and holiday pay. Details regarding our benefits can be found here: https://benefitsatshs.com/index.html. This information is provided per the required state Equal Pay Act. Base pay information is based on market location. Applicants should apply via Siemens Healthineers external or internal careers site.

Who we are: We are a team of more than 73,000 highly dedicated Healthineers in more than 70 countries. As a leader in medical technology, we constantly push the boundaries to create better outcomes and experiences for patients, no matter where they live or what health issues they are facing. Our portfolio is crucial for clinical decision-making and treatment pathways.

How we work: When you join Siemens Healthineers, you become one in a global team of scientists, clinicians, developers, researchers, professionals, and skilled specialists, who believe in each individual’s potential to contribute with diverse ideas. We are from different backgrounds, cultures, religions, political and/or sexual orientations, and work together, to fight the world’s most threatening diseases and enable access to care, united by one purpose: to pioneer breakthroughs in healthcare. For everyone. Everywhere. Sustainably.

To find out more about Siemens Healthineers businesses, please visit our company page here.

Siemens Healthineers offers a variety of health and wellness benefits to employees. Details regarding our benefits can be found here.

Equal Employment Opportunity Statement: Siemens Healthineers is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability unrelated to ability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, order of protection status, protected veteran or military status, or an unfavorable discharge from military service, and other categories protected by federal, state or local law.

EEO is the Law: Applicants and employees are protected under Federal law from discrimination. To learn more, click here.

Reasonable Accommodations: Siemens Healthineers is committed to equal employment opportunity. As part of this commitment, we will ensure that persons with disabilities are provided reasonable accommodations.

If you require a reasonable accommodation in completing a job application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please fill out the accommodations form here. If you’re unable to complete the form, you can reach out to our HR People Connect People Contact Center for support at peopleconnectvendorsnam.func@siemens-healthineers.com. Please note HR People Connect People Contact Center will not have visibility of your application or interview status.

Pay Transparency Non-Discrimination Provision: Siemens Healthineers follows Executive Order 11246, including the Pay Transparency Nondiscrimination Provision. To learn more, click here.

California Privacy Notice: California residents have the right to receive additional notices about their personal information. To learn more, click here.

Export Control: “A successful candidate must be able to work with controlled technology in accordance with US export control law.” “It is Siemens Healthineers’ policy to comply fully and completely with all United States export control laws and regulations, including those implemented by the Department of Commerce through the Export Administration Regulations (EAR), by the Department of State through the International Traffic in Arms Regulations (ITAR), and by the Treasury Department through the Office of Foreign Assets Control (OFAC) sanctions regulations.”

Data Privacy: We care about your data privacy and take compliance with GDPR as well as other data protection legislation seriously. For this reason, we ask you not to send us your CV or resume by email. We ask instead that you create a profile in our talent community where you can upload your CV. Setting up a profile lets us know you are interested in career opportunities with us and makes it easy for us to send you an alert when relevant positions become open. Register here to get started.

Beware of Job Scams: Please beware of potentially fraudulent job postings or suspicious recruiting activity by persons that are currently posing as Siemens Healthineers recruiters/employees. These scammers may attempt to collect your confidential personal or financial information. If you are concerned that an offer of employment with Siemens Healthineers might be a scam or that the recruiter is not legitimate, please verify by searching for the posting on the Siemens Healthineers career site.

To all recruitment agencies: Siemens Healthineers does not accept agency resumes. Please do not forward resumes to our jobs alias, employees, or any other company location. Siemens Healthineers is not responsible for any fees related to unsolicited resumes.","{""role_summary"":""A Data Analyst responsible for conducting analyses of data to extract information for decision making, working closely with leadership teams to implement solutions, and creating reports to communicate results to internal and external stakeholders."",""key_terms"":[{""term"":""Python"",""explanation"":""A programming language used for data analysis and development.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform used for data storage and analysis.""},{""term"":""Qlik"",""explanation"":""A business intelligence software used for data visualization and analysis.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft used for data visualization and business intelligence.""},{""term"":""Genesys Cloud"",""explanation"":""A cloud-based customer experience platform used for managing customer interactions.""},{""term"":""SAP"",""explanation"":""An enterprise resource planning software used for managing business operations and customer relations.""},{""term"":""PEAK"",""explanation"":""Not explicitly defined in the job description, but possibly a proprietary system or tool used by the company.""}],""skill_priorities"":{""must_have"":[""Python"",""Exceptional Communication skills"",""Proficiency with programming languages such as Python"",""Ability to grow strong working relationships"",""Comfortable with flexible work environments and changing priorities"",""Strong Time and Priority management ability""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to analyze complex data to inform business decisions?"",""example_answer"":""In my previous role, I analyzed customer purchase data to identify opportunities for growth, and presented my findings to the management team, resulting in a 10% increase in sales.""},{""question"":""How do you stay organized and manage competing priorities in a fast-paced work environment?"",""example_answer"":""I use project management software to prioritize tasks and deadlines, and regularly communicate with my team and stakeholders to ensure everyone is aligned and informed.""}],""red_flags"":[""Lack of experience with data analysis tools such as Snowflake, Qlik, or Power BI"",""Inability to work in a fast-paced environment with changing priorities""],""confidence_score"":90.0}"
Qliksense / Data Analyst,VRK IT Vision Inc.,"Mountain View, CA",March,2025,"Role : Qliksense – Data Analyst

Location : Mountain View CA (Day 1 onsite)

Skills

5+ years of experience working in a data analytics/ BI role
Fluency in conducting data discovery and quality checks
Building dashboards using Qlik (preferred)
Demonstrates strong business acumen and curiosity
Excellent problem-solving skills and end-to-end quantitative thinking
Produce & maintain scalable business performance reports
Build and maintain data pipeline for existing reports
Summarize high level trends in KPIs and performance (optional)
Works directly with the internal or external client to identify analytical requirements.
May occasionally guide less experienced business data analysts","{""role_summary"":""This role is responsible for analyzing data, creating dashboards, and maintaining reports to help the organization make informed business decisions."",""key_terms"":[{""term"":""Data discovery"",""explanation"":""The process of identifying and exploring data to understand its structure, quality, and potential uses.""},{""term"":""Qlik"",""explanation"":""A business intelligence software used to create interactive and reports.""},{""term"":""Data pipeline"",""explanation"":""A series of processes that extract, transform, and load data into a target system for analysis.""},{""term"":""KPIs"",""explanation"":""Key Performance Indicators, which are measurable values that indicate how well an organization is achieving its objectives.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in data analytics/BI"",""Fluency in conducting data discovery and quality checks"",""Excellent problem-solving skills and end-to-end quantitative thinking""],""nice_to_have"":[""Building dashboards using Qlik"",""Experience guiding less experienced business data analysts""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for conducting data discovery and quality checks?"",""example_answer"":""I use a combination of data profiling tools and manual review to identify data quality issues and ensure data accuracy.""},{""question"":""How do you approach building a scalable business performance report?"",""example_answer"":""I focus on understanding the business requirements, designing a flexible report structure, and using efficient data processing techniques.""}],""red_flags"":[""Lack of experience working with Qlik or similar BI tools"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":85.0}"
Data Analyst with Power BI experience,"Access Search, Inc.","Boston, MA",March,2025,"This Boston-based home services firm is looking to hire a Data Analyst to join their Boston team. Located near Boston North Station, the role will be hybrid, 2-3 days in the office, so someone local to Boston. You will need at least 1 year of professional experience building dashboards and reports in Power BI. This person should have solid SQL skills and any experience working with Snowflake, doing data transformation and cleansing work would be a big plus. The company is growing and while you are the first data hire, the team will grow in the future!

Responsibilities
Understand the day-to-day issues that our business faces, which can be better understood with data
Compile and analyze data related to business issues
Develop clear visualizations to convey complicated data in a straightforward fashion
Ability to work with external consultants and learn quickly

Qualifications

Bachelor's or Master's degree in Analytics, Applied Mathematics, or equivalent experience
2+ years of professional Data Analysis experience working with Power BI
Ability to support Operations, Finance, Sales, and Marketing
Solid SQL experience in data transformation, data ingestion, and cleansing
Snowflake, Fivetran, or Databricks will be a big plus
Comfortable meeting with company executives and working as the sole internal data resource.
Proactive, someone who finds ways data can impact the business before being asked.

This company cannot support OPT, provide sponsorship, visa transfer, or C2C.","{""role_summary"":""Support business growth by developing clear data visualizations and providing data-driven insights to various departments."",""key_terms"":[{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive dashboards and reports.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and analyzing data in relational database management systems.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform that enables fast and secure data analysis.""},{""term"":""Data transformation and cleansing"",""explanation"":""The process of converting and refining raw data into a format suitable for analysis.""}],""skill_priorities"":{""must_have"":[""Power BI"",""SQL"",""Data Analysis""],""nice_to_have"":[""Snowflake"",""Fivetran"",""Databricks""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach data transformation and cleansing in Power BI?"",""example_answer"":""I would use Power BI's data transformation tools to clean and prepare the data for analysis, ensuring data quality and integrity.""},{""question"":""How do you stay proactive in identifying business opportunities through data analysis?"",""example_answer"":""I regularly review business metrics and identify areas where data can drive improvement, then develop and present data-driven insights to drive business growth.""}],""red_flags"":[""Lack of experience with Power BI and SQL"",""Inability to work independently as the sole internal data analyst""],""confidence_score"":90.0}"
Data Analyst 7,nLeague,"Richmond, VA",March,2025,"Data Analyst

Location: Richmond, VA

Duration: 12+ Months

Client: VDH

Job Id: (756384)

Hybrid Job

Position will primarily be responsible for assisting with development of processes & architecture to support migration from VIIS to STC. This will include long-term collection of STC data & its integration with pre-existing VIIS data in the EDR.

This individual will be primarily responsible for assisting with development of processes and architecture to support migration from VIIS to STC. This will include the long-term collection of STC data and its integration with pre-existing VIIS data in the EDR.

Priority 1: Assisting with process development to migrate data to STC.

Priority 2: Assisting with process development to pull data from STC into EDR.

Priority 3: Assisting with designing both process and architecture for integration of STC with VIIS data.

Required skills: Oracle PL-SQL, Python, GCP cloud functions, ETL / ELT processing","{""role_summary"":""Assist in developing processes and architecture to migrate data from VIIS to STC, integrating with pre-existing data in the EDR."",""key_terms"":[{""term"":""VIIS"",""explanation"":""A data system that is being migrated from.""},{""term"":""STC"",""explanation"":""A data system that is being migrated to.""},{""term"":""EDR"",""explanation"":""A data repository that stores integrated data from VIIS and STC.""},{""term"":""GCP cloud functions"",""explanation"":""A cloud-based platform for deploying and managing functions.""},{""term"":""ETL / ELT processing"",""explanation"":""A process of extracting, transforming, and loading data into a target system.""}],""skill_priorities"":{""must_have"":[""Oracle PL-SQL"",""Python"",""GCP cloud functions"",""ETL / ELT processing""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach integrating STC data with pre-existing VIIS data in the EDR?"",""example_answer"":""I would first identify the data elements that need to be integrated, then design an ETL process to extract the required data from STC, transform it into a compatible format, and load it into the EDR.""},{""question"":""What experience do you have with Oracle PL-SQL and how would you apply it to this role?"",""example_answer"":""I have worked with Oracle PL-SQL for 3 years, and I would apply my knowledge to develop efficient data migration processes and optimize data integration with STC.""}],""red_flags"":[""Lack of experience with GCP cloud functions"",""Inability to design efficient ETL processes""],""confidence_score"":85.0}"
SR DATA ANALYST - ADVANCED ANALYTICS,Acunor,United States,March,2025,"Job title : SR. DATA ANALYST - ADVANCED ANALYTICS
Location : Charlotte, NC | Scottsdale, AZ | Malvern, PA | Dallas, TX (Hybrid 2days/week)

Employment type : FULLTIME

Note : Client is hiring for individuals who, now or in future does not require sponsorship for employment visa status
Job Responsibilities:
Engage with internal partners to understand business strategy, questions, and goals. Bring structure to business requests, translate requirements into an analytical project approach, and complete analyses.
Acquire and compile structured and unstructured data and verify its quality, accuracy, and reasonableness.
Perform analyses of historical data to surface trends and insights using advanced analytical methods.
Prepare and deliver visualizations and internal presentations that translate analytic insights into tangible, actionable solutions for business partners to implement.
Develop, own, and manage recurring analytic or reporting processes.
Mentor, coach, train, and develop junior data analysts. Proactively expand knowledge of business and analytics and shares with team members.
Share and document best practices.
Participate in special projects and perform other duties as assigned.

Basic Qualifications:
Minimum of five years related data analysis/science work experience
Undergraduate degree or equivalent combination of training and experience.
Coding knowledge in SQL and Python
Experience with data storytelling through visualization
Experience in designing and executing end to end experiments, including A/B, Multivariate (MVT) and Multi Arm Bandit (MAB) testing.

Nice to have:
Experience working with the NLP packages/techniques
Experience utilizing Graph networks to analyze the web behaviors
Adobe Analytics report creation experience.
Working knowledge of web tagging implementation","{""role_summary"":""Collaborate with internal partners to understand business strategy and goals, and provide actionable insights through advanced data analytics and visualization."",""key_terms"":[{""term"":""Advanced analytical methods"",""explanation"":""Using complex statistical techniques to identify trends and insights in data.""},{""term"":""Data storytelling"",""explanation"":""Presenting complex data in a clear and compelling way to non-technical stakeholders.""},{""term"":""NLP packages/techniques"",""explanation"":""Using natural language processing tools to analyze and extract insights from text data.""},{""term"":""Graph networks"",""explanation"":""Analyzing relationships between data points to understand web behaviors.""},{""term"":""A/B, Multivariate (MVT) and Multi Arm Bandit (MAB) testing"",""explanation"":""Designing and executing experiments to measure the impact of different variables on business outcomes.""}],""skill_priorities"":{""must_have"":[""SQL"",""Python"",""Data analysis/science work experience"",""Data storytelling through visualization"",""Designing and executing end to end experiments""],""nice_to_have"":[""NLP packages/techniques"",""Graph networks"",""Adobe Analytics report creation"",""Web tagging implementation""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a recent project where you had to design and execute an experiment?"",""example_answer"":""In my previous role, I designed an A/B test to measure the impact of a new feature on user engagement. I worked with cross-functional teams to implement the test, and presented results to stakeholders.""},{""question"":""How do you approach data storytelling?"",""example_answer"":""I believe data storytelling is about presenting complex insights in a clear and actionable way. I use visualization tools to create interactive dashboards that allow stakeholders to explore data themselves.""}],""red_flags"":[""Lack of experience with data storytelling and visualization"",""Inability to design and execute experiments"",""Limited knowledge of advanced analytical methods""],""confidence_score"":90.0}"
Data Analyst 1 – Data Analyst,State of Iowa - Executive Branch,"Des Moines, IA",March,2025,"Job Description

This is a non-merit position. Candidates must follow the instructions in the ""To Apply"" section.

The Department of Management (DOM), Division of Data, Planning, and Improvement, is seeking a Data Analyst to join our team!

This individual will play a critical role in developing research plans, managing and analyzing data, conducting high-level data analysis, and contributing to the development of impactful research findings by creating a variety of deliverables such as technical reports, dashboards, and other data visualizations. If you're passionate about data analysis, problem-solving, and contributing to meaningful research, we want to hear from you!

Key Responsibilities

Collect and utilize data according to research plans.
Develop and maintain secure databases for research projects.
Ensure data quality, identify errors, and resolve inconsistencies.
Conduct data analysis using software applications (e.g., R, SPSS) and present meaningful conclusions from the analyses.
Create technical reports, visualizations, dashboards, and presentations for diverse audiences.
Strong interpersonal and communication skills including the ability to effectively communicate complex ideas and information to both technical and non-technical audiences.
Assist in developing research proposals and grant applications and participate in peer reviews of team reports.
Meet deadlines for all deliverables as set by the Research Coordinator.
Communicate regularly with the Research Coordinator and supervisor.
Attend relevant meetings and trainings as needed.
Promote a culture of professionalism, accountability, and teamwork

Please note, candidates for this position must reside

in the state of Iowa at the time of starting the role.

Employer Highlights

The Department of Management is a well-respected employer. We are focused on providing excellent customer service, while offering a wonderful team atmosphere, work-life balance, free parking, and casual attire. We have a great total compensation package for all our full-time employees, including:

Iowa Public Employees' Retirement System (IPERS)
Retirement Investors Club (RIC)
Flexible Working Environment- Work from Home Opportunities
Health, Dental and Vision Insurance
Vacation Leave
Sick Leave
Paid Holidays
Flexible Spending Accounts
Life Insurance
Long-Term Disability Insurance

Background Check Requirements

After a conditional offer of employment has been made, and as the final step in the hiring process, candidates for this position will be subject to a background investigation, which may include but may not be limited to a verification of a candidate’s education, previous employment/work history, contact of personal references, motor vehicle records, and a criminal history check (including through Federal, State, or Local criminal justice agencies).
Information gathered as part of such background investigation will be treated as confidential to the extent permitted by Iowa Code section 22.7, 8B.4A, and other applicable laws, rules, and regulations; provided that, to the extent permitted by applicable law, such information shall be available to candidates upon request.

Minimum Qualification Requirements

Applicants must meet at least one of the following minimum requirements to qualify for positions in this job classification:

Graduation from an accredited four-year college or university with a degree in business analytics, economics, data science, statistics, mathematics, management information systems, or industrial management.
All of the following (a and b):
A total of four years of education and/or full-time experience in business/data/statistical analytics, economic research, or data science, where thirty semester hours of accredited college or university coursework in any field equals one year of full-time experience.
Possession of a professional certificate in data science, business analytics, or data analytics.
All of the following (a and b):
A total of four years of education and/or full-time experience in business/data/statistical analytics, economic research, or data science, where thirty semester hours of accredited college or university coursework in any field equals one year of full-time experience; and
A total of one year of graduate-level education and/or full-time experience (as described in part a), where twenty-four semester hours of accredited graduate college or university coursework in business analytics, economics, data science, statistics, mathematics, management information systems, or industrial management equals one year of full-time experience.","{""role_summary"":""The Data Analyst plays a critical role in developing research plans, managing and analyzing data, and contributing to the development of impactful research findings."",""key_terms"":[{""term"":""Data Analysis"",""explanation"":""The process of extracting insights and patterns from data using software applications such as R and SPSS.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to communicate complex information to both technical and non-technical audiences.""},{""term"":""Research Proposals"",""explanation"":""Written applications submitted to secure funding for research projects.""}],""skill_priorities"":{""must_have"":[""Data analysis using software applications (e.g., R, SPSS)"",""Strong interpersonal and communication skills"",""Ability to effectively communicate complex ideas and information to both technical and non-technical audiences""],""nice_to_have"":[""Experience with grant applications and peer reviews of team reports"",""Ability to promote a culture of professionalism, accountability, and teamwork""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for conducting high-level data analysis and presenting meaningful conclusions from the analyses?"",""example_answer"":""I use software applications such as R and SPSS to analyze data, and then create technical reports and visualizations to present my findings to both technical and non-technical audiences.""},{""question"":""How do you ensure data quality and resolve inconsistencies in your research projects?"",""example_answer"":""I follow a rigorous process for collecting and utilizing data according to research plans, and identify errors and resolve inconsistencies to ensure data quality.""}],""red_flags"":[""Candidates without experience in data analysis using software applications such as R and SPSS."",""Candidates who are unable to communicate complex ideas and information to both technical and non-technical audiences.""],""confidence_score"":90.0}"
DATA ANALYST - SUPPLY CHAIN ANALYTICS,The Home Depot,"Atlanta, GA",March,2025,"Req137838

Position Purpose

A Data Analyst Supply Chain leverages technical abilities to synthesize complex analytical tasks into easily understood data-driven stories. Responsible for working collaboratively with other analysts to apply established analytical processes on diverse datasets to deduce insights and solve real-world business problems. Also ensures that all reporting and analytical responsibilities are completed competently in a timely manner, continually seeking out opportunities to hone existing technical skills (e.g. writing SQL/code, statistics, machine learning, etc.) and learn new skills. Operates under the supervision and mentorship of more experienced managers and data scientists.

Key Responsibilities

30% Executes existing reporting and analytical responsibilities
20% Leverages data analytics tools to create new dashboards, reports, and any additional ad-hoc requests
20% Ensures the quality of work output by displaying a keen attention to detail
20% Develops additional technical competencies and subject matter expertise within core functional group
10% Presents findings in easily understood ways, focuses on how the data analytics fits into the bigger picture

Direct Manager/Direct Reports

This postion reports to Manager
This position has no Direct Reports

Travel Requirements

Typically requires overnight travel less than 10% of the time.

Physical Requirements

Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.

Working Conditions

Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.

Minimum Qualifications

Must be eighteen years of age or older.
Must be legally permitted to work in the United States.

Preferred Qualifications

Work experience with SQL Server, Teradata, Oracle, or comparable database systems
1-3 years work experience in data mining, statistical analysis, auditing, and/or forecasting.
Prior direct experience in analyzing the relevant subject matter (e.g. Supply Chain, Merchandising, Operations, etc.)
B.S. in Computer Science, Math, Engineering, Finance or related quantitative field

Minimum Education

The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.

Preferred Education

No additional education

Minimum Years Of Work Experience

0

Preferred Years Of Work Experience

No additional years of experience

Minimum Leadership Experience

None

Preferred Leadership Experience

None

Certifications

None

Competencies

Critical thinking skills to identify the strengths and weaknesses of alternative solutions; ability to understand and foresee implications of new information for current and future problems solving.
An unquenchable intellectual curiosity for getting at the underlying story being told within the data.
Strong written and verbal communications skills. Ability to persuade, inform, and influence others based on findings. A track record of taking complex results and communicating them in an easily understood way.
Superior interpersonal skills and ability to collaborate actively and work in a team environment.
Ability to quickly learn and adapt to new technologies, tools, and techniques.","{""role_summary"":""A Data Analyst Supply Chain synthesizes complex analytical tasks into easily understood data-driven stories, working collaboratively with analysts to solve real-world business problems."",""key_terms"":[{""term"":""SQL"",""explanation"":""A programming language used for managing and manipulating data in relational database management systems.""},{""term"":""Machine Learning"",""explanation"":""A type of artificial intelligence that enables them to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Data Mining"",""explanation"":""The process of automatically discovering patterns, relationships, and insights from large datasets.""},{""term"":""Teradata"",""explanation"":""A type of relational database management system used for storing and managing large amounts of data.""},{""term"":""Oracle"",""explanation"":""A type of relational database management system used for storing and managing large amounts of data.""}],""skill_priorities"":{""must_have"":[""SQL"",""Data Analysis"",""Communication Skills""],""nice_to_have"":[""Machine Learning"",""Teradata"",""Oracle"",""Data Mining"",""Statistical Analysis""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a complex data-driven story you've synthesized in the past?"",""example_answer"":""In my previous role, I analyzed customer purchase data and identified a trend that led to a 10% increase in sales. I presented my findings to the marketing team, and we worked together to develop a targeted campaign that drove further growth.""},{""question"":""How do you stay current with new technologies and tools in the field of data analysis?"",""example_answer"":""I regularly read industry blogs and attend webinars to stay up-to-date on the latest trends and tools. I also make time to experiment with new technologies and techniques to continually improve my skills.""}],""red_flags"":[""Lack of experience with SQL or data analysis"",""Poor communication skills"",""Inability to work collaboratively in a team environment""],""confidence_score"":90.0}"
BI Developer & Data Analyst,First Media US,United States,March,2025,"First Media is a top-ten social media publishing and marketing company at the intersection of content and commerce, driving the shoppable content revolution. Based in Los Angeles, with over 200 employees, 180 million fans, and over 1.5 billion monthly views, we’re a powerhouse of creative strategy, production, omnichannel distribution, and data. We use a proprietary formula to drive real-world action across our lifestyle brands, So Yummy, Blossom, Blusher, and BabyFirst.

BI Developer & Data Analyst
Join our passionate team as a BI Developer & Data Analyst, and let your love for data analysis and storytelling shine! As an essential part of our Business Intelligence department, you’ll deliver powerful insights and reports that drive our Performance Marketing and other key divisions. We’re seeking a strategic thinker with sharp problem-solving skills who thrives on collaboration with both internal teams and external partners.

While this role can be WFH anywhere in the US, the chosen candidate must be available and responsive for Pacific Time meetings and requests. There may also be the occasional need to respond to the team on the weekend.

Key Responsibilities:
Reporting & Analysis: Keep our reports and dashboards up-to-date, tracking key metrics and insights to help guide important decisions in direct marketing.
Data Solutions Development: Create and set up efficient back-end data processes and pipelines that make it easier for dashboards and other team members to access the information they need.
Insights and Recommendations: Use your analytical skills and business knowledge to offer helpful suggestions on ad performance, addressing key business questions and identifying promising opportunities.
Strategic Collaboration: Team up with colleagues from different departments to identify and shape strategic decisions through thorough research, analytics, and valuable insights.
Communication: Share findings and recommendations with senior management in a clear, engaging, and impactful way.
Continuous Improvement: Focus on developing business processes and improving your analytics skills to create even better solutions and approaches.

Qualifications:
Education: Bachelor’s or Master’s degree in a quantitative field (e.g., Computer Science, Statistics, Economics, Applied Math, Analytics) preferred
Experience: 2+ years in analytics or a related role, preferably in performance or growth-driven industries.

Technical Skills:
Proficiency in programming languages (Python, SQL).
Experience with data visualization and management tools (Looker is mandatory).
Analytical Skills: Strong ability to conduct quantitative and qualitative analyses to address business challenges.
Business Acumen: Demonstrated understanding of business needs and ability to translate data insights into impactful recommendations.
Communication: Excellent presentation and interpersonal skills to convey insights to diverse audiences.
Project Management: Ability to prioritize and manage multiple projects in time-sensitive environments.
Attention to Detail: A careful and thorough approach to analysis, organization, and execution.

If you’re ready to make a meaningful impact and elevate our data-driven initiatives, we can’t wait to hear from you!

First Media provides competitive compensation and exceptional benefits, including top-shelf medical, dental, vision, unlimited PTO, 401K with match, and more.

First Media is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity/expression, national origin, disability, protected veteran status, or any other characteristic protected under federal, state, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.","{""role_summary"":""As a BI Developer & Data Analyst, you'll deliver powerful insights and reports that drive key divisions, using your analytical skills and business knowledge to offer helpful suggestions on ad performance."",""key_terms"":[{""term"":""BI Developer"",""explanation"":""A professional responsible for developing and maintaining business intelligence systems, and analyzing data to inform business decisions.""},{""term"":""Data Analyst"",""explanation"":""A professional responsible for collecting, organizing, and analyzing data to help organizations make informed business decisions.""},{""term"":""Performance Marketing"",""explanation"":""A type of marketing that focuses on achieving specific, measurable results, such as conversions or sales, in exchange for payment.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Looker"",""Data Visualization"",""Analytical Skills"",""Business Acumen"",""Communication"",""Project Management"",""Attention to Detail""],""nice_to_have"":[""Experience in performance or growth-driven industries"",""Master's degree in a quantitative field""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a time when you had to analyze complex data to inform business decisions?"",""example_answer"":""In my previous role, I analyzed customer purchase data to identify trends and presented my recommendations to the marketing team, resulting in a 20% increase in sales.""},{""question"":""How do you stay up-to-date with industry trends and developments in data analysis and visualization?"",""example_answer"":""I regularly read industry blogs and attend webinars to stay current on the latest tools and methodologies, and I'm always looking for opportunities to apply new skills to real-world problems.""}],""red_flags"":[""Lack of experience with data visualization tools"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
Data Analyst (Remote),GovCIO,United States,March,2025,"Overview

GovCIO is currently hiring for Data Analyst. This position will be a fully remote position.

Responsibilities

Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information

Qualifications

Required Skills and Experience:

Bachelor's with 8+ years (or commensurate experience)
Proven working experience as a data analyst or business data analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings

Clearance Required: Ability to obtain and maintain a Suitability/Public Trust clearance.

Company Overview

GovCIO is a team of transformers--people who are passionate about transforming government IT. Every day, we make a positive impact by delivering innovative IT services and solutions that improve how government agencies operate and serve our citizens.

But we can't do it alone. We need great people to help us do great things - for our customers, our culture, and our ability to attract other great people. We are changing the face of government IT and building a workforce that fuels this mission. Are you ready to be a transformer?

We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, disability, or status as a protected veteran. EOE, including disability/vets.

Posted Pay Range

The posted pay range, if referenced, reflects the range expected for this position at the commencement of employment, however, base pay offered may vary depending on multiple individualized factors, including market location, job-related knowledge, skills, education, experience, and internal equity. The total compensation package for this position may also include other compensation elements, to be discussed during the hiring process. If hired, employee will be in an “at-will position” and the GovCIO reserves the right to modify base salary (as well as any other discretionary payment or compensation program) at any time, including for reasons related to individual performance, GovCIO or individual department/team performance, and market factors.

Posted Salary Range: USD $120,000.00 - USD $140,000.00 /Yr.","{""role_summary"":""The Data Analyst will interpret data, analyze trends, and provide ongoing reports to management. They will also acquire and maintain databases, identify patterns in complex data sets, and prioritize business and information needs."",""key_terms"":[{""term"":""Data models"",""explanation"":""A conceptual representation of data structures and relationships, used to organize and standardize data.""},{""term"":""Database design development"",""explanation"":""Creating and implementing a database structure to store and manage data efficiently.""},{""term"":""Data mining and segmentation techniques"",""explanation"":""Methods to extract insights from large datasets and group data into meaningful categories.""},{""term"":""ETL frameworks"",""explanation"":""Tools for extracting, transforming, and loading data from one system to another.""},{""term"":""SQL"",""explanation"":""A programming language for querying and managing relational databases.""},{""term"":""XML"",""explanation"":""A markup language for structuring and transporting data between systems.""},{""term"":""Business Objects"",""explanation"":""A reporting tool for creating and managing business intelligence reports.""},{""term"":""Statistical packages"",""explanation"":""Software for analyzing and modeling data, such as R or Python libraries.""}],""skill_priorities"":{""must_have"":[""Data analysis and interpretation"",""Database design and development"",""Data mining and segmentation techniques"",""Reporting packages (Business Objects etc)"",""Databases (SQL etc)"",""Programming (XML, Javascript, or ETL frameworks)"",""Statistics and statistical packages"",""Analytical skills and attention to detail""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to analyze a complex dataset and present your findings to management?"",""example_answer"":""I once analyzed customer purchase data to identify trends and presented my findings to the product team, which led to a 10% increase in sales.""},{""question"":""How do you stay up-to-date with new tools and technologies in data analysis?"",""example_answer"":""I regularly attend industry conferences, read blogs, and participate in online communities to stay current with the latest developments in data analysis.""}],""red_flags"":[""Lack of experience with data modeling and database design"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
Operations Data Analyst,Aroris Health,Greater Minneapolis-St. Paul Area,March,2025,"Reports to: Vice President of Operations 
 About Aroris: 
 Aroris Health is a leading healthcare technology company. Our proprietary platform, Aroris360, empowers healthcare providers with data-driven insights to optimize payer negotiations, enhance operational efficiency, and improve healthcare outcomes. We are driven by innovation, committed to excellence, and focused on delivering measurable impact to our clients.  
 Aroris's mission is to preserve the spirit of medicine. One way of doing this is to provide independent medical practices access to the same payer contracting resources as the largest health systems. We operate as an extension of practices, leveraging decades of industry experience, cutting-edge data analytics capabilities, and dedicated legal and negotiation teams to help practices capture more revenue without expending additional resources. 
 At Aroris, we look for individuals who embody our core values of being driven, joyful, relentless, and team players. We believe these qualities are vital in achieving our collective goals and fostering a thriving work environment. 
 Job Overview: 
 We are seeking a talented and detail-oriented Operations Data Analyst to join our team. As an Operations Data Analyst, your primary responsibilities will revolve around collecting, cleaning, analyzing, and sharing data as well as uploading data to our SaaS platform. You will play a crucial role in supporting decision-making processes and improving business operations through data-driven insights. Additionally, you will collaborate closely with clients and the operations team, providing clear communication and routine updates to ensure the successful execution of data-related projects. Data sources will include Excel, PDFs, EMR/Practice Management, Clearing House Revenue Reports, as well as other types of reporting software.   
 Job Responsibilities: 
 Data Collection: Gather data from various sources, including databases, APIs, and spreadsheets, while ensuring data quality and integrity 
Data Cleaning: Perform data cleansing and transformation tasks to ensure accuracy, consistency, and completeness of the data 
Data Analysis: Utilize statistical techniques and analytical tools to analyze large datasets, identify trends, patterns, and anomalies, and extract meaningful insights that drive business decisions 
Data Sharing: Prepare and present reports, visualizations, and dashboards to communicate findings and recommendations effectively to stakeholders 
Client and Operations Partnership: Collaborate with clients and the operations team to understand their requirements, goals, and challenges. Provide regular updates on project progress and maintain open lines of communication 
Proposal Modeling: Model healthcare reimbursement proposals from payers and share insights with negotiation teams   
SaaS Platform Management: Upload data into the SaaS platform, ensuring accurate and timely data entry, and troubleshooting any issues that may arise 
Data Accuracy Assurance: Implement data quality checks and validation procedures to ensure data accuracy, completeness, and consistency across all data sources 
Process Improvement: Continuously evaluate and enhance data collection, analysis, and reporting processes to optimize efficiency and effectiveness 
 Required Experience, Qualifications and Skills: 
2+ years using Microsoft Excel - data collection, cleaning, standardization, mining, analysis, and visualization 
2+ years of experience in data analysis role 
Solid understanding of the US HealthCare reimbursement model, Fee Schedules, and Insurance Payer processes 
Demonstrated ability to use data as a tool for problem-solving 
Excellent communication skills, specifically as it relates to explaining technical concepts and data-driven findings 
 Preferred Experience, Qualifications and Skills: 
2+ years of experience in database engineering 
Tableau, Power BI, or other data visualization programs 
2+ year of experience building, maintaining, and implementing financial models 
 Compensation:
Salary: $55-75K
Bonus Eligible: 15-30%

Equal Employment Opportunity:  
Aroris is an equal opportunity employer. Aroris is committed to equal employment opportunity in accordance with applicable federal, state, and local laws. Aroris will not discriminate against applicants for employment on any legally recognized basis. This includes, but is not limited to veteran status, race, color, religion, sex, sexual orientation, gender identity, gender expression, national origin, age and physical or mental disability.  ","{""role_summary"":""Support business operations and decision-making by collecting, analyzing, and sharing insights as an Operations Data Analyst."",""key_terms"":[{""term"":""Data-driven insights"",""explanation"":""Using data to inform business decisions and identify trends.""},{""term"":""Payer contracting resources"",""explanation"":""Tools and expertise to negotiate with healthcare payers.""},{""term"":""SaaS platform"",""explanation"":""Cloud-based software as a service, used for data management and analysis.""},{""term"":""EMR/Practice Management"",""explanation"":""Electronic Medical Records and practice management systems used in healthcare.""},{""term"":""Clearing House Revenue Reports"",""explanation"":""Reports on revenue and payment processing in healthcare.""}],""skill_priorities"":{""must_have"":[""Microsoft Excel"",""Data analysis"",""Communication skills""],""nice_to_have"":[""Database engineering"",""Tableau or Power BI"",""Financial modeling""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure data quality and integrity in your analysis?"",""example_answer"":""I use a combination of data validation rules, data profiling techniques, and manual reviews to ensure data accuracy and consistency.""},{""question"":""Can you give an example of a problem you solved using data analysis?"",""example_answer"":""I analyzed patient wait times and identified opportunities to optimize scheduling, resulting in improved patient satisfaction and reduced wait times.""}],""red_flags"":[""Lack of experience with healthcare reimbursement models"",""Inability to communicate technical concepts effectively""],""confidence_score"":90.0}"
Data Analyst (Payments),SpotOn,"San Francisco, CA",March,2025,"At SpotOn, we’re helping restaurants and small businesses compete and win with flexible payment and software technology—backed by real people who really care. From seamless point-of-sale systems to integrated restaurant management solutions, every SpotOn tool is designed to help local businesses increase profits and create better experiences for their customers and employees.  

Recently, SpotOn was:


Named one of Fast Company’s Most Innovative Companies of 2024

Awarded Great Places to Work and Built In’s Best Workplaces for the third year in a row

Selected as the Best Overall Restaurant POS by NerdWallet 

Rated the top-rated point-of-sale (POS) for restaurants, bars, retail, and small businesses by Capterra users


We’re committed to caring hard and moving fast so that we can continue to grow and make a positive impact together. 

That’s where you come in. 
Data Analyst (Payments data focus)
Ready to dive into the world of payments data and make a real impact? We're looking for a Data Analyst to join our growing team. You'll be analyzing payments data, building cool reports, and uncovering insights that optimize our pricing and payment systems. Your work will help us streamline processes, boost financial performance, and create a better experience for our merchants.

Your Mission:


Data Detective: Investigate payment glitches, sniff out financial risks (e.g. billing errors or unexpected rate changes), and serve up data-backed recs.

Merchant Mastermind: Get to the bottom of data discrepancies and merchant configuration issues to ensure smooth operations.

Churn Crusader: Dive deep into why merchants are churning, figure out ""what happened,"" and use those insights to help us improve.

Visualize Insights: Build intuitive reports to monitor payment revenue performance.

Improve Systems: Identify friction points in the payments platform and support efforts to improve processes.

Team Up: Collaborate with Finance, Operations, Engineering, and Product teams to maintain a reliable payments infrastructure.


What You'll Bring:


3-5 years of experience in business analytics, payments, finance, or a related field.

Strong SQL skills (ability to write complex queries to extract insights) and experience with BI tools.

Operating with a bias toward sharing, transparency and collaboration is your default!

Diving in, solving problems, and getting things done is second nature - no waiting for perfect conditions.

Thriving in fast-paced environments, embracing ambiguity, and taking initiative without a rulebook.


Bonus points: Experience in payments, finance, or e-commerce payment platforms.

Benefits:  

At SpotOn, we put people above everything else. We’re known for our innovative software and technology solutions, but we stand out because of the hard-working humans behind the tech. We can’t take care of our clients without taking care of our employees first, and that’s why we invest in you with a competitive benefits package which includes:


Medical, Dental and Vision Insurance 

401k with company match

RSUs

Paid vacation, 10 company holidays, sick time, and volunteer time off

Employee Resource Groups to build community and inclusion at work

Monthly cell phone and internet stipend

Tuition reimbursement for up to $2,000 per calendar year to assist with your professional development


Compensation:


Our base pay range starts at $107,000 -$140,000 for this role

Please note the salary range listed is just one component of a competitive compensation package which includes a company stock plan

Offers will be reflective of the candidate’s location and experience.

The base salary range listed will vary depending on location and experience.
Base salary range: $107,000 USD - $140,000 USD
SpotOn is an equal employment opportunity employer. Qualified candidates are considered for employment without regard to race, religion, gender, gender identity, sexual orientation, national origin, age, military or veteran status, disability, or any other characteristic protected by applicable law.

SpotOn is an e-verify company.","{""role_summary"":""As a Data Analyst at SpotOn, you'll analyze payments data, build reports, and uncover insights to improve pricing and payment processes, ultimately enhancing the merchant experience."",""key_terms"":[{""term"":""Payments data"",""explanation"":""Data related to financial transactions and payment processing.""},{""term"":""POS"",""explanation"":""Point-of-Sale system for restaurants and small businesses.""},{""term"":""SQL"",""explanation"":""Structured Query Language for managing and analyzing relational databases.""},{""term"":""BI tools"",""explanation"":""Business Intelligence tools for data visualization and analysis.""}],""skill_priorities"":{""must_have"":[""3-5 years of experience in business analytics, payments, finance, or a related field"",""Strong SQL skills"",""Experience with BI tools""],""nice_to_have"":[""Experience in payments, finance, or e-commerce payment platforms""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to investigate payment glitches and provide data-backed recommendations?"",""example_answer"":""In my previous role, I identified a payment error that resulted in a 5% revenue loss. I analyzed the data, and my findings led to a process change that prevented similar errors in the future.""},{""question"":""How do you stay organized and prioritize tasks in a fast-paced environment?"",""example_answer"":""I use project management tools to prioritize tasks and break them down into smaller, manageable tasks. I also communicate regularly with stakeholders to ensure everyone is aligned on goals and deadlines.""}],""red_flags"":[""Lack of experience with SQL or BI tools"",""Inability to work in a fast-paced environment""],""confidence_score"":90.0}"
Senior Data Analyst - Payment Success,Checkout.com,"New York, United States",March,2025,"Company Description

Checkout.com is one of the most exciting fintechs in the world. Our mission is to enable businesses and their communities to thrive in the digital economy. We’re the strategic payments partner for some of the best known fast-moving brands globally such as Wise, Hut Group, Sony Electronics, Homebase, Henkel, Klarna and many others. Purpose-built with performance and scalability in mind, our flexible cloud-based payments platform helps global enterprises launch new products and create experiences customers love. And it's not just what we build that makes us different. It's how.

We empower passionate problem-solvers to collaborate, innovate and do their best work. That’s why we’re on the Forbes Cloud 100 list and a Great Place to Work accredited company. And we’re just getting started. We’re building diverse and inclusive teams around the world — because that’s how we create even better experiences for our merchants and our partners. And we need your help. Join us to build the digital economy of tomorrow.

Job Description

Important note: Please submit CVs in English

The role

We empower businesses in the digital economy, and we know that every payment counts. Our Payment Performance team’s mission is to manage and optimise merchants’ payment flow, to achieve optimal conversion, compliance and cost.

Checkout.com is looking for a Senior Data Analyst to join our Payment Success team to craft an all-encompassing payments strategy tailored specifically for our Tier-1 merchants. You will be the main point of contact for a merchant regarding their payment performance. You will play a critical role in defining, delivering and building tools for the right insights to showcase the value of our optimal payment strategies.

You will work closely with Payment Performance engineers and data scientists leveraging cutting-edge technology and data insights. You will also collaborate regularly with other teams and cross-functional stakeholders to establish priorities and drive merchant performance improvements.

Hybrid Working Model: All of our offices globally are onsite 3 times per week (Tuesday, Wednesday, and Thursday). We’ve worked towards enabling teams to work collaboratively in the same space, while also being able to partner with colleagues globally. During your days at the office, we offer amazing snacks, breakfast, and lunch options in all of our locations.

How You’ll Make An Impact

Deliver expertise and guidance to our key merchants by crafting optimal payments strategy.
Conduct deep-dive exploratory data analysis to uncover insights and anomalies
Conduct experiments and A/B tests to improve performance, including ML based solutions.
Develop cutting-edge automation tools aimed at monitoring and optimising merchants’ performance.
Implement robust measurements to assess how proposed solutions impact merchants' performance and revenue, providing valuable insights for both internal and external ROI.
Collaborate with various teams across the company to ensure an outstanding merchant experience and feed requirements for product development
Elevate internal awareness, particularly within the executive team, regarding the full spectrum of merchant services and benefits provided
Drive a culture of cross-team learning and knowledge sharing

Qualifications

5+ years experience as data scientist, working with large and diversified data sets
Bachelor’s degree, preferably in Mathematics / Statistics / Computer Science / Engineering, Finance or equivalent
SQL/ Python knowledge to extract & analyse data from our Data Warehouse
Experience with Git & Spark, Databricks, Retool, API
Ability to find creative and effective solutions for business problems
Flexible, adaptable and has a willingness to learn
Payments or Fintech experience is a plus

If you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values

Please submit CVs in English.

Additional Information

Additional Information

New York City law requires Checkout.com to include in job postings a reasonable estimated salary range for this position. However, exact compensation may vary subject to several factors such as a candidate’s level, relevant experience, qualifications, skills and proficiency for the role.

The information provided here is applicable to those working in the New York City office. However, this role may also open to applicants from other US locations and will be advised on the relevant pay for that location.

For regular full-time employees in New York City, the estimated base salary for this role is $138,720 -163,200 per year.

Our competitive salaries are just one component of Checkout.com’s total compensation package. Additional benefits include: health, vision, dental insurance, 401k, vacation and sick and safe time, learning days and volunteer days.

To view more details of what you can look forward to, visit our careers page: https://www.checkout.com/careers.

Apply Without Meeting All Requirements Statement

If you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.

We believe in equal opportunities

We work as one team. Wherever you come from. However you identify. And whichever payment method you use.

Our clients come from all over the world — and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.

When you join our team, we’ll empower you to unlock your potential so you can do your best work. We’d love to hear how you think you could make a difference here with us.

We want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We’ll be happy to support you.

Take a peek inside life at Checkout.com via

Our Culture video https://youtu.be/BEwnpHuadSw
Our careers page https://www.checkout.com/careers
Our LinkedIn Life pages bit.ly/3OaoN1U
Our Instagram https://www.instagram.com/checkout_com/

Apply Without Meeting All Requirements Statement

If you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.

We believe in equal opportunities

We work as one team. Wherever you come from. However you identify. And whichever payment method you use.

Our clients come from all over the world — and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.

When you join our team, we’ll empower you to unlock your potential so you can do your best work. We’d love to hear how you think you could make a difference here with us.

We want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We’ll be happy to support you.

Take a peek inside life at Checkout.com via

Our Culture video https://youtu.be/BEwnpHuadSw
Our careers page https://www.checkout.com/careers
Our LinkedIn Life pages bit.ly/3OaoN1U
Our Instagram https://www.instagram.com/checkout_com/","{""role_summary"":""A Senior Data Analyst to craft an all-encompassing payments strategy tailored specifically for Tier-1 merchants, working closely with Payment Performance engineers and data scientists to deliver optimal payment strategies."",""key_terms"":[{""term"":""Payment Performance"",""explanation"":""A team responsible for managing and optimizing merchants' payment flow to achieve optimal conversion, compliance, and cost.""},{""term"":""Tier-1 merchants"",""explanation"":""High-value merchants that require tailored payment strategies to optimize their payment performance.""},{""term"":""A/B tests"",""explanation"":""Experiments to compare two or more versions of a product or service to determine which one performs better.""},{""term"":""ML-based solutions"",""explanation"":""Machine learning-based solutions that use algorithms to analyze data and make predictions or decisions.""},{""term"":""Data Warehouse"",""explanation"":""A central repository that stores data from various sources, making it accessible for querying and analysis.""}],""skill_priorities"":{""must_have"":[""5+ years of experience as a data scientist"",""SQL/Python knowledge"",""Experience with Git & Spark, Databricks, Retool, API""],""nice_to_have"":[""Payments or Fintech experience"",""Bachelor's degree in Mathematics/Statistics/Computer Science/Engineering, Finance or equivalent""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach crafting an optimal payments strategy for a Tier-1 merchant?"",""example_answer"":""I would analyze the merchant's payment data, identify areas of improvement, and develop a tailored strategy to optimize their payment performance.""},{""question"":""Can you explain how you would conduct A/B tests to improve payment performance?"",""example_answer"":""I would design an experiment to compare two versions of a payment strategy, collect data, and analyze the results to determine which version performs better.""}],""red_flags"":[""Lack of experience working with large and diversified data sets"",""Inability to find creative and effective solutions for business problems""],""confidence_score"":90.0}"
Full Time - Data Science Analyst,Themesoft Inc.,"Mountain View, CA",March,2025,"Job Title: Data Science Analyst
Location: Mountain View, CA
Client: Cognizant
Duration: Contract

Job Summary
We are looking for a Data Science Analyst with expertise in mining data for insights, KPI trend analysis, ROI measurement, and data-driven decision-making. This role requires a strong analytical mindset, and the ability to work with structured and unstructured data to drive business impact.
Key Responsibilities
Analyze and mine large datasets to uncover trends, correlations, and actionable insights.
Develop models and statistical techniques to track KPI trends, ROI measurement, and forecasting.
Conduct data-driven analysis to optimize business strategies and operational efficiency.
Build, maintain, and optimize codebases analytics workflows.
Work cross-functionally with business, finance, and product teams to support data-backed decision-making.
Ensure data integrity, quality, and governance while handling large datasets.
Required Skills & Qualifications
Experience: 3-5+ years in data analytics, data science, or a related field.
Technical Skills: Proficiency in SQL, Python/R.
Analytics & Modeling: Strong understanding of data mining, statistical modeling, and predictive analytics.
Strong Business Acumen: Ability to translate data insights into strategic recommendations.
Excellent Communication: Strong storytelling and visualization skills for data presentation.
Preferred Qualifications
Experience with ETL, data warehousing.
Background in A/B testing, regression modeling, and statistical analysis.","{""role_summary"":""A Data Science Analyst analyzes and mines large datasets to uncover trends, correlations, and actionable insights, driving business impact through data-driven decision-making."",""key_terms"":[{""term"":""KPI trend analysis"",""explanation"":""Analyzing key performance indicators) to measure business performance and make data-driven decisions.""},{""term"":""ROI measurement"",""explanation"":""Calculating the return on investment to evaluate the effectiveness of business strategies.""},{""term"":""Data mining"",""explanation"":""The process of automatically discovering patterns, relationships, and insights from large datasets.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from sources, transforming it into a usable format, and loading it into a target system.""},{""term"":""A/B testing"",""explanation"":""A method of comparing two versions of a product or service to determine which one performs better.""},{""term"":""Regression modeling"",""explanation"":""A statistical method for establishing relationships between variables to predict outcomes.""}],""skill_priorities"":{""must_have"":[""SQL"",""Python/R"",""Data mining"",""Statistical modeling"",""Predictive analytics"",""Business acumen"",""Communication skills""],""nice_to_have"":[""ETL"",""Data warehousing"",""A/B testing"",""Regression modeling"",""Statistical analysis""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing a large dataset to uncover trends and correlations?"",""example_answer"":""I would start by cleaning and preprocessing the data, then apply statistical techniques such as regression analysis to identify relationships between variables. Finally, I would visualize the results to communicate insights to stakeholders.""},{""question"":""How do you ensure data quality and governance when working with large datasets?"",""example_answer"":""I would implement data validation checks, ensure data consistency, and maintain data documentation to ensure data integrity and quality.""}],""red_flags"":[""Lack of experience in data analytics or a related field."",""Inability to communicate complex data insights effectively.""],""confidence_score"":90.0}"
Business Data Analyst (US - Contract),Expedia Group,"Seattle, WA",March,2025,"Business Data Analyst (US - Contract)

Salary/Hourly Rate:
$51 - $61 per hour

Onsite/Remote:
This is a hybrid role in either Seattle, WA, Austin, TX, or Springfield, MO; candidates will be required onsite 3 days per week (Tuesday – Thursday)

Position Overview:

Expedia Group brands power global travel for everyone, everywhere. We design cutting-edge tech to make travel smoother and more memorable, and we create groundbreaking solutions for our partners. Our diverse, vibrant, and welcoming community is essential in driving our success. We’re building a more open world. Join us.

Why Join Us?

To shape the future of travel, people must come first. Guided by our Values and Leadership Agreements, we foster an open culture where everyone belongs, differences are celebrated and know that when one of us wins, we all win.

Our Global Procurement organization is looking for a passionate, motivated Business Data Analyst. The successful candidate will turn data into information, and help turn information into insight that will drive business decisions. Their responsibilities will include conducting full lifecycle analysis, including requirements, activities and design. The successful candidate will develop analysis and reporting capabilities; they will also monitor performance plans to identify improvement opportunities. This is a temporary 12-month assignment.

Responsibilities of the Business Data Analyst:

Seek out, gather and interpret data, analyze results and provide both ongoing and custom/ad hoc reports
Participate in development and implementation of data collection techniques, data analytics and other strategies that optimize efficiency and enable reporting
Acquire data from primary and secondary data sources (combining and/or splitting as needed) and maintain databases, dashboards and other management resources
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and scrub data from various reports and raw data sources
Work with management to prioritize business and information needs, build analyses, reports and presentations that enable insight and decisions
Identify and define process improvement opportunities
Assist in the development implementation, monitoring and measurement of key performance indicators
Assist in translating findings into actionable and directional plans
Assist Leadership by synthesizing data into useable presentation material (PowerPoint, Excel, etc)

Qualifications of the Business Data Analyst:

Bachelor’s degree in Business, Technology, or another relevant field is preferred
Proven working experience as a Data Analyst or Business Data Analyst
Knowledge of and experience with reporting packages (e.g., Business Objects, Oracle Business Intelligence), and databases (e.g., SQL)
Knowledge of statistics and experience using statistical packages for analyzing datasets (e.g., Excel, Tableau, Power BI)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and compiling results in a cohesive and presentable format- including aptitude in Microsoft PowerPoint
Specific experience and proficiency in various business systems and applications
Critical: Excel, PowerPoint
Helpful: Salesforce, Oracle, Tableau
Experience working with a procurement/purchasing or payables function is a plus

Please note contractors are engaged to provide services to Expedia Group on a temporary basis in connection with a specific assignment. Contractors are hired and employed through Atrium, our third-party payrolling partner.

As a woman-owned firm, Atrium values diversity. We are an equal opportunity employer and will consider all applications without regard to race, sex, age, color, religion, national origin, veteran status, disability, genetic information or any other characteristic protected by law. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

This job posting is for a temporary role as an employee of Atrium on assignment at Expedia. The individual selected for this role will be offered the role as an employee of Atrium; compensation, medical benefits, fringe benefits and other terms and conditions of employment shall be presented by Atrium upon offer. The pay rate range provided is a reasonable estimate of the anticipated compensation range for this job at the time of posting. The actual pay rate will be based on a number of factors, including skills, competencies, experience, location and/or being pursued and other job-related factors permitted by law. In addition, this role will be eligible for overtime pay, in accordance with federal and state requirements.

No C2C or Third-Party Vendors","{""role_summary"":""The Business Data Analyst will turn data into information, and help turn information into insight that will drive business decisions. They will conduct full lifecycle analysis, develop analysis and reporting capabilities, and monitor performance plans to identify improvement opportunities."",""key_terms"":[{""term"":""Data Analytics"",""explanation"":""The process of examining data sets to draw conclusions and identify patterns.""},{""term"":""Business Objects"",""explanation"":""A reporting package used to create and manage business intelligence reports.""},{""term"":""SQL"",""explanation"":""A programming language used to manage and manipulate databases.""},{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft that allows users to create interactive visualizations and business intelligence reports.""},{""term"":""Procurement"",""explanation"":""The process of acquiring goods, services, or works from an external source.""}],""skill_priorities"":{""must_have"":[""Excel"",""PowerPoint"",""SQL"",""Business Objects"",""Tableau"",""Power BI""],""nice_to_have"":[""Salesforce"",""Oracle""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing a complex data set to identify trends and patterns?"",""example_answer"":""I would start by cleaning and organizing the data, then use statistical tools to identify correlations and trends. Finally, I would present the findings in a clear and concise manner.""},{""question"":""How do you stay up-to-date with new reporting packages and databases?"",""example_answer"":""I regularly attend webinars and training sessions to stay current with new tools and technologies.""}],""red_flags"":[""Lack of experience working with procurement or purchasing functions"",""Inability to work onsite 3 days a week""],""confidence_score"":90.0}"
"Data Analyst, Advertising",U.S. News & World Report,United States,March,2025,"U.S. News & World Report is a multifaceted digital media company dedicated to helping citizens, consumers, business leaders and policy officials make important decisions in their lives. We publish independent reporting, rankings, data journalism and advice that has earned the trust of our readers and users for nearly 90 years. Our platforms on usnews.com include Education, Health, Money, Travel, Cars, News and 360 Reviews.
We reach more than 40 million people monthly during moments when they are most in need of expert advice and motivated to act on that advice directly on our platforms. Our signature franchises include our “Best” series of consumer guides on colleges, graduate schools, hospitals, diets, cars, financial services and more. These guides provide an easy-to-digest list for consumers to better understand and compare when making their decisions. We continue to publish annual guides of the authoritative Best Colleges and Best Hospitals rankings on our website and in print. And our U.S. News Live flagship conferences highlight important national conversations including Healthcare of Tomorrow and Healthiest Communities.

We believe in having a broad range of talent and backgrounds at U.S. News. We strive to maintain a welcoming workplace where everyone is given an opportunity to succeed and contribute to their fullest. Learn more about our Diversity, Equity and Inclusion initiative.

Your role in helping us shape the future:
U.S. News empowers everyone to thrive. We are hiring a Senior Data Analyst to help empower stakeholders and business units with clear data visualizations and actionable takeaways.
This hands-on role is ideal for someone with strong analytical skills and a strong understanding of the marketing landscape to distill insights from disparate data sets and uncover revenue-generating opportunities. The successful candidate will be exposed to many parts of the business, including product, marketing, software development and sales. You will directly contribute to top-line revenue growth within the robust and multi-dimensional advertising business at U.S. News.

Are you up to the challenge?
Build and maintain data visualization suites surfacing advertising revenue for internal teams and stakeholders
Oversee project management of new initiatives with advertising partners
Lead end-to-end integration of new ad tech partners
Analyze reporting & develop yield-driving insights across partners, wrappers and environments
Execute on cutting-edge monetization opportunities surfaced by ad tech partners including Amazon, Microsoft, Google and The Trade Desk.
Coordinate with stakeholders to facilitate troubleshooting integrations, launching new ad products and testing ad stack configurations
Present new business opportunities based on analysis of performance data
Leverage data unification tools to supply actionable insights with regard to industry trends
Conduct periodic training sessions to keep internal teams up-to-date on the digital advertising landscape

You should definitely have:
Three years to five years of experience in the digital advertising industry
Bachelor of Science or a Bachelor of Arts preferred; equivalent experience accepted
Working knowledge of Google Ad Manager and analytics tools such as Looker Studio, Google Analytics, and Supermetrics
Experience working with ad tech platforms including SSPs, DSPs and DMPs
Intermediate to advanced working knowledge of Microsoft Excel
Ability to analyze data and present a clear & compelling action plan based on your findings
Experience managing first-party audience data, including identifying new first-party data sources and audience segmentation opportunities
Effective time management skills - ability to juggle multiple tasks and prioritize to meet necessary deadlines
Exceptional troubleshooting, A/B testing and problem-solving abilities
Knowledge and awareness of current programmatic and digital ad technology trends; remain up to speed on new in-platform betas and testing opportunities
Understanding of ad tagging and site taxonomy

Preferred qualifications:
Fluency with SQL and ability to write queries and join siloed data sets
Familiarity with programming languages such as javascript, CSS and HTML
Knowledge of oRTB protocol
Understanding of common web data structures such as JSON
Experience with system integrations, data ingestion & ETL

What it’s like to work with us:
Talent is our best asset!
We invest in people with passion and potential who understand U.S. News’ dedication to our consumers.
Entrepreneurial, mission-driven culture with core values of quality and integrity
Focus on fostering personal and professional growth
Competitive benefits including paid vacation time, medical, tuition reimbursement, and training
Collaborative Work Environment ~ Fun, diverse, inclusive and ambitious co-workers

Other Job Info:
Candidates are encouraged to submit a cover letter.
These statements are intended to describe the general nature and level of work being performed by employees assigned to this job. This is not intended to be an exhaustive list of all responsibilities, duties, and skills required of employees assigned to this job.
U.S. News & World Report strongly encourages all employees to be fully vaccinated (including boosters).
The anticipated base salary for this position is $60,000 to $85,000. The actual base salary offered will depend on a variety of factors, including without limitation, the qualifications of the individual applicant for the position, years of relevant experience, level of education attained, certifications or other professional licenses held, interview performance, and if applicable, the location in which the applicant lives and/or from which they will be performing the job.","{""role_summary"":""The Senior Data Analyst role at U.S. News & World Report is responsible for empowering stakeholders and business units with clear data visualizations and actionable takeaways, contributing to top-line revenue growth."",""key_terms"":[{""term"":""Ad tech"",""explanation"":""Advertising technology used to manage and optimize digital advertising campaigns.""},{""term"":""SSPs"",""explanation"":""Supply-side platforms that enable publishers to manage and optimize their ad inventory.""},{""term"":""DSPs"",""explanation"":""Demand-side platforms that enable advertisers to manage and optimize their ad campaigns.""},{""term"":""DMPs"",""explanation"":""Data management platforms that enable the collection, organization, and analysis of audience data.""},{""term"":""oRTB protocol"",""explanation"":""An open standard for real-time bidding in digital advertising.""},{""term"":""JSON"",""explanation"":""A lightweight data interchange format used for exchanging data between web servers and web applications.""}],""skill_priorities"":{""must_have"":[""Three to five years of experience in digital advertising industry"",""Working knowledge of Google Ad Manager and analytics tools"",""Experience working with ad tech platforms"",""Intermediate to advanced working knowledge of Microsoft Excel"",""Ability to analyze data and present a clear action plan""],""nice_to_have"":[""Fluency with SQL and ability to write queries and join siloed data sets"",""Familiarity with programming languages such as javascript, CSS and HTML"",""Knowledge of oRTB protocol"",""Understanding of common web data structures such as JSON"",""Experience with system integrations, data ingestion & ETL""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your experience with Google Ad Manager and analytics tools?"",""example_answer"":""I have worked with Google Ad Manager for three years, and I'm proficient in using analytics tools like Looker Studio and Supermetrics to analyze data and present actionable insights.""},{""question"":""How do you stay up-to-date with the latest trends in digital advertising?"",""example_answer"":""I regularly read industry blogs and attend conferences to stay current on the latest developments in digital advertising, including programmatic and ad technology.""}],""red_flags"":[""Lack of experience in digital advertising industry"",""Inability to analyze data and present clear action plans""],""confidence_score"":90.0}"
Analista de datos,Stefanini LATAM,Mexico,March,2025,"¡Sé parte de Stefanini!
En Stefanini somos más de 30.000 genios, conectados desde 41 países, haciendo lo que les apasiona y co-creando un futuro mejor.

Estamos en búsqueda de nuestro próximo Data Analyst, responsable de la investigación y correcta documentación de las necesidades de datos que tenga el negocio. Será responsable de traducir los requerimientos de datos/información en solicitudes claras y entendibles para las áreas de Dominios de Datos, Tecnología y Producto para que puedan ser priorizados y atendidos.

Responsabilidades princiaples:
Realizar Data Assessment con áreas de Negocio para la conformación de dominios de datos:
Entrevistar al negocio, analizar del flujo de trabajo, estructura y procesos, en sesiones de observación
Matriz de Assessment/Matriz de Trazabilidad de datos
Interpretación y entrega de resultados
Construcción de consultas base (SQL, insumos) para su implementación por parte de los equipos de desarrollo
Asegurar que las soluciones de TI reflejen la efectividad necesaria para alcanzar los objetivos comerciales (validación y oportunidades de optimización)
Crear requisitos y documentos de flujo de trabajo claros y concisos
Incrementar la adopción del negocio de las soluciones de datos a través de la consistencia de datos
Validar la información mediante pruebas
Evaluación de calidad de datos
Diseño de modelos de datos (lógicos, BI)

Requisitos:
Análisis de negocios centrado en el dominio de datos y sistemas de inteligencia empresarial (>3 años)
Entrevistas con usuarios comerciales, recopilación de informes y requisitos de KPI (>3 años)
Análisis de datos, unión de diferentes fuentes con SQL (nivel avanzado)
Documentación de requisitos y flujos de trabajo
Diagramado de soluciones de datos (alto nivel)
Traducción de requisitos para Ingeniería y Arquitectura de datos, y soluciones BI
Crear, analizar y entregar métricas clave utilizando paneles, informes y presentaciones (pptx, Google Slides, BI dashboards)
Construir modelos analíticos avanzados (indispensable)
Habilidades sólidas de programación (deseable)
Experiencia con metodologías Agile (SCRUM, Kanban)

Herramientas:
Office Suite (avanzado)
SQL (avanzado)
Tableau/Looker/Power BI (intermedio)
Marco de trabajo Ágiles
Python (deseable)

Habilidades:
Comunicación efectiva con directivos y equipos técnicos, de desarrollo (indispensable)
Capacidad analítica financiera (prioritario)
Conocimientos sólidos en estadística y probabilidad (indispensable)
Pensamiento estructurado (indispensable)
Liderazgo (indispensable)
Autogestión (indispensable)
Análisis de ETL y flujos de datos (prioritario)

¿Qué obtendrás al laborar con nosotros?
Sueldo acorde a experiencia.
Prestaciones de Ley.
Prestaciones Superiores a la Ley.
Bonos mensuales y Vales de Despensa.
Cartelera de convenios y descuentos.
Plan de carrera y crecimiento profesional.","{""role_summary"":""The Data Analyst is responsible for investigating and documenting data needs, translating business requirements into clear and actionable requests for Data Domains, Technology, and Product teams."",""key_terms"":[{""term"":""Data Assessment"",""explanation"":""Evaluating data needs and identifying opportunities for improvement.""},{""term"":""Dominios de datos"",""explanation"":""Data domains, which are categories of data used by the business.""},{""term"":""Matriz de Assessment/Matriz de Trazabilidad de datos"",""explanation"":""A matrix used to track and assess data quality and completeness.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process for extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""SQL"",""explanation"":""Structured Query Language - a programming language used for managing and analyzing relational databases.""},{""term"":""BI"",""explanation"":""Business Intelligence - a set of tools and techniques used to analyze and present business data.""},{""term"":""Agile"",""explanation"":""A software development methodology that emphasizes collaboration, flexibility, and rapid delivery.""}],""skill_priorities"":{""must_have"":[""Data analysis"",""SQL"",""Business intelligence"",""Data modeling"",""Communication skills"",""Analytical skills"",""Leadership skills""],""nice_to_have"":[""Programming skills"",""Experience with Agile methodologies"",""ETL and data flow analysis""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach a data assessment for a new business domain?"",""example_answer"":""I would start by conducting stakeholder interviews to understand the business requirements, followed by a thorough analysis of the data gaps and opportunities for improvement.""},{""question"":""How do you ensure data quality and completeness in your analysis?"",""example_answer"":""I use a combination of data validation techniques, such as data profiling and data quality metrics, to ensure that the data is accurate and complete.""}],""red_flags"":[""Lack of experience with data analysis and SQL"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Data Specialist,Hamlyn Williams,"New York, United States",March,2025,"About the Role
We are looking for a scientific data specialist to support efforts in computational drug discovery. This position offers the opportunity to work closely with researchers in machine learning, chemistry, and biology to curate, process, and analyze complex datasets. The ideal candidate will contribute to shaping data strategies for research applications in a collaborative and dynamic environment.
Key Responsibilities
Organize, process, and analyze biological and chemical datasets for research and development.
Collaborate with interdisciplinary teams to integrate machine learning approaches into drug discovery efforts.
Develop data workflows and ensure quality control across various research datasets.
Work within Linux-based environments and utilize Python for data processing.
Ideal Qualifications
Master’s or Ph.D. in medicinal chemistry, pharmacology, computational biology, or a related discipline.
Hands-on laboratory experience, with familiarity in assays and drug discovery techniques.
Proficiency in Linux environments and scripting languages such as Python.
Strong problem-solving skills and ability to work in an interdisciplinary setting.
Why Join?
This is an opportunity to contribute to cutting-edge research in molecular sciences while working alongside leading experts in the field. The position offers a competitive salary, performance-based bonuses, and comprehensive benefits, including relocation assistance.
For more information, get in touch with us!","{""role_summary"":""Support computational drug discovery by curating, processing, and analyzing complex datasets, collaborating with researchers in machine learning, chemistry, and biology."",""key_terms"":[{""term"":""Machine learning"",""explanation"":""A type of artificial intelligence that enables computers to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Linux-based environments"",""explanation"":""Computer systems that use the Linux operating system, often used for data processing and analysis.""},{""term"":""Assays"",""explanation"":""Laboratory tests used to measure the activity or concentration of a biological molecule, such as a drug.""}],""skill_priorities"":{""must_have"":[""Python"",""Linux environments"",""problem-solving skills""],""nice_to_have"":[""Hands-on laboratory experience"",""Ph.D. in medicinal chemistry, pharmacology, computational biology, or a related discipline""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to integrate machine learning approaches into a research project?"",""example_answer"":""In my previous role, I worked on a project that involved using machine learning algorithms to analyze large datasets and identify patterns. I was able to successfully integrate the algorithms into our research workflow, resulting in improved accuracy and efficiency.""},{""question"":""How do you ensure data quality control across various research datasets?"",""example_answer"":""I use a combination of automated scripts and manual checks to ensure data quality control. I also work closely with the research team to understand their data requirements and develop customized data workflows to meet those needs.""}],""red_flags"":[""Lack of experience with Python or Linux environments"",""Inability to work in an interdisciplinary setting""],""confidence_score"":90.0}"
Analyst,TechOp Solutions International,"Washington, DC",March,2025,"At TechOp Solutions, we are committed to delivering innovative technology and operational solutions that drive mission success. We are seeking a highly motivated Analyst to join our dynamic team. In this role, you will leverage data-driven insights, analytical expertise, and problem-solving skills to support critical business and operational initiatives. If you thrive in a fast-paced environment and are passionate about optimizing processes and driving strategic decisions, we want to hear from you!

The ERO Law Enforcement Systems and Analysis (LESA) division is responsible for helping inform the development of ERO strategies and supporting continuous enhancement of ERO business processes to execute those strategies. Through data collection and analysis and technology and process improvements, LESA delivers tools, studies, and recommendations that assist ICE's decision-making and planning (strategic, business, and operational). LESA studies ICE's operations and resources (personnel, processes, technology, and infrastructure) to find areas for continuous improvement.

Responsibilities Include:

Writing queries (in SQL or Python) via Databricks to wrangle data, compiling Excel reports, performing data validation on work products, performing code reviews (SQL, Python), and providing demonstrations to client stakeholders
Conducts research and prepares management, organizational and business analyses and forecasts using data science tools
Work independently as a part of a workstream to provide analytical and statistical support
Generate management tools that effectively control programs and generate reports; and supports the programmatic development of operational applications of the tools or analysis that are focused around operations research and document findings
Develop custom automation solutions to improve operational efficiencies
Prepare briefings and issue papers, studies, recommendation, responses and reports about the mission, activities, and related statistics
Develop, test, and deploy new data science models according to agency needs
Identify new data sets which would enhance the accuracy of existing models and dashboards
Analyze the impact of the effects of a regulation, policy, program, etc. and the effects of changes in budget, staffing or policy/priority changes on resources, performance, or schedule
Automate manual reports via Python scripts in Databricks following best practices


Requirements

Strong written and oral communication;
Bachelor's degree and 0-3 years of experience
SQL, Excel, Qlik, Python, Databricks, and other Business Intelligence tools","{""role_summary"":""Support critical business and operational initiatives through data-driven insights, analytical skills, and problem-solving abilities."",""key_terms"":[{""term"":""Databricks"",""explanation"":""A cloud-based platform for working with big data and machine learning""},{""term"":""Qlik"",""explanation"":""A business intelligence software for data visualization and analytics""},{""term"":""Business Intelligence tools"",""explanation"":""Software applications that help organizations make better decisions by providing insights from their data""}],""skill_priorities"":{""must_have"":[""SQL"",""Excel"",""Python"",""Databricks"",""Strong written and oral communication""],""nice_to_have"":[""Qlik"",""Business Intelligence tools""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize a manual report using Python in Databricks?"",""example_answer"":""I would identify the report's requirements, design a Python script to automate the process, and ensure the script follows best practices for maintainability and scalability.""},{""question"":""How do you stay up-to-date with changing business needs and priorities?"",""example_answer"":""I regularly review business requirements, attend stakeholder meetings, and engage with cross-functional teams to stay informed about changing needs and priorities.""}],""red_flags"":[""Lack of experience with data analysis and visualization tools"",""Inability to work independently in a fast-paced environment""],""confidence_score"":85.0}"
Data Analytics Analyst - US Based Remote,Lensa,"Seattle, WA",March,2025,"Lensa is the leading career site for job seekers at every stage of their career. Our client, Anywhere Real Estate, is seeking professionals in Seattle, WA. Apply via Lensa today!

Job Title: Data Analyst / Data Operations

Company Overview

Join our dynamic team where we leverage cutting-edge technology to drive data-driven decisions. We are committed to empowering our customers with actionable insights and superior outcomes. We value innovation, integrity, and excellence.

Job Description

We are seeking a dedicated and analytical Data Analyst to work on data and analytics organizations’ operations with 1 to 3 years of experience in the data field. The ideal candidate will manage vendor relationships, handle billing and invoice validation, oversee contracts, and track key metrics. This role requires strong analytical skills, excellent written and oral communication and presentation skills, attention to detail, and the ability to work collaboratively with various stakeholders.

Key Responsibilities

Coordinate with vendors to resolve issues, escalations, action plans, etc.
Conduct surveys, gather feedback and present aggregated data in an organized way.
Review and validate invoices from different vendors to ensure accuracy and compliance with contracts.
Gather, maintain, and publish metrics for the organization working with the leadership team. Also, monitor performance and identify areas for improvement.
Analyze data to support decision making and provide actionable insights.
Prepare and present reports and presentations on organizational and operational areas.
Ensure data integrity by verifying data regularly.
Work closely with matrixed cross functional teams to identify opportunities for process and efficiency improvements.

Qualifications And Skills

Bachelor’s degree in Data Analytics, Information Systems, Computer Science, or a related field.
Proficiency in Excel, including functions and macros.
Strong analytical skills and attention to detail.
Strong organizational and time management skills.
Excellent verbal and written communication skills.
Creative skills to put together presentations in MS PowerPoint.
Ability to work effectively in a team environment and collaborate with various stakeholders at different levels in a matrixed team environment.
Ability to adapt to changing priorities and manage multiple tasks simultaneously.
Basic understanding of data governance, data quality, data engineering, data analytics, BI reporting, and data science is a plus.
Background in working with cloud platforms such as AWS, Azure, or GCP is a plus.
Familiarity with Agile methodology is a plus.

Additional Information

1-3 years’ experience in the field.
Eager to learn and adapt in a fast-paced environment.
Ability to aggregate and present data and communicate effectively to different levels of leadership.

Anywhere Real Estate Inc. (http://www.anywhere.re/)  (NYSE: HOUS) is on a mission to empower everyone’s next move. Home to some of the most recognized brands in real estate Better Homes and Gardens® Real Estate (https://www.bhgre.com/) , Century 21® (https://www.century21.com/) , Coldwell Banker® (https://www.coldwellbanker.com/) , Coldwell Banker Commercial® (https://www.cbcworldwide.com/) , Corcoran® (https://www.corcoran.com/) , ERA® (https://www.era.com/) , and Sotheby's International Realty® (https://www.sothebysrealty.com/eng)

The Anywhere portfolio includes franchise and brokerage operations as well as national title, settlement, and relocation companies and nationally scaled mortgage origination and underwriting joint ventures.  Supporting approximately 1.5 million home transactions in 2021, Anywhere is focused on simplifying, digitizing and integrating the real estate transaction for all consumers, no matter where they may be in their home buying and selling journey.  With innovative products and technology, Anywhere fuels the productivity of its approximately 196,200 independent sales agents in the US and approximately 136,400 independent sales agents in 118 other countries and territories.

At Anywhere Real Estate, diversity fuels success – for our company, for our employees, and for our industry. We strive to be a top destination for diverse talent, committed to creating a culture of belonging that empowers everyone’s next move. We pursue talent – strategic thinkers who are eager to always find a better way, relentlessly focus on talent, obsess about growth, and achieve exceptional results. We value diversity – respecting backgrounds, cultures, perspectives, and beliefs. We develop our diverse talent base – through increasing representation in executive key leadership roles with actions including mentorship programs and partnerships with real estate associations that promote diversity and inclusion. Read more about our company’s diversity, equity, and inclusion efforts in our annual Corporate Social Responsibility Report (https://assets.website-files.com/633f08923c4c519693723aa5/63f7690462db639dcd8b18de_Anywhere%20CSR%20Report%202022.pdf) .

You’ll find our commitment to diversity reflected in our achievements:

Recognized as one of the World’s Most Ethical Companies since 2011.
Anywhere has also been designated a Great Place to Work since 2019.
Recognized by Fortune as one of America’s Most Innovative Companies.
Honored by Forbes as one of the World’s Best Employers for Diversity and Top Female Friendly Companies.

With a diverse employee population, we know we will succeed together and move real estate to what’s next. We hope you’ll join us.

EEO Statement: EOE including disability/veteran","{""role_summary"":""Data Analyst responsible for managing vendor relationships, tracking key metrics, and providing actionable insights to support decision-making."",""key_terms"":[{""term"":""Data Governance"",""explanation"":""Ensuring data quality, security, and compliance with organizational policies.""},{""term"":""Data Engineering"",""explanation"":""Designing and implementing data systems to support business operations.""},{""term"":""Agile Methodology"",""explanation"":""An iterative approach to project management, emphasizing flexibility and collaboration.""},{""term"":""Cloud Platforms"",""explanation"":""Cloud-based services like AWS, Azure, or GCP, used for data storage and processing.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in Data Analytics or related field"",""Proficiency in Excel"",""Strong analytical skills"",""Excellent communication skills""],""nice_to_have"":[""Background in cloud platforms"",""Familiarity with Agile methodology"",""Basic understanding of data governance, data quality, data engineering, data analytics, BI reporting, and data science""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure data integrity?"",""example_answer"":""I regularly verify data to ensure accuracy and compliance with contracts.""},{""question"":""Can you walk me through your experience with data analytics tools?"",""example_answer"":""I've worked with Excel, including functions and macros, to analyze and present data insights.""}],""red_flags"":[""Lack of experience in data analytics"",""Inability to work collaboratively with various stakeholders""],""confidence_score"":90.0}"
Data Analyst Consultant,MIGSO-PCUBED,Greater Boston,March,2025,"We are currently looking for a passionate Data Analyst Consultant to join our team in Boston! This role is hybrid and will require 1-2 days of onsite work in New Bedford, MA.

WHO ARE WE?
MIGSO-PCUBED is a consulting firm that focuses solely on Project, Program, and Portfolio Management and Change Management. We work with clients in a variety of sectors such as Financial Services, Energy, Aerospace and Defense, and Automotive. You will have the opportunity to vary your experience and support our leading clients in these areas!

We are looking for someone who is eager to learn and develop project plans to enable quality decision making while delivering added value. You should be a logical thinker, adept at collecting, compiling, analyzing and presenting data to key stakeholders. You should have the ability to build and foster client relationships , and focus on service delivery, quality work product, and exceeding project deliverables.

YOUR NEXT CHALLENGE:
· Creating dashboards in Power BI/Tableau/Qlik Sense or other relevant tools
· Gathering requirements from business stakeholders and translating into technical requirements
· Normalizing, cleaning, and procuring data from various sources (Internal/External)
· Creating, managing, and communicating data models
· Understanding commonly used business continuity and collaboration tools (SharePoint, MS Teams, Power Automate, etc)
· Knowledge of machine learning, natural language processing, robotic process automation, and statistical modeling are a huge plus
· Practical experience working in Waterfall and Agile project management settings

As an MIGSO-PCUBED consultant, you will deliver our expertise, adapt to new environments and work as part of a team. You will represent our brand on the client site and thanks to the materials that we provide, you will be prepared and polished to support our engagements.

WHO ARE YOU?
You should have a least a Bachelor’s Degree, 2-5 years of Data Analysis/Data Science experience working in a Project environment, and you want to develop yourself in consulting. You should also have experience with SharePoint web development. Comprehensive MS Project Online knowledge is required as well.

If this sounds like you, then we want to meet you!

MIGSO-PCUBED recognizes the civil right of every person to obtain and maintain employment without discrimination. We have a longstanding policy that no individual may be refused a job, discharged, or discriminated against in any way due to any protected characteristics established by local, state and Federal law. In all respects, MIGSO-PCUBED is committed to a policy of full and fair equal employment under the law and applies this in all employment decisions, including recruitment, hiring, compensation, engagement staffing, training, promotion, transfer, and termination.","{""role_summary"":""A Data Analyst Consultant will join our team in Boston, working on project management and change management projects for various clients. The role involves data analysis, stakeholder communication, and project delivery."",""key_terms"":[{""term"":""Power BI"",""explanation"":""A business analytics service by Microsoft to create interactive dashboards.""},{""term"":""Agile project management"",""explanation"":""An iterative approach to project management that focuses on flexibility and customer satisfaction.""},{""term"":""Machine learning"",""explanation"":""A subset of artificial intelligence that enables systems to learn from data without being explicitly programmed.""},{""term"":""SharePoint web development"",""explanation"":""A Microsoft-based web application platform for building intranet sites and collaboration tools.""}],""skill_priorities"":{""must_have"":[""Data Analysis"",""Project environment experience"",""SharePoint web development"",""MS Project Online knowledge""],""nice_to_have"":[""Machine learning"",""Natural language processing"",""Robotic process automation"",""Statistical modeling""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach data analysis for a project with multiple stakeholders?"",""example_answer"":""I would first gather requirements from stakeholders, then normalize and clean the data, and finally present the insights to the stakeholders using a dashboard tool like Power BI.""},{""question"":""How do you stay organized in an Agile project management environment?"",""example_answer"":""I prioritize tasks, use collaboration tools like MS Teams, and ensure clear communication with the project team and stakeholders.""}],""red_flags"":[""Lack of experience in SharePoint web development"",""Inability to work in a hybrid onsite-remote work environment""],""confidence_score"":85.0}"
Data Engineer,Ample Insight,"Toronto, Ontario, Canada",June,2024,"Company Description

You will join a world-class team of engineers and data scientists from Facebook, Uber, Amazon and Google. We are a fast growing consulting firm based in Toronto with clients ranging from leading startups building impactful technologies to Fortune 500 companies looking to scale their engineering and data capabilities.

Job Description

We are looking for a data engineer who is passionate about analytics and helping companies build and scale data. You enjoy working with data and are motivated to produce high quality data tools and pipelines that help empower other data scientists. You are experienced in architecting data ETL workflows and schemas. Critical thinking and problem-solving skills are essential for this role.

Qualifications

BS (or higher, e.g., MS, or PhD) in Computer Science, Engineering, Math, or Statistics
Hands on experience working with user engagement, social, marketing, and/or finance data
Proficient in Python (i.e. Pandas, Numpy, scikit-learn, etc), R, TensorFlow, amongst other data science related tools and libraries
Extensive experience working on relational databases, designing complex data schemas, and writing SQL queries
Deep knowledge on performance tuning of ETL Jobs, SQL, and databases
Working knowledge of Snowflake
Experience working with Airflow is a strong plus
Devops experiences is a plus

Additional Information

We have very competitive compensation.

Work on cool projects based on your interests and skills. We believe in accountability and NOT micro-management.","{""role_summary"":""Design and implement scalable data pipelines and tools to empower data scientists, with a focus on high-quality data workflows."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of data integration from multiple sources into a single, unified view.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and processing large amounts of data.""},{""term"":""Airflow"",""explanation"":""A platform for programmatically defining, scheduling, and monitoring workflows, often used for data pipelines.""},{""term"":""Devops"",""explanation"":""A set of practices combining software development (Dev) and IT operations (Ops) to improve collaboration and efficiency.""}],""skill_priorities"":{""must_have"":[""Python"",""Pandas"",""Numpy"",""scikit-learn"",""Relational databases"",""SQL"",""ETL workflows"",""Data schema design""],""nice_to_have"":[""R"",""TensorFlow"",""Snowflake"",""Airflow"",""Devops""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a recent ETL workflow you designed and how you optimized its performance?"",""example_answer"":""I designed an ETL workflow using Python and SQL to integrate user engagement data from multiple sources. I optimized its performance by implementing parallel processing, indexing, and caching.""},{""question"":""How do you approach data schema design for complex datasets?"",""example_answer"":""I follow a structured approach, considering data relationships, data types, and scalability requirements. I also ensure data quality and integrity by implementing data validation and normalization techniques.""}],""red_flags"":[""Lack of experience with data pipelines and ETL workflows"",""Inability to write efficient SQL queries"",""Limited knowledge of data schema design and performance tuning""],""confidence_score"":90.0}"
Data Engineer (x1)-Canada,Zortech Solutions,Canada,May,2024,"Role: Data Engineer (x1)

Location: Canada/Remote

Duration: Longterm

Job Description

Data Engineer (x1) who has experience with kafka streaming, flink SQL, and HL7 FHIR; and has experience with large scale data delivery to data consumers","{""role_summary"":""Design and implement large-scale data delivery to data consumers, utilizing expertise in Kafka streaming, Flink SQL, and HL7 FHIR."",""key_terms"":[{""term"":""Kafka streaming"",""explanation"":""A method of handling high-throughput and provides low-latency, fault-tolerant data processing.""},{""term"":""Flink SQL"",""explanation"":""A SQL-like query language for Apache Flink, allowing for real-time data processing and analysis.""},{""term"":""HL7 FHIR"",""explanation"":""A standard for exchanging healthcare information electronically, focusing on interoperability and data sharing.""}],""skill_priorities"":{""must_have"":[""Kafka streaming"",""Flink SQL"",""HL7 FHIR"",""Large scale data delivery""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data processing in a Kafka streaming pipeline?"",""example_answer"":""I would implement data partitioning, use efficient serialization formats, and ensure proper resource allocation to minimize latency and maximize throughput.""},{""question"":""Can you explain how you would integrate Flink SQL with HL7 FHIR for healthcare data analysis?"",""example_answer"":""I would use Flink SQL to process and transform the HL7 FHIR data, leveraging its real-time capabilities for timely insights.""}],""red_flags"":[""Lack of experience with large-scale data delivery"",""Inability to work with Kafka streaming, Flink SQL, and HL7 FHIR""],""confidence_score"":90.0}"
Data Engineer (x1)- Canada,Zortech Solutions,Canada,May,2024,"Role: Data Engineer (x1)

Location: Canada/Remote

Duration: Longterm

Job Description

Data Engineer (x1) who has experience with kafka streaming, flink SQL, and HL7 FHIR; and has experience with large scale data delivery to data consumers","{""role_summary"":""Design and implement large-scale data delivery to data consumers, utilizing expertise in Kafka streaming, Flink SQL, and HL7 FHIR."",""key_terms"":[{""term"":""Kafka streaming"",""explanation"":""A method of handling high-throughput and provides low-latency, fault-tolerant data processing.""},{""term"":""Flink SQL"",""explanation"":""A SQL-like query language for Apache Flink, allowing for real-time data processing and analysis.""},{""term"":""HL7 FHIR"",""explanation"":""A standard for exchanging healthcare information electronically, focusing on interoperability and data sharing.""}],""skill_priorities"":{""must_have"":[""Kafka streaming"",""Flink SQL"",""HL7 FHIR"",""Large scale data delivery""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data processing in a Kafka streaming pipeline?"",""example_answer"":""I would implement data partitioning, use efficient serialization formats, and ensure proper resource allocation to minimize latency and maximize throughput.""},{""question"":""Can you explain how you would integrate Flink SQL with HL7 FHIR for healthcare data analysis?"",""example_answer"":""I would use Flink SQL to process and transform the HL7 FHIR data, leveraging its real-time capabilities for timely insights.""}],""red_flags"":[""Lack of experience with large-scale data delivery"",""Inability to work with Kafka streaming, Flink SQL, and HL7 FHIR""],""confidence_score"":90.0}"
Data Engineer / Toronto,Intersog,"Toronto, Ontario, Canada",May,2024,"Intersog® is a Chicago-based provider of ROI-driven custom web and mobile development specializing in the delivery of full-service, end-to-end solutions, and project resources to Fortune 500 companies, SMEs, and startups. We help our clients attack their ambitious business goals, solve skills shortage issues, and become innovative by building Dedicated Software Development Teams in Mexico, Canada, the U.S.A., and Ukraine and/or providing on-demand IT project resources to complete required skills on their in-house teams.

About The Role

We are looking for a Data Engineer passionate about shaping the future of data infrastructure and eager to tackle the challenges of big data in a dynamic, collaborative environment. A Data Engineer plays a pivotal role by developing and overseeing the frameworks and systems that process and store vast data volumes efficiently. This individual works in sync with data scientists, analysts, and various stakeholders to guarantee data accessibility, accuracy, and integrity for strategic insights and operational efficiency.

Requirements

Bachelor's degree or higher in Computer Science, Data Science, or a related field
Proficiency in languages such as Python, Java, or Scala and experience with big data frameworks (Hadoop, Spark, Kafka)
Familiarity with cloud platforms (AWS, Azure) and data integration tools
A strong foundation in data ingestion, storage, orchestration, and management on cloud platforms, with a preference for Azure or AWS
3 to 5 years of experience in Data Engineering role
Minimum 5+ relevant industry experience with Big data - Hive, Spark, Hadoop, queueing system like Apache Kafka/Rabbit MQ/AWS Kinesis
Hands on experience in building metadata-driven, reusable design patterns for data pipeline, orchestration, ingestion patterns (batch, real time);
Experience in designing and implementing solutions on distributed computing and cloud services platform (but not limited to) - AWS, Azure, GCP;
Hands on experience building CI/CD pipelines and awareness of practices for application monitoring","{""role_summary"":""Develop and maintain data infrastructure to process and store large data volumes efficiently, ensuring data accessibility, accuracy, and integrity for strategic insights and operational efficiency."",""key_terms"":[{""term"":""Big Data"",""explanation"":""Large and complex data sets that require specialized processing and storage solutions.""},{""term"":""Data Ingestion"",""explanation"":""The process of collecting and transporting data from various sources to a centralized location for processing and analysis.""},{""term"":""Cloud Platforms"",""explanation"":""On-demand computing resources and services provided over the internet, such as AWS, Azure, and IBM Cloud.""},{""term"":""Data Pipeline"",""explanation"":""A series of processes that extract, transform, and load data from one system to another for analysis and reporting.""},{""term"":""CI/CD Pipelines"",""explanation"":""Automated processes that integrate code changes into a larger system, ensuring continuous integration and delivery of software applications.""}],""skill_priorities"":{""must_have"":[""Python, Java, or Scala programming languages"",""Big data frameworks (Hadoop, Spark, Kafka)"",""Cloud platforms (AWS, Azure)"",""Data integration tools"",""Data ingestion, storage, orchestration, and management on cloud platforms"",""CI/CD pipeline building and application monitoring practices""],""nice_to_have"":[""Azure or AWS cloud platform experience"",""GCP cloud platform experience"",""Apache Kafka/Rabbit MQ/AWS Kinesis experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach data pipeline design and implementation?"",""example_answer"":""I follow a metadata-driven approach to design reusable patterns for data pipeline, orchestration, and ingestion. I consider factors like data volume, velocity, and variety to ensure efficient data processing and storage.""},{""question"":""Can you explain your experience with big data frameworks?"",""example_answer"":""I have hands-on experience with Hadoop, Spark, and Kafka. I've worked on projects that involved building data pipelines using these frameworks to process large data sets.""}],""red_flags"":[""Lack of experience with cloud platforms (AWS, Azure)"",""Inadequate understanding of data ingestion, storage, and orchestration on cloud platforms""],""confidence_score"":90.0}"
Data Engineer (DE)- Canada,Zortech Solutions,"Toronto, Ontario, Canada",May,2024,"Role: Data Engineer (DE)

Location: Remote/Canada

Duration: 12+ Months

Job Description

What you'll do:

Build and maintain scalable data infrastructure that offers a best-in-class experience for internal stakeholders including consistent extraction of value from the data
Drive data ingestion and processing in innovative ways that inform strategic priorities and decision-making across the organization
Build expertise in the team to expose efficiency insights across data platforms
Ensure data security and privacy are top considerations
Implement automation and monitoring tools through a test-driven approach and mindset
Drive the adoption of new cloud technologies to further advance TELUS Health's data transformation strategy

Qualifications

What you bring:

2+ years of experience as a Data Engineer
An expert understanding of data warehouses/cloud architectures and ETL processes and Tools(SSIS)
Advanced working SQL knowledge and experience working with relational databases and query authoring (SQL), as well as working familiarity with a variety of databases
Experience with cloud platforms: GCP, Amazon or Azure (GCP gives you an edge!)
Experience with Python and software engineering best practices
Knowledge in Dataflow, Spark and Kafka, as well as other data pipeline components
Experience with data pipeline and workflow management tools such as Airflow
Experience with Github and CICD processes
Ready to work in new and challenging work environments
Getting excited by the opportunity to build a team's capabilities to create value and innovate through data, and doing so in an agile manner with a bias for action and speed

Great-to-haves:

Post-graduate education in Data Engineering, Cloud DevOps or Advanced Analytics
Machine learning and data science knowledge","{""role_summary"":""Design, build, and maintain scalable infrastructure to drive strategic priorities and decision-making across the organization, ensuring data security and privacy"",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of data integration from multiple sources into a single target system""},{""term"":""GCP"",""explanation"":""Google Cloud Platform - a suite of cloud computing services""},{""term"":""Dataflow"",""explanation"":""A fully-managed service for transforming and enriching data in stream and batch modes""},{""term"":""Spark"",""explanation"":""An open-source data processing and analytics engine""},{""term"":""Kafka"",""explanation"":""A distributed event streaming platform""},{""term"":""CICD"",""explanation"":""Continuous Integration and Continuous Deployment - a software development practice""}],""skill_priorities"":{""must_have"":[""Data Engineer experience"",""Data warehouses/cloud architectures"",""ETL processes and Tools"",""Advanced SQL knowledge"",""Cloud platforms (GCP, Amazon)"",""Python"",""Software engineering best practices"",""Data pipeline and workflow management tools (Airflow)"",""Github""],""nice_to_have"":[""Post-graduate education in Data Engineering, Cloud DevOps or Advanced Analytics"",""Machine learning and data science knowledge""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach data pipeline and workflow management?"",""example_answer"":""I use tools like Airflow to manage data pipelines and workflows, ensuring efficient data processing and minimizing errors.""},{""question"":""Can you explain your experience with cloud platforms?"",""example_answer"":""I have worked with GCP, Amazon, and Azure, and I'm familiar with their strengths and weaknesses. I've implemented cloud-based solutions that improved data processing efficiency.""}],""red_flags"":[""Lack of experience with cloud platforms"",""Lack of knowledge in data pipeline and workflow management tools""],""confidence_score"":90.0}"
Data Engineer - 10 Month Contract (Remote),Firmex,"Toronto, Ontario, Canada",June,2024,"Firmex is a global software-as-a-service provider with corporate headquarters in Toronto, Canada. The company’s Firmex VDR service is the world’s most trusted virtual data room, having been used by over 140,000 companies worldwide to share confidential documents for due diligence, litigation and compliance.

Firmex is looking to hire a Data Engineer for our Information Management & Analytics program. We are looking for an individual to design and build processes to move data within our FBI DW (Firmex Business Intelligence Data Warehouse). FBI DW is a key strategic system that provides insight to all of Firmex’s departments for customer and product decision making.

As our Data Engineer you will be responsible for:

Data Requirements Gathering: Work with internal business and technology staff to accurately gather and interpret requirements and specifications to determine appropriate data models and data specifications
Data Modeling & Data Specifications: Working with various team members to design/document, architect, and build the appropriate S3, Staging, and Redshift tables to support various reporting and analytics projects. Collect and document the transformation rules in a source to target matrix
Building & Supporting Data Pipelines in AWS environment: Build the code required for extraction, transformation, and loading of data from a wide variety of data sources using Python, APIs, Airflow, and AWS Service(s) such as EC2, S3, RDS, Redshift, and Glue
AWS Data & Analytics Infrastructure Support: Configure and maintain the AWS Data & Analytics Infrastructure. (ie, Data Opps: Support of AWS services EC2, S3, RDS, Redshift, Glue, Airflow, and Tableau on AWS)


What you'll need to be successful as our Data Engineer:

Strong experience in creating & maintaining data pipelines and ETL/ELT processes using Python, SQL and Apache Airflow and connecting to different data sources
Strong experience coding in Python & SQL (creating reusable Python scripts, SQL stored procedures/scripts, APIs, functions, etc.)
Experience with AWS stack (SQS, Glue, S3, Lamda, Apache Airflow, RDS,Redshift)
Experience in building logical and physical design of data lakes, relational databases and data warehouses such as Snowflake/Redshift
Experience in configuration and maintenance of AWS Data & Analytics Infrastructure is an asset (ie. knowledge of CF templates)
Strong interpersonal and analytical skills, as well as detail oriented
Experience with BI Tool(s) such as Tableau & Looker is an asset
Ability to learn new technologies quickly
Strong initiative and self-direction, as well as excellent time management skills


*Note: The “Core Duties” is a summary of the duties that are essential to this role and is not an exhaustive list. Firmex reserves the right to add or amend duties as necessary.

At Firmex, we’re guided by our core values of respect and collaboration to create an equitable, diverse and inclusive environment where all employees and candidates alike can thrive. BIPOC, LGBTQIA2S+, women, people with disabilities, internationally trained professionals and historically disenfranchised groups are encouraged to apply. If you need any accommodations or adjustments throughout the interview process and beyond, we’ll be happy to assist you.","{""role_summary"":""Design and build data pipelines and ETL/ELT processes to move data within Firmex's Business Intelligence Data Warehouse, supporting various reporting and analytics projects."",""key_terms"":[{""term"":""FBI DW"",""explanation"":""Firmex Business Intelligence Data Warehouse, a key strategic system providing insight to all Firmex departments for customer and product decision making.""},{""term"":""S3"",""explanation"":""Simple Storage Service, a cloud-based object storage service offered by AWS.""},{""term"":""Redshift"",""explanation"":""A fully managed, petabyte-scale data warehouse service offered by AWS.""},{""term"":""Airflow"",""explanation"":""A platform used to programmatically schedule and monitor workflows.""},{""term"":""EC2"",""explanation"":""Elastic Compute Cloud, a cloud-based virtual machine service offered by AWS.""},{""term"":""RDS"",""explanation"":""Relational Database Service, a cloud-based relational database service offered by AWS.""},{""term"":""Glue"",""explanation"":""A fully managed extract, transform, and load (ETL) service offered by AWS.""},{""term"":""Tableau"",""explanation"":""A business intelligence and analytics software that helps people see and understand data.""}],""skill_priorities"":{""must_have"":[""Strong experience in creating & maintaining data pipelines and ETL/ELT processes using Python, SQL and Apache Airflow"",""Strong experience coding in Python & SQL"",""Experience with AWS stack (SQS, Glue, S3, Lamda, Apache Airflow, RDS,Redshift)""],""nice_to_have"":[""Experience in building logical and physical design of relational databases and data warehouses such as Snowflake/Redshift"",""Experience in configuration and maintenance of AWS Data & Analytics Infrastructure"",""Experience with BI Tool(s) such as Tableau & Looker""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement a data pipeline using Python, SQL, and Apache Airflow?"",""example_answer"":""I would start by gathering requirements from stakeholders, then design the pipeline architecture, and finally implement it using Python, SQL, and Apache Airflow.""},{""question"":""How do you handle errors and exceptions in your ETL/ELT processes?"",""example_answer"":""I use try-except blocks in Python and SQL to catch errors and exceptions, and then log them for further analysis and debugging.""}],""red_flags"":[""Lack of experience with AWS services"",""Inability to write reusable Python scripts and SQL stored procedures""],""confidence_score"":90.0}"
Senior Data Engineer,Capgemini,"Vancouver, British Columbia, Canada",June,2024,"This position can work from Vancouver, Calgary and Toronto.

Job Description:
We are looking for an inquisitive, resourceful, and business-oriented Senior Data Engineer able to design, build and deploy solutions, review code from peers and be a technical lead for other data engineers. Primary skills are Databricks (Azure), Python and SQL, but a good understanding of Azure Data Services in general is also important.

Key Responsibilities:
Maintain existing and build new ETL/ELT pipelines on Azure Databricks
Build, Design and Model data objects in Databricks
Support a Python-based web app, by maintaining and augmenting its capabilities.
Work closely with Power BI and Data Science teams to empower them with the right data.
Collaborate with DevOps team on the CICD deployment of the DDL, DML and App code bases across multiple environments.
Review and approve code from other data engineers in the team, taking accountability results.

Required Skills:
Overall understanding of Azure Data Services
Databricks (Azure), SQL and Azure DevOps
Python, with Dash / Bootstrap / SQL Alchemy (Alembic)

Life at Capgemini
Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:
Collaborating with teams of creative, fun, and driven colleagues
Flexible work options enabling time and location-based flexibility
Company-provided home office equipment
Virtual collaboration and productivity tools to enable hybrid teams
Comprehensive benefits program (Health, Welfare, Retirement and Paid time off)
Other perks and wellness benefits like discount programs, and gym/studio access.
Paid Parental Leave and coaching, baby welcome gift, and family care/illness days
Back-up childcare/elder care, childcare discounts, and subsidized virtual tutoring
Tuition assistance and weekly hot skill development opportunities
Experiential, high-impact learning series events
Access to mental health resources and mindfulness programs
Access to join Capgemini Employee Resource Groups around communities of interest

About Capgemini
Capgemini is a global business and technology transformation partner, helping organizations to accelerate their dual transition to a digital and sustainable world, while creating tangible impact for enterprises and society. It is a responsible and diverse group of 340,000 team members in more than 50 countries. With its strong over 55-year heritage, Capgemini is trusted by its clients to unlock the value of technology to address the entire breadth of their business needs. It delivers end-to-end services and solutions leveraging strengths from strategy and design to engineering, all fueled by its market leading capabilities in AI, cloud and data, combined with its deep industry expertise and partner ecosystem. The Group reported 2023 global revenues of €22.5 billion.
Get The Future You Want | www.capgemini.com

Disclaimer
Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.

This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.
Capgemini is committed to providing reasonable accommodations during our recruitment process.

If you need assistance or accommodation, please reach out to your recruiting contact.
Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law
Please be aware that Capgemini may capture your image (video or screenshot) during the interview process and that image may be used for verification, including during the hiring and onboarding process.

Applicants for employment in Canada must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in Canada by Capgemini.","{""role_summary"":""Design, build, and deploy data solutions, lead other engineers, and collaborate with teams to empower them with the right data."",""key_terms"":[{""term"":""Databricks (Azure)"",""explanation"":""A cloud-based Apache Spark platform for data engineering, analytics, and machine learning.""},{""term"":""Azure Data Services"",""explanation"":""A set of cloud-based services for storing, processing, and analyzing data.""},{""term"":""ETL/ELT pipelines"",""explanation"":""Extract, Transform, Load/Extract, Load, Transform pipelines for data integration and processing.""},{""term"":""Power BI"",""explanation"":""A business analytics service for data visualization and business intelligence.""},{""term"":""DevOps"",""explanation"":""A set of practices combining software development and operations for efficient and reliable software releases.""}],""skill_priorities"":{""must_have"":[""Databricks (Azure)"",""Python"",""SQL"",""Azure Data Services""],""nice_to_have"":[""Dash"",""Bootstrap"",""SQL Alchemy (Alembic)""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing and building data pipelines on Azure Databricks?"",""example_answer"":""I would start by understanding the data requirements and then design a scalable and efficient pipeline using Azure Databricks features.""},{""question"":""Can you explain how you would collaborate with the Power BI and Data Science teams to empower them with the right data?"",""example_answer"":""I would work closely with the teams to understand their data requirements and then design and implement data solutions that meet their needs.""}],""red_flags"":[""Avoid candidates without experience in Azure Data Services and Databricks.""],""confidence_score"":90.0}"
"Engineer, Data",EllisDon,"Mississauga, Ontario, Canada",June,2024,"Connect with us LinkedIn, Instagram, Facebook, Twitter

Thinking about a change?

We recognize that the construction industry is changing at a rapid pace and we continually strive to be at the forefront. Our core values empower people to deliver great careers to one another and develop creative solutions for complex problems on some of the most exciting projects. It doesn’t matter what your expertise and craft is – there are no boundaries. We are a group of professionals with a variety of expertise within pre-construction, construction, and post-construction. To learn more, check out our Cradle to Grave services and hear from our team directly about what a career at EllisDon could look like for you. As you can see, we are a diverse bunch.

Above all, we are a group of individuals with unique experiences and at EllisDon, we choose to celebrate the strength in our differences, every day. EllisDon’s commitment to Inclusive Diversity is to work together to create an environment where every employee feels safe to be their true and authentic self. Ultimately, EllisDon’s purpose is to provide people with similar values the opportunity to achieve to their full potential; to deliver that opportunity for great careers to one another; and to contribute meaningfully to the community we share with others.

In case you’re curious, here’s what the industry thinks of us and some of the impacts we've made to the communities we work in.

You As a Data Engineer Will

Be a technical lead in the development of high-volume platforms and data pipelines
Work with relevant stakeholders to identify sources of data and map out processes/data flow while researching opportunities for data acquisition and innovative new uses for existing data
Design, construct, install, test, and maintain highly scalable data management systems while integrating new data management technologies into existing structures
Develop ETL processes to move internal and external data into EllisDon's external cloud-based data lake and data warehouse(s)
Provide input and feedback to support continuous improvement in team processes
Provide thought leadership for all data solutions, including designing data solutions that meet and exceed customer expectations
Continually improve our data pipelines and find innovative ways to maximize automation while recommending ways to improve data reliability, efficiency, and quality


Is this the right role for you?

Have knowledge and understanding of Programming Languages: Python and/or Java, SQL, ETL methodologies and toolsets, Azure/Google ecosystem, Database design, MS SQL, MySQL, Synapse/Big Query and NoSQL (MongoDB), Airflow, Kafka
Comfortable working in a fast-paced and collaborative environment
Have excellent communication, analytical, and problem-solving skills
Have a degree in Computer Science, Engineering, Mathematics, Statistics, or a related field
Have previous experience in data engineering, data warehousing, data modeling, or data analysis
Have a passion for data and innovation


EllisDon is proud to provide this unique career opportunity that provides continuous learning, opportunity for growth, and a competitive compensation package within an environment that is committed to inclusion and respects diversity.

Go ahead and be yourself. We'll pay you for it!

We are an equal opportunity employer. We welcome people of any age, culture, subculture, gender identity or expression, sexual orientation, nationality, ethnicity, race, size, mental or physical status, veteran status, religion, language, political opinion, working-style preference, family status, education, and socio-economic status. The EllisDon core values of Integrity and Mutual Respect welcomes everyone, at work and in the community, and our value of Mutual Accountability, means that we all have a role to play. As an EllisDon employee, this will ultimately be your commitment to Inclusive Diversity.

Accommodation for Applicants with disabilities will be made during the recruitment process when requested.

We are committed to providing a positive candidate experience and ensuring timely updates are provided to all candidates. If you haven’t already, be sure to create a profile on our Careers page here to remain up to date on the status of your application and learn about new career opportunities as they arise.","{""role_summary"":""Lead the development of high-performance data platforms and pipelines, working collaboratively with stakeholders to drive innovation and improvement."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of data between systems""},{""term"":""Data Lake"",""explanation"":""A centralized repository for storing and processing large amounts of structured and unstructured data""},{""term"":""Data Warehouse"",""explanation"":""A central repository that stores data from various sources in a single location""},{""term"":""NoSQL"",""explanation"":""A type of database that does not use structured query language (SQL)""},{""term"":""Kafka"",""explanation"":""A distributed streaming platform for building real-time data pipelines""}],""skill_priorities"":{""must_have"":[""Python and/or Java"",""SQL"",""ETL methodologies and toolsets"",""Azure/Google ecosystem"",""Database design"",""MS SQL"",""MySQL"",""Synapse/Big Query"",""NoSQL (MongoDB)"",""Airflow"",""Kafka""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a recent project where you had to design and implement a data pipeline?"",""example_answer"":""In my previous role, I designed a data pipeline that integrated with our CRM system, resulting in a 30% reduction in data processing time.""},{""question"":""How do you stay up-to-date with the latest developments in data engineering and data warehousing?"",""example_answer"":""I regularly read industry blogs and attend conferences to stay current with the latest trends and best practices.""}],""red_flags"":[""Lack of experience with cloud-based data lakes and data warehouses"",""Inability to work in a fast-paced and collaborative environment""],""confidence_score"":90.0}"
Sr Data Engineer,Zortech Solutions,"Toronto, Ontario, Canada",May,2024,"JOB DESCRIPTION: Basic Qualifications�10+ years of experience with data pipelines �Experience managing a team of 5-8 junior developers.�Strong coding background, ideally in Java/ Python / Scala�Experience in at least one big data product: Databricks, Elasticsearch, Snowflake�Experience building batch / real time data pipelines for production systems.�Experience with Relational and Non-Relational DBs like DB2, MongoDB�Experience with various data formats: Parquet, CSV, JSON, XML, Relational Data�Experience working in Agile environment.�Experience with scripting languages�Experience with Linux/Unix Desired Qualifications �Experience with Rest based applications�Experience with Databricks/ Delta Lake / Kafka�Experience with client reference data sourcing from vendors","{""role_summary"":""Lead a team of junior developers to design, build, and manage large-scale data pipelines, ensuring efficient data processing and storage in various formats and databases."",""key_terms"":[{""term"":""Data Pipelines"",""explanation"":""A series of processes that extract, transform, and load data from various sources to a target system.""},{""term"":""Big Data Products"",""explanation"":""Software solutions that handle large volumes of structured and unstructured data, such as Databricks, Elasticsearch, and Snowflake.""},{""term"":""Relational and Non-Relational DBs"",""explanation"":""Types of databases that organize data differently, such as DB2 (relational) and MongoDB (non-relational).""},{""term"":""Agile Environment"",""explanation"":""A project management approach that emphasizes flexibility, collaboration, and rapid delivery in short iterations.""}],""skill_priorities"":{""must_have"":[""Data Pipelines"",""Team Management"",""Java/Python/Scala"",""Big Data Products"",""Relational and Non-Relational DBs"",""Agile Environment""],""nice_to_have"":[""Rest-based Applications"",""Databricks/Delta Lake/Kafka"",""Client Reference Data Sourcing""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data pipeline performance for large-scale production systems?"",""example_answer"":""By leveraging parallel processing, data partitioning, and caching mechanisms.""},{""question"":""Can you explain the trade-offs between relational and non-relational databases in a big data context?"",""example_answer"":""Relational databases provide structured data and ACID compliance, while non-relational databases offer flexibility and scalability for large, unstructured data sets.""}],""red_flags"":[""Lack of experience with big data products and data pipelines."",""Inability to manage a team of junior developers.""],""confidence_score"":90.0}"
Data/ML Engineer,Raydiant,"Ontario, Canada",June,2024,"About Raydiant

Raydiant is on a mission to create amazing experiences for people everywhere they go.

Using a first-of-its-kind technology, Raydiant reimagines and transforms customer and employee experiences through dynamic and interactive digital signage. Some of the nation’s most recognizable brick-and-mortar companies, including Chick-Fil-A, First Bank, Harvard University, Thomson Reuters, and Wahlburgers use Raydiant to keep employees engaged and customers coming back, all while driving revenue.

Built with both people and businesses in mind, Raydiant focuses on the experience so companies can focus on their products. Franchise managers, IT, marketing, and communications executives can effectively scale their brick-and-mortar operations while eliminating outdated technology. Our superior product, service, and integrations seamlessly create more engaging and personalized in-store experiences that keep customers coming back and buying more.

Founded in April 2017, Raydiant is headquartered in San Francisco, California, and is the highest funded company of its kind. Raydiant currently works with 4,500+ brands. To learn more, visit www.raydiant.com.

About The Role

Join a team of Data Engineers to build the next-gen data platform at Raydiant; collaborate, manage, coach, and develop the members of the group to ensure that it is both effective and efficient in its mission. Fully hands-on position as Data Engineer.

The Data team is being built on lean and agile methodologies, promoting innovation, flexibility, and entrepreneurship. We are looking for an experienced Data Engineer who thrives in a fast-paced environment, with a passion for finding ways to extract unique value from data. You are someone who has a proven track record of architecting and solving complex data, math, and modeling problems with practical applications.

What You Will Be Doing

Hands-On data engineer and analyst to implement and verify production machine learning algorithms and pipelines
Design, build, and maintain data pipelines for both batch and real-time processing in a processing environment
Maintain and optimize the data infrastructure required for ETL workloads
Develop new ETL processes to help extract and manipulate data from multiple sources
Automate data workflows such as data ingestion, aggregation, and ETL processing
Process raw data in Data Warehouses into a consumable dataset for both technical and non-technical stakeholders
Partner with data scientists and functional leaders in sales, marketing, and product to deploy machine learning models in production
Build, maintain, and deploy data products for analytics and data science teams on cloud platforms (e.g. AWS, GCP)
Ensure data accuracy, integrity, privacy, security, and compliance through quality control procedures
Monitor data systems performance and implement optimization strategies
Leverage data controls to maintain data privacy, security, compliance, and quality for allocated areas of ownership
Create, qualify, and manage Big Data opportunities through to the completion
Build and maintain strong links with other engineering members, and product management to enable both understand and influence the company’s technology strategy
Develop approaches to establish, validate, and extend complex datasets used to train and evaluate statistical models

What We Are Looking For

Bachelor's degree in Computer Science or related field
A minimum of 5 years hands-on experience as a Data Engineer
Formal qualifications in one of the following disciplines Computer Science, Data Science, Statistics, Mathematical Modeling
Proven skill development and applying machine learning or algorithms to large-scale business problems.
Advanced SQL skills and experience with relational databases and database design
Experience working with cloud Data Warehouse solutions (e.g., Redshift, BigQuery, Snowflake, Databricks, etc.)
Experience working with data ingestion tools such as Kinesis Firehose, Kafka, Stitch, or Matillion
Working knowledge of public clouds (e.g. AWS, GCP)
Experience building and deploying data lakes
Experience building and deploying machine learning models in production
Strong proficiency in object-oriented languages: Python, Go
Strong proficiency in scripting languages like Bash
Strong proficiency in data pipeline and workflow management tools (e.g., AWS Glue, Airflow)
Experience working with IaC frameworks such as Terraform, AWS CDK
Good understanding of NoSQL databases like Redis, Cassandra, MongoDB, and DynamoDB
Expertise with popular off the shelf machine learning toolkits and APIs
Experience with R&D agile methodologies
Experience with CI/CD pipelines
Strong project management and organizational skills
Excellent problem-solving, communication, and organizational skills
Ability to explain/evangelize machine learning and statistical concepts to software engineers, project managers, team members, executives, and technical managers
Proven ability to work independently and with a team
Agile, enthusiastic self-starter who takes pride in being on top of the technology bleeding edge and recognized as a knowledge source within the community
Experience working with multiple customer and partner data sets
Experience building customer-facing data products

Bonus Point For

Strong knowledge of AWS Analytics services
Experience working with AWS Glue data pipeline services
Knowledge of building data mesh architectures with AWS lake formation.
Knowledge of data governance with AWS.
Experience working with Amazon SageMaker.
Experience with working on large data sets and distributed computing (e.g.Amazon EMR, Hive/Hadoop/Spark).
Experience with GenAI
Experience working with LLMs
Experience with RAG architectures

Perks/Benefits at Raydiant

Platinum medical, dental, & vision plan through Manulife
Flexible PTO and paid holidays
Be a part of low ego, high-performance team
Be one of the first 150 people in a very fast-growing company

Raydiant is proud to be an equal employment opportunity employer that values diversity in hiring and gives consideration to all candidates regardless of their race, age, creed, color, religion or religious belief, national origin or ancestry, disability, military or veteran status, genetic information, sex, gender, sexual orientation, gender identity or expression, pregnancy, or any other characteristic protected by local, state, or federal law.","{""role_summary"":""Lead a team of Data Engineers to build and maintain a next-generation data platform, focusing on extracting unique value from data and driving business growth."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Machine Learning"",""explanation"":""A type of Artificial Intelligence that enables systems to make predictions or decisions based on data and algorithms.""},{""term"":""Data Warehousing"",""explanation"":""A process of storing and managing large datasets in a centralized repository, enabling business intelligence and analytics.""},{""term"":""Cloud Platforms"",""explanation"":""Cloud-based infrastructure and services, such as AWS, GCP, and Azure, used for data processing, storage, and deployment.""},{""term"":""Big Data"",""explanation"":""Large, diverse datasets that require specialized processing and analysis techniques to extract insights and value.""}],""skill_priorities"":{""must_have"":[""Hands-on experience as a Data Engineer"",""Advanced SQL skills"",""Experience with cloud Data Warehouse solutions"",""Strong proficiency in object-oriented languages: Python, Go"",""Strong proficiency in scripting languages like Bash"",""Experience with data pipeline and workflow management tools""],""nice_to_have"":[""Experience with AWS Analytics services"",""Knowledge of building data mesh architectures with AWS lake formation"",""Knowledge of data governance with AWS"",""Experience working with Amazon SageMaker"",""Experience with working on large data sets and distributed computing""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement a data pipeline for real-time processing?"",""example_answer"":""I would use a combination of tools like AWS Kinesis, Apache Kafka to ingest data, and then process it using Apache Flink or Apache Spark. I would also ensure data quality and security by implementing data validation and data encryption.""},{""question"":""How do you approach data modeling and data warehousing?"",""example_answer"":""I follow a data modeling approach that considers the business requirements and the data architecture. I would use a data warehousing solution like Amazon Redshift or Google BigQuery to store and manage large datasets.""}],""red_flags"":[""Lack of hands-on experience as a Data Engineer"",""Inability to explain complex data concepts and technical details"",""Limited experience with cloud-based data solutions and tools""],""confidence_score"":95.0}"
Python Backend Developer (Airflow/ETL) - Remote,Techedin,Canada,June,2024,"We are seeking an experienced Python Backend Developer with a minimum of 7-8 years of expertise in backend development, particularly using Python. The ideal candidate will have strong experience in building robust and scalable applications, with at least 3 years of hands-on experience utilizing AWS technologies.

Key Responsibilities

Develop and maintain high-quality backend solutions using Python.
Design and implement well-tested applications, including unit tests, functional tests, and integration tests.
Work with third-party APIs and web services, and utilize API Gateways such as Apigee.
Build and optimize data ETL pipelines using technologies like Airflow, PySpark, MySQL, Hive, and Snowflake.
Collaborate with cross-functional teams in an Agile/Scrum environment, partnering with business analysts, developers, and testers to implement innovative solutions.

Qualifications

Minimum of 7-8 years of experience as a Backend Software Engineer.
Have strong development experience with Python.
At least 2-3 years of experience with AWS technologies.
Solid knowledge of building data ETL pipelines with tools such as Airflow, PySpark, MySQL, Hive, and Snowflake.
Proven experience in writing well-tested applications, including unit, functional, and integration tests.
Familiarity with third-party APIs, web services, and API Gateways like Apigee.
Experience with data catalog tools like Atlan is a plus.
Experience working in an Agile/Scrum setting, collaborating with business analysts, developers, and testers.

We are looking for a proactive and skilled individual who can contribute effectively to our dynamic team and help us achieve our goals through innovative solutions and best practices.

APPLY NOW!

Kindly share your upated resume at hr@techedinlabs.com

Techedin is a global IT Services company complementing the efforts of technology-driven enterprises in developing cutting-edge solutions for humans. We offer services in enterprise app development, content management solutions (CMS), customer relationship management (CRM), cloud engineering, custom software development, and data engineering. Our services include IT Consulting, project management, Software Quality Assurance, and data and analytics services. We develop and maintain various software applications and all other computer-related ancillary services. We have excellent professionals working round the clock to build the best technology teams and products for our customers.","{""role_summary"":""Develop and maintain high-quality backend solutions using Python, collaborating with cross-functional teams in an Agile/Scrum environment."",""key_terms"":[{""term"":""Backend Development"",""explanation"":""Building server-side logic, database integration, and API connectivity for applications.""},{""term"":""AWS Technologies"",""explanation"":""Cloud computing services offered by Amazon Web Services, including storage, computing power, and databases.""},{""term"":""ETL Pipelines"",""explanation"":""Extract, Transform, and Load data from various sources to a target system, such as a data warehouse.""},{""term"":""API Gateways"",""explanation"":""Server-side application that acts as an entry point, handling API requests and routing.""},{""term"":""Agile/Scrum"",""explanation"":""Iterative project management approach focusing on teamwork, flexibility, and continuous improvement.""}],""skill_priorities"":{""must_have"":[""Python"",""Backend Development"",""AWS Technologies"",""ETL Pipelines"",""API Gateways"",""Agile/Scrum""],""nice_to_have"":[""Experience with data catalog tools like Atlan""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of ETL pipelines and how you've utilized them in previous projects?"",""example_answer"":""I've used ETL pipelines to extract data from various sources, transform it into a standardized format, and load it into a data warehouse for analysis. In my previous project, I used Airflow to schedule and monitor the ETL process.""},{""question"":""How do you approach testing and validation in your backend development workflow?"",""example_answer"":""I write unit tests, functional tests, and integration tests to ensure my code is robust and scalable. I also use tools like Pytest and Unittest for testing.""}],""red_flags"":[""Lack of hands-on experience with AWS technologies"",""Inability to write well-tested applications""],""confidence_score"":90.0}"
Data Engineer (Azure),Tiger Analytics,"Toronto, Ontario, Canada",April,2024,"Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning, and AI. We are the trusted analytics partner for multiple Fortune 500 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best global analytics consulting team in the world.

We are looking for a Data Engineer to join our growing team of analytics experts. The right candidate will have strong analytical skills and the ability to combine data from different sources and will strive for efficiency by aligning data systems with business goals.

Requirements

Bachelor's degree in Computer Science or similar field
4+ years of experience in IT industry
Expertise in Python and Pyspark
Experience building data pipelines using Azure stack
2+ years of experience using Apache spark
Good working experience on Delta Lake and ETL processing
Proficiency in SQL queries
Prior experience of working in a Unix environment
Experience in harmonizing raw data into a consumer-friendly format using Azure Databricks
Experience extracting/querying/joining large data sets at scale
Experience building data ingestion pipelines using Azure Data Factory to ingest structured and unstructured data
Experience in data wrangling, advanced analytic modeling is preferred
Exposure to Java is a plus
Strong communication and organizational skills


Benefits

This position offers an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility.","{""role_summary"":""A Data Engineer responsible for combining data from different sources, aligning data systems with business goals, and striving for efficiency."",""key_terms"":[{""term"":""Pyspark"",""explanation"":""A Python library for big data processing, used for building data pipelines.""},{""term"":""Apache Spark"",""explanation"":""An open-source data processing, used for building data pipelines and processing large data sets.""},{""term"":""Delta Lake"",""explanation"":""An open-source storage layer that enables scalable, secure, and reliable data lake operations.""},{""term"":""ETL processing"",""explanation"":""Extract, Transform, Load process used for data integration and data migration.""},{""term"":""Azure Databricks"",""explanation"":""A cloud-based Apache Spark platform, used for data engineering and data science tasks.""},{""term"":""Azure Data Factory"",""explanation"":""A cloud-based data integration service, used for building data ingestion pipelines.""}],""skill_priorities"":{""must_have"":[""Python"",""Pyspark"",""Apache Spark"",""Azure stack"",""Delta Lake"",""ETL processing"",""SQL queries"",""Unix environment""],""nice_to_have"":[""Java"",""Data wrangling"",""Advanced analytic modeling""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data pipelines for efficiency?"",""example_answer"":""I use Pyspark and Apache Spark to optimize data pipelines, ensuring data alignment with business goals.""},{""question"":""Can you explain your experience with ETL processing?"",""example_answer"":""I have experience with ETL processing using Delta Lake, ensuring scalable and secure data lake operations.""}],""red_flags"":[""Lack of experience with Azure stack"",""Inability to work in a Unix environment""],""confidence_score"":90.0}"
"Python Data Engineer, Sovereign",Nascent,"Montreal, Quebec, Canada",June,2024,"About Nascent…

Founded in 2020, Nascent exists to build, expand, and capture opportunity, in open markets and permissionless technologies. Building from a base of permanent capital, we deploy assets across a range of both liquid and long-term strategies that ensure we are among the most active users of the open financial system we are helping to build. We've made venture investments in 50+ early-stage teams that we believe have the potential to create substantive change, expand boundaries, and find new horizons. We are consistently on the hunt for the most competitive and curious minds exploring the edges of the crypto ecosystem and leverage our hyper flexible structure to accelerate ideas into fully deployed strategies.

About Sovereign

Sovereign is a leading-edge proprietary trading fund at the forefront of innovation and intellectual property (IP) rights incubated within Nascent. Sovereign is building a unique approach to IP that enables individuals to retain full rights to the IP they create, ensuring value alignment between the creator and the company. This distinctive approach permits researchers the autonomy to potentially spin-off their IP into an independent entity, of which Sovereign will have an option to acquire 20%.

This approach minimizes the need for conventional employment limitations and constraints, offering increased slack. Our goal is to assemble a team of high-variance individuals, affording them the time, freedom, and motivation to discover and attempt their visions.

In the context of financial markets, higher-variance can lead to extreme results—from wild successes to uninvestable failures.

This process also produces uncorrelated results, creating an ideal environment for debate in a field where intellectual honesty is a prerequisite. Variance will grow when individuals are unconstrained. We aim to build a lab where diversity of ideas obtained through independent exploration leads to quality collaborations and discussions.

The Opportunity

As a Data Engineer on Sovereign, leverage your skills to create impactful data solutions in a fast-moving and flexible environment. You'll drive critical projects within our team by maintaining extensive historical data repositories from diverse sources, ensuring data quality and developing versatile tools for researchers to access data in various formats. By joining us, you'll play a vital part in enabling data-driven insights and supporting progressive research.

Experience Required

Demonstrated abilities in one of the Python data frame libraries (Pandas|Polars)
Ability to automate data collection from many different sources (websocket, api, S3, etc…)
Ability to handle reasonably large quantities of data (>10 TB,
Ability to build and maintain an API for the researchers to query the data.
The ideal candidate would have a baseline understanding of simple financial data.

Our Team & Culture

At Nascent, we are an interdisciplinary team of investors, builders & creators, capable of achieving more together than we can as individuals. We offer the opportunity to contribute to building the future global economic system with a world-class team and culture that pairs the freedom to explore, experiment & play with a competitive drive to win. We invest in our people by providing the autonomy to build, coupled with accountability & honest feedback to help learn, grow, perform & win. We’re a fully distributed team that understands the value of in-person time—we host two team retreats per year and encourage team members to come together for more frequent in-person work.

Principles that drive our team & work

Compete to win
Own your shit
Explore, experiment, play
Always be building
Seek and speak truth

What We Offer

At Nascent, we offer a competitive total compensation package heavily weighted toward bonus, ensuring that when we perform at our best and the firm wins we all win.

The opportunity to learn, experiment and build in an entrepreneurial environment
Comprehensive health benefits package including dental, vision, and life
Generous paid parental leave & supported return to work
Annual Health & Wellness Stipend of up to $1,000
Retirement plan matching contributions
Open vacation policy as well as flexible work hours and location
Access to our internal performance coaching, technical experts and support for continuing your skill development and growth
Team activities and bi-annual in-person team retreats

We are an equal opportunity employer and celebrate diversity and differences of perspectives. We do not discriminate on the basis of any status, inclusive of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","{""role_summary"":""As a Data Engineer on Sovereign, you'll create impactful data solutions in a fast-moving and flexible environment, driving critical projects and enabling data-driven insights and supporting progressive research."",""key_terms"":[{""term"":""Data Engineer"",""explanation"":""A technical role responsible for designing, building data solutions and maintaining data repositories.""},{""term"":""Python data frame libraries"",""explanation"":""Technical skills required for data manipulation and analysis, specifically using Python libraries like Pandas or Polars.""},{""term"":""API"",""explanation"":""A technical interface for researchers to access data, built and maintained by the Data Engineer.""}],""skill_priorities"":{""must_have"":[""Python data frame libraries (Pandas|Polars)"",""Automation of data collection from diverse sources"",""Handling large quantities of data (>10 TB)"",""Building and maintaining an API for researchers""],""nice_to_have"":[""Baseline understanding of simple financial data""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach automating data collection from diverse sources?"",""example_answer"":""I would use Python libraries like Pandas to create a data pipeline that can handle large quantities of data and ensure data quality.""},{""question"":""Can you explain how you would build and maintain an API for researchers to access data?"",""example_answer"":""I would design a RESTful API using Python, ensuring data security and scalability, and provide clear documentation for researchers to access the data.""}],""red_flags"":[""Lack of experience with Python data frame libraries"",""Inability to automate data collection from diverse sources"",""Insufficient experience handling large quantities of data""],""confidence_score"":90.0}"
"Data Engineer, Advanced Analytics",Zortech Solutions,"Toronto, Ontario, Canada",May,2024,"Toronto, ON

Contract

The Data Engineer will enable the data infrastructure for Advanced Analytics team in Canadian Banking

Analytics (CBA) group ensuring business strategies, plans and initiatives are executed / delivered in

compliance with internal policies and procedures. The role will be responsible for leading the development and

execution of data pipelines and data assets supporting the CBA group. The role will also support the creation

of new enterprise data sources in coordination with other teams in CBA. The incumbent will report into the

Director, Advanced Analytics.

Accountabilities

Guides the data architecture for creation of data assets to be used for modelling, BI, Marketing

operations and other analytic functions within the scope of Canadian Banking Analytics

Performs data engineering activities to create and maintain the data assets required. Leads the

creation of data pipelines and design of ETL work to transform and manage data at scale. Responsible

for the orchestration of the data pipelines / ETL processes and monitoring of these processes for

accuracy, reliability and timeliness.

Enables the migration of data stores and analytical datasets from the data warehouse and enterprise

data lake to global data & analytics platform.

Executes data management activities to design and build dataset for analytics and bring in data from

multiple data platform and environments. Assemble large, complex data sets that meet functional / nonfunctional business requirements

Executes on data governance activities to ensure good data quality and integrity for critical datasets

used by the CBA team across the various analytical use cases.

Responsible for ingesting new/alternative sources of data to generate business value.

Champions a high-performance environment and contributes to an inclusive work environment.

Participate on special project teams as required to support the delivery of strategic Bank initiatives.

Actively pursues effective and efficient operations of his/her respective areas, while ensuring the

adequacy, adherence to and effectiveness of day-to-day business controls to meet obligations with

respect to operational risk, regulatory compliance risk, AML/ATF risk and conduct risk, including but not

limited to responsibilities under the Operational Risk Management Framework, Regulatory Compliance

Risk Management Framework, AML/ATF Global Handbook and the Guidelines for Business Conduct.","{""role_summary"":""The Data Engineer leads the development and execution of data pipelines and data assets supporting the Canadian Banking Analytics group, ensuring business strategies are executed in compliance with internal policies."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of transforming data into a usable format for analysis.""},{""term"":""Data Governance"",""explanation"":""A set of practices to ensure data quality, integrity, and compliance with regulations.""},{""term"":""Data Lake"",""explanation"":""A centralized repository that stores all types of data in its native format.""},{""term"":""AML/ATF"",""explanation"":""Anti-Money Laundering and Anti-Terrorist Financing regulations to prevent illegal activities.""}],""skill_priorities"":{""must_have"":[""Data pipeline development"",""Data governance"",""ETL process management"",""Data architecture design""],""nice_to_have"":[""Experience with global data & analytics platforms"",""Familiarity with AML/ATF regulations""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure data quality and integrity in a large-scale data pipeline?"",""example_answer"":""I implement data validation checks at each stage of the pipeline and perform regular data audits to identify and correct any issues.""},{""question"":""Can you describe your experience with data governance and how you ensure compliance with regulations?"",""example_answer"":""I have implemented data governance frameworks in previous roles, ensuring data quality, and usage align with organizational policies and regulatory requirements.""}],""red_flags"":[""Lack of experience with data governance and compliance regulations"",""Inability to design and implement scalable data pipelines""],""confidence_score"":85.0}"
Data Engineer - II,Techedin,"Montreal, Quebec, Canada",June,2024,"We are looking for a ""Data Engineer"" in Montreal, QC, Canada. The position's description is given below. It is a Hybrid opportunity (2 days a week in office)

Responsibilities

Job description:

Advise on the optimal plan for the Genuine Optimized Campaign process.
Create foundational campaign tables into Hive and Snowflake using SQL, Python and Pyspark.
Help collect new data points from VWO via API access to assess the performance the campaigns.
Enable daily assignment to have fresh new non-compliant users into the campaign.
Create databases to enable Champion/Challenger philosophy.
Improve the current data stack for launching automated campaigns.
Help create the environment for deploying RL (Reinforcement Learning) algorithm to manage campaigns.

Minimum Qualifications

Bachelor’s degree or higher in a quantitative field
5+ years of experience in data analysis role
3+ years of experience in Python, SQL, and visualization tools like PowerBI
A proven track record of decision making and problem solving based on analytics. Conceptual thinking skills must be complemented by a strong quantitative orientation.
Experienced with AWS and proficient in coding with Spark/PySpark
Strong business judgment, leadership, and integrity. You should be a tenacious decision maker, able to bring a healthy, aggressive, yet responsible approach to business.
Excellent written and oral communication skills, coupled with strategic influencing skills and the ability to drive agreement through intellect, interpersonal and negotiation.
Strong skills in BI tools and Excel. Knowledge of PowerBI a plus
Skilled in using data mining techniques, including supervised and unsupervised learning
Familiar with Airflow for workflow management
Able to collaborate effectively within a cross-functional, matrix environment.

Techedin is a global IT Services company complementing the efforts of technology-driven enterprises in developing cutting-edge solutions for humans. We offer services in enterprise app development, content management solutions (CMS), customer relationship management (CRM), cloud engineering, custom software development, and data engineering. Our services include IT Consulting, project management, Software Quality Assurance, and data and analytics services. We develop and maintain various software applications and all other computer-related ancillary services. We have excellent professionals working round the clock to build the best technology teams and products for our customers.","{""role_summary"":""The Data Engineer will design and implement data solutions to optimize campaign performance, leveraging tools like Hive, Snowflake, and Python. They will also develop and maintain databases to support automated campaigns."",""key_terms"":[{""term"":""Hive"",""explanation"":""A data warehousing and SQL-like query language for Hadoop""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and analyzing data""},{""term"":""Pyspark"",""explanation"":""A Python library for working with Spark, a big data processing engine""},{""term"":""Reinforcement Learning (RL)"",""explanation"":""A machine learning approach that involves training models to make decisions based on rewards or penalties""},{""term"":""Champion/Challenger philosophy"",""explanation"":""A data-driven approach to testing and optimizing campaign performance""},{""term"":""Airflow"",""explanation"":""A workflow management tool for automating and scheduling tasks""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Data analysis"",""AWS"",""Spark/PySpark"",""BI tools"",""Excel""],""nice_to_have"":[""PowerBI"",""Data mining"",""Supervised and unsupervised learning"",""Airflow""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize data processing for a large-scale campaign?"",""example_answer"":""I would use distributed computing frameworks like Spark or Hadoop to process large datasets in parallel, and then use data warehousing tools like Snowflake to store and analyze the data.""},{""question"":""Can you explain how you would implement a Champion/Challenger philosophy in a campaign?"",""example_answer"":""I would create separate databases for champion and challenger campaigns, and use data analysis to compare their performance and identify areas for improvement.""}],""red_flags"":[""Lack of experience with cloud-based data warehousing platforms like Snowflake"",""Inability to write efficient SQL queries for large datasets""],""confidence_score"":85.0}"
Data Engineer - Data Platform,Mark43,"Toronto, Ontario, Canada",June,2024,"Mark43 is approved to hire in Canada, the UK, and 40 U.S states, including AL, AZ, CA-excluding San Francisco, CO, CT, DC, DE, FL, GA, IA, ID, IL, IN, KS, LA, MA, MD, ME, MI, MN, MO, NE, NV, NH, NJ, NM, NY, NC, OH, OR, PA, SC, SD, TN, TX, UT, VA, VT, WA, and WI. Before applying to a remote role, please ensure that you are able to perform the position in one of the states listed above. State locations and specifics are subject to change as our hiring requirements shift.

Applicants must be authorized to work for any employer in the country in which the role is being hired. We are unable to sponsor or take over sponsorship of an employment visa at this time.

At Mark43, our mission is to empower communities and their governments with new technologies that improve the safety and quality of life for all. We build powerful, scalable, and elegant software that sets a new standard for the tools upon which our first responders rely. Our users are diverse, and we are therefore committed to embracing diversity of thought and experience within our team.

Role Overview:

We're looking for an experienced and innovative Data Engineer to join our team and help propel our data platform to enterprise capabilities. In this role, you'll take ownership of architecting and implementing scalable infrastructure and data pipelines dedicated to providing analytic systems to our customers.

What You'll Do:

If you were a part of our team, here are some things you would have done last week:

Collaborated with Product Managers to understand requirements for new data features.
Utilized technologies such as SQL, Python, DMS, Redshift, Glue, S3, Lambdas, PySpark, Google Looker, Terraform.
Participated in on-call rotation to ensure the reliability and performance of our data platform.
Owned end-to-end technical solutions for data products or subsets.
Reviewed code submitted by other engineers and provided valuable feedback.
Improved the architectural strategy of our data platform to meet the growing needs of our customer base.
Tested out new technologies and contributed to discussions on improving our engineering practices.

What You'll Need:

We are seeking engineers with at least 4 years of professional experience in data focused engineering roles. You should have experience building infrastructure with technologies like SQL, DMS, Redshift, Glue, S3, Lambdas, PySpark, Google Looker, Terraform. Experience with cloud-based development, such as AWS or Azure, is essential. Additionally, you should have strong proficiency in building and managing RESTful APIs, automated testing, and Agile methodologies.

Characteristics We Look For:

Humble, open, and curious mindset.
Attentive, active listener who values collaboration.
Resilience and proactive problem-solving abilities.
Comfortable with uncertainty and eager to learn and grow.
Enthusiastic collaborator who values shared ownership and knowledge sharing.

Compensation:

We believe in equal pay for equal work, and transparency in compensation is a core value. Total compensation for this role is market competitive, including a target base annual salary range of $115,000 - $140,000, plus bonus opportunity, company stock options, and a full benefits package, including health insurance, paid time off, and a 401k.

Our Privacy Notice describes how Mark43 uses and protects the personal information of prospective employees during the recruitment process. It informs you about our handling of the personal information you provide to us when you apply for a position in our organization and in general when you express your interest in joining our team.

As a part of Mark43's security measures all employees must: Engage in appropriate use of the company's electronic information resources; Become knowledgeable about and follow relevant security policies and guidelines; Protect the resources under their control, such as passwords, computers, and data that they create, receive, or download; and Promptly report security-related incidents and violations, and responding to official reports of security incidents involving their systems or accounts.

Mark43 is committed to the full inclusion of all qualified individuals. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex disability, age, sexual orientation, gender identity, national origin, veteran status, or genetic information. As part of this commitment, we will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed, please email recruiting@Mark43.com requesting the accommodation.","{""role_summary"":""Design and implement scalable data infrastructure and pipelines to support analytical systems for customers, ensuring reliability and performance."",""key_terms"":[{""term"":""Data Engineer"",""explanation"":""A technical expert responsible for designing and implementing scalable data infrastructure and pipelines.""},{""term"":""SQL"",""explanation"":""A standard language for managing relational databases.""},{""term"":""PySpark"",""explanation"":""A Python library for large-scale data processing.""},{""term"":""Terraform"",""explanation"":""An infrastructure as code tool for managing and provisioning cloud and on-premises infrastructure.""},{""term"":""Cloud-based development"",""explanation"":""Software development that utilizes cloud computing services and infrastructure.""},{""term"":""Agile methodologies"",""explanation"":""Iterative and flexible approaches to project management and software development.""}],""skill_priorities"":{""must_have"":[""4+ years of professional experience in data-focused engineering roles"",""Experience building infrastructure with technologies like SQL, DMS, Redshift, Glue, S3, Lambdas, PySpark, Google Looker, Terraform"",""Strong proficiency in building and managing RESTful APIs, automated testing, and Agile methodologies""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with designing and implementing scalable data infrastructure and pipelines?"",""example_answer"":""I have worked on several projects that involved designing and implementing scalable data infrastructure and pipelines using technologies like SQL, PySpark, and Terraform. I have experience with cloud-based development and Agile methodologies.""},{""question"":""How do you approach collaboration and knowledge sharing with cross-functional teams?"",""example_answer"":""I believe in open and active communication, and I prioritize collaboration and knowledge sharing. I have experience working with cross-functional teams and have developed strong relationships with product managers, engineers, and other teams.""}],""red_flags"":[""Lack of experience with cloud-based development or Agile methodologies"",""Inability to work collaboratively with cross-functional teams""],""confidence_score"":90.0}"
Data Engineer - Tableau,GalaxE.Solutions,"Toronto, Ontario, Canada",June,2024,"Work and develop in the Data Science and Data Engineering area


Required

2-5 years of experience with the following
Alteryx
Tableau
Data story telling experience
Desired

Data Management and Data warehouse knowledge
Technical writing experience
Data Governance Skills
JIRA knowledge
Agile Knowledge


GalaxE is a professional IT services firm that specializes in platform-driven solutions and the use of automation to achieve enterprise business transformation and mission-critical change for some of the largest companies in the world. Using our proprietary solution set, GxFource®, we apply machine learning techniques and predictive analytics tools as part of a broad artificial intelligence strategy that provides effective impact and data-driven business transformation.

Since its founding, GalaxE has been dedicated to advancing the benefits of technology. As we continue that legacy and look to the future, a focus on business enablement through agile, cost-efficient, and effective integration of people, process, and technology anchors our success. We revolutionize change in the costs of doing business that transform companies and their ability to leap beyond the competition.

At GalaxE we value people and are committed to diversity and inclusion where our employees are made to feel comfortable and are encouraged to be authentic. We focus on cultivating both traditional IT and non-traditional, new collar, workers through our Outsource to America®, program.

We are always looking for passionate, entrepreneurial-minded innovators and disrupters; game-changers that take ownership of the work they produce and bring it each and every day. Working with like-minded team members you will get a chance to discover, develop, and use cutting-edge technologies to transform the way we deliver creative business solutions.

Sound like you? Join us and find out for yourself what it means for you, and your career, to be part of the GalaxE team. Let’s build something, together. #WeAreGalaxE

Equal Opportunity Employer/Veterans/Disabled
Pay is based on several factors including market location and may vary depending on actual job-related knowledge, skills, and experience.


Physical Requirements

Prolonged periods of remaining stationary at a desk and working on a computer
Must be able to lift to 15 lbs., as needed
Must be able to work on-site (corporate/client offices), as needed (not applicable for 100% remote roles)
Occasionally required to bend, kneel, crouch, and reach overhead.
Hand-eye coordination necessary to operate computers and various pieces of office equipment.
Specific vision abilities required include close vision, the ability to tolerate fluorescent lighting, and the ability to adjust focus.


Employees must be able to perform the physical requirements of the position satisfactorily and, if requested, reasonable accommodations will be made to enable employees requiring accommodations to perform the essential functions of their jobs, absent undue hardship.

For more information, please visit https//www.galaxe.com/","{""role_summary"":""Work in the Data Science and Data Engineering area, developing and utilizing data storytelling skills to drive business transformation."",""key_terms"":[{""term"":""Alteryx"",""explanation"":""A data analytics platform used for data preparation and data science tasks.""},{""term"":""Tableau"",""explanation"":""A data visualization tool used to create interactive dashboards and stories.""},{""term"":""Data Governance"",""explanation"":""The process of managing and security of an organization's data assets.""},{""term"":""Agile"",""explanation"":""An iterative approach to project management that emphasizes flexibility and collaboration.""},{""term"":""JIRA"",""explanation"":""A project management tool used to track and manage agile projects.""}],""skill_priorities"":{""must_have"":[""Alteryx"",""Tableau"",""Data storytelling experience""],""nice_to_have"":[""Data Management and Data warehouse knowledge"",""Technical writing experience"",""JIRA knowledge"",""Agile Knowledge""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you've used Alteryx to drive business insights in your previous role?"",""example_answer"":""In my previous role, I used Alteryx to create data pipelines that informed our marketing strategy, resulting in a 20% increase in sales.""},{""question"":""How do you approach data storytelling, and what tools do you use to effectively communicate insights?"",""example_answer"":""I use Tableau to create interactive dashboards that tell a story with data. I also use data storytelling principles to ensure my insights are actionable and easy to understand.""}],""red_flags"":[""Lack of experience with Alteryx or Tableau"",""Inability to communicate technical insights effectively""],""confidence_score"":85.0}"
Data Engineer (Canada),Jobs Malaysia - Two95 HR HUB,"Montreal, Quebec, Canada",May,2024,"Title: Data Engineer

Location: Remote

Duration: Contract

Rate: $Open

Requirements

Technical expertise :

BSc/MSc in Computer Science, Computer Science, Information Systems or related Technical Discipline
1-4 years' experience in Data Engineer role (5-10 years for senior data engineer)
Deep knowledge of Python, SQL, and PySparkis required.
Experience working with data pipelines, architecture principles, batch and stream processing systems, and DataOps.
Experience working with large data sets, Azure cloud services including Azure Data Lake, Data factory, Databricks, Azure DevOps.
Background in programming in Python, Scala, C, C++, Java is beneficial


Agile experience :

Experience working in AI startup environment or organisationswith an agile culture
Professional attitude and service orientation; superb team player


Benefits

Note: If interested please send your updated resume to ajith.anthoniraj@two95intl.com and include your rate requirement along with your contact details with a suitable time when we can reach you. If you know of anyone in your sphere of contacts, who would be a perfect match for this job then, we would appreciate if you can forward this posting to them with a copy to us.

We look forward hearing from you at the earliest!","{""role_summary"":""Design, build, and maintain large-scale data systems, ensuring efficient data pipelines and architecture principles."",""key_terms"":[{""term"":""PySpark"",""explanation"":""A Python library for large-scale data processing, used for building data pipelines.""},{""term"":""DataOps"",""explanation"":""A set of practices that combines DevOps and data engineering to improve collaboration and efficiency in data workflows.""},{""term"":""Azure Data Lake"",""explanation"":""A cloud-based data storage and analytics service, used for storing large datasets.""},{""term"":""Databricks"",""explanation"":""A cloud-based platform for working with big data and AI, providing a collaborative workspace for data engineers.""},{""term"":""Agile culture"",""explanation"":""An iterative approach to project management, emphasizing flexibility, and continuous improvement.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""PySpark"",""Data pipelines"",""Azure cloud services""],""nice_to_have"":[""Scala"",""C"",""C++"",""Java"",""Agile experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data pipeline performance in PySpark?"",""example_answer"":""I use techniques like parallel processing, caching, and optimizing Spark configurations to improve performance.""},{""question"":""Can you explain how you would design a data architecture for a large-scale data system?"",""example_answer"":""I would follow architecture principles, considering factors like data volume, velocity, and variety, and design a scalable and efficient data pipeline.""}],""red_flags"":[""Lack of experience with PySpark or data pipelines"",""Inability to work in an agile environment""],""confidence_score"":85.0}"
Python ETL Developer/Data Engineer - Remote,IPVISIBILITY,"Ottawa, Ontario, Canada",April,2024,"Specific Duties

-Reviewing, designing, developing ETL jobs to ingest data into Data Lake, load data to data marts;
-extract data to integrate with various business applications.
-Parse unstructured data, semi structured data such XML etc.
-Design and develop efficient Mapping and workflows to load data to Data Marts
-Map XML DTD schema in Python (customized table definitions)
-Write efficient queries and reports in Hive or Impala to extract data on ad hoc basis for data analysis.
-Identify the performance bottlenecks in ETL Jobs and tune their performance by enhancing or redesigning them.
-Responsible for performance tuning of ETL mappings and queries.
-import tables and all necessary lookup tables to facilitate the ETL process required to process daily XML files in addition to processing the very large (multi-terabytes) historical XML data files","{""role_summary"":""Design, develop, and maintain ETL processes to extract and integrate data from various sources into data marts, ensuring efficient data flow and performance."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, and Load processes to move data between systems.""},{""term"":""Data Lake"",""explanation"":""A centralized storage system for raw, unprocessed data.""},{""term"":""Data Marts"",""explanation"":""Smaller, focused repositories of data for specific business applications.""},{""term"":""XML"",""explanation"":""Extensible Markup Language, a format for structuring data.""},{""term"":""DTD"",""explanation"":""Document Type Definition, a schema for defining XML structures.""},{""term"":""Hive"",""explanation"":""A data warehousing and SQL-like query language for Hadoop.""},{""term"":""Impala"",""explanation"":""A high-performance, distributed SQL engine for Hadoop.""}],""skill_priorities"":{""must_have"":[""ETL development, Data Lake, Data Marts, XML, Python""],""nice_to_have"":[""Hive, Impala, performance tuning""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize ETL job performance?"",""example_answer"":""I identify bottlenecks, redesign workflows, and enhance queries to improve efficiency.""},{""question"":""How do you handle large, historical XML data files?"",""example_answer"":""I import necessary tables, optimize ETL processes, and leverage distributed processing to handle large files.""}],""red_flags"":[""Lack of experience with ETL development, inability to optimize performance""],""confidence_score"":90.0}"
Data Engineer (Snowflake),MindPal,"Montreal, Quebec, Canada",December,2023,"We are looking for experienced Data Engineers with knowledge of Snowflake platform.

Responsibilities

Creating and managing data in the Snowflake environment
Designing and implementing ETL (Extract, Transform, Load) solutions for transferring data between various sources and platforms
Optimizing the performance of Snowflake databases, including designing and implementing data structures and using indexes appropriately
Automating data processing workflows using tools such as Airflow or other workflow management tools
Deploying and configuring tools to monitor and report on the performance of the Snowflake system

Requirements

Minimum 1 year of experience as a Data Engineer
Ability to use Snowflake
Very good knowledge of SQL and programming in Python
Ability to work with databases, including the Snowflake platform
Knowledge of ETL tools and data integration
Ability to work in a team and good communication skills
Fluent English in speaking and writing

We Offer

B2B contract type
Full-time job
Remote and flexible working hours","{""role_summary"":""Design, implement, and manage data in Snowflake, ensuring efficient data processing and integration."",""key_terms"":[{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and processing large datasets.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of transferring data between systems, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Airflow"",""explanation"":""A workflow management tool for automating and monitoring data processing tasks.""}],""skill_priorities"":{""must_have"":[""Snowflake"",""SQL"",""Python"",""ETL tools"",""data integration""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize the performance of a Snowflake database?"",""example_answer"":""I would analyze the database structure, identify bottlenecks, and implement indexing strategies to improve query performance.""},{""question"":""Can you explain the concept of ETL and how you've applied it in a previous project?"",""example_answer"":""ETL involves extracting data from sources, transforming it into a standardized format, and loading it into a target system. In my previous project, I used ETL to integrate data from multiple sources, ensuring data consistency and reducing data latency.""}],""red_flags"":[""Lack of experience with Snowflake or ETL tools"",""Inability to work with databases or data integration""],""confidence_score"":90.0}"
Data Bricks/ETL Developer,ClifyX,"Brampton, Ontario, Canada",May,2024,"Data Bricks/ETL Developer
Brampton, ON
""Required Skills:
• Strong knowledge of Data Management and Principles
• At least over 3 years of experience in Azure Enterprise data lake development, with 6- 8 years of total experience in Data Warehousing.
• Hands-on experience designing and delivering solutions using Azure Data Lake
• Experience in building ETL/ELT/ data warehouse.
• Experience of building data pipelines using Azure Data Factory and Apache Spark (preferably PySpark in Databricks).
• Experience in working with structured and semi-structured data from various sources like blob (json/avro | delimited flat files | parquet... etc.) , rdbms etc.
• Adept in Structured Query Language.
• Ability to apply spark Dataframe api to complete data manipulation within Spark Session
• Good understanding of Spark Architecture including spark core, spark sql, dataframe, driver node, worker node, fault tolerance, collection, executors and tasks
• Experience in Delta Lake API.

Roles and responsibilities:

• Designing and implementing efficient data ingestion pipelines from multiple sources using Azure Data factory and/or Azure Databricks
• Integrating the end-to-end data pipeline to take data from different source systems to target data repositories ensuring the quality and consistency of data.
• Processing performance analysis and code optimization.","{""role_summary"":""Design and implement efficient data ingestion pipelines from multiple sources, integrating end-to-end data pipelines to ensure quality and consistency of data."",""key_terms"":[{""term"":""Azure Enterprise data lake development"",""explanation"":""Developing data storage solutions using Azure's enterprise-level data lake technology.""},{""term"":""ETL/ELT"",""explanation"":""Extract, Transform, Load/Extract, Load, Transform data from various sources to a target system.""},{""term"":""Azure Data Factory"",""explanation"":""A cloud-based data integration service that allows for the creation, scheduling, and management of data pipelines.""},{""term"":""Apache Spark"",""explanation"":""An open-source, distributed computing system for large-scale data processing.""},{""term"":""PySpark"",""explanation"":""A Python library for Apache Spark that allows for interactive data analysis and machine learning.""},{""term"":""Delta Lake API"",""explanation"":""An open-source storage layer that provides ACID transactions, scalable metadata handling, and unified streaming and batch data processing.""},{""term"":""Spark Architecture"",""explanation"":""The underlying architecture of Apache Spark, including Spark SQL, DataFrames, Driver Node, Worker Node, Fault Tolerance, Collection, Executors, and Tasks.""}],""skill_priorities"":{""must_have"":[""Azure Enterprise data lake development"",""ETL/ELT experience"",""Azure Data Factory experience"",""Apache Spark experience"",""PySpark experience"",""Delta Lake API experience"",""Spark Architecture knowledge""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of ETL/ELT and how it differs from ELT?"",""example_answer"":""ETL stands for Extract, Transform, Load, where data is extracted from a source, transformed into a compatible format, and loaded into a target system. ELT, on the other hand, stands for Extract, Load, Transform, where data is extracted from a source, loaded into a target system, and then transformed into a compatible format.""},{""question"":""How do you optimize the performance of a Spark job?"",""example_answer"":""To optimize the performance of a Spark job, I would first analyze the Spark UI to identify performance bottlenecks. Then, I would optimize the data processing pipeline by adjusting the number of executors, cores, and memory allocation. Additionally, I would use Spark's built-in optimization techniques such as broadcast variables and caching.""}],""red_flags"":[""Lack of experience with Azure Data Factory and/or Azure Databricks"",""Inability to explain the concept of ETL/ELT""],""confidence_score"":95.0}"
Data Engineer [Scotiabank],Scotiabank,"Toronto, Ontario, Canada",June,2024,"Requisition ID: 200905

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

This role requires a blend of a Data Engineer and a Developer who will be responsible for designing, building, monitoring, tuning, and troubleshooting data pipelines for Global Finance & Risk Technology.

Is this role right for you? In this role, you will:

Design, Develop and maintain robust data pipelines for the ingestion, transformation, and distribution of large datasets.
Utilize services and tools to automate data workflows and streamline the data engineering process.
Collaborate with other stakeholders to support data analysis, data mapping and reporting needs.
Monitor application performance, identifying bottlenecks, and implementing improvements to enhance efficiency.
Conduct data quality checks and implementing measures to ensure data accuracy and integrity.
Stay current with emerging technologies and data engineering practices to recommend and adopt innovations that improve data systems.
Provide technical expertise and support for data-related issues, including troubleshooting and resolving data pipeline failures.
Document data engineering processes, creating data flow diagrams, and maintaining metadata for data lineage and cataloging.

Skills

Do you have the skills that will enable you to succeed in this role? We'd love to work with you if you have experience with:

Proficiency in Java is crucial.
Experience using Streaming Architecture (Kafka) and Big Data Platform (Hadoop) is required.
Strong SQL knowledge is needed.
Experience in NiFi is desired.
General Understanding of continuous integration/continuous deployment (CI/CD) pipelines
Experience building CI/CD pipelines using GitHub, Artifactory etc. to reduce cycle times and ensure quality.
Strong scripting skills (i. e. shell scripting for automation.
Working experience with source control systems like Git.
Exposure to working on cloud platforms like Azure/GCP/AWS
Experience with Agile/Scrum development methodologies
Team player with effective communication skills (verbal and written)
Able to see tasks through to completion without significant guidance.
Self-managed and results-oriented with sense of ownership is required.
A university degree in Mathematics, Science, Engineering, Management or relevant.

What's in it for you?

We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success!
We provide you with the tools and technology needed to create meaningful customer experiences.
An opportunity for mentorship from experienced and knowledgeable technologists
You'll get to work with and learn from diverse industry leaders, who have hailed from top technology companies around the world.
We offer a competitive total rewards package that includes a base salary, a performance bonus, company matching programs (on pension & profit sharing), generous vacation, personal & sick days, personal development funding, maternity leave top-up, parental leave and much more.

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here . Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","{""role_summary"":""Design, build, and maintain data systems for Global Finance & Risk Technology, collaborating with stakeholders to support data analysis and reporting needs."",""key_terms"":[{""term"":""Data Pipelines"",""explanation"":""A series of processes that extract, transform, and load data for analysis and reporting.""},{""term"":""Streaming Architecture (Kafka)"",""explanation"":""A method of handling high-volume, real-time data streams, often used in big data applications.""},{""term"":""Big Data Platform (Hadoop)"",""explanation"":""A suite of tools for storing, processing, and analyzing large datasets.""},{""term"":""NiFi"",""explanation"":""An open-source data integration tool for managing and processing data flows.""},{""term"":""Continuous Integration/Continuous Deployment (CI/CD) pipelines"",""explanation"":""A practice of automating and streamlining the build, test, and deployment process.""},{""term"":""Agile/Scrum development methodologies"",""explanation"":""Iterative approaches to project management that emphasize flexibility, collaboration, and continuous improvement.""}],""skill_priorities"":{""must_have"":[""Proficiency in Java"",""Experience using Streaming Architecture (Kafka) and Big Data Platform (Hadoop)"",""Strong SQL knowledge""],""nice_to_have"":[""Experience in NiFi"",""General Understanding of continuous integration/continuous deployment (CI/CD) pipelines"",""Experience building CI/CD pipelines using GitHub, Artifactory etc."",""Strong scripting skills (i.e. shell scripting for automation)"",""Working experience with source control systems like Git"",""Exposure to working on cloud platforms like Azure/GCP/AWS"",""Experience with Agile/Scrum development methodologies""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design a data pipeline for a large dataset?"",""example_answer"":""I would start by identifying the data sources, then determine the data transformation requirements, followed by selecting the appropriate tools for data processing and finally, I would implement data quality checks and monitoring.""},{""question"":""How do you stay current with emerging technologies and data engineering practices?"",""example_answer"":""I regularly read industry blogs and articles, attend webinars and conferences, and participate in professional networks to stay informed about the latest trends and best practices.""}],""red_flags"":[""Lack of experience with Java or big data platforms"",""Inability to explain data pipeline design principles"",""No exposure to Agile/Scrum development methodologies""],""confidence_score"":90.0}"
Business Intelligence Engineer,Hour Consulting,"North York, Ontario, Canada",May,2024,"Our client, a rapidly expanding global technology partner, is looking for a highly skilled Business Intelligence Engineer to join their exceptional Technology and Development team. If you are passionate about demonstrating your expertise and thrive on collaborating with a group of talented engineers, then this role was made for you!
At the heart of technology innovation, our client specializes in delivering cutting-edge solutions to clients across a wide array of sectors. With a strategic focus on finance, banking, and corporate verticals, they have earned a stellar reputation for their commitment to excellence in every project they undertake.

Are you a highly motivated and seasoned Business Intelligence Engineer (BIE) with a remarkable track record in harnessing the capabilities of AWS Redshift, excelling in ETL processes, and mastering reporting tools within a serverless AWS cloud environment? If you're a self-starter who thrives in the face of ambiguity, we seek someone like you to join our dynamic team.

As a BIE, you will be responsible for setting the vision, defining the roadmap, and collaborating with stakeholders to deliver impactful results. This role offers a unique opportunity to have an immediate and lasting impact on internal and external customers by harnessing the power of data to drive key business insights.

What you will be doing:
 Data Modeling and Analysis: Develop and maintain multidimensional data models that enable complex analyses and reporting, utilizing AWS Redshift and other relevant technologies.
ETL Process Optimization: Design, implement, and enhance ETL processes to ensure efficient data extraction, transformation, and loading from various sources into data warehouses.
Reporting and Visualization: Create and maintain visually compelling dashboards, reports, and data visualizations to communicate key insights and performance metrics.
Business Collaboration: Collaborate with business leaders to understand their data needs and provide analytical support in answering critical business questions.
Roadmap and Vision: Define the long-term vision and roadmap for business intelligence solutions, aligning them with organizational goals and strategies.
Automated Processes: Develop and maintain automated processes for data extraction, transformation, and reporting to improve efficiency and accuracy.
Data Quality Assurance: Implement data validation and quality checks to ensure data accuracy and consistency.
Stakeholder Engagement: Engage with stakeholders across various departments to gather requirements, provide insights, and deliver data-driven solutions.
Performance Optimization: Optimize queries, reports, and ETL processes for performance and scalability, ensuring timely access to data.
Documentation: Create and maintain documentation for data models, ETL processes, and reporting solutions to facilitate knowledge sharing.

What we are looking for
Bachelor's or Master's in Computer Science, Data Science, Business Analytics, or a related field.
Proven experience as a Business Intelligence Engineer with expertise in AWS Redshift, ETL processes, and reporting tools.
Proficiency in SQL and data modeling for analytics and reporting.
Strong proficiency in business intelligence and data visualization tools (e.g., Tableau, Power BI).
Excellent problem-solving and analytical skills, with the ability to translate complex data into actionable insights.
Experience with AWS serverless technologies (e.g., AWS Lambda, AWS Glue) is highly desirable.
Strong scripting skills (e.g., Python) for process automation.
Effective communication and collaboration skills to work closely with cross-functional teams.
Comfortable working in an agile, dynamic, and rapidly evolving environment.
A self-starter with a passion for innovation and a track record of delivering results.
AWS certifications (e.g., AWS Certified Data Analytics - Specialty) are a bonus
 What's In It For You?
Join an inclusive, collaborative work environment that fosters creativity and curiosity and celebrates success!
Receive access to the latest tools and technology to create exceptional customer experiences.
Enjoy career advancement opportunities. Your talent is valued, and they want to see you succeed, not just in your current role but throughout your career.
After-work socials
 We encourage you to apply today if you're ready to take the reins of your career and be a driving force behind transformative data solutions—a chance to unlock the power of data to make a real difference.
 Location: North York, Onsite 3/4 days a week
Permanent, Full-time/ Contract","{""role_summary"":""A Business Intelligence Engineer responsible for developing and maintaining data models, ETL processes, and reporting solutions to drive business insights and collaborate with stakeholders."",""key_terms"":[{""term"":""AWS Redshift"",""explanation"":""A cloud-based data warehousing and analytics platform used for data modeling and reporting.""},{""term"":""ETL processes"",""explanation"":""Extract, Transform, and Load data from various sources into data warehouses.""},{""term"":""Serverless AWS cloud environment"",""explanation"":""A cloud computing model where the cloud provider manages infrastructure and resources, allowing for scalability and cost savings.""},{""term"":""Data modeling"",""explanation"":""The process of creating a conceptual representation of data structures to facilitate data analysis and reporting.""}],""skill_priorities"":{""must_have"":[""AWS Redshift"",""ETL processes"",""Reporting tools"",""SQL"",""Data visualization tools (e.g., Tableau, Power BI)"",""Problem-solving and analytical skills"",""Collaboration and communication skills""],""nice_to_have"":[""AWS serverless technologies (e.g., AWS Lambda, AWS Glue)"",""Scripting skills (e.g., Python)"",""AWS certifications (e.g., AWS Certified Data Analytics - Specialty)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize ETL processes for efficient data extraction, transformation, and loading?"",""example_answer"":""I would analyze the current ETL workflow, identify bottlenecks, and implement parallel processing, data partitioning, and data compression to improve performance.""},{""question"":""How do you ensure data quality and accuracy in your reporting solutions?"",""example_answer"":""I implement data validation and quality checks, perform regular data audits, and maintain documentation for data models and ETL processes to ensure data accuracy and consistency.""}],""red_flags"":[""Lack of experience with AWS Redshift and ETL processes"",""Inability to communicate complex data insights effectively to stakeholders""],""confidence_score"":95.0}"
Analytics Engineer,Rakuten Rewards,"Toronto, Ontario, Canada",June,2024,"Job Description:

Rakuten International oversees 7 businesses with over 4,000 employees globally. The brand is recognized for its leadership and innovation in e-commerce, digital content, advertising, entertainment, and communications, bringing the joy of discovery and access to more than 1 billion members across the world. Our teams deliver on the company’s mission to delight merchants and customers through innovation, optimism, and teamwork.

Rakuten Rewards is a leading e-commerce company that enhances the way people shop by offering Cash Back, deals and rewards from more than 3,500 merchants. Founded in 1999, Rakuten has grown to become the go-to shopping destination for consumers, having paid out nearly $2 billion in Cash Back to its 15 million members. The company also operates ShopStyle, a leading fashion discovery destination, and Cartera Commerce, a top rewards platform for airlines and banks. For more information, visit www.rakuten.com.

As a Product Analyst/Analytics Engineer, you will collaborate with product, engineering, and other teams as you translate complex data into strategic recommendations. You will develop solutions to complex business problems, and present data to enable data-driven decision making. You will help shape product development initiatives, optimize user experiences, and improve overall product performance. You will also own projects to elevate KPI reporting and be the expert on the data sets and data tools that are available.

KEY RESPONSIBILITIES:

Collaborate with Product and Engineering teams to identify opportunities, estimate impact, implement, and analyze tests.
Develop and maintain key performance indicators (KPIs) and dashboards to monitor product performance, identify trends, and generate actionable insights for stakeholders.
Perform ad hoc analysis to quickly solve time sensitive funnel conversion issues.
Collaborate with the development team to track and resolve data quality issues or discrepancies.
Support the development of data products and tools to facilitate self-service and enable analytics to scale across the company.
Provide technical expertise in extracting, integrating, and analyzing critical data.

MINIMUM REQUIREMENTS:

Strong SQL skills, comfortable working with large data sets like clickstream data on Snowflake.
2+ years of experience with Python or any other programming languages.
Experience working with reporting and visualization tools (Tableau preferred)
Strong interpersonal skills, both written and verbal, with the ability and confidence to succinctly convey complex information to senior management.
Strong analytical and problem-solving skills, with a keen attention to detail.
Experience with A/B testing is a plus.

QUALIFICATION REQUIREMENTS:

Bachelor’s or master’s degree in a relevant field (e.g., Data science, Statistics or Data Analytics).
2+ years professional experience in data analytics.
Ability to translate data-driven learnings into stories, actionable insights and communicate to key stakeholders.
Excellent team player and ability to work in a fast-paced environment, manage multiple tasks and meet deadlines.

Five Principles for Success

Our worldwide practices describe specific behaviors that make Rakuten unique and united across the world. We expect Rakuten employees to model these 5 Shugi Principles of Success.

Always improve, Always Advance - Only be satisfied with complete success - Kaizen

Passionately Professional - Take an uncompromising approach to your work and be determined to be the best

Hypothesize - Practice - Validate – Shikumika - Use the Rakuten Cycle to succeed in unknown territory

Maximize Customer Satisfaction - The greatest satisfaction for our teams is seeing their customers smile

Speed!! Speed!! Speed!! - Always be conscious of time - take charge, set clear goals, and engage your team

Rakuten provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type. Rakuten considers applicants for employment without regard to race, color, religion, age, sex, national origin, disability status, genetic information, protected veteran status, sexual orientation, gender, gender identity or expression, or any other characteristic protected by federal, state, provincial or local laws.","{""role_summary"":""Collaborate with cross-functional teams to translate complex data into strategic recommendations, driving data-driven decision making and product development initiatives."",""key_terms"":[{""term"":""A/B testing"",""explanation"":""A method of comparing two versions of a product to determine which one performs better.""},{""term"":""Clickstream data"",""explanation"":""A type of data that records user interactions with a website or application, used to analyze user behavior and optimize user experience.""},{""term"":""Data quality issues"",""explanation"":""Problems with the accuracy, validity, or completeness of data, affecting its reliability for analysis and decision-making.""},{""term"":""KPI reporting"",""explanation"":""The process of tracking and reporting key performance indicators to measure business performance and progress towards goals.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform used for storing and processing large datasets.""}],""skill_priorities"":{""must_have"":[""Strong SQL skills"",""Experience with Python or other programming languages"",""Strong interpersonal skills"",""Strong analytical and problem-solving skills""],""nice_to_have"":[""Experience with A/B testing"",""Experience with reporting and visualization tools (Tableau preferred)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing a complex data set to identify trends and insights?"",""example_answer"":""I would start by cleaning and processing the data, then use visualization tools to identify patterns and trends. Finally, I would communicate my findings and recommendations to stakeholders.""},{""question"":""How do you stay up-to-date with new tools and technologies in data analytics?"",""example_answer"":""I regularly read industry blogs and attend conferences to learn about new tools and technologies. I also network with peers to learn from their experiences.""}],""red_flags"":[""Lack of experience with large datasets"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":90.0}"
Data Engineer - Spark Streaming,Intelliswift Software,"Vancouver, British Columbia, Canada",June,2024,"Data Engineer (Spark)
Duration: Fulltime with Intelliswift Software Inc
Location: Canada 100% remote (Needs to work in PST Hours)
Description:
Must know Big Data in depth, handled large datasets
Doing Spark Streaming
Scala good but not required
Java Exp is a must","{""role_summary"":""Design and develop large-scale data systems, handling big data and implementing Spark Streaming."",""key_terms"":[{""term"":""Big Data"",""explanation"":""Handling large datasets and complex data structures.""},{""term"":""Spark Streaming"",""explanation"":""Processing real-time data streams using Apache Spark.""},{""term"":""Scala"",""explanation"":""A programming language used for building scalable applications.""}],""skill_priorities"":{""must_have"":[""Java Experience"",""Big Data"",""Spark Streaming""],""nice_to_have"":[""Scala""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you handle large datasets in a distributed computing environment?"",""example_answer"":""I use Apache Spark to handle large datasets, leveraging its in-memory processing and scalability features.""},{""question"":""Can you explain the concept of real-time data processing in Spark Streaming?"",""example_answer"":""Spark Streaming allows for real-time data streams, enabling applications to respond to events as they occur.""}],""red_flags"":[""Lack of experience with Java"",""No exposure to Big Data or Spark""],""confidence_score"":80.0}"
"Data Engineer - Scarborough, ON",Michael Page,"Toronto, Ontario, Canada",June,2024,"An opportunity to join a growing multi-national company|Ability for internal mobility and career progression


About Our Client

Our client is an international company, that designs, manufactures, and distributes packaging solutions.

Job Description

Design, build, and automate data flows while improving existing data systems.
Proficient in constructing SQL data warehouses from scratch.
Analyze business requirements for business intelligence, converting them into technical specifications and task timelines.
Design and implement data models and schemas to support data analysts and stakeholders.
Lead the development of centralized data storage for our transition to a data lake.
Perform data analysis across multiple sources to provide insights for informed decisions.
Evaluate data access control practices and develop remediation strategies.
Create and update technical documentation.
Visualize data with charts and explain algorithms, parameters, models, and relationships.
Manage and maintain data warehouse development.
Build multi-dimensional data models.
Document algorithms, parameters, and models comprehensively.
Design new systems by analyzing existing ETL processes.
Implement technical improvements for business intelligence systems.
Develop and manage data warehousing solutions for structured and unstructured data.
Use Git for version control of code and data pipeline configurations.

MPI does not discriminate on the basis of race, religion, sex, sexual orientation, gender identity or expression, age, disability, marital status, or based on an individual's status in any group or class otherwise protected under applicable human rights legislation. MPI encourages applications from minorities, women, the disabled and all other qualified applicants

The Successful Applicant

Bachelor's degree in Computer Science, Statistics, or a related field.
More than 5 years of experience in database development and administration.
Profound understanding of database management systems and ELT (Extract, Load, Transform) processes.
Extensive experience with crafting SQL queries, SQL Server Reporting Services (SSRS), and SQL Server Integration Services (SSIS).
Advanced skills in query optimization, index management, statistics, and partitioning.
Proven track record in developing intricate scripts, queries, and stored procedures without compromising data integrity, privacy, or security.
Proficiency in infrastructure automation and scripting for streamlined operations.
Hands-on experience with big data architectures and modeling for efficient data processing.
Comprehensive knowledge of data platform architecture, database optimization, and data management practices.
Familiarity with data governance, ingestion and extraction frameworks, and data security protocols.
Proficiency in programming languages such as SAS, R, Python, MATLAB, Java, VBA, and Excel.
Competence in managing both SQL and NoSQL databases.
Ability to collaborate effectively with stakeholders and assess potential risks.
Strong emphasis on documentation and adherence to well-defined procedures.
Familiarity with Domo or Power BI considered advantageous.
Experience working with cloud Data Lake platforms like AWS and Azure seen as beneficial.

What's On Offer

An opportunity to join a leading Canadian company
A hybrid position
Competitive compensation
Opportunity for growth and internal mobility


Contact: Jaco Venter

Quote job ref: JN-062024-6466398","{""role_summary"":""Design, build, and automate data flows, and improve existing data systems to support business intelligence and informed decision-making."",""key_terms"":[{""term"":""Data Lake"",""explanation"":""A centralized repository that holds structured and unstructured data in its native format.""},{""term"":""ELT (Extract, Load, Transform)"",""explanation"":""A process of extracting data from multiple sources, loading it into a target system, and transforming it into a standardized format.""},{""term"":""Data Governance"",""explanation"":""A set of practices and standards that ensure the quality, security, and integrity of an organization's data.""}],""skill_priorities"":{""must_have"":[""Database development and administration"",""SQL query optimization"",""index management"",""statistics"",""partitioning"",""ELT processes"",""Data modeling"",""Data platform architecture"",""Database optimization"",""Data management practices""],""nice_to_have"":[""Familiarity with Domo or Power BI"",""Experience working with cloud Data Lake platforms like AWS and Azure""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design a data model to support business intelligence?"",""example_answer"":""I would start by analyzing business requirements and identifying key performance indicators. Then, I would design a data model that incorporates relevant data sources and ensures data quality and integrity.""},{""question"":""How do you optimize SQL queries for better performance?"",""example_answer"":""I use query optimization techniques such as indexing, caching, and rewriting queries to improve performance. I also analyze query execution plans to identify bottlenecks and optimize accordingly.""}],""red_flags"":[""Lack of experience with data lake platforms"",""Inability to collaborate effectively with stakeholders""],""confidence_score"":90.0}"
Data Engineer (Airflow),Kyndryl,"Toronto, Ontario, Canada",June,2024,"Position: Apache Airflow Data Engineer
Client: Financial Services Client
Location: Toronto – Hybrid
Duration: 3 Months initial contract
Security Clearance: N/A
Language: English
Background:

Kyndryl Canada is supporting our Financial Services client and their project to build and maintain ETL pipelines to process and move data more efficiently.


Qualifications:

Extensive experience working with Apache Airflow.
Experience working with data process automation.
Ability to work on-site in downtown Toronto, multiple days a week.


Responsibilities could entail:
• Data Pipeline Development: Build and maintain ETL pipelines to process and move data efficiently.
• Workflow Orchestration: Use Apache Airflow to schedule and manage complex data workflows.
• Automation: Automate data processing tasks to ensure they run reliably and on time.
• Performance Optimization: Optimize data pipelines for speed and efficiency.
• Monitoring and Logging: Monitor pipeline performance and maintain detailed logs for troubleshooting.
• Collaboration: Work with data scientists and analysts to meet data needs.","{""role_summary"":""Design, build, and maintain data pipelines to process and move data efficiently, ensuring reliability and performance optimization."",""key_terms"":[{""term"":""Apache Airflow"",""explanation"":""A platform used to schedule and manage complex data workflows.""},{""term"":""ETL pipelines"",""explanation"":""A process of extracting, transforming, and loading data from one system to another for efficient data processing.""},{""term"":""Workflow Orchestration"",""explanation"":""The process of scheduling and managing complex data workflows using Apache Airflow.""}],""skill_priorities"":{""must_have"":[""Apache Airflow"",""Data process automation"",""On-site work in downtown Toronto""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data pipelines for speed and efficiency?"",""example_answer"":""I use techniques like parallel processing, data partitioning, and caching to improve pipeline performance.""},{""question"":""Can you explain how you would automate data processing tasks?"",""example_answer"":""I would use Apache Airflow to schedule and manage tasks, and implement retry mechanisms to ensure tasks run reliably and on time.""}],""red_flags"":[""Lack of experience with Apache Airflow"",""Inability to work on-site in downtown Toronto""],""confidence_score"":90.0}"
Big Data Engineer,Info Way Solutions,"Toronto, Ontario, Canada",June,2024,"Location : Austin TX or Sunnyvale, CA

JD: In the role of Lead Data Engineer, you will interface with key stakeholders and apply your technical proficiency across different stages of the Software Development Life Cycle including Requirements Elicitation, Application Architecture definition and Design. You will play an important role in creating the high-level design artifacts. You will also deliver high quality code deliverables for a module, lead validation for all types of testing and support activities related to implementation, transition and warranty. You will be part of a learning culture, where teamwork and collaboration are encouraged, excellence is rewarded, and diversity is respected and valued. Required Qualifications: Bachelor's degree or foreign equivalent required from an accredited institution. Will also consider three years of progressive experience in the specialty in lieu of every year of education At least 6 years of experience in Information Technology. At least 3 years of hands on experience with Hadoop distributed frameworks while handling large amount of big data using Spark and Hadoop Ecosystems. At least 3 years of experience with Spark/PySpark required. At least 2 years of experience with Scala required. At least 3 years of experience with SQL with any RDBMS. Preferred Qualifications: At least 1 years of AWS development experience is preferred Ability to work within deadlines and effectively prioritize and execute on tasks. Strong communication skills (verbal and written) with ability to communicate across teams, internal and external at all levels. Experience in Drive automations DevOps Knowledge is an added advantage.","{""role_summary"":""Lead a team of data engineers to design, develop, and implement large-scale data processing systems using Hadoop and Spark, ensuring high-quality code delivery and leading validation efforts."",""key_terms"":[{""term"":""Distributed computing architecture for processing large datasets"",""explanation"":""Hadoop is a framework for handling big data, used for storing and processing large datasets.""},{""term"":""Spark"",""explanation"":""An open-source data processing engine for large-scale data processing, often used with Hadoop.""},{""term"":""Scala"",""explanation"":""A programming language used for building scalable and concurrent systems, often used with Spark.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development (Dev) and operations (Ops) to improve collaboration and efficiency.""}],""skill_priorities"":{""must_have"":[""Hadoop"",""Scala"",""Spark"",""SQL"",""Communication skills""],""nice_to_have"":[""AWS development experience"",""DevOps knowledge"",""Drive automation experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data processing performance in a Hadoop cluster?"",""example_answer"":""I would use techniques like data partitioning, caching, and parallel processing to improve performance.""},{""question"":""Can you explain how you would handle data inconsistencies in a Spark pipeline?"",""example_answer"":""I would use Spark's built-in data quality checks and implement custom data validation rules to handle inconsistencies.""}],""red_flags"":[""Lack of hands-on experience with Hadoop and Spark"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Azure Data Engineer,Wipro,"Toronto, Ontario, Canada",June,2024,"About Wipro
Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs.
We leverage our holistic portfolio of capabilities in consulting, design, engineering, operations, and emerging technologies to help clients realize their boldest ambitions and build future-ready, sustainable businesses.
A company recognized globally for its comprehensive portfolio of services, strong commitment to sustainability and good corporate citizenship, we have over 250,000 dedicated employees serving clients across 66 countries.
We deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world.
· A PROUD HISTORY OF OVER 75 YEARS
· FY22 REVENUE 10.4 BN USD
· WE’RE PRESENT IN 66 COUNTRIES
· OVER 1,400 ACTIVE GLOBAL CLIENTS

JD:
Must-have skills
• Cloud certified in one of these categories
• Azure Data Engineer
• Azure Data Factory , Azure Data bricks Spark (PySpark or scala), SQL
• Experience in Azure ingestion from on-prem source, e.g. mainframe, SQL server, Oracle.
• Experience in Sqoop / Hadoop
• Microsoft Excel (for metadata files with requirements for ingestion)
• Any other certificate in Azure/AWS/GCP and data engineering hands-on experience in cloud
• Strong Programming skills with at least one of Python, Scala or Java
• Strong SQL skills ( T-SQL or PL-SQL)
• Data files movement via mailbox
• Source-code versioning/promotion tools, e.g. Git/Jenkins
• Orchestration tools, e.g. Autosys, Oozie
• Source-code versioning with Git.
Nice-to-have skills
• Experience working with mainframe files
• Experience in Agile environment, JIRA/Confluence tools.

Wipro is an Equal Employment Opportunity employer and makes all employment and employment-related decisions without regard to a person's race, sex, national origin, ancestry, disability, sexual orientation.","{""role_summary"":""Design and implement cloud-based solutions, leveraging Azure, AWS, or GCP, to ingest data from various sources, including mainframes, and manage data movement and orchestration."",""key_terms"":[{""term"":""Azure Data Engineer"",""explanation"":""A certified professional with expertise in designing and implementing data solutions on Azure cloud platform.""},{""term"":""PySpark or Scala"",""explanation"":""Programming languages used for data processing on Azure Data Bricks.""},{""term"":""Sqoop"",""explanation"":""A tool used for transferring data between Hadoop and structured data stores.""},{""term"":""Autosys"",""explanation"":""A job scheduling and workload automation software.""}],""skill_priorities"":{""must_have"":[""Cloud certification (Azure, AWS, or GCP)"",""Azure Data Engineer skills"",""Azure Data Factory experience"",""Azure Data Bricks Spark (PySpark or Scala) experience"",""SQL skills (T-SQL or PL-SQL)"",""Programming skills (Python, Scala or Java)"",""Experience with source-code versioning/promotion tools (Git/Jenkins)""],""nice_to_have"":[""Experience working with mainframe files"",""Experience in Agile environment, JIRA/Confluence tools""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design a data ingestion pipeline from an on-premises source to Azure Data Factory?"",""example_answer"":""I would use Azure Data Factory to create a pipeline that ingests data from the on-premises source, such as a mainframe, using Sqoop or Azure Data Factory's built-in connectors. I would also ensure data quality and validation using Azure Data Factory's data quality features.""},{""question"":""How do you handle data movement and orchestration in a cloud-based data engineering project?"",""example_answer"":""I would use orchestration tools like Autosys or Azure Data Factory's orchestration capabilities to manage data movement and processing. I would also ensure data versioning and promotion using Git and Jenkins.""}],""red_flags"":[""Lack of hands-on experience with cloud-based data engineering"",""Inability to explain data ingestion and processing concepts""],""confidence_score"":90.0}"
"Associate Software Engineer, Domain Data Engineering",Wayfair,"Toronto, Ontario, Canada",June,2024,"Candidates for this position are preferred to be based in Toronto and will be expected to comply with their team's hybrid work schedule requirements.

Associate Software Engineer, Domain Data Engineering

Who We Are:

Wayfair Data Engineering is the engine that powers our data-obsessed eCommerce enterprise. We move fast, iterating quickly on big business problems. We work smart, applying technology to unlock insights and provide outsized value to our customers. We swing big, knowing our customers won't benefit from micro optimizations. Leveraging the largest data set for products sold in the Home space, this team treats data as an asset and determines how to maximize its business value and extend our competitive advantage.

You will be instrumental in designing and delivering Data Warehouses, Data Lake, Self-Service Tooling, Real-time Streaming and Big Data Solutions for multiple functional areas using modern cloud technologies. You will have the chance to combine a deep knowledge of business and technical mastery to own and deliver the right solution for the right business problem. Most importantly, you will have the opportunity to move fast, adapt quickly, and leave a lasting mark through the new solutions you deliver!

What You'll Do:

Own technical design and implementation of big data platforms and self-service solutions
Collaborate with stakeholders and other engineering leaders to define and develop the data architecture roadmap.
Act as a subject matter expert to leadership for technical guidance around solution design and best practices.
Keep current on big data and data visualization technology trends, evaluate, work on proof-of-concepts and make merit-based recommendations on technologies

We Are a Match Because You Have:

An expert at SQL-based ETL development, and experienced with Python, Java, or equivalent scripting language.
Experienced developing in cloud platforms such as Google Cloud Platform (preferred), AWS, Azure, or Snowflake at scale.
Comfortable designing and implementing OLTP and OLAP data solutions.
Experience with real-time data streaming tools like Kafka, Kinesis, Apache Storm or any similar tools is a plus.
Experience with big data technologies like Hadoop, Spark, Cassandra, MongoDB or other open source big data tools is a plus.
Experience architecting data solutions utilizing Bl tools like Looker, Tableau, AtScale, PowerBI, or any similar tools is a plus.
Excellent communication and presentation skills, strong business acumen, critical thinking, and ability to work cross functionally through collaboration with engineering and business partners. Previous e-commerce experience is a plus.
Experience working with large data sets (5+TB highly desired)
Bachelor's or Masters in Computer Science, Computer Engineering, Statistics, or another quantitative discipline

Why You’ll Love Wayfair:

Time Off:
Paid Holidays
Paid Time Off (PTO)
Health & Wellness:
Full Health Benefits (Medical, Dental, Vision, HSA/FSA)
Life Insurance
Disability Protection (Short Term & Long Term Disability)
Global Wellbeing: Gym/Fitness discounts (including US Peloton, Global ClassPass, and various regional gym memberships)
Mental Health Support (Global Mental Health, Global Wayhealthy Recordings)
Caregiver Services
Financial Growth & Security:
RRSP (Registered Retirement Savings Plan)
Tuition Reimbursement
Financial Health Education (Knowledge of Financial Education - KOFE)
Tax Advantaged Accounts
Family Support:
Family Planning Support
Parental Leave
Global Surrogacy & Adoption Policy
Professional Development & Recognition:
Rewards & Recognition
Global Employee Anniversary Awards
Paid Volunteer Work
Unique Perks:
Employee Discount
Global Pod Outings
Work/Life Balance:
Emphasizing a supportive & flexible work environment that encourages a balance between personal and professional commitments
We are looking forward to your application!

About Wayfair Inc.

Wayfair is one of the world’s largest online destinations for the home. Whether you work in our global headquarters in Boston or Berlin, or in our warehouses or offices throughout the world, we’re reinventing the way people shop for their homes. Through our commitment to industry-leading technology and creative problem-solving, we are confident that Wayfair will be home to the most rewarding work of your career. If you’re looking for rapid growth, constant learning, and dynamic challenges, then you’ll find that amazing career opportunities are knocking.

No matter who you are, Wayfair is a place you can call home. We’re a community of innovators, risk-takers, and trailblazers who celebrate our differences, and know that our unique perspectives make us stronger, smarter, and well-positioned for success. We value and rely on the collective voices of our employees, customers, community, and suppliers to help guide us as we build a better Wayfair – and world – for all. Every voice, every perspective matters. That’s why we’re proud to be an equal opportunity employer. We do not discriminate on the basis of race, color, ethnicity, ancestry, religion, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, veteran status, genetic information, or any other legally protected characteristic.

Your personal data is processed in accordance with our Candidate Privacy Notice (https://www.wayfair.com/careers/privacy). If you have any questions or wish to exercise your rights under applicable privacy and data protection laws, please contact us at dataprotectionofficer@wayfair.com.","{""role_summary"":""Design and deliver data warehousing, data lake, self-service tooling, real-time streaming, and big data solutions for multiple functional areas using modern cloud technologies."",""key_terms"":[{""term"":""Data Warehouses"",""explanation"":""A central repository that stores data from various sources in a single location, making it easier to analyze and report.\n""},{""term"":""Data Lake"",""explanation"":""A storage repository that holds raw, unprocessed data in its native format, allowing for flexible schema-on-read analytics.""},{""term"":""Self-Service Tooling"",""explanation"":""A platform that enables users to easily access, manipulate, and analyze data without requiring extensive technical expertise.""},{""term"":""Real-time Streaming"",""explanation"":""The process of continuously processing and analyzing data as it is generated, enabling timely insights and decision-making.""},{""term"":""Big Data Solutions"",""explanation"":""Large-scale data processing and analysis technologies, including Hadoop, Spark, and NoSQL databases, designed to handle massive data volumes.""},{""term"":""Cloud Technologies"",""explanation"":""On-demand computing resources and services provided over the internet, such as Google Cloud Platform, AWS, and Azure.""}],""skill_priorities"":{""must_have"":[""SQL-based ETL development"",""Experience with Python, Java, or equivalent scripting language)"",""Experience with cloud platforms like Google Cloud Platform, AWS, Azure, or Snowflake""],""nice_to_have"":[""Experience with real-time data streaming tools like Kafka, Kinesis, Apache Storm"",""Experience with big data technologies like Hadoop, Spark, Cassandra, MongoDB"",""Experience architecting data solutions utilizing BI tools like Looker, Tableau, AtScale, PowerBI""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design a scalable data warehousing solution for a large e-commerce platform?"",""example_answer"":""I would consider using a cloud-based data warehousing solution like Amazon Redshift or Google BigQuery, and design a scalable architecture that can handle large volumes of data. I would also ensure data is properly partitioned, and implement efficient ETL processes to minimize latency.""},{""question"":""Can you explain the trade-offs between using a data lake versus a data warehouse?"",""example_answer"":""A data lake is ideal for storing large amounts of raw, unprocessed data, while a data warehouse is better suited for storing processed, transformed data for reporting and analytics. The choice between the two depends on the specific use case and requirements.""}],""red_flags"":[""Lack of experience with cloud-based data engineering"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":95.0}"
Co-op Engineer- Data Science,Huawei Canada,"Markham, Ontario, Canada",June,2024,"Our team has an immediate Co-op opening for Data Science

Responsibilities:

Research & Build (and/or Prototype) Gen AI model(s) using LLMs
Design, develop and fine-tune scalable LLMs (Large Language Model)
Collaborate with UX designer and front-end developer to incorporate UI design to the Gen-AI platform
Collaborate with platform software engineers for integrating Gen-AI model into existing solution
Conduct technical research and present to the team

Job requirements

What you’ll bring to the team:

Strong background in mathematics and statistics.
A strong foundation in algorithms, data structure, and object-oriented-programming along with proficiency in Python, R, and Java.
Experience in using ML algorithms (i.e., supervised, unsupervised, and Reinforcement Learning) and exploratory data analysis (EDA) tool and libraries including Numpy, Pandas, Matplotlib, Seaborn, and Scikit-learn.
Solid knowledge of Artificial neural networks like CNN, RNN, LSTM, and GRU, along with expertise in DL frameworks such as PyTorch, TensorFlow.
Deep understanding of various NLP tasks and concepts in both NLU (e.g, text/token classification) and NLG (e.g., text generation) domains as well as hands-on experience with NLP libraries like SpaCy, and NLTK.
Theoretical knowledge of advanced NLP concepts including transformers, pre-training with self-supervised techniques, and transfer learning, along with experience in fine-tuning Auto-encoder, Autoregressive and Seq2Seq Language Models from Hugging Face.
Familiarity with Generative AI concepts and tools including (Mutlimodal) Large Language Models, Retrieval Augmented Generation, Vector databases and Langchain.
Prior internship expeirnece in AI/ML development","{""role_summary"":""Conduct research, design, and develop scalable Large Language Models (LLMs) and integrate them into existing solutions, collaborating with cross-functional teams."",""key_terms"":[{""term"":""LLMs"",""explanation"":""Large Language Models, a type of AI model used for natural language processing.""},{""term"":""NLU"",""explanation"":""Natural Language Understanding, a subfield of NLP that deals with text/token classification.""},{""term"":""NLG"",""explanation"":""Natural Language Generation, a subfield of NLP that deals with text generation.""},{""term"":""Transformers"",""explanation"":""A type of neural network architecture used in NLP, particularly in pre-training and transfer learning.""},{""term"":""Generative AI"",""explanation"":""A subfield of AI that deals with generating new content, such as text or images, using machine learning models.""}],""skill_priorities"":{""must_have"":[""Strong background in mathematics and statistics"",""Proficiency in Python, R, and Java"",""Experience in using ML algorithms and exploratory data analysis tools"",""Solid knowledge of Artificial neural networks and DL frameworks"",""Deep understanding of various NLP tasks and concepts""],""nice_to_have"":[""Prior internship experience in AI/ML development""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of transfer learning in NLP?"",""example_answer"":""Transfer learning is a technique where a pre-trained model is fine-tuned on a smaller dataset to adapt to a new task, leveraging the knowledge learned from the larger dataset.""},{""question"":""How do you approach fine-tuning a Large Language Model for a specific NLP task?"",""example_answer"":""I would start by selecting a suitable pre-trained LLM, then adjust the hyperparameters and fine-tune it on a relevant dataset, monitoring the model's performance on a validation set.""}],""red_flags"":[""Lack of experience with Large Language Models or NLP concepts"",""Inability to explain technical NLP concepts, such as transformers or transfer learning""],""confidence_score"":95.0}"
Data WareHouse Engineer-Canada,Zortech Solutions,"Montreal, Quebec, Canada",May,2024,"Role: Data WareHouse Engineer

Location: Montreal, Canada-Hybrid (3 days to office)

Duration: 6+ Months

Job Description

Leading provider of platforms; digital innovation; artificial Intelligence and end-to-end IT services and solutions for Global 1000 companies.
We are transforming corporations through deep domain expertise; knowledge-based ML platforms; as well as profound anthropological efforts to understand the end customer and design products and interactions that create delight.
We are deeply committed to developing a comprehensive understanding of our client's problems and developing platforms to address them.
This position is a key lead in the analysis, definition and development of a long-term data plan that will meet the analytical needs of the organization.
This position involves making large amounts of data digestible by our researchers and traders.
You will lead or assist in all aspects of our data warehouse, including: ELT/ETL, data quality evaluation and management, data modeling, database architecture, warehousing principles, and other activities.
Be a thought leader and driving force behind all big data initiatives Design, build and support both real-time and batch data flows Learn our client's users' needs both from a historical/warehouse perspective and an operational/transactional perspective Support the logical and physical integration of all applications that are developed or licensed, including how data are used for multiple purposes Create and manage architecture documentation and project artifacts such as data models, data dictionaries, ETL data maps, performance requirements, etc.
Create standards and conventions for data warehouse, analytics, and ETL systems. Lead governance and enforcement of standards Communicate frequently and effectively with all internal associates, including research, management, development, and other operations personnel.
Demonstrate a disciplined approach to testing both software and data; show diligence in identifying and pursuing data anomalies, always striving not only to correct the data but also to identify the source of the corruption

Required Skill

Teradata *data warehouse development
Enhancement with good to have cloud (Azure, Snowflake, AWS)","{""role_summary"":""Lead the development of a long-term data warehouse to meet the analytical needs of the organization, making large amounts of data digestible for researchers and traders."",""key_terms"":[{""term"":""ELT/ETL"",""explanation"":""Extract, Load, Transform/Extract, Transform, Load processes for data integration and management.""},{""term"":""Data Modeling"",""explanation"":""Designing and structuring data to meet business needs and support data warehousing principles.""},{""term"":""Data Governance"",""explanation"":""Establishing and enforcing standards, policies, and procedures for data management and quality.""}],""skill_priorities"":{""must_have"":[""Teradata data warehouse development""],""nice_to_have"":[""Cloud experience (Azure, Snowflake, AWS)""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach data quality evaluation and management in a data warehouse environment?"",""example_answer"":""I implement data validation rules, data profiling, and data quality metrics to ensure data accuracy and integrity.""},{""question"":""Can you describe your experience with data governance and standards enforcement?"",""example_answer"":""I have established and enforced data governance policies, procedures, and standards for data warehousing, analytics, and ETL systems.""}],""red_flags"":[""Lack of experience with Teradata data warehouse development"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":85.0}"
Junior Front End Software Engineer,DataVisor,"Toronto, Ontario, Canada",June,2024,"DataVisor is the world's leading AI-powered Fraud and Risk Platform that delivers the best overall detection coverage in industry. With an open SaaS platform that supports easy consolidation and enrichment of any data, DataVisor's solution scales infinitely and enables organizations to act on fast-evolving fraud and money laundering activities in real time. Its patented unsupervised machine learning technology, advanced device intelligence, powerful decision engine and investigation tools work together to provide guaranteed performance lift from day one. DataVisor's platform is architected to support multiple use cases across different business units flexibly, dramatically lowering total cost of ownership, compared to legacy point solutions. DataVisor is recognized as an industry leader and has been adopted by many Fortune 500 companies across the globe. Our award-winning software platform is powered by a team of world-class experts in big data, machine learning, security, and scalable infrastructure. Our culture is open, positive, collaborative, and results driven.

We are looking for excellent web front-end engineers who can constantly challenge theirselves and surpass themselves. We hope that candidates have a solid development foundation and broad front-end or full-stack development experience. Mature experience in front-end framework and early start-up technology company experience is preferred, we look forward to furthering communication with you!

Responsibility:

Develop DataVisor user analysis interface, including data visualization and database interface functionality, and complete the development efficiently tasks;
Constantly participate in the development of the Web front-end, back-end development, API interface, etc. of the DataVisor big data analysis platform;
Focus on business, and business goals, and exert self-creativity and productivity to achieve business needs


Requirements

Basic Qualifications:

BS degree in Computer Science or relevant field of study
2+ years of web development experience, proficient in HTML, CSS, Javascript, Typescript and other related knowledge
2+ years of front-end frameworks (such as Angular, React), etc., experience in data visualization is preferred
Familiar with web testing framework, Java Selenium, experienced in writing E2E test cases/test suites and Unit Tests for frontend code, and also to be able to extend existing applications and have certain experience in performance tuning
Experienced in Java/Spring programming, familiar with Web back-end development and big data analysis experience is preferred
NodeJS server-side development, database interface development experience and SQL proficiency are preferred
Proficiency in using git, jenkins and other tools
Good communication skill including reading and writing skills


Benefits

Health Insurance, PTO and retirement plan","{""role_summary"":""Develop and maintain the user interface of DataVisor's big data analysis platform, focusing on business goals and self-creativity."",""key_terms"":[{""term"":""Front-end framework"",""explanation"":""A software framework used to build the user interface of a web application, such as Angular or React.""},{""term"":""Data visualization"",""explanation"":""The process of creating graphical representations of data to help users understand and analyze it.""},{""term"":""Big data analysis"",""explanation"":""The process of examining large and complex data sets to extract insights and patterns.""}],""skill_priorities"":{""must_have"":[""HTML"",""CSS"",""Javascript"",""Typescript"",""Front-end framework experience"",""Web testing framework experience"",""Git""],""nice_to_have"":[""Data visualization experience"",""Java/Spring programming"",""NodeJS server-side development"",""Database interface development experience"",""SQL proficiency""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach performance tuning in a web application?"",""example_answer"":""I use tools like Webpack and Chrome DevTools to identify performance bottlenecks and optimize code accordingly.""},{""question"":""Can you explain how you would implement data visualization in a front-end framework?"",""example_answer"":""I would use a library like D3.js to create interactive visualizations and integrate them into the framework.""}],""red_flags"":[""Lack of experience with front-end frameworks"",""Inability to write E2E test cases and Unit Tests for frontend code""],""confidence_score"":90.0}"
New Graduate Software Engineer (Toronto),Jerry,"Edmonton, Alberta, Canada",June,2024,"We'd love to hear from you if you like:

Making a big impact on Day One with a Forbes Top Startup Employer
Working at a startup that has traction ($240M in funding, 40X revenue growth in 4 years)
Working with a newer tech stack and building products that have a real impact (Jerry saves the average person $1K a year)
Mentorship from talented engineering leaders and peers who have built and scaled companies like Nvidia, Kuaishou, Cepton, and Tiktok
Meritocracy: we promote based on performance, not tenure

About the opportunity:

Jerry is building the first AI-powered AllCar™ app to redefine car ownership. The average American spends over 20% of their annual income on their vehicle, yet every part of owning and managing a car is painful – lack of transparency, poor service, high costs, etc. We are simplifying and automating every step of car ownership, all streamlined on our mobile app. We started with insurance shopping in 2019, since then we’ve launched loan refinancing, real-time driving insights, car diagnostics, a repair marketplace, and a GPT-4 chatbot. Our engineering team isn’t just focused on making something that works, we want to make something that works exceptionally well. If you want to contribute to something that matters and is actively making car ownership easier, simpler, and more accessible for 5M+ people, join us!

We are looking for new graduates in the Toronto area to join our engineering team! We are in growth mode and have aggressive goals to scale our technology and our business in the next few years as we go from 5M to 50M users. We don't require any specific work experience but we are looking for the following characteristics: passion for learning, hustle, and ownership. The pace of learning at a startup like Jerry is unbeatable. You can expect your scope of responsibilities to grow quickly if you excel in your role and demonstrate a willingness to keep learning and growing. If you’re looking for an opportunity to accelerate your career, we are hiring across multiple engineering teams!

Our tech stack:

Hosting infra: AWS
React for web frontend
NodeJS + Typescript for backend development
React (mobile app is written in React Native)
Redis, Postgres, DynamoDB for backend storage
Python for data pipeline and ML
Clickhouse for data warehouse
Python + Go for infrastructure as code and continuous integration

What we are looking for:

Bachelor's degree in computer science or engineering
Any internship, co-op, or summer work experience is an asset

Jerry is proud to be an Equal Employment Opportunity employer. We prohibit discrimination based on race, religion, color, national origin, sex, pregnancy, reproductive health decisions or related medical conditions, sexual orientation, gender identity, gender expression, age, veteran status, disability, genetic information, or other characteristics protected by applicable local, state or federal laws.

Jerry is committed to providing reasonable accommodations for individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, please contact us at recruiting@getjerry.com

About Jerry:

Jerry is America’s first and only AllCar™ app. We are redefining and radically improving how people manage owning a car, one of their most expensive and time-consuming assets.

Backed by artificial intelligence and machine learning, Jerry simplifies and automates owning and maintaining a car while providing personalized services for all car owners' needs. We spend every day innovating and improving our AI-powered app to provide the best possible experience for our customers. From car insurance and financing to maintenance and safety, Jerry does it all.

We are the #1 rated and most downloaded app in our category with a 4.7 star rating in the App Store. We have more than 6 million customers — and we’re just getting started.

Jerry was founded in 2017 by serial entrepreneurs and has raised more than $242 million in financing.

Join our team and work with passionate, curious and egoless people who love solving real-world problems. Help us build a revolutionary product that’s disrupting a massive market.","{""role_summary"":""Join Jerry's engineering team as a new graduate in the Toronto area, contributing to an AI-powered car ownership platform that simplifies and automates car management, with opportunities for rapid growth and learning."",""key_terms"":[{""term"":""AI-powered AllCar™ app"",""explanation"":""A mobile application that uses artificial intelligence to simplify and automate car management tasks.""},{""term"":""GPT-4 chatbot"",""explanation"":""A type of artificial intelligence language model used for conversational interfaces, in this case, a chatbot within the Jerry app.""},{""term"":""React Native"",""explanation"":""A framework for building cross-platform mobile applications using React, used for Jerry's mobile app.""},{""term"":""Typescript"",""explanation"":""A programming language used for backend development, providing type safety and compatibility with JavaScript.""},{""term"":""Clickhouse"",""explanation"":""A column-oriented database management system used for Jerry's data warehouse.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in computer science or engineering""],""nice_to_have"":[""Internship, co-op, or summer work experience"",""Passion for learning, hustle, and ownership""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach learning new technologies and staying up-to-date with industry trends?"",""example_answer"":""I prioritize self-learning, participate in online forums, and attend industry events to stay current.""},{""question"":""Can you describe a project where you demonstrated ownership and hustle?"",""example_answer"":""In my previous internship, I took initiative to optimize a process, resulting in X% improvement in efficiency.""}],""red_flags"":[""Lack of passion for learning and growth"",""Inability to work in a fast-paced startup environment""],""confidence_score"":90.0}"
Senior Data Engineer- Snowflake,Tiger Analytics,"Montreal, Quebec, Canada",October,2023,"Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning and AI. We are the trusted analytics partner for several Fortune 100 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best analytics global consulting team in the world.

We are seeking an experienced Sr. Data Engineer with expertise in Snowflake to join our data team. As a Data Engineer, you will be responsible for designing, building, and maintaining data pipelines, data integration processes, and data infrastructure using Cloud Snowflake DBT. You will collaborate closely with data scientists, analysts, and other stakeholders to ensure efficient data flow and support data-driven decision making across the organization.

Requirements

9+ years of overall industry experience specifically in data engineering
5+ years of experience building and deploying large-scale data processing pipelines in a production environment
Understanding of Datawarehouse (DWH) systems, and migration from DWH to data lakes/Snowflake
Solid experience with Snowflake Cloud Data Platform (SnowPro Core Certification is a bonus) or other cloud data warehouses (AWS Services)
Experience with dbt (core and/or Cloud) and Fivetran
Experience with Informatica Cloud is a bonus
Strong problem-solving skills and the ability to handle complex data challenges
Build processes supporting data transformation, data structures, metadata, dependency and workload management


Benefits

Significant career development opportunities exist as the company grows. The position offers a unique opportunity to be part of a small, challenging, and entrepreneurial environment, with a high degree of individual responsibility.","{""role_summary"":""Design, build, and maintain data pipelines, integration processes, and infrastructure using Cloud Snowflake DBT, collaborating with data scientists and analysts to support data-driven decision making."",""key_terms"":[{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and processing large amounts of data.""},{""term"":""DBT"",""explanation"":""An open-source tool for transforming and loading data into a target system, such as a data warehouse.""},{""term"":""Datawarehouse (DWH)"",""explanation"":""A system designed to store and manage large amounts of data, typically used for reporting and analytics.""},{""term"":""Data lakes"",""explanation"":""A storage repository that holds raw, unprocessed data in its native format, allowing for flexible schema-on-read analysis.""},{""term"":""SnowPro Core Certification"",""explanation"":""A certification that demonstrates expertise in Snowflake's cloud data warehousing platform.""},{""term"":""Fivetran"",""explanation"":""A cloud-based data integration platform for connecting and transforming data from various sources.""},{""term"":""Informatica Cloud"",""explanation"":""A cloud-based data integration platform for integrating, transforming, and managing data across various systems.""}],""skill_priorities"":{""must_have"":[""9+ years of industry experience in data engineering"",""5+ years of experience building and deploying large-scale data processing pipelines"",""Understanding of Datawarehouse (DWH) systems and migration to data lakes/Snowflake"",""Solid experience with Snowflake Cloud Data Platform"",""Experience with dbt (core and/or Cloud) and Fivetran""],""nice_to_have"":[""SnowPro Core Certification"",""Experience with Informatica Cloud""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with building and deploying large-scale data processing pipelines in a production environment?"",""example_answer"":""I have built and deployed multiple pipelines using Snowflake and dbt, processing millions of records daily, and ensured data quality and integrity.""},{""question"":""How do you approach data transformation and metadata management in Snowflake?"",""example_answer"":""I use dbt to transform data and manage metadata, ensuring data is properly structured and easily accessible for analysis.""}],""red_flags"":[""Lack of experience with Snowflake or similar cloud data warehousing platforms"",""Inability to demonstrate problem-solving skills in complex data challenges""],""confidence_score"":95.0}"
"Data Engineer, Finance Data",OMERS,"Toronto, Ontario, Canada",June,2024,"Why join us?

Are you looking to join a dynamic pension plan that embodies the strong values of its 500,000 members and is an industry leading global investor? If so, we would love to tell you our story.

At OMERS we put our people first and are proud to embrace the diversity of thought and leadership that comes from having locations in Toronto, London, New York, Singapore, Sydney and other major cities across North America and Europe. Our culture is truly one of a kind. We get stuff done, and have fun doing it! We take great pride in contributing to the communities where we live with an ever-constant eye to the global investment markets.

We’d be thrilled to have you join our team as we set up our Capital Markets Finance Data team for new and continued success! We’ll focus equally on expertise and excellence, paired with culture and community. We will serve OMERS teams primarily in Capital Markets, Total Portfolio Management, and the Corporate function through understanding their needs, delivering against their expectations, and contributing our proficiencies – to achieve collective wins. This role joins a team on a journey, with much future potential in a global, sophisticated, complex enterprise.

Scope of Position Support investment teams by enabling robust and reliable investment data, analytics, and reporting through investment technology and change management at one of Canada’s largest pension funds having assets exceeding $120 Billion.

Responsibilities

Design, develop, and help maintain data assets to extract, transform, and load data from various data files, APIs, and databases, and to make them accessible to various client-facing applications as well as investment data warehouse and internal tools
Implement data strategies that prepare, transform, combine and manage structured and unstructured data (e.g. internal investment accounting systems as well as external third-party investment feeds) to integrate the data into an investment data warehouse and BI solutions
Develop and operate highly scalable data pipelines and infrastructure that enable investment analytics, and investment reporting use cases
Automate manual processes and optimize data delivery
Utilize modern technologies for designing and building data solutions to meet business needs
Partner with business analysts and reporting analysts to develop reports and PowerBI dashboards
Support and troubleshoot existing investment data applications and BI reporting solutions as needed
Work as part of a cross-functional agile team responsible for end-to-end delivery of business needs
Collaborate and work effectively with business analysts and reporting analysts team members, and other investment professionals and leaders in solutioning and support

Qualifications

Track of record working in a fast-paced environment and multi-faceted role that intersects with business and technical analysts to support existing solutions, solution delivery, and contributions as a project resource for investment system implementations and upgrades
Strong experience with data management, investment systems, business intelligence, and other reporting technologies
Experience with Microsoft based BI/ETL tools (e.g. SQL Server, SSRS, SSIS, data factory or similar
Experience with Cloud based data and analytics platforms (e.g. Snowflake, DataBricks, Azure Synapse)
Deep proficiency in SQL, Python, and similar languages
Good understanding of investment products
Demonstrated ability to handle multiple projects and tasks at the same time to support daily production issues
Critical thinking skills with the ability to independently solve problems with data and/or reference documents
Investment data modeling experience using the Kimball method is an asset
Experience with BNY Eagle PACE, Calypso, and Charles River is an asset
Data governance experience is an asset
Bachelor’s or master’s degree in Computer Science, Engineering, Finance, or a related field

And you demonstrate

A people-first focus with a desire to develop meaningful, positive relationships across all levels of the organization
A teammate mentality coupled with servant leadership
A sense of urgency, optimism, and a desire to deliver excellence
A desire to drive debate, to speak candidly, and to listen empathetically
Strong orientation towards strategy, change, and results
A continuous improvement mindset

Our story

Founded in 1962, OMERS is one of Canada’s largest defined benefit pension plans, with $128.6 CAD billion in net assets as of December 31, 2023. OMERS is a jointly-sponsored pension plan, with more than 1,000 participating employers ranging from large cities to local agencies, and over half a million active, deferred and retired members. OMERS members include union and non-union employees of municipalities, school boards, local boards, transit systems, electrical utilities, emergency services and children’s aid societies across Ontario. Contributions to the Plan are funded equally by members and employers. OMERS teams work in Toronto, London, New York, Amsterdam, Luxembourg, Singapore, Sydney and other major cities across North America and Europe – serving members and employers and originating and managing a diversified portfolio of high-quality investments in public markets, private equity, infrastructure and real estate.

OMERS is committed to having a workforce that reflects the communities in which we live and work. We are an equal opportunity employer committed to a barrier-free recruitment and selection process. At OMERS inclusion and diversity means belonging. How we create a sense of belonging is through our employees and our vast network of Employee Resource Groups. Whether you are passionate about gender, pride, or visible minorities, we have groups that are focused on making a difference in all of our lives.","{""role_summary"":""Support investment teams by enabling robust and reliable investment data, analytics, and reporting through investment technology and change management at one of Canada's largest pension funds."",""key_terms"":[{""term"":""Investment data warehouse"",""explanation"":""A centralized repository that stores and managing investment data for business intelligence and analytics.""},{""term"":""BI solutions"",""explanation"":""Business Intelligence solutions that provide data visualization and analytics capabilities to support investment decision-making.""},{""term"":""Cloud-based data and analytics platforms"",""explanation"":""Cloud-based platforms that enable scalable and secure data management, and analytics capabilities.""},{""term"":""Data governance"",""explanation"":""The policies, procedures, and standards for managing and using data to ensure data quality, security, and compliance.""},{""term"":""Kimball method"",""explanation"":""A data modeling approach used for designing and implementing data warehouses and business intelligence solutions.""}],""skill_priorities"":{""must_have"":[""Strong experience with data management, investment systems, business intelligence, and reporting technologies"",""Experience with Microsoft-based BI/ETL tools"",""Deep proficiency in SQL, Python, and similar languages"",""Good understanding of investment products""],""nice_to_have"":[""Experience with Cloud-based data and analytics platforms"",""Investment data modeling experience using the Kimball method"",""Experience with BNY Eagle PACE, Calypso, and Charles River"",""Data governance experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with data files, APIs, and databases, and how you would make them accessible to various client-facing applications?"",""example_answer"":""I have worked with multiple data sources, including APIs and databases, to extract, transform, and load data into an investment data warehouse. I have experience with data integration and data visualization tools, and I can provide examples of how I would design and implement data solutions to meet business needs.""},{""question"":""How do you stay current with new technologies and trends in data management and analytics?"",""example_answer"":""I regularly read industry publications, attend webinars, and participate in online forums to stay current with new technologies and trends in data management and analytics. I also network with peers and attend conferences to learn from others in the field.""}],""red_flags"":[""Lack of experience with data management, investment systems, business intelligence, and reporting technologies"",""Inability to work in a fast-paced environment with multiple projects and tasks"",""Limited understanding of investment products and data governance principles""],""confidence_score"":90.0}"
"Data Engineer, Data Application",TikTok,"Vancouver, British Columbia, Canada",June,2024,"Responsibilities

TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.
Join us.

TikTok's immersive experience, global presence, and high engagement makes it the ideal marketing destination for business, big and small, to showcase their unique brand identity, connect with their consumers, and build strong lasting relationships over time. The Ads Data Team builds and manages the petabyte scale data infrastructure, batch/realtime pipelines and services to support Tiktok's global Ads business. We are committed to building a robust data foundation and scalable data applications, unblocking the full potential of advertising data to optimize advertiser experience, boost business growth, empower strategy execution.

We are looking for passionate Data Engineers that have strong problem solving skills to join forces with talented cross functional partners (business operation, data science, engineering and product management) to solve some of the most interesting data challenges with efficiency and quality. In this role, you will contribute to the company's core business across innovative advertising products, campaign management and measurement solutions. You will see a direct impact from your day-to-day work to customer satisfaction and company growth.

Responsibilities:
1. Work closely with Product Managers, Data Scientists/Analysts, and Software/Machine Learning Engineers and other stakeholders to understand data requirements and deliver data solutions that meet business needs.
2. Evaluate, implement and maintain data infrastructure tools and technologies to support efficient data processing, storage and query.
3. Design, build and optimize scalable data pipelines to ingest, process and transform large volumes of data.
4. Design and implement robust data models and visualization to support complex analytical queries and reporting requirements.
5. Ensure the data integrity, accuracy and consistency of data by implementing data quality checks, validation processes and monitoring mechanisms.
6. Continously optimize data pipelines, queries and processes to improve performance, reduce latency and enhance scalability.
7. Provide rapid response to SLA oncall support to business critical data pipelines.
8. Create and maintain good documentation for data assets and promote best practices for data governance within the data user community.

Qualifications

Qualifications:
1. Bachelor's degree in Computer Science, Engineering, or a related field.
2. Proven 1~3 years' experience as a Data Engineer or similar role in supporting data-centric business.
3. Strong knowledge of SQL and experience working with relational and non-relational databases.
4. Proficiency in programming languages such as Python, Java, Go etc.
5. Solid understanding of data modeling and data warehousing concepts, data integration and ETL/ELT techniques.
6. Effective communication skills and ability to collaborate effectively with cross-functional teams.
7. Excellent problem-solving skills, attention to detail, and ability to thrive in a fast-paced environment.

Preferred Qualifications:
1. Experience with big data technologies(e.g. Apache Hadoop, Spark, Kafka, Flink) and working with terabyte to petabyte scale data.
2. Experience with cloud data warehouses(eg. Snowflake, Databricks, BigQuery) and modern business intelligence/data stack.
3. Experience with data governance, data privacy and compliance.
4. Experience in the advertising, e-commerce or gaming industry.

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://shorturl.at/cdpT2

Job Information:

【For Pay Transparency】Compensation Description (annually)
The base salary range for this position in the selected city is CAD$ 136800- CAD$ 205000 annually.
Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.
The compensation for this position is based on a monthly compensation structure. The range specified is the expected annual compensation for a person in this position.
Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees:
We cover 100% premium coverage for employee and dependent's extended health care insurance. As well as Short/Long term Disability, Basic Life, Survivor Benefit and AD&D insurance plans.
Our time off and leave plans are: 11 paid holidays per year plus 19 days of vacation (prorated upon hire and increased by tenure) and 7 paid sick days per year as well as 13 weeks of supplemental paid maternity leave top-up and 10 weeks of Supplemental Paid Parental Leave top-up.
We also provide generous benefits such as RRSP company match, EAP, gym and cell phone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","{""role_summary"":""As a Data Engineer at TikTok, you will work closely with cross-functional teams to design, build, and optimize scalable data pipelines, ensuring data integrity and accuracy to support business growth and customer satisfaction."",""key_terms"":[{""term"":""Petabyte scale data"",""explanation"":""Refers to the massive amount of data TikTok handles, requiring robust data infrastructure and scalable data applications.""},{""term"":""Data governance"",""explanation"":""The process of managing and maintaining data assets, ensuring data quality, security, and compliance with regulations.""},{""term"":""ETL/ELT"",""explanation"":""Extract, Transform, Load/Extract, Load, Transform - techniques used to move data from one system to another, often used in data integration and data warehousing.""}],""skill_priorities"":{""must_have"":[""Strong problem-solving skills"",""SQL knowledge"",""Programming language proficiency (Python, Java, etc.)"",""Data modeling and data warehousing concepts""],""nice_to_have"":[""Experience with big data technologies (Hadoop, Spark, Kafka, Flink)"",""Cloud data warehouses (Snowflake, Databricks, BigQuery)"",""Data governance, data privacy, and compliance experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize data pipelines for better performance and scalability?"",""example_answer"":""I would analyze the current pipeline architecture, identify bottlenecks, and implement parallel processing, data caching, and query optimization techniques.""},{""question"":""How do you ensure data quality and integrity in a large-scale data environment?"",""example_answer"":""I would implement data validation checks, data quality metrics, and monitoring mechanisms to ensure data accuracy and consistency.""}],""red_flags"":[""Lack of experience with big data technologies or cloud data warehouses"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Data Developer [Scotiabank],Scotiabank,"Toronto, Ontario, Canada",June,2024,"Requisition ID: 199915

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

The Team

Automotive Finance IT support team is responsible for supporting the technology solutions implementations to drive the bank's automotive business. By joining us, you will be emersed in multiple ecosystems and you will be entraining on a journey of professional and personal development!

The Role

As a member of Automotive team, the Data Developer is responsible for operational data support and development for Automotive Finance System applications. The incumbent is responsible for providing specialized development and support work in data integration to and from Enterprise Data Lake and Data Warehouse and development work within our agile lab based on business requirements.

Champions a customer focused culture to deepen client relationships and leverage broader Bank relationships, systems, and knowledge.
Serves as a liaison between the business community and the IT organization in order to provide technical solutions to meet user needs.
Demonstrates an informed knowledge of business functions to resolve problems and capitalize on improvement opportunities.
Exercise good judgment in selecting methods and techniques for obtaining solutions.
Understand how the Bank's risk appetite and risk culture should be considered in day-to-day activities and decisions.

Is this role right for you? In this role you will:

Developing SQL queries / ETL packages using T-SQL and SSIS to ingest data from source systems to integrate with SQL Server data warehouse.
Design and develop physical data model structures in SQL Server
Design and development of high-quality dashboards / reports using tools like Power BI, SSRS, Crystal Report, Excel/PowerPivot, and Tableau. Develop custom reports, analytics and KPI's for the Business
Builds and maintain proper documentation, data lineage and extract-transform-load (ETL) processes.
Collecting business requirements / user stories while working in a lab with a product owner, Business Analyst, Scrum Master, and application developers.
Developing SQL views to enable data consumers to read data from data warehouse.
Documenting databases, data process flows and maintain data dictionaries, support and onboarding procedures.
Troubleshoot and resolve database and application defects in a timely manner with consultation with internal and external groups as needed.
Train and assist users at all levels.
Analyze root causes of operational malfunctions including but not limited to batch jobs and provide resolutions.
Analyze highly complex business requirements; generate technical specifications to design or redesign complex software components and applications.
Act as an expert technical resource in Data Warehouse/DBs and ETL
Leverage industry best practices to design, test, implement and support a solution.
Assure quality, security and compliance requirements are met for supported area.
Be flexible and thrive in an evolving environment.
Adapt to change quickly and adjust work accordingly in a positive manner.
On-call responsibilities to operate as the L2 point of contact for monitoring TIDAL/EDL jobs requests may be required for weekends rotation.

Skills

Do you have the skills that will enable you to succeed in this role? We'd love to work with you if you have:

3-5 years previous experience working within a technically focused environment as a database analyst / data developer.
Experience with databases such as Microsoft BI stack SQL Server, T-SQL, SSRS, MS SQL Enterprise Manager, MySQL, Crystal Report, Tidal jobs etc.
Experience working in an agile development team engaged in the SDLC process and SDLC methodologies (agile / waterfall).
Experience with EDL / Hadoop / Hive / Tableau a plus. Hands-on programming experience and advanced knowledge of SQL.
Expertise with data visualization / BI tools like e.g., Power BI.
Clear communication and interpersonal skills required.
Familiarity with JIRA/SharePoint
Attention to detail and feedback from clients on dashboards and reports must be completed rapidly.
Experience developing code to consume REST API services and integrating systems with sftp a plus.
Experience with MS Azure / SQL Server MI / Machine Learning services a plus.
Experience with databases, dimensional data modeling design.
Experience with data warehouse, ETL, SSIS, SSAS/cubes a must.
Experience with implementing DevOps / CIAD a plus.
Experience with web development (in ASP.NET MVC / C#) a plus.

Technical Environment

Database: SQL Server / MS SQL Enterprise Manager / Oracle
Platform: Microsoft.NET, IIS, SharePoint Online / Azure
Development Environment: Visual Studio / SSMS
Languages: T-SQL, C#, .NET, Python
Source Control: MS Team Foundation Server / Git / Bitbucket / TFS
Reporting: MS SQL Server Reporting Services, Crystal Reports, SSRS
Data Visualizations: MS PowerBI / Tableau / Excel

What's in it for you?

Diversity, Equity, Inclusion & Allyship - We strive to create an inclusive culture where every employee is empowered to reach their fullest potential, respected for who they are, and are embraced through bias-free practices and inclusive values across Scotiabank. We embrace diversity and provide opportunities for all employee to learn, grow & participate through our various Employee Resource Groups (ERGs) that span across diverse gender identities, ethnicity, race, age, ability & veterans.
Accessibility and Workplace Accommodations - We value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. Scotiabank continues to locate, remove and prevent barriers so that we can build a diverse and inclusive environment while meeting accessibility requirements.
Upskilling through online courses, cross-functional development opportunities, and tuition assistance.
Competitive Rewards program including bonus, flexible vacation, personal, sick days and benefits will start on day one.
Community Engagement - no matter where you choose to work from; we offer opportunities for community engagement & belonging with our various programs such as hackathons, contests, cooking with friends, Humans of Digital and much more!

Work arrangements: Hybrid

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here . Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","{""role_summary"":""The Data Developer is responsible for operational data support and development for Automotive Finance System applications, providing technical solutions to meet user needs, and championing a customer-focused culture."",""key_terms"":[{""term"":""Enterprise Data Lake"",""explanation"":""A centralized repository that stores all data in its raw, unprocessed form, allowing for scalability and flexibility in data analysis and reporting.""},{""term"":""Data Warehouse"",""explanation"":""A centralized repository that stores data in a structured and processed form, optimized for querying and analysis.""},{""term"":""ETL (Extract, Transform, Load)"",""explanation"":""A process of extracting data from source systems, transforming it into a standardized format, and loading it into a target system, such as a data warehouse.""},{""term"":""Agile Development"",""explanation"":""An iterative approach to software development that emphasizes collaboration, flexibility, and rapid delivery in response to changing business requirements.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development (Dev) and IT operations (Ops) to improve collaboration, automation, and speed in software delivery and deployment.""}],""skill_priorities"":{""must_have"":[""3-5 years of experience as a database analyst/data developer"",""Experience with databases such as SQL Server, T-SQL, SSRS, and MySQL"",""Experience with data visualization/BI tools like Power BI"",""Experience with data warehouse, ETL, SSIS, and SSAS/cubes""],""nice_to_have"":[""Experience with EDL/Hadoop/Hive/Tableau"",""Experience with MS Azure/SQL Server MI/Machine Learning services"",""Experience with implementing DevOps/CIAD"",""Experience with web development (in ASP.NET MVC/C#)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the difference between a data lake and a data warehouse?"",""example_answer"":""A data lake stores raw, unprocessed data, while a data warehouse stores processed and structured data optimized for analysis and reporting.""},{""question"":""How do you approach data modeling and design in a data warehouse environment?"",""example_answer"":""I follow industry best practices, considering factors such as data normalization, denormalization, and data governance to ensure data quality and integrity.""}],""red_flags"":[""Lack of experience with data visualization/BI tools"",""Inability to work in an agile development environment"",""Limited experience with data warehouse, ETL, SSIS, and SSAS/cubes""],""confidence_score"":90.0}"
Data Analyst with Python and ETL [Scotiabank],Scotiabank,"Toronto, Ontario, Canada",June,2024,"Requisition ID: 200666

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

The Team

This position belongs to a highly skilled development team that develops and supports various applications in growing Global Regulatory & Controls Technology team. The team is responsible for providing specialized analysis, design, development, and support of cost effective, mission critical, on-line, risk management and decision support systems for business users within Scotiabank IT group.

The Role

The incumbent will be responsible for supporting and building end-to-end technical solutions to support regulatory reporting of Scotia Capital Markets transactions. From root cause and business requirements analysis, aided by strong data and technical system analysis, to solutioning, development, testing, and release to production, the incumbent will ensure timely resolution of high priority Production Support tickets.
The incumbent will work closely with the broader project team, developers, scrum masters, regulatory stakeholders, trading systems, and downstream consumers to ensure high priority support tickets are resolved within SLAs with high quality. The incumbent will also be expected to develop application and business process subject matter expertise over the duration of the assignment.

Is this role right for you?

Work within a cross functional Agile team to analyse and troubleshoot technical issues and production support tickets and deliver solutions for the same.
Change request delivery – requirements gathering, design, implementation, and testing as part of new regulatory initiatives.
Support of advanced issue triage and ad-hoc data analysis and reporting
Work closely with business users and IT teams from multiple key trading systems in Canada, US, and Asia, in the design and prototyping of business solutions
Ad hoc inquiries from business stakeholders on G20 Regulatory Reporting logic (CFTC, SEC, CSA, MAS, HKMA, EMIR, UK, etc.), behaviour, and data requests
Keep current on rapidly changing technological trends, self-leaner on new technologies and maintain an understanding of the business and technology strategies.
Ability to look at a problem from both a business and technical angle.
Other projects and initiatives as required.

Do you have the skills that will enable you to succeed in this role?

Strong hands-on experience with data analysis and ETL (SQL, Python, Kafka, Jupyter, Java, XML, and JSON)
High levels of analytical, conceptual, problem solving and organizational skills
Excellent verbal and written communication skills
Attitude and willingness to learn fast, go above and beyond consistently and work independently without supervision.
Experience with Apache Kafka , Postman, ElasticSearch, Kubernetes, Airflow, and/or Linux
Ability to perform Java coding is a strong asset.
Knowledge of Capital Market products, front office trading, and back-office booking process globally.
Provide timely IT support to the enquiries from regulators in Canada and US and internal business stakeholders to meet critical timelines.
Excellent team building skills, working with diverse groups to resolve issues and identify efficiencies.
Ability to work in a project environment as required, with key deliverables and ensuring requirements of department are represented.
Strong ability to establish relationships with internal customers, as well as senior management.
A recognized degree in engineering, computer science, math, related discipline or experience

What's in it for you?

We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success!
We provide you with the tools and technology needed to create beautiful customer experiences
You'll get to work with and learn from diverse industry leaders, who have hailed from top technology companies around the world
We offer a competitive total rewards package that includes a base salary, a performance bonus, company matching programs (on pension & profit sharing), generous vacation, personal & sick days, personal development funding, maternity leave top-up, parental leave and much more.

#Python

#ETL

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here . Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","{""role_summary"":""Support and build end-to-end technical solutions for regulatory reporting of Scotia Capital Markets transactions, ensuring timely resolution of high-priority production support tickets."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load process for data analysis""},{""term"":""Kafka"",""explanation"":""Distributed streaming platform for data processing""},{""term"":""Apache Kafka"",""explanation"":""Open-source implementation of Kafka""},{""term"":""Postman"",""explanation"":""API testing and development tool""},{""term"":""ElasticSearch"",""explanation"":""Search and analytics engine for data""},{""term"":""Kubernetes"",""explanation"":""Container orchestration system for deployment""},{""term"":""Airflow"",""explanation"":""Workflow management system for data pipelines""},{""term"":""Linux"",""explanation"":""Operating system for development and deployment""},{""term"":""Java"",""explanation"":""Programming language for development""},{""term"":""XML"",""explanation"":""Markup language for data exchange""},{""term"":""JSON"",""explanation"":""Data interchange format for web applications""}],""skill_priorities"":{""must_have"":[""Strong hands-on experience with data analysis and ETL"",""High levels of analytical, conceptual, problem-solving and organizational skills"",""Excellent verbal and written communication skills""],""nice_to_have"":[""Experience with Apache Kafka, Postman, ElasticSearch, Kubernetes, Airflow, and/or Linux"",""Ability to perform Java coding"",""Knowledge of Capital Market products, front office trading, and back-office booking process globally""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach data analysis and reporting for regulatory compliance?"",""example_answer"":""I use ETL tools like SQL, Python, and Kafka to extract, transform, and load data for analysis and reporting. I ensure data quality and integrity by implementing data validation and verification processes.""},{""question"":""Can you explain your experience with Apache Kafka and its applications in regulatory reporting?"",""example_answer"":""I have hands-on experience with Apache Kafka for real-time data streaming and event-driven architecture. I've used Kafka to build scalable and fault-tolerant data pipelines for regulatory reporting.""}],""red_flags"":[""Lack of experience with data analysis and ETL tools"",""Inability to work independently without supervision"",""Limited knowledge of Capital Market products and regulatory reporting""],""confidence_score"":90.0}"
GCP Data Engineer,Zortech Solutions,"Toronto, Ontario, Canada",May,2024,"Role: GCP Data Engineer

Location: Ontario/Remote

Duration: 6-12+ Months

Job Description

As a Data Engineer, you'll focus on solving problems and creating value for business by
building solutions that are reliable and scalable to work with the size and scope of the
company. You will be tasked with creating a custom-built pipeline on GCP stack, and you
will be part of teams that implement vendor sourced enterprise software, configuring that
software, customizing it, and integrating with other internal systems.

Required Skills

5+ years of industry experience in software development, data engineering, business intelligence, or related field with experience in manipulating, processing, and extracting value from datasets.
Design, build and deploy internal applications to support our technology life cycle, collaboration and spaces, service delivery management, data and business intelligence among others.
Building Modular code for multi usable pipeline or any kind of complex Ingestion Framework used to ease the job to load the data into Datalake or Data Warehouse from multiple sources.
Work closely with analysts and business process owners to translate business requirements into technical solutions.
Coding experience in scripting and languages (YAML, Python, SQL).
Expertise in Google Cloud Platform (GCP) technologies in the data warehousing space (BigQuery, Cloud SQL, Dataflow, Data Catalog, Cloud Composer, Cloud SDK, Cloud PubSub, Google Cloud Storage, IAM, Compute Engine, Cloud Data Fusion, Dataproc, BigTable).
Maintain highest levels of development practices including: technical design, solution development, systems configuration, test documentation/execution, issue identification and resolution, writing clean, modular and self-sustaining code, with repeatable quality and predictability.
Understanding CI/CD Processes using Github, Cloud Build, Google Cloud SDK
Willing to work in ET Shift.

Qualifications

Bachelor's degree in Computer Science or related technical field, or equivalent practical experience.
GCP Certified Data Engineer (preferred)
Excellent verbal and written communication skills","{""role_summary"":""Design, build, and deploy internal applications to support technology lifecycle, collaboration, and spaces, service delivery management, data and business intelligence."",""key_terms"":[{""term"":""GCP"",""explanation"":""Google Cloud Platform, a suite of cloud computing services""},{""term"":""BigQuery"",""explanation"":""A fully-managed enterprise data warehouse for analytics""},{""term"":""Dataflow"",""explanation"":""A fully-managed service for processing and analyzing data in stream and batch modes""},{""term"":""Cloud Composer"",""explanation"":""A fully-managed workflow orchestration service to automate and manage data pipelines""},{""term"":""Cloud SDK"",""explanation"":""A set of tools for interacting with Google Cloud Platform services""},{""term"":""IAM"",""explanation"":""Identity and Access Management, a system for managing access to cloud resources""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a set of practices for automating software development and delivery""}],""skill_priorities"":{""must_have"":[""5+ years of industry experience in software development, data engineering, business intelligence, or related field"",""Experience in manipulating, processing, and extracting value from datasets"",""Coding experience in scripting and languages (YAML, Python, SQL)"",""Expertise in Google Cloud Platform (GCP) technologies in the data warehousing space""],""nice_to_have"":[""GCP Certified Data Engineer"",""Experience with CI/CD processes using Github, Cloud Build""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design a scalable data pipeline for a large-scale enterprise?"",""example_answer"":""I would use GCP's BigQuery and Dataflow to create a scalable data pipeline, and ensure data quality by implementing data validation and data quality checks.""},{""question"":""How do you stay up-to-date with the latest developments in GCP technologies?"",""example_answer"":""I regularly check the GCP blog and documentation, and participate in online communities and forums to stay current.""}],""red_flags"":[""Lack of experience with GCP technologies"",""Inability to work in ET Shift""],""confidence_score"":90.0}"
Data Engineer I,TD,"Toronto, Ontario, Canada",March,2025,"Work Location:

Toronto, Ontario, Canada

Hours:

37.5

Line Of Business:

Technology Solutions

Pay Details:

$65,600 - $98,400 CAD

TD is committed to providing fair and equitable compensation opportunities to all colleagues. Growth opportunities and skill development are defining features of the colleague experience at TD. Our compensation policies and practices have been designed to allow colleagues to progress through the salary range over time as they progress in their role. The base pay actually offered may vary based upon the candidate's skills and experience, job-related knowledge, geographic location, and other specific business and organizational needs.

As a candidate, you are encouraged to ask compensation related questions and have an open dialogue with your recruiter who can provide you more specific details for this role.

Job Description:

About the Team

Data as a Service (DaaS) is an enterprise-wide data management improvement initiative that brings business data and technology resources together to maximize customer and colleague benefit.

The DaaS Practice is comprised of a group of highly skilled Subject Matter Experts (SME) who are focused on the delivery of specialized work including building data pipelines, supporting data science needs, driving data automation, creating and implementing data & analytics platforms.

Job Description

We are seeking highly motivated and capable technologists to join our Data as a Services team to work on the forefront of enabling TD's big data strategy with a special focus on ETL/data curation on on-cloud Azure Platform.

Across multiple large-scale transformation programs and in a data management context, reporting to the engineering manager, the data engineer will lead team members to develop ETL processes, design and build data stores and transformations on Azure platform, coordinate team member's work into an integrated high quality product.

As a Data Engineer, You Will:

Design and develop ETL processes based on functional and non-functional requirements in python / pyspark within Azure platform.
Recommend and execute improvements.
Execute and provide support during testing cycles and post-production deployment, engage in peer code reviews.
Apply automation and innovation on new and on-going data platforms that aligned to business strategies.
Understand the full end to end development activities from design to go live for ETL development in Azure platform.
Document component design for developers and for broader communication.
Understand and adopt an Agile (SCRUM like) software development mindset
Follow established processes/standards, business technology architecture for development, release management and deployment process.
Design, develop and implement reporting platforms and complex ETL frameworks that meet business requirements.
Provide data analysis and requirements within enterprise platform.
Develop, maintain knowledge of data available from upstream sources and data within various platforms.

Job Requirements

Undergraduate Degree or Technical Certificate.
2-3 years relevant design and development experience.
Working experience for the following:
Azure platform and tools like Azure Data Factory, Azure Databricks, Synapse
Python, Pyspark, Spark
Data Flow Processes
SQL Development
ETL
Working experience with data modeling, relational modeling and dimensional modeling.
Working knowledge of source code control tool such as GIT
Implementation experience in managing and working in multiple environments, release and change management and knowledge of firewall, network work protocols, file transfer – TIBCO
Familiar with Agile development methodologies
Readiness and motivation (as an experienced developer and subject matter expert) to address and resolve complex issues, guide/advise/support clients, partners and project teams, often working on multiple medium-to-large sized projects.
Commitment to and belief in the quality of your deliverables.
Capacity and eagerness to work independently as a senior/lead role on multiple tasks and also coach/educate/guide/direct others.
Ability to assume assignments that are moderate- to highly- complex and multi-faceted, to be performed under management guidance.
Innovative, problem-solving and critical thinking - asking the right questions, taking calculated risks.
Teamwork and collaboration strengths - ability to network, get involved and learn the organization culture and values.
Communication skills - ability to articulate impactfully and through the correct means.
Who We Are:

TD is one of the world's leading global financial institutions and is the fifth largest bank in North America by branches/stores. Every day, we deliver legendary customer experiences to over 27 million households and businesses in Canada, the United States and around the world. More than 95,000 TD colleagues bring their skills, talent, and creativity to the Bank, those we serve, and the economies we support. We are guided by our vision to Be the Better Bank and our purpose to enrich the lives of our customers, communities and colleagues.

TD is deeply committed to being a leader in customer experience, that is why we believe that all colleagues, no matter where they work, are customer facing. As we build our business and deliver on our strategy, we are innovating to enhance the customer experience and build capabilities to shape the future of banking. Whether you’ve got years of banking experience or are just starting your career in financial services, we can help you realize your potential. Through regular leadership and development conversations to mentorship and training programs, we’re here to support you towards your goals. As an organization, we keep growing – and so will you.

Our Total Rewards Package

Our Total Rewards package reflects the investments we make in our colleagues to help them and their families achieve their financial, physical, and mental well-being goals. Total Rewards at TD includes a base salary, variable compensation, and several other key plans such as health and well-being benefits, savings and retirement programs, paid time off, banking benefits and discounts, career development, and reward and recognition programs. Learn more

Additional Information:

We’re delighted that you’re considering building a career with TD. Through regular development conversations, training programs, and a competitive benefits plan, we’re committed to providing the support our colleagues need to thrive both at work and at home.

Please be advised that this job opportunity is subject to provincial regulation for employment purposes. It is imperative to acknowledge that each province or territory within the jurisdiction of Canada may have its own set of regulations, requirements.

Colleague Development

If you’re interested in a specific career path or are looking to build certain skills, we want to help you succeed. You’ll have regular career, development, and performance conversations with your manager, as well as access to an online learning platform and a variety of mentoring programs to help you unlock future opportunities. Whether you have a passion for helping customers and want to expand your experience, or you want to coach and inspire your colleagues, there are many different career paths within our organization at TD – and we’re committed to helping you identify opportunities that support your goals.

Training & Onboarding

We will provide training and onboarding sessions to ensure that you’ve got everything you need to succeed in your new role.

Interview Process

We’ll reach out to candidates of interest to schedule an interview. We do our best to communicate outcomes to all applicants by email or phone call.

Accommodation

Your accessibility is important to us. Please let us know if you’d like accommodations (including accessible meeting rooms, captioning for virtual interviews, etc.) to help us remove barriers so that you can participate throughout the interview process.

We look forward to hearing from you!

Language Requirement (Quebec Only):

Sans Objet","{""role_summary"":""Design and develop ETL processes, lead team members, and coordinate work into an integrated high-quality product as a Data Engineer in the Data as a Service team, focusing on ETL/data curation on the on-cloud Azure Platform."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Azure Platform"",""explanation"":""A cloud computing platform and set of services offered by Microsoft, used for building, deploying, and managing applications and services.""},{""term"":""Data as a Service (DaaS)"",""explanation"":""A data management model where data is provided on-demand to users, regardless of geographical location or organizational boundaries.""},{""term"":""Pyspark"",""explanation"":""A Python library for Apache Spark, used for large-scale data processing and machine learning tasks.""},{""term"":""Agile (SCRUM like) software development mindset"",""explanation"":""An iterative approach to project management and software development, emphasizing flexibility and continuous improvement.""}],""skill_priorities"":{""must_have"":[""Azure platform and tools like Azure Data Factory, Azure Databricks, Synapse"",""Python, Pyspark, Spark"",""Data Flow Processes"",""SQL Development"",""ETL"",""Working knowledge of source code control tool such as GIT"",""Implementation experience in managing and working in multiple environments, release and change management and knowledge of firewall, network work protocols, file transfer – TIBCO"",""Familiar with Agile development methodologies""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with ETL processes and data curation on the Azure Platform?"",""example_answer"":""I have worked on multiple projects involving ETL processes using Azure Data Factory, and I'm familiar with data curation principles and best practices.""},{""question"":""How do you approach data modeling and relational modeling in your work?"",""example_answer"":""I follow a structured approach to modeling, using techniques like dimensional modeling and data warehousing to ensure data quality and integrity.""}],""red_flags"":[""Lack of experience with Azure platform and tools"",""Inadequate understanding of ETL processes and data modeling concepts""],""confidence_score"":85.0}"
DATA ENGINEER,Atos,"Windsor, Ontario, Canada",March,2025,"Eviden, part of the Atos Group, with an annual revenue of circa € 5 billion is a global leader in data-driven, trusted and sustainable digital transformation. As a next generation digital business with worldwide leading positions in digital, cloud, data, advanced computing and security, it brings deep expertise for all industries in more than 47 countries. By uniting unique high-end technologies across the full digital continuum with 47,000 world-class talents, Eviden expands the possibilities of data and technology, now and for generations to come.

Role Azure Data Engineer

Location Toronto, ON

Fulltime with Eviden

Job Description

Must Have – Azure Data Bricks, Azure Data Factory, Spark SQL with analytical knowledge.

4-5 Years Of Development Experience In Data Engineering Skills.

Strong experience in Spark.

Understand complex data system by working closely with engineering and product teams.

Develop scalable and maintainable applications to extract, transform, and load data in various formats to SQL Server, Hadoop Data Lake or other data storage locations.



Let’s grow together.","{""role_summary"":""Design and develop scalable data applications to extract, transform, and load data in various formats, working closely with engineering and product teams."",""key_terms"":[{""term"":""Azure Data Bricks"",""explanation"":""A cloud-based analytics platform for data engineering and data science""},{""term"":""Azure Data Factory"",""explanation"":""A cloud-based data integration service for creating, managing, and scheduling data pipelines""},{""term"":""Spark SQL"",""explanation"":""A unified analytics engine for large-scale data processing""},{""term"":""Hadoop Data Lake"",""explanation"":""A storage repository that holds a vast amount of raw, unprocessed data in its native format""}],""skill_priorities"":{""must_have"":[""Azure Data Bricks"",""Azure Data Factory"",""Spark SQL"",""Data Engineering Skills""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data processing in Spark for large-scale datasets?"",""example_answer"":""I use techniques like data partitioning, caching, and parallel processing to optimize Spark performance.""},{""question"":""Can you explain the concept of data lakes in Hadoop?"",""example_answer"":""A data lake is a centralized repository that stores raw, unprocessed data in its native format, allowing for flexible data processing and analysis.""}],""red_flags"":[""Lack of experience with Azure Data Bricks and Azure Data Factory"",""Inability to work with complex data systems""],""confidence_score"":90.0}"
Data Engineer (Finance),KOHO,Canada,March,2025,"About KOHO

KOHO’s purpose is to empower Canadians to build a great financial foundation with products that are radically transparent and easy to manage. We first launched in 2017, and we have since built a community of over 1.5 million users. Leading investors around the globe believe in our vision, and we’ve successfully raised over $320M to make our vision a reality.

Discover our culture here and get the inside scoop from our team here!

Ready to Shape the Future of FinTech? 🚀

We’re seeking a Senior Analytics Engineer to help lead the future of financial analytics at KOHO. This is your opportunity to make a significant impact at the intersection of finance, technology, and analytics!

As a key player in our high-performing analytics engineering team, you’ll act as the direct intermediate between the data and finance teams to collect requirements, prioritize requests, build data products, communicate insights, and influence decisions. You'll have the unique opportunity to influence strategic decisions across the entire organization while working specifically with our finance domain. Your work will directly impact how KOHO operates, grows, and innovates in the FinTech space.

Impact & Influence 💫

Inform data-driven decision-making across multiple business units
Shape the future of financial analytics at a rapidly growing FinTech leader
Be the bridge between technical excellence and business success
Influence company strategy through powerful data insights

Your Mission 🎯

You'll revolutionize how KOHO leverages data to make strategic decisions. You'll be the driving force behind:

Building strong relationships with stakeholders (the finance team), scope and prioritize their analytics requests.
Understanding business needs and translating them to requirements.
Using dbt (Core for development and Cloud for orchestration) to transform, test, deploy, and document financial data while applying software engineering best practices.
Troubleshooting variances in reports, and striving to eliminate them at the source.
Building game-changing data products that empower the finance team
Architecting solutions that transform complex financial data into actionable insights
Monitoring, optimizing and troubleshooting warehouse performance (AWS Redshift).
Creating scalable, self-service analytics solutions that democratize data access
Occasionally building dashboards and reports in Sigma and Drivetrain.
Defining processes, building tools, and offering training to empower all data users in the organization.

Technical Excellence You'll Bring 💡

5+ years of mastery in data manipulation and analytics architecture
Advanced expertise in dbt (incremental modeling, materializations, snapshots, variables, macros, jinja)
Strong knowledge of SQL and how to write efficient SQL queries
Strong command of SQL, query optimization, and data warehouse design
Finance/accounting background is a plus!

What Sets You Apart 🌟

You're a natural problem-solver who thrives in complex environments
You have exceptional communication skills and can translate technical concepts for any audience
You're passionate about automation and continuous improvement
You have a track record of building strong stakeholder relationships

The KOHO Analytics Engineering Vision 🔮

We're Building The Future Of Data Accessibility And Reliability. Our Mission Is To Deliver a Unified Source Of Truth That Empowers Every Team Member To Make Data-driven Decisions. We Value

Enablement over control
Scalability over quick fixes
Agility over perfection

Ready to Transform Financial Analytics?

Join us in revolutionizing how financial data drives business success. Your expertise will directly impact millions of users while working with cutting-edge technologies in a dynamic, fast-paced environment.

What's In It For You?

We Invest Time And Resources Into Making Sure KOHO Is As Good As The People We Hire. Here Are Some Of The Reasons We Attract The Best People

🧘‍♂️ Balance Your Life - Company-wide summer wellness days, winter holiday closure, personal days, a wellness spending account, and maternity & parental leave top-up

💻 Remote First - Work from anywhere in Canada with a budget to set up your home office

🆙 Level Up - Access to an in-house certified performance coach and an annual training budget

🙌 The KOHO Culture - We have won 7 ""Great Place to Work ®"" awards since 2019

🤝 Be an Owner - Every KOHO employee gets a generous amount of equity with a 10 year exercise window

The KOHO culture is one of collaboration, creativity, and diverse perspectives. We are committed to building and fostering an inclusive, accessible environment for everyone. If you have any questions, concerns, or requests regarding accessibility needs, please contact peopleaccessibility@koho.ca and the People and Culture team will be happy to help.","{""role_summary"":""Lead the future of financial analytics at KOHO, acting as a bridge between the data and finance teams to collect requirements, prioritize requests, build data products, communicate insights, and influence decisions."",""key_terms"":[{""term"":""dbt"",""explanation"":""A data transformation tool for building data products and applying software engineering best practices.""},{""term"":""FinTech"",""explanation"":""Financial Technology, referring to the intersection of finance, technology, and analytics.""},{""term"":""AWS Redshift"",""explanation"":""A cloud-based data warehousing and analytics platform for monitoring, optimizing, and troubleshooting warehouse performance.""}],""skill_priorities"":{""must_have"":[""5+ years of mastery in data manipulation and analytics architecture"",""Advanced expertise in dbt"",""Strong knowledge of SQL and query optimization""],""nice_to_have"":[""Finance/accounting background"",""Passion for automation and continuous improvement""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach building strong relationships with stakeholders in a high-performing analytics engineering team?"",""example_answer"":""I prioritize active listening, clear communication, and empathy to understand their needs and requirements, ensuring that I deliver data products that meet their expectations.""},{""question"":""Can you give an example of how you've applied software engineering best practices to transform, test, deploy, and document financial data?"",""example_answer"":""In my previous role, I used dbt to build a data product that automated report generation, reducing manual effort by 80% and increasing data accuracy by 95%.""}],""red_flags"":[""Lack of experience with dbt or similar data transformation tools"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":95.0}"
Data Developer,Astek,"Toronto, Ontario, Canada",March,2025,"Job Offer: Data Developer
Location: Toronto
Contract Duration: 7 months
Work Mode: Hybrid
Start Date: March 10th

Why Join Us?

Astek is a global leader in technology consulting. With 9,600 experts worldwide, we guide our clients through digital transformation by developing innovative solutions.

In Canada, we excel in IT and engineering. We collaborate with leading companies to tackle major technological challenges, putting innovation, collaboration, and excellence at the heart of our actions.

Join a passionate and committed team ready to bring your ideas to life.

About the Role

On behalf of our client in the Banking industry, Astek Canada is seeking a motivated Data Developer ready to take on new challenges.

Your Responsibilities

As a Data Developer , you will be responsible for:
Support existing production tools used in operations and delivery, while working with business partners and our delivery teams on the creation of new process improvement tools.
Support the ideation, development, deployment and governance of new tools, processes and workflows that support our production teams.
Adopt Agile methodologies, enabling us to rapidly and efficiently deploy new tools that exceed our business partners' expectations.

Your Qualifications

Education/Experience:
Computer Science Degree.
2 - 4 Years' experience.

Key Skills:
Experience working as a Developer with Html/CSS and JavaScript coding with the ability to code with good quality (Need to be able to Code/update code/code from scratch).
Advanced knowledge of Visual Basic, MS Access, and MS Excel.
Knowledgeable in using built-in browser dev tools to understand web site API methods.
Advanced knowledge of SQL and experience working with SQL Databases.
Strong communication and stakeholder management skills are an asset.
Experience working in an Agile operating model using JIRA/Confluence would be beneficial.

Personal Qualities:
Analytical and solution-oriented mindset.
Team collaboration and teamwork skills.
Autonomy and rigor in managing priorities.

The Astek Advantages
Personalized CARE plan for our employees.
Diversity & Inclusion Charter.

Ready to Take on the Challenge?
Apply now by sending your CV and discover a rewarding career at Astek Canada.","{""role_summary"":""Support and develop production tools and processes to improve operations and delivery, working closely with business partners and delivery teams."",""key_terms"":[{""term"":""Agile methodologies"",""explanation"":""A project management approach that emphasizes flexibility, collaboration to deliver projects quickly and efficiently.""},{""term"":""Html/CSS and JavaScript"",""explanation"":""Programming languages used to build websites and web applications.""},{""term"":""Visual Basic, MS Access, and MS Excel"",""explanation"":""Software applications used for building business applications, data analysis, and reporting.""},{""term"":""SQL Databases"",""explanation"":""A type of database that stores and retrieves data using structured queries.""},{""term"":""JIRA/Confluence"",""explanation"":""Project management tools used to track and manage projects, and collaborate with team members.""}],""skill_priorities"":{""must_have"":[""Html/CSS and JavaScript"",""Advanced knowledge of SQL and experience working with SQL Databases"",""Experience working as a Developer""],""nice_to_have"":[""Experience working in an Agile operating model using JIRA/Confluence"",""Strong communication and stakeholder management skills""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach improving the efficiency of a production tool using Agile methodologies?"",""example_answer"":""I would work closely with the business partners and delivery teams to identify areas of improvement, and then prioritize and implement changes using Agile principles.""},{""question"":""How do you stay up-to-date with the latest developments in Html/CSS and JavaScript?"",""example_answer"":""I regularly follow industry blogs and online forums, and participate in online courses to stay current with the latest developments.""}],""red_flags"":[""Lack of experience working with SQL Databases"",""Inability to code with good quality""],""confidence_score"":85.0}"
Intern - Data Engineer,"Tilray Brands, Inc.","Leamington, Ontario, Canada",March,2025,"(Leamington, ON)

Summer 2025 Internship

On-Site: 5 days/week

Full-time. Paid Internship

Duration: June - August 2025

About Tilray Brands, Inc.

Tilray Brands, Inc. (“Tilray”) (Nasdaq: TLRY; TSX: TLRY), is a leading global lifestyle and consumer packaged goods company with operations in Canada, the United States, Europe, Australia, and Latin America that is leading as a transformative force at the nexus of cannabis, beverage, wellness, and entertainment, elevating lives through moments of connection. Tilray’s mission is to be a leading premium lifestyle company with a house of brands and innovative products that inspire joy, wellness and create memorable experiences. Tilray’s unprecedented platform supports over 40 brands in over 20 countries, including comprehensive cannabis offerings, hemp-based foods, and craft beverages.

Looking to develop your career at the forefront of a rapidly expanding industry?

JOB SUMMARY:

The Intern - Data Engineer is responsible for preparing and cleansing data for analytics and machine learning operations around the company, while maintaining standards for accuracy and scalability required for a global enterprise.

This is a great 3-month paid internship opportunity for third or fourth-year students, as well as new graduates looking for real-world experience. As a candidate for this role, you are passionate about learning new technologies and implementing systems that unlock data for various stakeholders across the business. You are a self-starter who enjoys collaborating within a communicative and enthusiastic technical team. You are also personable and able to engage non-technical stakeholders with exciting technical solutions.

Work Schedule: Monday - Friday / 8:30am - 5:00pm

ROLE AND RESPONSIBILITIES:

Assist in the deployment of ETL and ELT data pipelines in an Azure environment
Build and design Data Warehouse tables which fit stakeholder needs in a computationally efficient manner
Quickly troubleshoot and remediate errors due to source data changes
Engage with stakeholders to gather requirements, and translate their needs into concrete, technically sound solutions
Properly document and outline changes for an enterprise IT environment
Coding complex transformations using programming languages like Python
Maintaining and improving scripts and libraries used for data processing and delivery


QUALIFICATIONS AND EDUCATION REQUIREMENTS:

Ability to write and troubleshoot SQL queries
Moderate knowledge of Python, and some familiarity with the major data processing libraries like pandas, polars, and pyspark
Familiarity with software engineering techniques and practices such as unit testing, CI/CD pipelines, containerized environments, and version control
Knowledge of cloud environments like Azure and AWS an asset
Excellent problem-solving skills.
Ability to help solve problems and develop solutions while working with stakeholders around the business


Accommodations are available for applicants with disabilities throughout the recruitment process. If you require accommodations for interviews or other meetings, please advise when submitting your application.

Please note that Tilray does not authorize, engage, or sponsor any consultants, agencies or organizations that seek certain personal or financial information from you (e.g. passwords, login ids, credit card information). Tilray does not charge any application, processing or onboarding fee at any stage of the recruitment or hiring process.

When replying to emails, please ensure the sender name and email address match exactly. Please also ensure the Reply-To address matches the sending address exactly.

If you are concerned about the authenticity of an email, letter, or call purportedly from, for, or on behalf of Tilray, please send an email inquiry to infosec@tilray.com","{""role_summary"":""Assist in preparing and cleansing data for analytics and machine learning operations, maintaining standards for accuracy and scalability required for a global enterprise."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from multiple sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""ELT"",""explanation"":""Extract, Load, Transform - a variation of ETL where data is loaded into a target system and then transformed.""},{""term"":""Azure"",""explanation"":""A cloud computing platform and set of services offered by Microsoft.""},{""term"":""pandas"",""explanation"":""A popular Python library for data manipulation and analysis.""},{""term"":""pyspark"",""explanation"":""A Python library for big data processing that provides high-level APIs in Python and R.""},{""term"":""CI/CD pipelines"",""explanation"":""Continuous Integration and Continuous Deployment pipelines - a set of practices that automate testing, building, and deployment of software.""}],""skill_priorities"":{""must_have"":[""Ability to write and troubleshoot SQL queries"",""Moderate knowledge of Python"",""Familiarity with software engineering techniques and practices""],""nice_to_have"":[""Knowledge of cloud environments like Azure and AWS"",""Familiarity with major data processing libraries like pandas, polars, and pyspark""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the difference between ETL and ELT data pipelines?"",""example_answer"":""ETL stands for Extract, Transform, Load, whereas ELT stands for Extract, Load, Transform. The key difference lies in when the data is transformed.""},{""question"":""How would you troubleshoot errors due to source data changes in an Azure environment?"",""example_answer"":""I would use Azure's built-in logging and monitoring tools to identify the issue, then work with stakeholders to understand the root cause and implement a solution.""}],""red_flags"":[""Lack of experience with cloud environments like Azure and AWS"",""Inability to write and troubleshoot SQL queries""],""confidence_score"":90.0}"
AI Software Engineer Graduate,TrustFlight,"Vancouver, British Columbia, Canada",March,2025,"About Us

TrustFlight is an innovative aviation software company that specializes in developing cutting-edge digital workflow and analytics applications for the aviation industry. Our software empowers airlines, airports, and aviation service providers to optimize their operations, enhance safety, and improve overall efficiency. As we continue to expand our global presence, we are looking for an AI Process Graduate to join our dynamic team and contribute to the growing AI efforts within the organization.

Why Choose TrustFlight?

Our Mission: To revolutionize aviation by delivering digital workflow solutions that enhance safety, streamline operations, and inspire confidence across the industry.
Impact: Over 200,000 users rely on our systems daily, making aviation safer and more efficient.
Core Values: Guided by integrity, responsibility, innovation, and excellence, we are committed to empowering our partners to operate with confidence.


Join us in shaping the future of aviation and making an impact through technology.✈️

Locations: Jersey | Leamington Spa | Luton | Vancouver

Role Overview

As an AI Software Engineer Graduate at TrustFlight you will play a pivotal role in transforming our internal processes and automations. Your work will involve implementing, developing, and optimizing AI solutions to augment our digital workflows, and collaborating closely across our Sales Ops and Finance teams to ensure seamless integration of AI technologies into our existing systems. We value each member's input and believe in harnessing the power of collective intelligence, with each team members contribution playing a crucial role in our success. Working with us means working at the forefront of technology. With AI being central to our innovation strategy, we're invested in staying ahead of the curve. Here, you won't be maintaining the status quo; you'll be pushing it forward. Your work will directly contribute to our AI-driven solutions, which are set to revolutionize the way the aviation industry operates. The scale of the impact we strive to make offers an unparalleled opportunity to apply your skills in a context that matters, making your work rewarding and purposeful. Come join us, and let's shape the future of aviation together.

Key Responsibilities:

Integrating AI to transform and scale our internal business processes
Implementing and contributing to the ongoing development of AI solutions.
Optimizing and maximizing AI tools to increase workflow efficiency.
Collaborate with cross-functional teams to embed AI-driven solutions across the organization.
Leveraging weekly advancements in AI to increase the scope of integration.


Qualifications:

Bachelor’s degree in Computer Science, Software Engineering, or a related field.
Proficiency in JavaScript/TypeScript and familiarity with Python.
Hands-on experience with OpenAI and Anthropic APIs, specifically GPT-4 and Claude 3.
Experience with GPT-4/Claude 3 function-calling and integration in large scale applications.
Track record of developing and deploying applications leveraging OpenAI/Anthropic APIs.
Experience working with embeddings, vector databases and similarity search.
Experience working with, fine-tuning and deploying the infrastructure to integrate open source LLMs.
Strong communication and interpersonal skills.
Ability to work independently and as part of a team.
Ability to work seamlessly across teams.
Familiarity with React and NextJS.
Experience with CRM or ERP systems is a bonus


Why Join Us:

Opportunity to shape the revenue processes within a leading SaaS company.
Hands-on experience with cutting-edge technology and automation.
Collaborative and innovative work environment.
Health & Wellness: Comprehensive benefits package including health and dental benefits. Generous vacation days, plus an extra day off to celebrate your birthday.
Invest in your future: Take advantage of our RRSP matching program to grow your savings while you work.
Professional Growth: As a fast-growing company, we offer incredible opportunities for career advancement and skill development.
We place huge importance on the contribution and experience you bring to the team. The salary will be based on the value you will bring to the role with a range spanning from $63000 to $65000 CAD per year. The actual base pay offered will be based on a wide range of factors, including skills, qualifications, relevant experience, and work location.


How To Apply

Send us your resume, including a cover letter. Let us know how you can contribute to creating best-in-class tools and services throughout the aviation industry.

While we sincerely appreciate all applications, only those candidates selected for an interview will be contacted.

TrustFlight is an equal-opportunity employer. We work together to create the most talented team that celebrates inclusivity, diversity and equality in a serious way. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. All candidates will receive consideration for this role without regard for race, nationality, colour, religion, gender, gender identity and expression, sexual orientation, disability, or age. Our inclusive culture empowers all of us to inspire, enlighten and thrive.","{""role_summary"":""Transform internal processes and automations by implementing, developing, and optimizing AI solutions to augment digital workflows, collaborating with cross-functional teams to ensure seamless integration of AI technologies."",""key_terms"":[{""term"":""AI Process Graduate"",""explanation"":""A role that contributes to the growing AI efforts within the organization, implementing and developing AI solutions to transform internal processes and automations.""},{""term"":""OpenAI and Anthropic APIs"",""explanation"":""Specifically GPT-4 and Claude 3, used for integrating AI to transform and scale internal business processes.""},{""term"":""GPT-4/Claude 3 function-calling and integration in large scale applications"",""explanation"":""Experience with calling and integrating GPT-4/Claude 3 in large-scale applications to increase workflow efficiency.""},{""term"":""Embeddings, vector databases and similarity search"",""explanation"":""Experience working with these concepts to optimize and maximize AI tools for increasing workflow efficiency.""},{""term"":""Fine-tuning and deploying the infrastructure to integrate open source LLMs"",""explanation"":""Experience with fine-tuning and deploying infrastructure for open source LLMs to increase the scope of integration.""}],""skill_priorities"":{""must_have"":[""JavaScript/TypeScript"",""Python"",""Hands-on experience with OpenAI and Anthropic APIs"",""Experience with GPT-4/Claude 3 function-calling and integration in large scale applications"",""Strong communication and interpersonal skills""],""nice_to_have"":[""Familiarity with React and NextJS"",""Experience with CRM or ERP systems""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would integrate AI to transform and scale internal business processes?"",""example_answer"":""I would leverage OpenAI and Anthropic APIs, specifically GPT-4 and Claude 3, to develop and deploy AI solutions that increase workflow efficiency and optimize internal processes.""},{""question"":""How do you stay updated with weekly advancements in AI to increase the scope of integration?"",""example_answer"":""I regularly follow industry blogs, attend conferences, and participate in online forums to stay current with advancements in AI and its applications.""}],""red_flags"":[""Lack of hands-on experience with OpenAI and Anthropic APIs"",""Inability to work independently and as part of a team""],""confidence_score"":90.0}"
Sr. Data Engineer - Data & AI Platform,Rivian,"Vancouver, British Columbia, Canada",March,2025,"Rivian and Volkswagen Group Technologies is seeking a Data Engineer to join our Data & AI team. This role is pivotal in enabling our big data platform to operate seamlessly at a petabyte scale. The successful candidate will be an architect and custodian of scalable, high-volume vehicle data processing pipelines written in Pyspark and executed on our Databricks platform.
 PySpark Pipeline Development: Design, develop, deploy, and enhance petabyte-scale Spark structured streaming pipelines using Pyspark on Databricks. 
Databricks Platform Ownership: Understand the intricacies of the Databricks Platform, manage our Databricks deployment using Terraform infrastructure as code, and possess a firm grasp of data governance concepts. 
CI/CD & Infrastructure Management: Take ownership of the pipeline deployment lifecycle. Implement and manage robust CI/CD pipelines using Terraform to ensure smooth, automated, and reliable deployments.
Performance Optimization: Monitor pipeline performance, identify bottlenecks, and implement optimizations to ensure they operate at peak efficiency even as data volumes grow.
Troubleshooting & Issue Resolution: Proactively identify and resolve issues that may arise. The ability to diagnose problems quickly and implement effective solutions will be critical to maintaining system uptime.
Collaborative Development: Collaborate with data producers, data consumers, and data stewards to deliver dependable and scalable solutions.
Staying Ahead of the Curve: Keep abreast of the latest advancements in big data technologies, data engineering practices, and cloud computing. Explore new tools and techniques to improve our data infrastructure.
 Education: Bachelor's or Master's degree in Computer Science, Data Science, or a related field.
Experience: 5+ years of hands-on experience in data engineering or a similar role, with a proven track record of building and maintaining large-scale data processing systems.
Spark Expertise: Deep proficiency in the Apache Spark data engineering engine, with a strong understanding of best practices for building high-performance applications. Proficiency with structured streaming preferred. 
Big Data Technologies: Solid understanding of big data ecosystems such as Databricks. Experience with data warehousing and data lake concepts is a plus.
Problem-Solving Skills: Exceptional analytical and problem-solving skills, with the ability to break down complex problems into manageable components and develop effective solutions.
Communication & Collaboration: Excellent communication and interpersonal skills, with the ability to collaborate effectively with cross-functional teams
Delta Lake: Familiarity interacting with open source or Databricks proprietary Delta tables.","{""role_summary"":""Design, develop, and maintain large-scale data processing pipelines and platforms, ensuring seamless operation and peak efficiency."",""key_terms"":[{""term"":""Pyspark"",""explanation"":""A Python library for Apache Spark, used for big data processing.""},{""term"":""Databricks"",""explanation"":""A cloud-based platform for working with big data and Apache Spark.""},{""term"":""Terraform"",""explanation"":""An infrastructure as code tool for managing cloud infrastructure.""},{""term"":""Delta Lake"",""explanation"":""An open-source storage layer for data lakes, providing ACID transactions.""}],""skill_priorities"":{""must_have"":[""Apache Spark"",""Pyspark"",""Databricks"",""Data engineering"",""Problem-solving skills"",""Communication and collaboration skills""],""nice_to_have"":[""Terraform"",""Data warehousing"",""Data lake concepts"",""Delta Lake""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize the performance of a PySpark pipeline on Databricks?"",""example_answer"":""I would monitor pipeline performance, identify bottlenecks, and implement optimizations using techniques like caching, parallel processing, and data partitioning.""},{""question"":""Can you explain the concept of structured streaming in Apache Spark?"",""example_answer"":""Structured streaming is a scalable and fault-tolerant stream processing engine built on the Spark SQL engine, allowing for real-time data processing and event-time processing.""}],""red_flags"":[""Lack of hands-on experience with Apache Spark and PySpark"",""Inability to explain data governance concepts"",""No experience with Databricks or similar big data platforms""],""confidence_score"":95.0}"
Data Engineer - Contract,hireVouch,Canada,March,2025,"Our client is a leading data and cloud services provider that works with enterprise companies to build systems and infrastructures for them.

As a Data Engineer, you'd be responsible for designing, building, and optimizing data pipelines, ensuring seamless data flow and analytics capabilities.

This is a 6-month contract, with a possibility of extension.

Responsibilities:

Develop and maintain scalable data pipelines using Python and SQL.
Design and implement ETL processes for efficient data ingestion, transformation, and storage.
Work extensively with AWS SageMaker to develop, train, and deploy machine learning models.
Optimize data storage, retrieval, and performance in AWS Redshift.
Collaborate with data scientists, analysts, and software engineers to provide data solutions.
Ensure data integrity, quality, and governance across various platforms.
Automate data workflows and deployment processes.
Troubleshoot and resolve data issues efficiently.

Requirements:

3+ years of experience in data engineering.
Strong proficiency in Python and SQL.
Hands-on experience with AWS SageMaker (model training, deployment, and management).
Expertise in AWS Redshift (performance tuning, data modeling, and query optimization).
Experience working with ETL processes, data lakes, and data warehousing solutions.
Knowledge of cloud infrastructure (AWS Lambda, S3, Glue, Step Functions, etc.).
Familiarity with CI/CD pipelines and infrastructure as code (Terraform, CloudFormation) is a plus.
Strong problem-solving skills and the ability to work independently in a contract-based role.","{""role_summary"":""Design, build, and optimize data pipelines to ensure seamless data flow and analytics capabilities, working closely with data scientists, analysts, and software engineers."",""key_terms"":[{""term"":""ETL processes"",""explanation"":""Extract, Transform, Load processes for efficient data ingestion, storage, and transformation.""},{""term"":""AWS SageMaker"",""explanation"":""A cloud-based machine learning platform for developing, training, and deploying models.""},{""term"":""AWS Redshift"",""explanation"":""A data warehousing and analytics platform for storing and processing large datasets.""},{""term"":""CI/CD pipelines"",""explanation"":""Continuous Integration and Continuous Deployment pipelines for automating software development and deployment.""},{""term"":""Infrastructure as code"",""explanation"":""Managing and provisioning cloud infrastructure using code, such as Terraform or CloudFormation.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""AWS SageMaker"",""AWS Redshift"",""ETL processes"",""cloud infrastructure""],""nice_to_have"":[""CI/CD pipelines"",""Infrastructure as code""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize data storage and retrieval in AWS Redshift?"",""example_answer"":""I use techniques like data compression, distribution, and sorting to improve query performance and reduce storage costs.""},{""question"":""Can you explain your experience with ETL processes and data warehousing solutions?"",""example_answer"":""I've worked with ETL tools like Informatica and targets like Amazon Redshift, designing and implementing data pipelines for efficient data ingestion and analytics.""}],""red_flags"":[""Lack of hands-on experience with AWS SageMaker"",""Inability to work independently in a contract-based role""],""confidence_score"":90.0}"
Data engineer,Ministerie van Binnenlandse Zaken en Koninkrijksrelaties,"Piikani 147, Alberta, Canada",March,2025,"Functie­omschrijving

Wil jij ons helpen bij de verdere doorontwikkeling van ons eigen datawarehouse bij ODC Noord? En wil jij werken in een gedreven, gezellig en warm team? Lees dan snel verder en reageer!

De ontwikkeling van een datawarehouse is een teamsport. Als data engineer werk je samen met data-analisten, data scientists en businessanalisten aan het standaardiseren en optimaliseren van data exchange processen. Dit doe je binnen (een nog in ontwikkeling zijnde) analyse omgeving. Je realiseert data pipelines, gebruik makend van DBT (Data Build Tool) binnen onze PostgreSQL omgeving, waarbij je ook data transformeert en code structureert in repositories (GitLab). We werken veel met open source software, daarom zien we graag dat je niet bang bent om met de command line aan de slag te gaan.

Bij transformaties maak je verder gebruik van PostgreSQL (via DBT) en Python. Je zorgt dat data beschikbaar komen via de centrale databases of via API’s. Veel voorkomende transformaties en scripts beheer je gestructureerd. Je monitort periodieke scripts en zorgt dat deze up to date blijven zodat de benodigde data continu en stabiel beschikbaar is voor producten, analyses en dashboards.

Als data engineer binnen de afdeling Beleidsinformatie houd jij je daarnaast bezig met het functioneel ontwerp van ons eigen datawarehouse. Je kunt op conceptueel niveau denken en ontwerpen en bent in staat om de performance van onze databases te optimaliseren. Daarnaast weet je hoe je SQL query’s kan maken en beoordelen.

Functie-eisen

Wij bieden een dynamische, uitdagende werkomgeving waarin ruimte is voor vernieuwing, innovatie en verdere professionele ontwikkeling!

We zijn op zoek naar een ervaren data engineer (datawarehouse ontwikkelaar). Je hebt:

Afgeronde HBO of WO-studie in een relevante richting.
Aantoonbaar relevante werkervaring als data(-base) engineer, datawarehouse ontwikkelaar of vergelijkbare functie.
Kennis van databasetechnologieën, waarbij ervaring met PostgreSQL een pré is.
Vaardigheid in Python (bij voorkeur met relevante Python libraries zoals Pandas/Polars).
Een groot analytisch vermogen.
Een proactieve en positieve instelling.
Ervaring met Git en goede version-control gewoonten.
Goede beheersing van de Nederlandse taal.
Affiniteit of ervaring in het werken in een beleidsomgeving.
Verder zijn kennis van dataformaten (JSON, CSV, Parquet), data storage (S3) en FTP; als ook affiniteit met Netwerk & Systeem beheer en ervaring met DBT (data build tool) en Apache Airflow een pré.

Arbeids­voorwaarden

Salaris­niveau

schaal 11



Maand­salaris: Min €4024 - Max €6110","{""role_summary"":""As a data engineer, you will contribute to the development of our data warehouse, working closely with data analysts, scientists, and business analysts to standardize and optimize data exchange processes."",""key_terms"":[{""term"":""Datawarehouse"",""explanation"":""A data engineer responsible for developing and maintaining data pipelines, data transformation, and data structuring.""},{""term"":""DBT (Data Build Tool)"",""explanation"":""An open-source tool used for building, testing, and deploying data pipelines.""},{""term"":""PostgreSQL"",""explanation"":""A relational database management system used for storing and managing data.""},{""term"":""Python"",""explanation"":""A programming language used for data transformation, scripting, and data analysis.""},{""term"":""GitLab"",""explanation"":""A web-based platform used for version control and collaboration.""}],""skill_priorities"":{""must_have"":[""Data engineering experience"",""PostgreSQL experience"",""Python skills"",""Analytical skills"",""Proactive and positive attitude""],""nice_to_have"":[""Experience with data formats (JSON, CSV, Parquet)"",""Knowledge of data storage (S3)"",""FTP knowledge"",""Affinity with Network & System management"",""Experience with Apache Airflow""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize data pipelines using DBT?"",""example_answer"":""I would use DBT to standardize and optimize data exchange processes, ensuring data quality and reducing data latency.""},{""question"":""How do you handle data transformation and structuring in a PostgreSQL environment?"",""example_answer"":""I would use Python to transform and structure data, and then load it into PostgreSQL for further analysis.""}],""red_flags"":[""Lack of experience with PostgreSQL"",""Inability to work with command-line interfaces""],""confidence_score"":85.0}"
"Sr. Data Engineer, Analytics (Remote)",Luxury Presence,"Toronto, Ontario, Canada",March,2025,"About Us

Luxury Presence is the leading digital platform revolutionizing the real estate industry for agents, teams, and brokerages. Our award-winning websites, cutting-edge marketing solutions, and AI-powered mobile platform empower real estate professionals to grow their business, operate more efficiently, and deliver exceptional service to their clients. Trusted by over 60,000 real estate professionals, including 31 of the nation’s 100 top-performing agents as published in the Wall Street Journal, Luxury Presence continues to set the standard for innovation and excellence in real estate technology.

Why Now?

We’ve enjoyed tremendous growth over the last 5 years. With that growth comes a treasure trove of data that is valuable to us, and our customers. We need experienced and passionate data professionals to help us realize that value and unlock the insights that exist at the intersection of our operational, financial, and product data. This is a unique opportunity to join a fast growing startup and build our data team, culture, and processes from the ground up.

What You’ll Do

Design, develop, and maintain scalable data pipelines and ELT processes for our data lake/data warehouse
Implement data orchestration tools to automate and streamline data workflows.
Work with our AI Solutions team to implement AI enhanced processes throughout the organization
Build and integrate machine learning models and data pipelines into end-to-end analytics solutions
Build and manage reverse ETL workflows to business systems such as the CRM
Support development of predictive models to support strategic and operational initiatives
Develop and maintain comprehensive documentation for data processes and systems.
Build production-ready data models and schemas using DBT to support downstream analytics
Collaborate with cross-functional teams to define and implement data governance policies and best practices.
Manage our modern analytics tech stack to support the democratization of data and analytics through dashboards, reports, and predictive models
Support analysts in developing dashboards, data products, and ad hoc report studies to analyze and present data associated with GTM analytics, product performance, business operations, and strategic decision-making

Must Haves

Proficiency in SQL
Proficiency in any statistical programming language (i.e, Python or R)
Hands-on experience building and managing ETL and rETL workflows
Strong understanding of data engineering principles, including ETL/ELT processes, data modeling, and data warehousing
Experience with workflow orchestration tools, such as Airflow
Experience with ETL/ELT tools, such as Fivetran
Experience with cloud data warehouse and transformation tools (e.g.,, snowflake, DBT etc)

Nice to Haves

Experience working with AI workflow orchestration tools such as AirOps or Vectorshift
Experience working with entitlements and connecting the CRM to the Platform to gatekeep product features
Experience setting up large scale integrations to pull data from various Google products
Experience working with BI tools (Tableau, SiSense, Sigma, or Looker etc)
Ability to communicate technical concepts to both technical and non-technical audiences through visualizations and presentations
Ability to partner with leadership and stakeholders across the company to understand business needs and how these can be addressed through analytics
Experience in a B2B or SaaS environment, supporting functions such as sales, marketing, product development, and/or customer success.

Join us in shaping the future of real estate

The real estate industry is in the midst of a seismic shift, and the future belongs to those who break new ground. As one of the fastest-growing companies in the proptech and marketing sectors, Luxury Presence challenges the status quo of what technology can do for real estate agents, leaders, and brokerages.

We’re a team of agile and tenacious innovators working collaboratively to drive the industry forward. Together, we build game-changing products that empower modern real estate entrepreneurs to dominate their markets. From award-winning web design to agile SEO solutions to cutting-edge AI tools, we deliver tech that anticipates market shifts and keeps our clients ahead of their competition.

Founded in 2016 by Stanford Business School alum Malte Kramer, Luxury Presence has grown to a global team ranked on the Inc. 5000 fastest-growing companies list three years in a row. We’re backed by world-class investors, including Bessemer Venture Partners, Toba Capital, and Switch Ventures, and have raised $52.6 million to date.

More than 13,000 real estate businesses rely on our platform, including 31 of the RealTrends top 100 agents featured in The Wall Street Journal. Additionally, many of the industry’s most powerful brokerages — including Compass, Coldwell Banker, and Sotheby’s International Realty — rely on Luxury Presence as a trusted business partner.

Every year since 2020, Luxury Presence has ranked on BuiltIn’s Best Place to Work lists. HousingWire named our founder and CEO a 2024 Tech Trendsetter, we’ve received several Tech100 Awards, and our lead nurturing tool just scored an Inman Innovation Award for Best AI-Powered Platform.

Luxury Presence is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin.","{""role_summary"":""Design, develop, and maintain scalable data pipelines and ELT processes for a data lake/data warehouse, and work with cross-functional teams to define and implement data governance policies and best practices."",""key_terms"":[{""term"":""ELT"",""explanation"":""Extract, Load, and Transform process for data warehousing""},{""term"":""ETL"",""explanation"":""Extract, Transform, and Load data for data warehousing""},{""term"":""Data Lake"",""explanation"":""A centralized repository for storing structured and unstructured data""},{""term"":""Data Warehouse"",""explanation"":""A centralized repository for storing structured data""},{""term"":""AI Workflow Orchestration"",""explanation"":""Automating and streamlining AI-enhanced processes""}],""skill_priorities"":{""must_have"":[""Proficiency in SQL"",""Hands-on experience building and managing ETL and rETL workflows"",""Experience with workflow orchestration tools, such as Airflow"",""Experience with ETL/ELT tools, such as Fivetran"",""Experience with cloud data warehouse and transformation tools (e.g., Snowflake, DBT)""],""nice_to_have"":[""Experience working with AI workflow orchestration tools such as AirOps or Vectorshift"",""Experience working with entitlements and connecting the CRM to the Platform"",""Experience setting up large scale integrations to pull data from various Google products"",""Experience working with BI tools (Tableau, SiSense, Sigma, or Looker etc)"",""Ability to communicate technical concepts to both technical and non-technical audiences"",""Experience in a B2B or SaaS environment, supporting functions such as sales, marketing, product development, and/or customer success""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you design a scalable data pipeline for a data lake?"",""example_answer"":""I would use a combination of ETL/ELT tools and workflow orchestration tools like Airflow to automate and streamline the data pipeline""},{""question"":""How do you handle data governance and quality in a fast-paced startup environment?"",""example_answer"":""I would work closely with cross-functional teams to define and implement data governance policies, and ensure data quality through regular data audits and validation""}],""red_flags"":[""Lack of experience with cloud data warehouse and transformation tools"",""Inability to communicate technical concepts to non-technical audiences""],""confidence_score"":90.0}"
Data Engineer - Snowflake,Tiger Analytics,"Toronto, Ontario, Canada",January,2025,"Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning and AI. We are the trusted analytics partner for several Fortune 100 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best analytics global consulting team in the world.

The Data Engineer will be responsible for architecting, designing, and implementing advanced analytics capabilities. The right candidate will have broad skills in database design, be comfortable dealing with large and complex data sets, have experience building self-service dashboards, be comfortable using visualization tools, and be able to apply your skills to generate insights that help solve business challenges.We are looking for someone who can bring their vision to the table and implement positive change in taking the company's data analytics to the next level.

Requirements

8+ years of overall industry experience specifically in data engineering

5+ years of experience building and deploying large-scale data processing pipelines in a production environment.

Strong experience in Python, SQL, and PySpark

Creating and optimizing complex data processing and data transformation pipelines using python

Experience with ""Snowflake Cloud Datawarehouse"" and DBT tool

Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases

Understanding of Datawarehouse (DWH) systems, and migration from DWH to data lakes/Snowflake

Understanding of ELT and ETL patterns and when to use each. Understanding of data models and transforming data into the models

Strong analytic skills related to working with unstructured datasets

Build processes supporting data transformation, data structures, metadata, dependency and workload management

Experience supporting and working with cross-functional teams in a dynamic environment

Benefits

Significant career development opportunities exist as the company grows. The position offers a unique opportunity to be part of a small, challenging, and entrepreneurial environment, with a high degree of individual responsibility.","{""role_summary"":""Design and implement advanced analytics solutions, leveraging expertise in data engineering to drive business value and insights."",""key_terms"":[{""term"":""Data Engineering"",""explanation"":""Designing, building, and maintaining large-scale data processing systems, and architectures.""},{""term"":""Snowflake Cloud Datawarehouse"",""explanation"":""A cloud-based data warehousing platform for storing, processing, and analyzing large datasets.""},{""term"":""DBT tool"",""explanation"":""A data transformation tool for building, testing, and deploying data pipelines.""},{""term"":""ELT and ETL patterns"",""explanation"":""Data integration patterns for extracting, loading, and transforming data between systems.""},{""term"":""Datawarehouse (DWH) systems"",""explanation"":""Centralized repositories for storing, and managing large datasets for business intelligence, and analytics.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""PySpark"",""Data Engineering"",""Snowflake Cloud Datawarehouse"",""DBT tool""],""nice_to_have"":[""Experience with unstructured datasets"",""Knowledge of data models, and data transformation""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with designing, and implementing large-scale data processing pipelines?"",""example_answer"":""I have 5+ years of experience building, and deploying large-scale data processing pipelines in a production environment using Python, SQL, and PySpark.""},{""question"":""How do you approach data transformation, and data structures in a data engineering project?"",""example_answer"":""I use ELT and ETL patterns to transform data into the required models, and ensure data quality, and integrity.""}],""red_flags"":[""Lack of experience with Snowflake Cloud Datawarehouse, and DBT tool"",""Inability to work with unstructured datasets""],""confidence_score"":90.0}"
Sr. Data/Backend Engineer - Canada,Knotch,"Toronto, Ontario, Canada",March,2025,"About KnotchKnotch is a Content Intelligence Platform that enables brands to drive business growth through content. We build products for people who use content to drive performance. We also offer Strategic Consulting services which enable brands to achieve new levels of efficiency and effectiveness through ongoing and ad hoc support. Knotch gives marketers a holistic view of content’s performance and provides insights and actions that drive performance and increase efficiency.
About the Role
As a Sr Data Engineer at Knotch you will design, build, and maintain data infrastructure that powers business intelligence and analytics. In this role, you'll bridge the gap between raw data and actionable insights by creating robust data pipelines and models. This role is ideal for someone who combines technical excellence with business acumen and thrives in a collaborative environment where data drives decision-making.
How you will add value at Knotch
Collaborate cross-functionally to gather requirements and design data models that deliver successful analytics outcomes
Design and implement production-grade ETL/ELT processes to transform raw data into valuable business assets
Maintain and enhance existing data applications to ensure optimal performance and reliability
Build strong relationships with various teams to understand data needs and deliver appropriate solutions
Own data quality and serve as the subject matter expert for assigned business domains
You will successful if you bring:
5+ years of Data Engineering experience with demonstrated expertise in pipeline development and data modeling
Strong application development skills with advanced proficiency in SQL and Python
Hands-on experience with AWS services and Snowflake
Sharp analytical skills to identify data gaps, inconsistencies, and deliverable opportunities
Excellent communication abilities to translate complex technical concepts for both technical and business audiences
Prior experience as a backend engineer (application development) is a plus!
Our Benefits and Perks:
Salary - The expected salary range for this role is $150,000 - $165,000 CADdepending on experience.
Knotch is a fully remote company. Candidates can work from anywhere in Canada for this position.
Knotch is a US based equal opportunity employer. We strive to provide equal opportunities in all of our processes, including our hiring and employee experience.mWe pride ourselves on our three values: transparency, relentlessness, and inclusiveness.
We commit to daily work towards leading with empathy, reducing bias through periodic training, and engaging with and uplifting communities of marginalized groups. We condemn all forms of racism and discrimination on the basis of race, religion, ethnicity, nationality, gender identity, sexual orientation, age, marital status, pregnancy or parenthood status, veteran status, disability status or any other identifier. We encourage all employees, clients, investors, candidates, vendors, and friends of Knotch to deliver honest feedback directly or anonymously so that we may always seek to improve as an organization that is dedicated to diversity, equity, inclusion, and belonging.
Powered by JazzHR
lK7M04uXEn","{""role_summary"":""Design, build, and maintain data infrastructure that powers business intelligence and analytics, bridging the gap between raw data and actionable insights."",""key_terms"":[{""term"":""ETL/ELT"",""explanation"":""Extract, Transform, Load/Extract, Load, Transform processes to transform raw data into valuable business assets.""},{""term"":""Data Modeling"",""explanation"":""Designing data structures to deliver successful analytics outcomes.""},{""term"":""AWS services"",""explanation"":""Amazon Web Services used for cloud computing and data storage.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and processing large datasets.""}],""skill_priorities"":{""must_have"":[""5+ years of Data Engineering experience"",""Strong application development skills with advanced proficiency in SQL and Python"",""Hands-on experience with AWS services and Snowflake""],""nice_to_have"":[""Prior experience as a backend engineer (application development)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a recent project where you had to design and implement a data pipeline?"",""example_answer"":""I designed a data pipeline using AWS Glue and Snowflake to transform raw data into actionable insights for a marketing analytics project, resulting in a 30% increase in data quality.""},{""question"":""How do you stay up-to-date with the latest developments in data modeling and ETL/ELT processes?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and read blogs to stay current with the latest trends and best practices in data engineering.""}],""red_flags"":[""Lack of experience with cloud-based data storage and processing"",""Inability to communicate complex technical ideas to non-technical audiences""],""confidence_score"":95.0}"
"Software Engineer, Data Pipelines",Lyft,"Toronto, Ontario, Canada",March,2025,"At Lyft, our purpose is to serve and connect. To do this, we start with our own community by creating an open, inclusive, and diverse organization.

Our Infrastructure team is passionate about building software to solve problems at massive scale. We do this often, and when we believe our solution is worth sharing with the community, such as Envoy Proxy, we open source our ideas for the benefit of others.

As a Infrastructure Engineer at Lyft, you will run our Production Infrastructure by monitoring system availability and take a holistic view of our platform health. You will build software and platforms to automate infrastructure platform operations and management. By measuring and monitoring our operations you will seek opportunities to optimize our systems in order to push our platform forward, anticipating our customers' needs in order to continually improve the platform. You will provide Lyft partner teams with operational support to help them build robust large scale distributed systems.

About The Team

Data Pipelines is at the heart of all critical data flowing through Lyft supporting hundreds of services that impact millions of drivers and passengers every day. We support Kafka as our primary data streaming platform and offer a number of services to manage data and make it available to our internal customers.

Responsibilities:

Maintain and analyze metrics from; operating systems; control planes; and applications to assist in fault detection and performance enhancement
Design, develop and deploy tooling and systems that continually improve the reliability, scalability and efficiency of our platform
Balance feature development speed and reliability with service-level objectives
Operate and improve our Infrastructure using industry best practices and tools
Participate in design and production readiness reviews, platform management and capacity planning ceremonies with cross-functional teams
Document Infrastructure operations process and insights, identify repeatable actions and ruthlessly automate repetitive tasks
Participate in our teams on-call rotations, respond to incidents and support other teams mitigate customer impacting events

Experience:

2+ years experience working on teams responsible for software development, automation and systems engineering
Ability to create production ready code in one or more high level languages, such as Go Lang, Python
Experience operating large scale infrastructure in public cloud environments, such as AWS
Prior infra experience with infra tooling (Terraform, Cloud Formation, Docker, Kubernetes, Ansible, Chef, Puppet etc preferably in an AWS context)
Experience identifying nascent problems, performance bottlenecks and areas for improvement and developing and executing plans to mitigate them

Benefits:

Extended health and dental coverage options, along with life insurance and disability benefits
Mental health benefits
Family building benefits
Child care and pet benefits
Access to a Lyft funded Health Care Savings Account
RRSP plan to help save for your future
In addition to provincial observed holidays, salaried team members are covered under Lyft's flexible paid time off policy. The policy allows team members to take off as much time as they need (with manager approval). Hourly team members get 15 days paid time off, with an additional day for each year of service
Lyft is proud to support new parents with 18 weeks of paid time off, designed as a top-up plan to complement provincial programs. Biological, adoptive, and foster parents are all eligible.
Subsidized commuter benefits

Lyft proudly pursues and hires a diverse workforce. Lyft believes that every person has a right to equal employment opportunities without discrimination because of race, ancestry, place of origin, colour, ethnic origin, citizenship, creed, sex, sexual orientation, gender identity, gender expression, age, marital status, family status, disability, pardoned record of offences, or any other basis protected by applicable law or by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Accommodation for persons with disabilities will be provided upon request in accordance with applicable law during the application and hiring process. Please contact your recruiter now if you wish to make such a request.

This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Wednesdays, and Thursdays. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid

The expected base pay range for this position in the Toronto area is CAD $108,000 - CAD $149,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.","{""role_summary"":""As an Infrastructure Engineer at Lyft, you will run and optimize the company's production infrastructure, building software and platforms to automate operations and management, and providing operational support to partner teams."",""key_terms"":[{""term"":""Envoy Proxy"",""explanation"":""An open-source software proxy that helps manage traffic flow and API communication between services.""},{""term"":""Kafka"",""explanation"":""A distributed streaming platform used for handling high-throughput and provides low-latency, fault-tolerant, and scalable data processing.""},{""term"":""Terraform"",""explanation"":""An infrastructure as code tool that enables you to define and manage cloud and on-premises infrastructure using a human-readable configuration file.""}],""skill_priorities"":{""must_have"":[""2+ years experience working on teams responsible for software development, automation and systems engineering"",""Ability to create production ready code in one or more high level languages, such as Go Lang, Python"",""Experience operating large scale infrastructure in public cloud environments, such as AWS""],""nice_to_have"":[""Prior infra experience with infra tooling (Terraform, Cloud Formation, Docker, Kubernetes, Ansible, Chef, Puppet etc preferably in an AWS context)""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach fault detection and performance enhancement in a large-scale infrastructure?"",""example_answer"":""I use metrics from operating systems, control planes, and applications to identify areas for improvement and develop plans to mitigate bottlenecks.""},{""question"":""Can you describe a time when you had to balance feature development speed and reliability with service-level objectives?"",""example_answer"":""In my previous role, I had to prioritize feature development while ensuring the reliability and scalability of our platform, and I achieved this by implementing industry best practices and tools.""}],""red_flags"":[""Lack of experience with large-scale infrastructure in public cloud environments"",""Inability to create production-ready code in high-level languages""],""confidence_score"":90.0}"
Database Engineer,RPIA,"Toronto, Ontario, Canada",March,2025,"We are currently seeking a full-time permanent Database Engineer to join our Technology team.

As a Database Engineer, you will be responsible for ensuring the performance, availability, and security of databases within the organization. You will also play a crucial role in designing, implementing, and maintaining large-scale data processing systems that handle sizable amounts of structured and unstructured data. Your role involves managing, maintaining, and optimizing databases to meet the needs of the business and its users, architecting data pipelines, optimizing data workflows, and ensuring the scalability, reliability, and performance of data solutions. You will work closely with other members of the IT team to ensure seamless integration and efficient operation of database systems.

The duties and responsibilities of the Database Engineer include but are not limited to:

Design and Architecture: Develops database schemas, tables, and relationships. Designs scalable and fault-tolerant data architectures that leverage modern design principles to process and analyze large datasets.
Database Configuration: Ensures proper settings and configurations are in place for optimal performance and security of all Relational Database Management Systems.
Data Ingestion and Integration: Develops robust data ingestion pipelines to collect, extract, transform, and load (ETL) data from various sources, including databases, streaming platforms, and APIs. Implements data processing workflows to cleanse, enrich, and transform raw data into usable formats for analytics, reporting, and machine learning applications.
Performance Tuning: Monitors database performance and identifies opportunities for optimization. Tunes database queries, indexes, and other performance-critical elements to enhance efficiency and response times.
Backup and Disaster Recovery: Implements and manages backup and disaster recovery procedures to safeguard data against loss or corruption. Tests procedures regularly to ensure reliability.
Application Performance Optimization: Optimizes data processing algorithms, data structures, and resource utilization to maximize performance, reduce latency, and improve throughput in big data systems.
Security Management: Enforces security best practices to protect sensitive data from unauthorized access, breaches, or cyberattacks. Manages user access privileges, roles, and permissions, and data lineage throughout various data processing system.
Troubleshooting and Issue Resolution: Investigates and resolves database-related issues, such as performance bottlenecks, and system errors. Provides timely support to stakeholders. Collaborates with cross-functional teams to resolve system issues.
Automation and Scripting: Develops scripts and automation workflows to streamline repetitive tasks, such as data imports, exports, and maintenance activities. Embraces automation tools to improve operational efficiency.
Research and Innovation: Stays abreast of emerging trends, technologies, and best practices in big data, machine learning, and artificial intelligence. Experiments with new tools and techniques to drive innovation and enhance data engineering capabilities.
Documentation and Reporting: Maintains comprehensive documentation of database configurations, data processing procedures, and security policies.

Critical Competencies
Technical Knowledge – Profound knowledge in data architecture, real-time analytics, and cloud computing platforms, especially within financial services. Expert knowledge of data modeling, ETL processes, and data warehousing concepts.
Attention to Detail – Meticulous attention to precision in data handling and system design to ensure the integrity and reliability of our data platforms.
Problem Solving – Exceptional analytical skills with the ability to tackle complex technical challenges and innovate solutions.
Communication – Excellent communication skills, capable of articulating complex data concepts to non-technical stakeholders.
Teamwork – Strong aptitude to work well with others and support a thriving, team-first culture.
Requirements
Bachelor's or Master’s degree in Computer Science, Data Engineering, or a related field
Minimum of 5 years of experience as a DBA, Data Engineer, or similar role, with a focus on designing and implementing large-scale data processing systems
Experience with cloud platforms and services, such as AWS (EMR, S3, Glue), Azure (HDInsight, Data Lake, Data Factory), or Google Cloud (Dataproc, BigQuery)
Experience with SQL Server and MySQL
Strong knowledge of and experience with real-time analytics, persistent data stores, data modeling techniques, and adept data pipeline management
Proficient in various programming languages (Python/C#/Java) and adept with tools required for developing complex APIs and executing streaming or real-time data processes
Experience with cloud platforms and services, such as AWS (EMR, S3, Glue), Azure (HDInsight, Data Lake, Data Factory), or Google Cloud (Dataproc, BigQuery)
Familiarity with containerization technologies (e.g., Docker, Kubernetes) and orchestration tools (e.g., Apache Airflow) is considered an asset

Additional Information
Position Type: Full-Time Permanent
Work Location: Toronto To learn more about life at RPIA, visit https://rpia.ca/
Read our firm’s magazine, Voices of RPIA: https://online.flippingbook.com/view/859829658/24/

RPIA is proud to be Great Place to Work Certified™. What sets us apart?
Exceptional single and family benefits package that includes health, dental, and vision insurance plus additional Health Care Spending and Wellness credits.
Employee and Family Assistance Program to support mental well-being and extends to all family members in your household.
Opportunities for professional and personal growth through: Cross-functional Mentorship Program, Internally-curated Leadership Skills training program, Community outreach opportunities and monthly team socials.

RPIA is an Equal Opportunity Employer
We believe in the power of diversity of thought, and we aspire to have an inclusive workplace that mirrors the fabric of our community. We strongly encourage applications regardless of race, religion, colour, national origin, gender, sexual orientation, age, marital status, or disability status. We are committed to providing an accessible and equitable application and hiring process and will make accommodations should you require it at any point. We encourage you to connect with us at hr@rpia.ca if you require accommodation during the recruitment process.
Our culture is defined by our five core values: excellence, partnership, transparency, integrity, and community. Our clients often say the outstanding service we deliver is as important to them as the returns we achieve for them. With over 100 employees and $14 billion under management for a broad investor base of institutions and private clients, we proudly remain privately owned by employees who invest alongside our clients.","{""role_summary"":""The Database Engineer is responsible for ensuring the performance, availability, and security of databases within the organization, designing and implementing large-scale data processing systems, and managing, maintaining, and optimizing databases to meet business needs."",""key_terms"":[{""term"":""Data Architecture"",""explanation"":""The design and structure of data systems to process and analyze large datasets.""},{""term"":""ETL (Extract, Transform, Load)"",""explanation"":""A process to collect, transform, and load data from various sources into usable formats.""},{""term"":""Real-time analysis of data to gain insights and make informed decisions."",""explanation"":""The ability to process and analyze data in real-time, enabling timely decision-making.""},{""term"":""Cloud Computing Platforms"",""explanation"":""Scalable and on-demand computing resources and services, such as AWS, Azure, or Google Cloud.""}],""skill_priorities"":{""must_have"":[""Data Engineering"",""Cloud Computing Platforms"",""SQL Server"",""MySQL"",""Real-time Analytics"",""Data Modeling"",""ETL Processes"",""Data Warehousing""],""nice_to_have"":[""Containerization Technologies (e.g., Docker, Kubernetes))"",""Orchestration Tools (e.g., Apache Airflow)""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing scalable and fault-tolerant data architectures?"",""example_answer"":""I leverage modern design principles to process and analyze large datasets, ensuring scalability and fault-tolerance.""},{""question"":""Can you explain your experience with ETL processes and data pipeline management?"",""example_answer"":""I've developed robust data ingestion pipelines, implementing data processing workflows to cleanse, transform, and load data into usable formats.""}],""red_flags"":[""Lack of experience with cloud platforms and services (AWS, Azure, or similar)."",""Inadequate knowledge of data modeling techniques and data pipeline management.""],""confidence_score"":95.0}"
Sr. Data Engineer,CGS Federal (Contact Government Services),"Yellowstone, Alberta, Canada",October,2024,"Employment Type: Full-Time, Mid-level

Department: Business Intelligence

CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges.

CGS brings motivated, highly skilled, and creative people together to solve the government’s most dynamic problems with cutting-edge technology. To carry out our mission, we are seeking candidates who are excited to contribute to government innovation, appreciate collaboration, and can anticipate the needs of others. Here at CGS, we offer an environment in which our employees feel supported, and we encourage professional growth through various learning opportunities.

Skills and attributes for success:


Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
Write code to ensure the performance and reliability of data extraction and processing
Support continuous process automation for data ingest
Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
Work with program management and engineers to implement and document complex and evolving requirements
Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists




Qualifications:


Must be a US Citizen
Must be able to obtain a Public Trust Clearance
7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models
Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
Proficiency in developing ETL processes, and performing test and validation steps
Proficiency to manipulate data (Python, R, SQL, SAS)
Strong knowledge of big data analysis and storage tools and technologies
Strong understanding of the agile principles and ability to apply them
Strong understanding of the CI/CD pipelines and ability to apply them
Experience with relational database, such as, PostgreSQL
Work comfortably in version control systems, such as, Git Repositories




Ideally, you will also have:


Experience creating and consuming APIs
Experience with DHS and knowledge of DHS standards a plus
Candidates will be given special consideration for extensive experience with Python
Ability to develop visualizations utilizing Tableau or PowerBI
Experience in developing Shell scripts on Linux
Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions
Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences




Our Commitment:

Contact Government Services (CGS) strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting-edge technology with world-class personnel to deliver customized solutions that fit our client’s specific needs. We are committed to solving the most challenging and dynamic problems.

For the past seven years, we’ve been growing our government-contracting portfolio, and along the way, we’ve created valuable partnerships by demonstrating a commitment to honesty, professionalism, and quality work.

Here at CGS we value honesty through hard work and self-awareness, professionalism in all we do, and to deliver the best quality to our consumers mending those relations for years to come.

We care about our employees. Therefore, we offer a comprehensive benefits package:


Health, Dental, and Vision
Life Insurance
401k
Flexible Spending Account (Health, Dependent Care, and Commuter)
Paid Time Off and Observance of State/Federal Holidays




Contact Government Services, LLC is an Equal Opportunity Employer. Applicants will be considered without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Join our team and become part of government innovation!

Explore additional job opportunities with CGS on our Job Board:

https://cgsfederal.com/join-our-team/

For more information about CGS please visit: https://www.cgsfederal.com or contact:

Email: info@cgsfederal.com","{""role_summary"":""Support a rapidly growing Data Analytics and Business Intelligence platform, providing data-driven solutions to empower clients, and contribute to innovation through collaboration and skill-building."",""key_terms"":[{""term"":""Agile/Scrum"",""explanation"":""A software development methodology that emphasizes collaboration, flexibility, and continuous improvement.""},{""term"":""Lean-agile engineering principles"",""explanation"":""A set of principles and practices that aim to minimize waste, maximize value, and promote continuous improvement in software development.""},{""term"":""API-first design"",""explanation"":""An approach to software development that prioritizes the creation of application programming interfaces (APIs) as the primary interface for interacting with a system.""},{""term"":""CI/CD pipelines"",""explanation"":""A set of practices and tools that automate the build, testing, and deployment of software applications, ensuring continuous integration and delivery.""},{""term"":""ETL processes"",""explanation"":""Extract, Transform, and Load processes that enable the extraction of data from various sources, transformation into a standardized format, and loading into a target system.""},{""term"":""Big data analysis and storage tools and technologies"",""explanation"":""A set of technologies and techniques used to handle large and complex datasets, including storage, processing, and analysis.""}],""skill_priorities"":{""must_have"":[""7+ years of IT experience"",""Experience in design, management, and solutioning of large, complex data sets and models"",""Proficiency in developing ETL processes, and performing test and validation steps"",""Strong knowledge of big data analysis and storage tools and technologies"",""Strong understanding of agile principles and ability to apply them"",""Strong understanding of CI/CD pipelines and ability to apply them"",""Experience with relational database, such as, PostgreSQL"",""Work comfortably in version control systems, such as, Git Repositories""],""nice_to_have"":[""Experience creating and consuming APIs"",""Experience with DHS and knowledge of DHS standards"",""Extensive experience with Python"",""Ability to develop visualizations utilizing Tableau or PowerBI"",""Experience in developing Shell scripts on Linux"",""Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions"",""Demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement a data pipeline to store, manage, and provision data to consumers?"",""example_answer"":""I would follow agile principles and use API-first design to create a scalable and flexible pipeline. I would also ensure continuous integration and delivery using CI/CD pipelines.""},{""question"":""How do you stay current with emerging trends and technologies in data engineering?"",""example_answer"":""I participate in online forums and attend conferences to stay updated on the latest developments in data engineering. I also engage in continuous learning and knowledge-sharing with my peers.""}],""red_flags"":[""Lack of experience with agile principles and CI/CD pipelines"",""Inability to communicate technical terms to non-technical audiences"",""Limited experience with data visualization tools such as Tableau or PowerBI""],""confidence_score"":90.0}"
Azure DWH Data Engineer,Tangent International,Canada,February,2025,"Proficient in deriving solutions from loosely defined business challenges, demonstrating adaptability and problem-solving acumen.
Exceptional team leadership and mentoring abilities, fostering collaboration and professional growth within teams.
Skilled in architecting and implementing medium to large scale BI solutions on Azure, utilizing a comprehensive suite of Azure Data Platform services.
Capable of assessing the current production state of applications and evaluating the impact of new implementations on existing business processes.
Proficient in developing cost-effective architectures in Azure, providing recommendations to optimize data infrastructure.
Experienced in designing, setting up, and maintaining Azure services, ensuring smooth operations of critical components.
Expertise in executing Extract, Transform, and Load (ETL) processes from diverse source systems to Azure Data Storage services, employing a variety of tools and languages.
Competent in developing and managing pipelines in Azure Data Factory, facilitating seamless data extraction, transformation, and loading from multiple sources.
Possesses a strong understanding of Spark Architecture and effectively develops Spark applications for data extraction, transformation, and aggregation.
Assumes responsibility for estimating cluster sizes, monitoring, and troubleshooting Spark Databricks clusters, optimizing performance parameters for efficiency.
Demonstrates exceptional communication skills, conveying complex data insights to non-technical stakeholders with clarity and precision.
Proven ability to drive organizational buy-in for data-driven initiatives, influencing stakeholders to embrace data-driven decision-making.
Expertise in data analysis, data mining, and statistical techniques, leveraging statistical packages and programming languages like SAS, R, or Python.
Familiarity with statistical packages, quantitative analytics, forecasting, and optimization algorithms, enabling informed decision-making and strategic planning.
Possesses solid industry knowledge and extensive experience leading teams, guiding them to deliver impactful results in alignment with organizational goals.","{""role_summary"":""Lead and architect medium to large scale BI solutions, driving data-driven decision-making and strategic planning."",""key_terms"":[{""term"":""Azure Data Platform services"",""explanation"":""A suite of cloud-based services for building, deploying, and managing data solutions.""},{""term"":""ETL"",""explanation"":""A process of extracting data from sources, transforming it into a usable format, and loading it into a target system.""},{""term"":""Spark Architecture"",""explanation"":""A unified analytics engine for large-scale data processing, providing high-level APIs in Java, Python, and R.""},{""term"":""Azure Data Factory"",""explanation"":""A cloud-based data integration service for orchestrating data movement and transformation.""},{""term"":""Spark Databricks clusters"",""explanation"":""A fast, easy, and collaborative Apache Spark-based analytics platform.""}],""skill_priorities"":{""must_have"":[""Azure"",""BI solutions"",""team leadership"",""problem-solving"",""ETL"",""Azure Data Platform services""],""nice_to_have"":[""SAS"",""R"",""Python"",""statistical packages"",""optimization algorithms""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a recent project where you had to architect and implement a medium to large scale solution on Azure?"",""example_answer"":""In my previous role, I led a team to design and deploy a cloud-based data warehouse on Azure, utilizing Azure Data Factory and Azure Databricks. We successfully migrated 500 GB of data from on-premises storage to Azure, achieving a 25% reduction in costs.""},{""question"":""How do you approach estimating cluster sizes and optimizing performance parameters for efficiency?"",""example_answer"":""I use a combination of historical data, benchmarking, and monitoring tools to estimate cluster sizes. I also continuously monitor performance metrics and adjust parameters to ensure smooth operations and optimal resource utilization.""}],""red_flags"":[""Lack of experience with Azure Data Platform services"",""Inability to communicate complex data insights to non-technical stakeholders""],""confidence_score"":95.0}"
"Software Engineer, Python",AutoSync,"Greater Toronto Area, Canada",March,2025,"TRADER Corporation is a trusted Canadian leader in online media, dealer and lender services. The company is comprised of AutoTrader.ca, AutoSync and Dealertrack Canada. AutoTrader.ca (AutoHebdo.net in Quebec) offers the largest inventory of new cars and used cars in Canada, receiving over 25 million monthly visits to its marketplace. With over 3,500 subscribers and counting, AutoSync is the largest and fastest growing dealer and OEM software provider in Canada. The platform's suite of connected automotive software solutions brings advertising, conversion and operational support together, synchronizing the entire retail process. AutoSync's diverse range of offerings includes: vAuto, EasyDeal, xtime, Motoinsight, Activix, TAdvantage and TRFFK. Dealertrack is Canada’s largest automotive financing portal, enhancing efficiency and profitability for all major segments of the automotive, marine, recreational vehicle, motorcycle and powersport retail industries. Over 6.5 million credit applications are submitted via the Dealertrack Canada portal each year. Collateral Management is a national, end-to-end, managed technology solution that offers industry insight and multi-channel collection strategies to maximize funds recovered. Collateral Management helps you remain compliant in all jurisdictions, alleviating your exposure to reputational and financial risks. Visit tradercorporation.com to learn more. .

TRADER Corporation's parent company AutoScout24 is the largest pan-European online car market with over 2 million listings and more than 43,000 dealer customers. With AutoScout24, users can find, finance, buy, subscribe for and sell used and new cars. The marketplace provides inspiration on cars and other vehicles and makes hard decisions easy.

Since 1998 AutoScout24 has been offering private users, car dealers and other cooperation partners from the automotive, financial and insurance services sector a comprehensive digital platform for car trading. The online marketplace includes used and new cars, motorcycles as well as commercial vehicles. AutoScout24 has over 30 million users per month, more than 43,000 dealers and around 500 employees. In addition to Germany, AutoScout24 is also represented in the European core markets of Belgium, Luxembourg, the Netherlands, Italy, France and Austria.

More information on www.autoscout24.de

Experience leveraging AI, Generative AI (GenAI) to enhance engineering productivity, automate repetitive tasks, and optimize workflows. Candidates should demonstrate the ability to integrate AI-driven solutions into their daily work — such as code generation, debugging, reviews, documentation, and decision support—to improve efficiency for themselves and their teams. A proactive approach to exploring and implementing AI tools that drive innovation and streamline development processes is highly valued

Key areas of responsibility
- Design, develop and oversee the successful end-to-end delivery of full-stack web solutions, from technical analysis to architecture and implementation, through to unit testing, development, integration testing and documentation.
- Providing appropriate testing information and environments to QA engineers and Product Owners, to validate the deliverables meet the desired expectations.
- Maintain and improve our engineering standards by participating in thorough code reviews, proposing process changes, and having a proactive attitude towards improvement in all areas of our software delivery lifecycle.
- Participate in the on-call rotation to ensure a timely response during production incidents.
- Performing root-cause analysis on software defects, to help identify weak spots in processes and tools, with the aim of preventing defects from happening again.
- Being an active participant in your team's meetings and processes, providing useful information through efficient communication with Product and Project stakeholders.
- Working closely with Product stakeholders in understanding project needs and providing technical advice in the feasibility of solutions as well as alternative options that could be considered.

Required skills
- Experience working as a full-stack web developer with Python and Vue.js or React.
- Hands-on knowledge of SQL and RDBMs fundamentals, particularly Postgres.
- Experience writing detailed unit, component and integration tests.
- Experience designing and implementing RESTful APIs.
- Working knowledge of git or similar VCS, docker, and cloud-based platforms.
- Working experience profiling and optimizing software in all levels of the stack, from time-consuming API endpoints to expensive queries, through to inefficient algorithms.
- Ability to work in a fully-remote environment, with a distributed team.
- Ability to dig into issues and errors and figure out their causes and potential solutions.
- Great self-organization and time management skills.
- Exceptional written and spoken English.

Required experience
- University degree in Computer Science, or equivalent experience.
- 5+ years of experience building online software. Strong knowledge of website usability and web application architectures.
- Knowledge of relational and non-relational storage foundations and their tradeoffs.
- Working knowledge of modern security fundamentals and best practices.
- Great understanding of agile methodologies in a Kanban delivery environment.
- Experience working with a remote, distributed team.

What’s in it for you…
-We understand that there is life at work and life outside of work. Here are a few benefits we all benefit from that support us to be our creative best.
Fitness and wellness
-We provide discounts to nation-wide gyms, onsite gyms (when we’re in the office), an Employee and Family Assistance Program, as well as a virtual wellness program.
Benefits from Day 1
-Gym discounts
-Local in-office free gyms
-Employee and Family Assistance program
-Weekly virtual wellness events
-Conferences & training budget
-Regular internal training programs
Financial planning
-Let us help you invest in your future with 3% matching towards your pension and multiple forms of income protection.
Competitive salary
-Annual bonus structure
-3% CPP matching","{""role_summary"":""Design, develop, and deliver full-stack web solutions, ensuring efficient engineering standards, and collaborating with product stakeholders to provide technical advice."",""key_terms"":[{""term"":""Generative AI (GenAI)"",""explanation"":""Artificial intelligence that generates new, original content, such as code, to enhance engineering productivity and automate repetitive tasks.""},{""term"":""Full-stack web development"",""explanation"":""Developing complete web applications, from front-end user interface to back-end server-side logic, and database integration.""},{""term"":""RESTful APIs"",""explanation"":""Application Programming Interfaces that follow Representational State of Resource principles, enabling efficient and scalable communication between systems.""}],""skill_priorities"":{""must_have"":[""Python"",""Vue.js or React"",""SQL and RDBMs fundamentals"",""Experience writing unit, component, and integration tests"",""Experience designing and implementing RESTful APIs"",""Working knowledge of git, docker, and cloud-based platforms""],""nice_to_have"":[""Experience with profiling and optimizing software"",""Ability to work in a fully-remote environment"",""Ability to dig into issues and figure out their causes and potential solutions""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would integrate AI-driven solutions into your daily work to improve efficiency?"",""example_answer"":""I would leverage AI tools to automate repetitive tasks, such as code generation and debugging, and optimize workflows to reduce development time.""},{""question"":""How do you approach code reviews and proposing process changes to improve engineering standards?"",""example_answer"":""I participate in thorough code reviews, identify areas for improvement, and propose process changes to enhance efficiency and reduce defects.""}],""red_flags"":[""Lack of experience with AI-driven solutions"",""Inability to work in a fully-remote environment""],""confidence_score"":90.0}"
Senior Software Data Engineer - (Remote - Canada),Jobgether,Canada,February,2025,"Jobgether has ALL remote jobs globally. We match you to roles where you're most likely to succeed and provide feedback on every application to help you learn. No more guesswork, application black holes, or recruiter ghosting in your job search.

For one of our clients, we are looking for a Senior Software Data Engineer, remotely from Canada.

As a Senior Software Data Engineer, you will play a key role in designing, developing, and optimizing data solutions that drive strategic decision-making. You will be responsible for building scalable data pipelines, ensuring data integrity, and collaborating with cross-functional teams to create efficient data architectures. This position requires a deep technical background, a problem-solving mindset, and a passion for transforming raw data into valuable insights.

Accountabilities:

Develop and maintain robust data pipelines to process and analyze large datasets efficiently
Design scalable data architectures, ensuring optimal performance and reliability
Collaborate with stakeholders across different teams to evaluate business needs and translate them into technical solutions
Implement and refine data integrity tests to maintain high-quality data standards
Stay current with emerging technologies, continuously improving data infrastructure and methodologies
Own and operate data products, ensuring seamless functionality and usability


Requirements

Extensive experience with distributed query engines and SQL-based data processing
Proficiency in SQL composition frameworks such as dbt or SQLMesh
Strong Python programming skills for data engineering tasks
Experience designing and building data pipelines with a focus on scalability and reliability
Excellent communication skills, with the ability to collaborate across remote teams and time zones
Proven ability to stay ahead of industry trends and implement innovative solutions
A track record of continuous learning and professional growth


Preferred Qualifications:

Experience with data governance and regulatory compliance
Familiarity with workflow orchestration tools
Previous contributions to production-level code
Experience developing fully managed cloud services
Knowledge of integrating Business Intelligence tools


Benefits

💰 Competitive compensation package, including Restricted Stock Units (RSUs)
🌴 Generous paid vacation, sick time, and 16 company holidays (including 2 floating holidays)
🏡 Flexible, fully remote work environment with no mandatory office presence
👶 Up to 26 weeks of paid parental leave
❤️ Paid volunteer and mental health days
🏦 RRSP plan with company match
🏥 Employer-provided supplemental medical, dental, disability, and life insurance coverage","{""role_summary"":""Design, develop, and optimize data solutions to drive strategic decision-making as a Senior Software Data Engineer, working remotely from Canada."",""key_terms"":[{""term"":""Data pipelines"",""explanation"":""A series of processes that extract, transform, and load data into a target system for analysis.""},{""term"":""Distributed query engines"",""explanation"":""Systems that allow multiple computers to work together to process large amounts of data.""},{""term"":""SQL composition frameworks"",""explanation"":""Tools that help create and manage complex SQL queries, such as dbt or SQLMesh.""},{""term"":""Data governance"",""explanation"":""Policies and procedures to ensure data quality, security, and integrity.""}],""skill_priorities"":{""must_have"":[""Extensive experience with distributed query engines and SQL-based data processing"",""Proficiency in SQL composition frameworks such as dbt or SQLMesh"",""Strong Python programming skills for data engineering tasks"",""Experience designing and building data pipelines with a focus on scalability and reliability"",""Excellent communication skills, with the ability to collaborate across remote teams and time zones""],""nice_to_have"":[""Experience with data governance and regulatory compliance"",""Familiarity with workflow orchestration tools"",""Previous contributions to production-level code"",""Experience developing fully managed cloud services"",""Knowledge of integrating Business Intelligence tools""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design a scalable data pipeline to process large datasets efficiently?"",""example_answer"":""I would use a distributed query engine like Apache Spark to process large datasets in parallel, ensuring optimal performance and reliability.""},{""question"":""How do you stay current with emerging technologies and continuously improve data infrastructure and methodologies?"",""example_answer"":""I regularly read industry blogs and attend conferences to stay updated on the latest technologies and methodologies, and apply them to my work.""}],""red_flags"":[""Avoid candidates without experience with distributed query engines and SQL-based data processing."",""Be cautious of candidates without strong Python programming skills for data engineering tasks.""],""confidence_score"":95.0}"
Big Data Developer,Tata Consultancy Services,"Mississauga, Ontario, Canada",March,2025,"Inclusion without Exception
Tata Consultancy Services (TCS) is an equal opportunity employer, and embraces diversity in race, nationality, ethnicity, gender, age, physical ability, neurodiversity, and sexual orientation, to create a workforce that reflects the societies we operate in. Our continued commitment to Culture and Diversity is reflected in our people’s stories across our workforce and implemented through equitable workplace policies and processes.

About TCS
TCS is an IT services, consulting, and business solutions organization that has been partnering with many of the world’s largest businesses in their transformation journeys for over 55 years. Its consulting-led, cognitive-powered portfolio of business, technology, and engineering services and solutions is delivered through its unique Location Independent Agile™ delivery model, recognized as a benchmark of excellence in software development. A part of the Tata group, India's largest multinational business group, TCS employs over 612,000 of the world’s best-trained consultants in 55 countries. The company generated consolidated revenues of US $29 billion in the fiscal year ended March 31, 2024, [BS1] and is listed on the BSE and the NSE in India. TCS' proactive stance on climate change and award-winning work with communities across the world have earned it a place in leading sustainability indices such as the MSCI Global Sustainability Index and the FTSE4Good Emerging Index.

Job Description:
Role Description:
Design high quality deliverables adhering to business requirements with defined standards and design principles and patterns.
Develop and maintain highly scalable, high performance Data transformation applications using Apache Spark framework.
Develop/Integrate the code adhering to CI/CD, using Spark Framework in Scala/Java. Provide solutions to big data problems dealing with huge volumes of data using Spark based data transformation solutions, Hive, MPP processes like IMPALA.
Create Junit tests and ensure code coverage is met as per the agreed standards.
Should be able to work with a team who might be geographically distributed.
Review the code modules developed by other juniors.

Required Skill Sets
Hands-on development experience in programming languages such as JAVA, SCALA using Maven, Apache Spark Frameworks and Unix Shell scripting.
Should be comfortable with Unix File system as well as HDFS commands.
Should have worked on query languages such as Oracle SQL, Hive SQL, Spark SQL, Impala, HBase DB.
Should be flexible and should have good communication and customer management skills.

Desired Skill Set
Should have knowledge on Big data Data Ingestion tools such as SQOOP and KAFKA.
Should be aware of the components in Big Data ecosystem.
Should have worked on building projects using Eclipse IDE, Tectia Client, Oracle SQL Developer.

Tata Consultancy Services Canada Inc. is committed to meeting the accessibility needs of all individuals in accordance with the Accessibility for Ontarians with Disabilities Act (AODA) and the Ontario Human Rights Code (OHRC). Should you require accommodation during the recruitment and selection process, please inform Human Resources.

Thank you for your interest in TCS. Candidates that meet the qualifications for this position will be contacted within a 2-week period. We invite you to continue to apply for other opportunities that match your profile.","{""role_summary"":""Design and develop high-quality data transformation applications using Apache Spark framework, ensuring scalability and high performance."",""key_terms"":[{""term"":""Apache Spark"",""explanation"":""An open-source framework for large-scale data processing.""},{""term"":""CI/CD"",""explanation"":""Continuous Integration and Continuous Deployment, a practice for automating testing and deployment of code changes.""},{""term"":""HDFS"",""explanation"":""Hadoop Distributed File System, a distributed storage system for large data sets.""},{""term"":""IMPALA"",""explanation"":""A high-performance, distributed SQL engine for Hadoop.""},{""term"":""MPP"",""explanation"":""Massively Parallel Processing, a technique for processing large data sets in parallel.""}],""skill_priorities"":{""must_have"":[""Hands-on development experience in programming languages such as JAVA, SCALA"",""Experience with Apache Spark Frameworks and Unix Shell scripting"",""Knowledge of query languages such as Oracle SQL, Hive SQL, Spark SQL, Impala, HBase DB""],""nice_to_have"":[""Knowledge on Big data Data Ingestion tools such as SQOOP and KAFKA"",""Experience with building projects using Eclipse IDE, Tectia Client, Oracle SQL Developer""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize the performance of a Spark-based data transformation application?"",""example_answer"":""I would use Spark's built-in optimization techniques such as caching and parallel processing, and also consider using data partitioning and indexing to improve query performance.""},{""question"":""How do you handle big data problems dealing with huge volumes of data using Spark-based data transformation solutions?"",""example_answer"":""I would use Spark's data processing capabilities, such as batch processing and real-time processing, and also consider using data aggregation and filtering techniques to reduce the data volume.""}],""red_flags"":[""Lack of experience with Apache Spark framework"",""Inability to work with geographically distributed teams""],""confidence_score"":85.0}"
Software Engineer (New Grad),OSI Maritime Systems,"Burnaby, British Columbia, Canada",March,2025,"The Software Engineer applies the principles of software engineering to design, develop, test, and maintain our OSI software products. The Software Engineer has the primary responsibility to provide a successful implementation of the assigned software modules. The Software Engineer will collaborate with a team of multidisciplinary engineers and stakeholders to ensure the successful delivery of our software products to our end users and customers. Our Engineers have a focus on collaboration, and assist their team with devising innovative technical solutions and removing roadblocks. As a group, the engineers work together to complete software development activities through the full software lifecycle. To do this the Software Engineer must demonstrate strong communication skills and interpersonal skills. The OSI Software Engineer exhibits professionalism, integrity, and ownership.

RESPONSIBILITIES
Follows the SDLC, Software Development Lifecycle using Software Engineering best practices as described in the OSI documented processes and training. Follows the coding standards and best practices to write high quality source code in C and C++. Participates in peer reviews of the source code and ensures all development is maintained in the version control repository.
Prepares software specifications and manages requirements for new software features.
Produces software detailed designs and makes regular updates to the design documents when changes are made.
Maintains the code by correcting defects (bugs) and troubleshooting system problem reports and customer tickets.
Demonstrates full ownership for their work, resolving road blocks, and communicates deadlines and technical challenges to their Technical Lead or Manager.
Produces software estimates and participates in technical work breakdown and defining scope.
Identifies, analyses, and resolves diverse software technical challenges.
Commits to project objectives and meeting the project schedule and budgets.
Provides technical expertise and reviews of documentation including the publications developed by the Technical Publication group.
Produces software technical documentation which supports the project or department needs.
May participate in the concept phase including the creation of prototypes or use cases.
May support the Test Team activities including running test procedures and supporting lab setup or deployment may assistance is required.
Provides technical guidance and mentoring to new staff including participation in onboarding and the buddy program.
May interface and provide support and assistance to customers while visiting sites or ships.
Demonstrates professionalism when interfacing with customer and prioritizes customer requests.
Commits to prioritizing and correcting Usability, Safety and Security concerns.
Complies with OSI’s established ISO-9001-compliant development guidelines and standards
Follows and ensures workplace operating and environmental, health and safety procedures and guideline

KNOWLEDGE & QUALIFICATIONS
Education: Degree in Computer Science, Software, Electrical or Computer Engineering, Engineering Physics or Mathematics.
Experience: 0-3 years’ experience in a software environment; experience in developing real-time interfaces to external systems; experience working in an ISO 9001 compliant software engineering environment would be an asset; experience in the defense or aerospace domains is an asset
Technical Skills: Experience in C/C++ development under Windows; Experience in areas such as 2D/3D graphics,
Open GL, TCP/IP, GPS, UDP Multicast, and real-time systems are highly desirable; ability to understand and work with complex software requirement specifications; strong theoretical and algorithmic background with experience in mathematical and/or geospatial applications; ability to assist with analysis and design of solutions for algorithmically complex requirements; Ability to learn quickly
Soft Skills: Excellent verbal and written communication skills
Uses strong communication skills to ask questions, provide technical solutions and help build a strong team environment
Ability to work well under pressure in a high paced, challenging environment; strong team work skills; takes full ownership of any mistakes that are made and corrects the situation.
Other: Required to obtain security clearance; occasional travel; knowledge of marine navigation concepts and systems is an asset","{""role_summary"":""Design, develop, test, and maintain OSI software products, collaborating with a multidisciplinary team to ensure successful delivery to end users and customers."",""key_terms"":[{""term"":""SDLC"",""explanation"":""Software Development Lifecycle, a process for planning, creating, testing, and delivering software""},{""term"":""OSI documented processes"",""explanation"":""Standardized procedures for software development and training within the OSI organization""},{""term"":""C and C++"",""explanation"":""Programming languages used for developing software applications""},{""term"":""ISO-9001-compliant development guidelines"",""explanation"":""International standard for quality management systems, ensuring consistency and quality in software development""},{""term"":""Real-time systems"",""explanation"":""Computer systems that process and respond to data in real-time, often used in critical applications""},{""term"":""TCP/IP"",""explanation"":""Communication protocol suite used for transmitting data over the internet""},{""term"":""GPS"",""explanation"":""Global Positioning System, a satellite-based navigation system""},{""term"":""UDP Multicast"",""explanation"":""A communication protocol used for sending data to multiple recipients simultaneously""},{""term"":""2D/3D graphics"",""explanation"":""Computer-generated images used for visualization and simulation""},{""term"":""Open GL"",""explanation"":""A cross-language, cross-platform application programming interface for rendering 2D and 3D vector graphics""}],""skill_priorities"":{""must_have"":[""C and C++ development"",""Strong communication skills"",""Ability to work in an ISO 9001-compliant software engineering environment""],""nice_to_have"":[""Experience in real-time interfaces to external systems"",""Experience in the defense or aerospace domains"",""Knowledge of marine navigation concepts and systems""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the SDLC process and how you've applied it in previous projects?"",""example_answer"":""I've worked on projects that followed the SDLC process, ensuring that our software development met the required standards and best practices.""},{""question"":""How do you handle complex software requirement specifications?"",""example_answer"":""I break down the requirements into smaller components, analyze each part, and then develop a plan to implement the solution, ensuring that I meet the required specifications.""},{""question"":""Can you give an example of a time when you had to troubleshoot a system problem report?"",""example_answer"":""In my previous role, I identified and resolved a critical issue with our software, working closely with the team to implement a solution and ensure timely delivery to our customers.""}],""red_flags"":[""Lack of experience in C/C++ development"",""Inability to work in an ISO 9001-compliant software engineering environment"",""Poor communication skills""],""confidence_score"":80.0}"
"Data Enginner- Databricks, ADF, Snowflake, Pyspark, SQL -Canada/Hybrid",W3Global,"Toronto, Ontario, Canada",March,2025,"Montreal/Toronto, Canada/Hybrid

Databricks, ADF, Snowflake, Pyspark, SQL

7-10 years

Collaborate with stakeholders to understand requirements, data solutions, data models and mapping documents.
Lead the design, development, and implementation of data solutions using Azure Data Lake Storage (ADLS), Azure Data Factory, Event Hub, Databricks, and Snowflake.
Oversee the end-to-end data pipeline, ensuring data quality, integrity, and security.
Lead the deployment activities including the Dev test approval, PR approval, Collaboration with DevOps team, Release mgmt. for deployment into all environments including production and provide knowledge sharing to Data operations team
Assist data analysts with technical input.
Provide data engineering inputs to the data solution architect.
Lead the effort estimates/story point estimates for the sprint.
Mentor and guide a team of data engineers.
Foster a collaborative environment to encourage knowledge sharing and continuous improvement.

Conduct code reviews and ensure adherence to coding standards and best practices.","{""role_summary"":""Lead the design, development, and implementation of data solutions, ensuring data quality, integrity, and security, while collaborating with stakeholders and mentoring a team of data engineers."",""key_terms"":[{""term"":""Azure Data Lake Storage (ADLS)"",""explanation"":""A cloud-based storage solution for large amounts of data.""},{""term"":""Databricks"",""explanation"":""A cloud-based platform for working with big data and analytics.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and analyzing data.""},{""term"":""Pyspark"",""explanation"":""A Python library for working with big data and analytics.""},{""term"":""Event Hub"",""explanation"":""A cloud-based event streaming platform for handling large amounts of data.""}],""skill_priorities"":{""must_have"":[""Azure Data Factory"",""Databricks"",""Snowflake"",""Pyspark"",""SQL""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design a data pipeline with Azure Data Factory and Databricks?"",""example_answer"":""I would start by understanding the data requirements and then create a data pipeline using Azure Data Factory to handle data ingestion and Databricks for data processing and transformation.""},{""question"":""How do you ensure data quality and integrity in a data pipeline?"",""example_answer"":""I would implement data validation and data quality checks at each stage of the pipeline, and also perform regular data audits to ensure data accuracy and completeness.""}],""red_flags"":[""Lack of experience with cloud-based data platforms such as Azure, Databricks, or Google Cloud.""],""confidence_score"":90.0}"
Data Engineering Analyst,Sobeys,"Toronto, Ontario, Canada",March,2025,"Requisition ID: 187935

Career Group: Corporate Office Careers

Job Category: Data Science - Merchandising

Travel Requirements: 0 - 10%

Job Type: Full-Time

Country: Canada (CA)

Province: Ontario

City: Toronto

Location: Sobeys Innovation Hub

Embark on a rewarding career with Sobeys Inc., celebrated among Canada’s Top 100 employers, where your talents contribute to our commitment to excellence and community impact.

Our family of 128,000 employees and franchise affiliates share a collective passion for delivering exceptional shopping experiences and amazing food to all our customers. Our mission is to nurture the things that make life better – great experiences, families, communities, and our employees. We are a family nurturing families.

A proudly Canadian company, we started in a small town in Nova Scotia but we are now in communities of all sizes across this great country. With over 1,600 stores in all 10 provinces, you may know us as Sobeys, Safeway, IGA, Foodland, FreshCo, Thrifty Foods, Lawtons Drug Stores or another of our great banners but we are all one extended family.

Ready to Make an impact?

Job title - Data Engineering Analyst

Location: Sobeys COLAB Office (Toronto Downtown)

Team: Advanced Analytics

The Advanced Analytics team at Sobeys operates on the frontlines of retail innovation. We are a multi-disciplinary team of data scientists, engineers, developers, and analysts who design, develop, and deploy high-impact, scalable ML/AI solutions that are fundamentally transforming how Sobeys and its family of banners interact with customers and plan and operate their businesses. We leverage the latest cloud tech and advanced analytical techniques to connect the dots between customer behaviour and business operations and unearth the true drivers of customer engagement, sales growth, and profitability. Our work directly impacts the daily lives of millions of Canadian consumers and is a key pillar in our mission to deliver a best-in-class shopping experience for our customers.

In this role, you’ll have the chance to roll up your sleeves and apply data engineering methods and analytics to real-world business situations in one of the biggest retailers in Canada. The Data Engineer will play a key role in enhancing our advanced analytics and machine learning capabilities within the organization

Responsibilities

Here’s where you’ll be focusing:

Maintaining, streamlining and hardening existing data pipelines, from ingestion, through ETL and batch processing in order to reliably process billions of records per day.
Build data support for our personalization and experimentation efforts, solving problems from statistical test automation to building real-time M/L applications.
Working with Analytics and Product Management to ensure optimal data design and efficiency.
Assisting Data Analysts and Data Scientists with pipeline and model deployment
Use an analytical, data-driven approach to drive a deep understanding of our fast-changing business.
Building data models to deliver insightful analytics while ensuring the highest standard in data integrity.

Qualifications

What you have to offer:

Bachelor’s or higher degree in Engineering, Computer Science, Statistics, Economics, Mathematics, Finance or related quantitative field, or equivalent practical experience.
Experience on back-end data infrastructure in cloud, preferably like Databricks, Azure, Airflow, Snowflake
Ability to build, debug, optimize, monitor of large and complex spark data pipelines comprising of complex UDF.
Experience with SQL and SQL-like languages (2 year+)
Experience on cloud-based CI/CD infrastructure e.g. Azure DevOps, Jenkins, MLOps exposure. (2 year +)
Proficiency with at least one of the following languages: Java, Python, Scala. (Python is preferred) (2 year+)
Proficiency with Spark and Hadoop/YARN environment and comfortable with Linux operating system
Ability to creatively solve problems in a fast paced, rapidly changing environment
Ability to navigate ambiguity, drive solutions forward and bring stakeholders along.
Strong problem solving, analytical skills and capability of managing multiple projects and reporting simultaneously across different stakeholders.
Strong structured thinking and the ability to easily break down complex ambiguous problems and propose impactful data modeling designs.

At Sobeys we require our teammates to have the ability to adhere to a hybrid work model that requires your presence at one of our office locations at least three days per week. This requirement is integral to our commitment to team collaboration and the overall success of our office culture.

We offer a comprehensive Total Rewards package, which varies by role and designed to help our teammates to live better – physically, financially and emotionally.

Some websites share our job opportunities and may provide salary estimates without our knowledge. These estimates are based on similar jobs and postings for general comparison, but these numbers are not provided by our organization nor monitored for accuracy.

We will consider factors such as your working location, work experience and skills as well as internal equity, and market conditions to ensure the selected candidate is paid fairly and competitively. We look forward to discussing the specific compensation details relevant to this role with candidates who are selected to move forward in the recruitment process.

Our Total Rewards programs, for full-time teammates, goes well beyond your paycheque:

Competitive Benefits Package, tailored to meet your needs, including health and dental coverage, life, short- and long-term disability insurance.
Access to Virtual Health Care Platform and Employee and Family Assistance Program.
A Retirement and Savings Plan that provides you with the opportunity to build and add value to your savings.
A 10% in-store discount at our participating banners and access to a wide range of other discount programs, making your purchases more affordable.
Learning and Development Resources to fuel your professional growth.
Parental leave top-up
Paid Vacation and Days-off

We are committed to accommodating applicants with disabilities throughout the hiring process and will work with applicants requesting accommodation at any stage of this process.","{""role_summary"":""The Data Engineering Analyst will apply data engineering methods and analytics to real-world business situations in one of the biggest retailers in Canada, enhancing advanced analytics and machine learning capabilities within the organization."",""key_terms"":[{""term"":""Data pipelines"",""explanation"":""A series of processes that extract, transform, and load data for analysis and machine learning.""},{""term"":""ETL"",""explanation"":""Extract, Transform, Load - a process of extracting data from sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Machine Learning (ML)"",""explanation"":""A type of artificial intelligence that enables systems to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Cloud tech"",""explanation"":""Cloud computing technologies, such as Databricks, Azure, and Snowflake, that provide on-demand access to computing resources over the internet.""}],""skill_priorities"":{""must_have"":[""Experience with SQL and SQL-like languages"",""Experience with cloud-based CI/CD infrastructure"",""Proficiency with at least one of the following languages: Java, Python, Scala"",""Experience with Spark and Hadoop/YARN""],""nice_to_have"":[""Experience with Databricks, Azure, Airflow, Snowflake"",""MLOps exposure"",""Experience with statistical test automation""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you optimize a complex Spark data pipeline?"",""example_answer"":""I would use techniques such as caching, parallel processing, and data partitioning to improve performance.""},{""question"":""Can you explain how you would approach building a real-time M/L application?"",""example_answer"":""I would start by identifying the business problem, then design and develop a scalable architecture using cloud-based services and machine learning frameworks.""}],""red_flags"":[""Lack of experience with cloud-based data infrastructure"",""Inability to work with complex data pipelines"",""Limited proficiency with programming languages such as Python, Scala, or Java""],""confidence_score"":90.0}"
Software Engineer (Intern),Naptha AI,"Toronto, Ontario, Canada",February,2025,"Software Engineer (Intern) | naptha.ai

About This Role

We are seeking exceptional Software Engineering interns to join Naptha AI and contribute to building the future of AI agent infrastructure. This internship offers hands-on experience working with frontier AI technology, backed by industry veterans and technical leaders through NVIDIA Inception, Google for Startups, and Microsoft for Startups.

We're building the foundational infrastructure for the next wave of AI companies, enabling frontier AI developers to build products powered by enormous networks of highly capable next-generation AI agents. As an Engineering Intern, you'll work directly with our technical team on real projects that impact our core platform.

What You'll Do

Build and improve components of our agent infrastructure
Work on real features that ship to production
Collaborate with experienced engineers and researchers
Learn about large-scale AI systems and infrastructure
Contribute to our agent development platform
Gain experience with cutting-edge AI tools and frameworks

Technical Areas

Backend development with Python and modern frameworks
Agent system implementation and testing
API development and integration
Performance optimization and monitoring
Infrastructure and tooling development
Testing and deployment automation

Requirements

Currently pursuing BS/MS in Computer Science or related field
Strong programming skills, particularly in Python
Basic understanding of AI/ML concepts
Experience with software development practices
Ability to work independently and learn quickly
Strong problem-solving abilities

Nice to Have

Experience with AI frameworks or tools
Familiarity with distributed systems
Open source contributions
Experience with developer tools
Interest in AI infrastructure

About The Internship

Duration: 12-16 weeks
Location: Remote
Competitive compensation
Real-world project ownership
Mentorship from experienced engineers
Opportunity for return offers

This internship offers a unique opportunity to work on cutting-edge AI infrastructure while learning from experienced technical leaders. You'll gain practical experience building systems that power the next generation of AI applications.","{""role_summary"":""Contribute to building the future of AI agent infrastructure as a software engineering intern, working on real projects that impact our core platform."",""key_terms"":[{""term"":""AI agent infrastructure"",""explanation"":""The underlying systems and tools that enable the development and deployment of AI applications.""},{""term"":""Frontier AI technology"",""explanation"":""Cutting-edge AI tools and frameworks that are at the forefront of AI development.""},{""term"":""NVIDIA Inception"",""explanation"":""A program that supports startups with NVIDIA technology and expertise.""},{""term"":""Google for Startups"",""explanation"":""A program that supports startups with Google's resources and expertise.""},{""term"":""Microsoft for Startups"",""explanation"":""A program that supports startups with Microsoft's resources and expertise.""}],""skill_priorities"":{""must_have"":[""Python programming skills"",""Basic understanding of AI/ML concepts"",""Ability to work independently and learn quickly"",""Strong problem-solving abilities""],""nice_to_have"":[""Experience with AI frameworks or tools"",""Familiarity with distributed systems"",""Open source contributions"",""Experience with developer tools"",""Interest in AI infrastructure""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would optimize the performance of an AI agent?"",""example_answer"":""I would use techniques such as model pruning, knowledge distillation, and quantization to reduce the computational requirements of the AI agent while maintaining its performance.""},{""question"":""How do you stay up-to-date with the latest developments in AI?"",""example_answer"":""I regularly read research papers, attend conferences, and participate in online communities to stay current with the latest advancements in AI.""}],""red_flags"":[""Lack of experience with Python programming"",""No understanding of AI/ML concepts"",""Inability to work independently""],""confidence_score"":90.0}"
"Senior Software Engineer, Admin Area",Asana,"Vancouver, British Columbia, Canada",March,2025,"The Product team builds features end-to-end. From designing our data models to implementing the subtle interaction behaviors that differentiate good software from great software. We work closely with UI designers and are supported by our infrastructure team. We aim to delight users with both large new features and smaller, daily product enhancements—thanks to our continuous deployment architecture. We want to create a superlative user experience, down to the smallest details.

We are looking for a Senior Software Engineer to join the Data Management team in our Vancouver Office. The team plays a vital role in understanding the Asana data graph and ensuring the integrity and compliant use of data across the product. You’ll work on essential features touching the entire customer data lifecycle, such as data exports, object archiving, trashing & recovery, and audit logs. All of these are fundamental for Enterprise customers and involve handling and managing large-scale datasets to ensure smooth and secure operations.

Being part of this team will provide you with the opportunity to dive deep into Asana’s data graph, gaining a deep understanding of how data is managed at scale. While compliance is a key focus, our work goes beyond and empowers customers to efficiently manage their data across large, complex environments. You will implement efficient algorithms for handling vast datasets and work closely with cross-functional teams, including core infrastructure, product, and legal, to deliver scalable, secure solutions.

This role is based in our Vancouver office with an office-centric hybrid schedule. The standard in-office days are Monday, Tuesday, and Thursday. Most Asanas have the option to work from home on Wednesdays. Working from home on Fridays depends on the type of work you do and the teams with which you partner. If you're interviewing for this role, your recruiter will share more about the in-office requirements.

What You’ll Achieve
Work in a high-performance, dynamic team with a strong focus on velocity and software quality
Contribute to building a complex SaaS application that is a market leader in its segment
Be exposed to Asana’s core infrastructure, particularly how data is represented, stored and deleted in the storage layer.
Work with asynchronous jobs and efficiently and implement algorithms that efficiently traverse the Asana Work Graph
Work with legal to implement data ownership rules, requiring simple and effective technical solutions to make this process easy and clear to customers.
Drive large, impactful projects, delivering features that will be rolled out and used in large organizations
Support other teams and stakeholders that work in the team’s space

About You
Experience working in ambiguous and complex technical spaces and creating clarity and alignment with partners and stakeholders
Comfortable and autonomously diving deep into the weeds of complex technical contexts, to make sense of them, and then share their knowledge in a clear way with people in different roles and with different technical backgrounds
Have a strong understanding of software concepts and design patterns that make solutions scalable and robust.
Care deeply about the User Experience and comfortable working with frontend frameworks such as React.
Excited about mentoring and coaching teammates and stakeholders and contributing to leveling the team
Have experience driving projects of medium to large complexity.
You have a continuous improvement mindset and are never satisfied with the status quo, whether it's about the architecture, the code or the team's processes

At Asana, we're committed to building teams that include a variety of backgrounds, perspectives, and skills, as this is critical to helping us achieve our mission. If you're interested in this role and don't meet every listed requirement, we still encourage you to apply.

What We’ll Offer
Our comprehensive compensation package plays a big part in how we recognize you for the impact you have on our path to achieving our mission. We believe that compensation should be reflective of the value you create relative to the market value of your role. To ensure pay is fair and not impacted by biases, we're committed to looking at market value which is why we check ourselves and conduct a yearly pay equity audit.

For this role, the estimated base salary range is between $176,000 CAD - $224,000 CAD. The actual base salary will vary based on various factors, including market and individual qualifications objectively assessed during the interview process. The listed range above is a guideline, and the base salary range for this role may be modified.

In addition to base salary, your compensation package may include additional components such as equity, sales incentive pay (for most sales roles), and benefits. If you're interviewing for this role, speak with your Talent Acquisition Partner to learn more about the total compensation and benefits for this role.

We strive to provide equitable and competitive benefits packages that support our employees worldwide and include:
Mental health, wellness & fitness benefits
Career coaching & support
Inclusive family building benefits
Long-term savings or retirement plans
In-office culinary options to cater to your dietary preferences

These are just some of the benefits we offer, and benefits may vary based on role, country, and local regulations. If you're interviewing for this role, speak with your Talent Acquisition Partner to learn more about the total compensation and benefits for this role.

About Us
Asana helps teams orchestrate their work, from small projects to strategic initiatives. Millions of teams around the world rely on Asana to achieve their most important goals, faster. Asana has been named a Top 10 Best Workplace for 5 years in a row, is Fortune's #1 Best Workplace in the Bay Area, and one of Glassdoor’s and Inc.’s Best Places to Work. After spending more than a year physically distanced, Team Asana is safely and mindfully returning to in-person collaboration, incorporating flexibility that adds hybrid elements to our office-centric culture . With 11+ offices all over the world, we are always looking for individuals who care about building technology that drives positive change in the world and a culture where everyone feels that they belong.

We believe in supporting people to do their best work and thrive, and building a diverse, equitable, and inclusive company is core to our mission. Our goal is to ensure that Asana upholds an inclusive environment where all people feel that they are equally respected and valued, whether they are applying for an open position or working at the company. We provide equal employment opportunities to all applicants without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by law. We also comply with the San Francisco Fair Chance Ordinance and similar laws in other locations.","{""role_summary"":""As a Senior Software Engineer, you will work on essential features touching the entire customer data lifecycle, ensuring the integrity and compliant use of data across the product, and implement efficient algorithms for handling vast datasets and work closely with cross-functional teams."",""key_terms"":[{""term"":""Data Management"",""explanation"":""Understanding the Asana data graph, and ensuring the integrity and compliant use of data across the product.""},{""term"":""Data Exports"",""explanation"":""Handling and managing large-scale datasets to ensure smooth and secure operations.""},{""term"":""Object Archiving"",""explanation"":""Ensuring the integrity and compliant use of data across the product.""},{""term"":""Audit Logs"",""explanation"":""Handling and managing large-scale datasets to ensure smooth and secure operations.""},{""term"":""Asynchronous Jobs"",""explanation"":""Efficiently traversing the Asana Work Graph.""},{""term"":""Data Ownership Rules"",""explanation"":""Implementing simple and effective technical solutions to make this process easy and clear to customers.""}],""skill_priorities"":{""must_have"":[""Experience working in ambiguous and complex technical spaces"",""Strong understanding of software concepts and design patterns"",""Comfortable working with frontend frameworks such as React"",""Experience driving projects of medium to large complexity""],""nice_to_have"":[""Mentoring and coaching teammates and stakeholders"",""Continuous improvement mindset""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach complex technical spaces and create clarity and alignment with partners and stakeholders?"",""example_answer"":""I use a structured approach to break down complex technical spaces into manageable components, and then communicate these solutions clearly to stakeholders.""},{""question"":""Can you give an example of a scalable solution you've implemented in a previous role?"",""example_answer"":""In my previous role, I implemented a scalable solution using asynchronous jobs to efficiently traverse a large dataset, resulting in a significant improvement in performance.""}],""red_flags"":[""Lack of experience working with complex technical spaces"",""Inability to communicate technical solutions effectively to non-technical stakeholders""],""confidence_score"":90.0}"
Sr. Data Analyst - CANADA (Remote),Luxury Presence,Greater Montreal Metropolitan Area,February,2025,"About Us
Luxury Presence is the leading digital platform revolutionizing the real estate industry for agents, teams, and brokerages. Our award-winning websites, cutting-edge marketing solutions, and AI-powered mobile platform empower real estate professionals to grow their business, operate more efficiently, and deliver exceptional service to their clients. Trusted by over 60,000 real estate professionals, including 31 of the nation’s 100 top-performing agents as published in the Wall Street Journal, Luxury Presence continues to set the standard for innovation and excellence in real estate technology.

Position

Title: Sr. Data Analyst

Location: Canada, Remote

Compensation: Stock Options, Flex PTO, Health/Vision/Dental, Retreats

Why Now?

We’ve enjoyed tremendous growth over the last 5 years. With that growth comes a treasure trove of data that is valuable to us, and our customers. We need experienced and passionate data analysts to help us realize that value and unlock the insights that exist at the intersection of our operational, financial, and product data. This is a unique opportunity to join a fast growing startup and build our data team, culture, and processes from the ground up.

What You’ll Do

Deliver recommendations and actionable insights to key stakeholders to help drive revenue
Use strong technical and business intuition to optimize GTM motions, ensuring data-driven approaches drive efficiency, revenue growth, and customer acquisition
Solve difficult open ended up problems through novel data solutions and analytics
Support development of predictive models to support strategic and operational initiatives
Build dashboards, data products, and ad hoc report studies to analyze and present data associated with GTM analytics, product performance, business operations, and strategic decision making
Work with key stakeholders and the leadership team to define and monitor KPIs across the company
Build production-ready data models and schemas using DBT to support downstream analytics




Must Haves

Proficiency in SQL
Proficiency in any statistical programming language (i.e, Python or R)
5+ years in doing analytics with a robust understanding of statistical concepts
Experience working with BI tools (Sigma, Tableau, SiSense, Hex, or Looker etc)
Experience building predictive/forecasting models
Ability to work independently, and lead projects from start to finish
Ability to handle multiple stakeholders, and prioritize competing requests
Ability to identify and push for process improvements for the teams we support
Ability to communicate technical concepts to both technical and non-technical audiences through visualizations and presentations
Ability to partner with leadership and stakeholders across the company to understand business needs and how these can be addressed through analytics
Experience supporting any GTM teams including Sales, Marketing, or Customer Success




Nice to Haves

M.S. in Math, Statistics, or closely related quantitative field
Experience with Snowflake and dbt
Experience building supervised and unsupervised learning models
Experience working in a B2B or SaaS company




Join us in shaping the future of real estate
The real estate industry is in the midst of a seismic shift, and the future belongs to those who break new ground. As one of the fastest-growing companies in the proptech and marketing sectors, Luxury Presence challenges the status quo of what technology can do for real estate agents, leaders, and brokerages.

We’re a team of agile and tenacious innovators working collaboratively to drive the industry forward. Together, we build game-changing products that empower modern real estate entrepreneurs to dominate their markets. From award-winning web design to agile SEO solutions to cutting-edge AI tools, we deliver tech that anticipates market shifts and keeps our clients ahead of their competition.

Founded in 2016 by Stanford Business School alum Malte Kramer, Luxury Presence has grown to a global team ranked on the Inc. 5000 fastest-growing companies list three years in a row. We’re backed by world-class investors, including Bessemer Venture Partners, Toba Capital, and Switch Ventures, and have raised $52.6 million to date.

More than 13,000 real estate businesses rely on our platform, including 31 of the RealTrends top 100 agents featured in The Wall Street Journal. Additionally, many of the industry’s most powerful brokerages — including Compass, Coldwell Banker, and Sotheby’s International Realty — rely on Luxury Presence as a trusted business partner.

Every year since 2020, Luxury Presence has ranked on BuiltIn’s Best Place to Work lists. HousingWire named our founder and CEO a 2024 Tech Trendsetter, we’ve received several Tech100 Awards, and our lead nurturing tool just scored an Inman Innovation Award for Best AI-Powered Platform.

Luxury Presence is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin.","{""role_summary"":""As a Sr. Data Analyst, you will deliver actionable recommendations to drive revenue, optimize business processes, and unlock insights from operational, financial, and product data, supporting Luxury Presence's growth and innovation in real estate technology."",""key_terms"":[{""term"":""Data Analyst"",""explanation"":""A professional responsible for analyzing and interpreting complex data to inform business decisions.""},{""term"":""GTM"",""explanation"":""Go-to-Market strategy, referring to the process of launching and promoting a product or service to the market.""},{""term"":""DBT"",""explanation"":""Data Build Tool, a platform for building and managing data pipelines and models.""}],""skill_priorities"":{""must_have"":[""Proficiency in SQL"",""Proficiency in statistical programming language"",""5+ years of analytics experience"",""Experience with BI tools"",""Experience building predictive models"",""Ability to work independently and lead projects"",""Ability to communicate technical concepts to various audiences""],""nice_to_have"":[""M.S. in Math, Statistics, or related field"",""Experience with Snowflake and dbt"",""Experience building supervised and unsupervised learning models"",""Experience working in a B2B or SaaS company""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a time when you had to communicate complex data insights to a non-technical stakeholder?"",""example_answer"":""In my previous role, I had to present data-driven recommendations to the marketing team. I used visualizations and clear explanations to ensure they understood the insights and could make informed decisions.""},{""question"":""How do you stay up-to-date with new tools and technologies in the data analytics space?"",""example_answer"":""I regularly attend industry conferences, participate in online forums, and take online courses to expand my skill set and stay current with industry trends.""}],""red_flags"":[""Lack of experience working with GTM teams"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":95.0}"
Data Engineer II,Zafin,"Toronto, Ontario, Canada",January,2025,"Who we are

Founded in 2002, Zafin offers a SaaS product and pricing platform that simplifies core modernization for top banks worldwide. Our platform enables business users to work collaboratively to design and manage pricing, products, and packages, while technologists streamline core banking systems.

With Zafin, banks accelerate time to market for new products and offers while lowering the cost of change and achieving tangible business and risk outcomes. The Zafin platform increases business agility while enabling personalized pricing and dynamic responses to evolving customer and market needs.

Zafin is headquartered in Vancouver, Canada, with offices and customers around the globe including ING, CIBC, HSBC, Wells Fargo, PNC, and ANZ. Zafin is proud to be recognized as a top employer and certified Great Place to Work® in Canada, India and the UK.

What You Will Do

We're looking for a product-focused Senior Data Engineer. In this role, you build and maintain the cloud-based data stack that powers Zafin Analytics. You will think deeply about the undercurrents of data engineering, such as security, DataOps, data modelling and data integration – to help design the data architecture that delivers on the product roadmap, while maintaining a high standard for scalability, data integrity and reliability.

If you are passionate about building hi-tech products, comfortable with ambiguity, have the lateral skills to go from roadmap to architecture to code, and most importantly, if you want to apply your engineering chops to make an impact, talk to us.



Location: Toronto



As a Data Engineer, you will:

Build the pipeline to ingest data from source systems to a cloud-based data warehouse and perform required data transformations.
Develop the analytics product from prototyping to production-quality code.
Implement processes to monitor data quality and the health of the data pipeline.
Implement test cases for the data pipelines and the data-intensive application.
Define and extend the data model required to power the analytics use-cases.
Contribute to the analytics strategy and help set up the data infrastructure stack.
Apply software engineering best practices to analytics code (e.g., version control, testing, CI/CD).

To be successful in this position, you must have:

Bachelor of Computer Science or a related technical field.
4+ years of experience as a Data Engineer.
Experience with Java or Python.
Demonstrated expertise in engineering data-intensive applications.
Ability to work with large datasets, including the skills to establish scalable data pipelines.
Schema design for data warehouses, preferably with cloud-native data warehouses.
Experience with Infrastructure as Code.
Although not required, please highlight your Lambda or Kappa architecture experience.

What's in it for you

Joining our team means being part of a culture that values diversity, teamwork, and high-quality work. We offer competitive salaries, annual bonus potential, generous paid time off, paid volunteering days, wellness benefits, and robust opportunities for professional growth and career advancement. Want to learn more about what you can look forward to during your career with us? Visit our careers site and our openings: zafin.com/careers

Zafin welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.

Zafin is committed to protecting the privacy and security of the personal information collected from all applicants throughout the recruitment process. The methods by which Zafin contains uses, stores, handles, retains, or discloses applicant information can be accessed by reviewing Zafin's privacy policy at https://zafin.com/privacy-notice/. By submitting a job application, you confirm that you agree to the processing of your personal data by Zafin described in the candidate privacy notice.","{""role_summary"":""Design and maintain a cloud-based data stack for Zafin Analytics, focusing on data engineering, security, and scalability."",""key_terms"":[{""term"":""DataOps"",""explanation"":""Data Operations, a set of practices to improve collaboration and efficiency in data management.""},{""term"":""Data modelling"",""explanation"":""The process of creating a conceptual representation of data structures to support business processes.""},{""term"":""Lambda or Kappa architecture"",""explanation"":""Cloud-native architecture patterns for designing scalable and fault-tolerant data pipelines.""}],""skill_priorities"":{""must_have"":[""4+ years of experience as a Data Engineer"",""Experience with Java or Python"",""Demonstrated expertise in engineering data-intensive applications"",""Ability to work with large datasets and establish scalable data pipelines"",""Schema design for data warehouses, preferably with cloud-native data warehouses""],""nice_to_have"":[""Experience with Lambda or Kappa architecture""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach data quality and health of the data pipeline?"",""example_answer"":""I implement processes to monitor data quality issues and develop test cases for the data pipelines and data-intensive application.""},{""question"":""Can you explain your experience with Infrastructure as Code?"",""example_answer"":""I have experience with schema design for data warehouses and have implemented Infrastructure as Code to manage data infrastructure.""}],""red_flags"":[""Lack of experience with cloud-native data warehouses"",""Inability to work with large datasets""],""confidence_score"":90.0}"
AWS Data Engineer-Developer,J&M Group,"Toronto, Ontario, Canada",October,2024,"Role Description: AWS Redshift, AWS GLUE, Python, Pyspark, Cloud Data Engineering

Competencies: Digital : Python, Digital : NoSQL Key-Value DB

Experience (Years): 10 & Above

Essential Skills: AWS Redshift, AWS GLUE, Python, Pyspark, Cloud Data Engineering","{""role_summary"":""Design and implement data engineering solutions on cloud-based platforms, utilizing tools like AWS Redshift and GLUE, and programming languages such as Python and Pyspark."",""key_terms"":[{""term"":""AWS Redshift"",""explanation"":""A cloud-based data warehousing and analytics service by Amazon Web Services.""},{""term"":""AWS GLUE"",""explanation"":""A fully managed extract, transform, and load (ETL) service offered by AWS.""},{""term"":""Pyspark"",""explanation"":""A Python library for large-scale data processing, built on top of Apache Spark.""},{""term"":""Cloud Data Engineering"",""explanation"":""The process of designing, building, and managing large-scale data systems on cloud-based infrastructure.""}],""skill_priorities"":{""must_have"":[""AWS Redshift"",""AWS GLUE"",""Python"",""Pyspark"",""Cloud Data Engineering""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the difference between AWS Redshift and AWS GLUE?"",""example_answer"":""AWS Redshift is a data warehousing service, while AWS GLUE is an ETL service. Redshift is used for data storage and querying, whereas GLUE is used for data integration and transformation.""},{""question"":""How do you optimize data processing in Pyspark?"",""example_answer"":""I use techniques like caching, broadcasting, and parallel processing to optimize data processing in Pyspark.""}],""red_flags"":[""Avoid candidates without cloud experience"",""Be cautious of candidates with limited experience in data engineering""],""confidence_score"":90.0}"
Software Engineer Intern (Summer 2025),Block,"Toronto, Ontario, Canada",March,2025,"Block is one company built from many blocks, all united by the same purpose of economic empowerment. The blocks that form our foundational teams — People, Finance, Counsel, Hardware, Information Security, Platform Infrastructure Engineering, and more — provide support and guidance at the corporate level. They work across business groups and around the globe, spanning time zones and disciplines to develop inclusive People policies, forecast finances, give legal counsel, safeguard systems, nurture new initiatives, and more. Every challenge creates possibilities, and we need different perspectives to see them all. Bring yours to Block.

The Role

Our Software Engineers keep Block simple and make our users faster and smarter. We're looking for engineers of all skillsets, who are excited about building outstanding software and solving hard problems. Our challenges span many technologies, from web and mobile applications (iOS, Android) to server-side development (Java, Ruby). As an engineer at Block, you will work on a small team with people across engineering, product, and creative, building reliable, fast, responsive, and beautiful software.

You Will

Reliability: Ensure our products work right, every time, by using testing, continuous integration, and in-depth code reviews
Security: Create interactions and APIs that promote trust, increase security, and make it harder to do the wrong thing
Analytics: Collect all the data around every transaction and turn it into tools that help our users
Products: Envision entire new products, features, and flows that are inspired, considered, and magical
Fraud Prevention: Make quick decisions on millions of dollars which requires diligence and passion for detecting bad actors and preventing loss

You Have

Pursuing degree in Computer Science, Electrical Engineering, Math or related technical field, graduating between May 2026 and May 2027. Recent bootcamp graduates and engineering training participants are also considered within three months of completing program/training requirements
Programming experience in one or more object-oriented languages, including: Java, Python, Ruby, Go, Kotlin, Swift, C, and C++
Internships are 12-weeks
Co-op placements are 16 weeks

Technologies We Use And Teach

Java, Python, Ruby, Go, Kotlin, Swift, C, and C++

We’re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is an equal opportunity employer evaluating all employees and job applicants without regard to identity or any legally protected class. We also consider qualified applicants with criminal histories for employment on our team, and always assess candidates on an individualized basis.

We believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations throughout the recruitment process. If you require an accommodation, let your recruiter know.

Want to learn more about what we’re doing to build an inclusive workplace? Check out our Inclusion & Diversity page.

Every benefit we offer is designed with one goal: empowering you to do the best work of your career while building the life you want. Remote work, medical insurance, flexible time off, retirement savings plans, and modern family planning are just some of our offering. Check out our other benefits at Block.

Block, Inc. (NYSE: XYZ) builds technology to increase access to the global economy. Each of our brands unlocks different aspects of the economy for more people. Square makes commerce and financial services accessible to sellers. Cash App is the easy way to spend, send, and store money. Afterpay is transforming the way customers manage their spending over time. TIDAL is a music platform that empowers artists to thrive as entrepreneurs. Bitkey is a simple self-custody wallet built for bitcoin. Proto is a suite of bitcoin mining products and services. Together, we’re helping build a financial system that is open to everyone.

Privacy Policy","{""role_summary"":""As a Software Engineer at Block, you will work on a small team to build reliable, fast, responsive, and beautiful software, solving hard problems and ensuring products work right every time."",""key_terms"":[{""term"":""Continuous Integration"",""explanation"":""A development practice where code changes are automatically built, tested, and prepared for production.""},{""term"":""Object-Oriented Languages"",""explanation"":""Programming languages that organize code into objects and classes, such as Java, Python, Ruby, Go, Kotlin, Swift, C, and C++.""}],""skill_priorities"":{""must_have"":[""Programming experience in one or more object-oriented languages"",""Pursuing degree in Computer Science, Electrical Engineering, Math or related technical field""],""nice_to_have"":[""Internship or co-op experience"",""Recent bootcamp graduates""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach ensuring the reliability of a software product?"",""example_answer"":""I use testing, continuous integration, and in-depth code reviews to ensure our products work right every time.""},{""question"":""Can you give an example of a time when you had to make a quick decision on a complex problem?"",""example_answer"":""In my previous role, I had to quickly identify and prevent fraudulent transactions, requiring diligence and passion for detecting bad actors.""}],""red_flags"":[""Lack of experience with object-oriented languages"",""Inability to work in a fast-paced environment with tight deadlines""],""confidence_score"":90.0}"
Senior Software Engineer - Integrations,Cut+Dry,"Toronto, Ontario, Canada",February,2025,"Who We’re Looking For
The Senior Software Engineer will act as both a hands-on software engineer and a liaison between our customers and integration developers. You will be responsible for performing integrations which typically involve coding, developing requirements, estimating tasks, and providing technical leadership to our offshore development team. Your expertise in software development, cloud platforms, and integration processes will be essential in executing integration projects and guiding the development team. Additionally, you will analyse integration processes to identify commonalities and implement improvements for greater efficiency and reuse. We are a 100% remote company, but have regional concentrations of team members in Canada, the United States and Sri Lanka. In this role you will be coordinating with team members in every location.
Job Responsibilities:
Hands-On Integration: Perform coding tasks required for integrations in order to become an expert in our integration processes and technologies.
Technical Leadership: Provide technical guidance and mentorship to the offshore development team.
Liaison Role: Serve as the primary technical point of contact between U.S. customers and the development team in Sri Lanka.
Requirement Development: Gather, analyze, and document customer requirements for integration projects.
Task Estimation: Evaluate and estimate the time and resources needed for development tasks.
Team Coordination: Manage and coordinate the activities of the offshore development team to ensure project milestones are met.
Process Improvement: Identify commonalities across different integrations and enhance our systems to improve efficiency and promote code reuse.
Project Execution: Oversee the integration process from initiation to completion, ensuring alignment with customer expectations.
Quality Assurance: Monitor project outcomes to ensure they meet quality standards and customer requirements.
Stakeholder Communication: Regularly update internal and external stakeholders on project status, challenges, and solutions.
Qualifications:
Education: Bachelor's degree in Computer Science, Information Technology, or a related field.
Experience: Minimum of 5 years of experience in software integration, development, or a related technical role.
Technical Skills:
Strong proficiency in software development and coding practices.
Experience with programming languages such as PHP, Python, or JavaScript.
Familiarity with cloud platforms like AWS, Azure, or Google Cloud Platform.
Knowledge of databases such as SQL or NoSQL databases.
Experience with API integrations and file-based data exchange.
Understanding of web technologies and frameworks.
Leadership Skills: Proven experience in leading and mentoring development teams.
Process Improvement: Demonstrated ability to analyze processes and implement improvements for efficiency.
Communication Skills:
Exceptional verbal and written communication abilities, especially with non-technical stakeholders.
Must be fluent in English, with excellent spoken and written skills, to effectively communicate with U.S customers.
Analytical Skills: Strong problem-solving skills with a focus on attention to detail.
Preferred Qualifications:
Experience with PHP, AWS services (especially S3), React, and SQL.
Familiarity with cloud-based integration tools.
Relevant technical certifications.
Food service experience.
Who We AreCut+Dry is a fast-growing FoodTech startup searching for flexible go-getters who welcome the challenge of meeting the needs of a rapidly expanding business. Our company is revolutionizing the $300B US food supply industry by directly connecting the people who produce and distribute food with those who purchase and prepare it in a commercial setting. Our platform provides wholesale suppliers, manufacturers, and their customers (restaurants, caterers, hotels, lodging, etc.) with an all-in-one order management, shopping, payment, marketing, and tracking solution. Our solution drives revenue and saves valuable time, allowing users to do more with their existing staff, and ultimately, build a more profitable business.
The Cut+Dry founders and executive team have a background uniquely suited to attack this complicated problem. Consisting of lifelong Silicon Valley entrepreneurs, the leaders have built and exited multiple startups and possess deep domain expertise in the restaurant and food supply chain business. The founders have sold prior startups to the world’s largest food distributor, Sysco, and were directly responsible for building Sysco’s industry leading digital customer experiences.
Why Work at Cut+Dry?
Results-driven company culture that encourages a balanced lifestyle
Base salary + stock options package
Paid Medical, Dental, and Vision
401k Plan
Unlimited PTO
Flexible remote (work-from-anywhere) environment
Workspace equipment provided (computer, external monitor, and VoIP headset)
Powered by JazzHR
0s2fjRE24a","{""role_summary"":""The Senior Software Engineer will act as a hands-on software engineer and a liaison between customers and integration developers, performing integrations, developing requirements, estimating tasks, and leading the development team."",""key_terms"":[{""term"":""Cloud platforms"",""explanation"":""Cloud-based services like AWS, Azure, or Google Cloud Platform used for integration and development.""},{""term"":""Integration processes"",""explanation"":""The steps involved in integrating different systems or applications, including coding, testing, and deployment.""},{""term"":""API integrations"",""explanation"":""The process of connecting different applications or systems using APIs to exchange data or functionality.""}],""skill_priorities"":{""must_have"":[""Software development and coding practices"",""Experience with programming languages like PHP, or JavaScript"",""Familiarity with cloud platforms like AWS, Azure, or Google Cloud Platform"",""Leadership and mentoring experience"",""Process improvement and analytical skills""],""nice_to_have"":[""Experience with PHP, AWS services (especially S3), React, and SQL"",""Familiarity with cloud-based integration tools"",""Relevant technical certifications"",""Food service experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with cloud platforms and how you've used them for integration projects?"",""example_answer"":""I've worked with AWS for several integration projects, and I'm familiar with its services like S3. I've used cloud platforms to improve efficiency and scalability in my previous projects.""},{""question"":""How do you approach process improvement, and can you give an example of a successful improvement you've made?"",""example_answer"":""I analyze the current process, identify bottlenecks, and implement improvements. For example, I once improved the code review process by implementing automated testing, which reduced the review time by 30%.""}],""red_flags"":[""Lack of experience with cloud platforms or integration processes"",""Inability to communicate technical information to non-technical stakeholders"",""No experience with leading or mentoring development teams""],""confidence_score"":90.0}"
"Machine Learning Software Engineer, Mapping",Lyft,"Toronto, Ontario, Canada",March,2025,"At Lyft, our purpose is to serve and connect. To do this, we start with our own community by creating an open, inclusive, and diverse organization.

With over half a billion rides and counting, Lyft is solving hard problems in a rapidly growing domain with a lot of data and creative solutions in Mapping to better serve our customers. The mapping organization is seeking a machine learning engineer to help turn our telemetry and feedback pipelines into improved traffic predictions for more accurate ETAs. Accurate ETAs are important for providing the best service for both our drivers and riders. Our highly motivated Machine Learning Engineers work on these challenging problems and define solutions to directly impact various aspects of our core business.

If you are a critical thinker with experience in machine learning workflows, passionate about solving business problems using data and working in a dynamic, creative, and collaborative environment, we are searching for you.

As a machine learning engineer, you will be developing and launching the algorithms that power Mapping systems to create better experiences for our customers. Compared to similarly-sized technology companies, the set of problems that we tackle is incredibly diverse. We are hiring motivated experts in each of these fields. We’re looking for someone who is passionate about solving problems with data, building reliable ML systems, and is excited about working in a fast-paced, innovative, and collegial environment.

Responsibilities:

Partner with Engineers, Data Scientists, Product Managers, and Business Partners to apply machine learning for business and user impact
Perform data analysis and build proof-of-concept to explore and propose ML solutions to both new and existing problems
Develop statistical, machine learning, or optimization models
Write production quality code to launch machine learning models at scale
Evaluate machine learning systems against business goal

Experience:

B.S., M.S., or Ph.D. in Computer Science or other quantitative fields or related work experience
3+ years of Machine Learning experience
Passion for building impactful machine learning models leveraging expertise in one or multiple fields.
Proficiency in Python, Golang, or other programming language
Excellent communication skills and fluency in English
Strong understanding of Machine Learning methodologies, including supervised learning, forecasting, reinforcement learning, and neural networks.
Interest and experience in the Mapping domain.

Benefits:

Extended health and dental coverage options, along with life insurance and disability benefits
Mental health benefits
Family building benefits
Child care and pet benefits
Access to a Lyft funded Health Care Savings Account
RRSP plan to help save for your future
In addition to provincial observed holidays, salaried team members are covered under Lyft's flexible paid time off policy. The policy allows team members to take off as much time as they need (with manager approval). Hourly team members get 15 days paid time off, with an additional day for each year of service
Lyft is proud to support new parents with 18 weeks of paid time off, designed as a top-up plan to complement provincial programs. Biological, adoptive, and foster parents are all eligible.
Subsidized commuter benefits

Lyft proudly pursues and hires a diverse workforce. Lyft believes that every person has a right to equal employment opportunities without discrimination because of race, ancestry, place of origin, colour, ethnic origin, citizenship, creed, sex, sexual orientation, gender identity, gender expression, age, marital status, family status, disability, pardoned record of offences, or any other basis protected by applicable law or by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Accommodation for persons with disabilities will be provided upon request in accordance with applicable law during the application and hiring process. Please contact your recruiter now if you wish to make such a request.

This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Wednesdays, and Thursdays. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid

The expected base pay range for this position in the Toronto area is CAD $118,000 - CAD $163,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.","{""role_summary"":""Develop and launch machine learning algorithms that power Mapping systems to create better experiences for customers, working collaboratively with cross-functional teams."",""key_terms"":[{""term"":""Machine Learning"",""explanation"":""Using data and algorithms to enable machines to learn and make predictions or decisions.""},{""term"":""Telemetry"",""explanation"":""Automated data collection and transmission from devices or systems, used to improve traffic predictions.""},{""term"":""ETAs"",""explanation"":""Estimated Time of Arrival, a critical metric for ride-hailing services to provide accurate pickup times.""},{""term"":""Mapping"",""explanation"":""The process of creating and maintaining digital maps for navigation and location-based services.""}],""skill_priorities"":{""must_have"":[""Machine Learning experience"",""Python or other programming language proficiency"",""Strong understanding of Machine Learning methodologies"",""Excellent communication skills""],""nice_to_have"":[""Experience in the Mapping domain"",""Golang programming language proficiency""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a machine learning model to improve traffic predictions?"",""example_answer"":""I would start by analyzing the telemetry data, identifying key features that impact traffic patterns, and then develop a supervised learning model to predict ETAs. I would also consider using reinforcement learning to optimize the model for real-time traffic updates.""},{""question"":""How do you evaluate the performance of a machine learning model in a production environment?"",""example_answer"":""I would use metrics such as mean absolute error, mean squared error, and R-squared to evaluate the model's performance. I would also monitor the model's performance over time to identify potential issues or areas for improvement.""}],""red_flags"":[""Lack of experience with machine learning workflows"",""Inability to communicate complex technical concepts effectively""],""confidence_score"":95.0}"
Data Analyst - GCP,Tata Consultancy Services,"Mississauga, Ontario, Canada",March,2025,"Inclusion without Exception

Tata Consultancy Services (TCS) is an equal opportunity employer, and embraces diversity in race, nationality, ethnicity, gender, age, physical ability, neurodiversity, and sexual orientation, to create a workforce that reflects the societies we operate in. Our continued commitment to Culture and Diversity is reflected in our people stories across our workforce and implemented through equitable workplace policies and processes.

About TCS

TCS is an IT services, consulting, and business solutions organization that has been partnering with many of the world’s largest businesses in their transformation journeys for over 55 years. Its consulting-led, cognitive-powered portfolio of business, technology, and engineering services and solutions is delivered through its unique Location Independent Agile™ delivery model, recognized as a benchmark of excellence in software development. A part of the Tata group, India's largest multinational business group, TCS employs over 612,000 of the world’s best-trained consultants in 55 countries. The company generated consolidated revenues of US $29 billion in the fiscal year ended March 31, 2024, and is listed on the BSE and the NSE in India. TCS' proactive stance on climate change and award-winning work with communities across the world have earned it a place in leading sustainability indices such as the MSCI Global Sustainability Index and the FTSE4Good Emerging Index.

Required Skills:
· Data Collection & Cleaning: Gathering data from various sources and ensuring its accuracy and consistency through cleaning and preprocessing.
· Data Analysis: Using statistical methods and analytical tools to identify patterns, trends, and insights within the data.
· Data Visualization: Creating clear and compelling visual representations of data, such as charts and dashboards, to facilitate decision-making.
· Reporting: Generating detailed reports and summaries that communicate findings effectively to stakeholders.
· Collaboration: Working closely with cross-functional teams to understand business requirements and tailor data analysis to support strategic initiatives.
· Continuous Improvement: Regularly evaluating data processes and methodologies to enhance data quality and analysis efficiency.
Roles & Responsibilities:
· combination of technical expertise, hands-on experience with data science tools and methodologies, familiarity with cloud technologies, and the ability to drive impactful insights from data.

Tata Consultancy Services Canada Inc. is committed to meeting the accessibility needs of all individuals in accordance with the Accessibility for Ontarians with Disabilities Act (AODA) and the Ontario Human Rights Code (OHRC). Should you require accommodations during the recruitment and selection process, please inform Human Resources.
Thank you for your interest in TCS. Candidates that meet the qualifications for this position will be contacted within a 2-week period. We invite you to continue to apply for other opportunities that match your profile.","{""role_summary"":""This role is responsible for collecting, cleaning, and visualizing data to support strategic business initiatives, collaborating with cross-functional teams and driving impactful insights from data."",""key_terms"":[{""term"":""Data Collection & Cleaning"",""explanation"":""Gathering data from various sources and ensuring its accuracy and consistency through cleaning and preprocessing.""},{""term"":""Data Analysis"",""explanation"":""Using statistical methods and analytical tools to identify patterns, trends, and insights within the data.""},{""term"":""Data Visualization"",""explanation"":""Creating clear and compelling visual representations of data, such as charts and dashboards, to facilitate decision-making.""},{""term"":""Cloud Technologies"",""explanation"":""Familiarity with cloud-based platforms and tools for data analysis and processing.""}],""skill_priorities"":{""must_have"":[""Data Collection & Cleaning"",""Data Analysis"",""Data Visualization"",""Cloud Technologies""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the importance of data cleaning and preprocessing in data analysis?"",""example_answer"":""Data cleaning and preprocessing are crucial steps in ensuring the accuracy and consistency of data, which in turn affects the reliability of the insights generated from the data.""},{""question"":""How do you stay updated with the latest developments and advancements in data analysis and visualization?"",""example_answer"":""I regularly follow industry blogs, attend webinars, and participate in online forums to stay current with the latest trends in data analysis and visualization.""}],""red_flags"":[""Lack of hands-on experience with data analysis and visualization tools"",""Inability to communicate complex data insights effectively to stakeholders""],""confidence_score"":90.0}"
"Data Engineer, Dash Finance",Dropbox,Canada,March,2025,"Dropbox is a Virtual First company. For this role, we are currently only authorized to hire candidates from the following provinces: Alberta, British Columbia, Ontario, and Saskatchewan.

Company Description

Dropbox isn’t just a workplace—it’s a living lab for more enlightened ways of working. We're a global community of more than 2,000 bold visionaries and resourceful doers who are shaping the future of Dropbox—and with it the future of work. Our Virtual First model combines the flexibility of a distributed workplace with the power of human connection, making space for both meaningful work and meaningful relationships. With our start-up mindset and enterprise-level opportunities, you can be who you are and grow into who you’re meant to be. Here, you can own your impact to make work more intuitive, joyful, and human—for you as a Dropboxer and for hundreds of millions of people worldwide. If you're ready to push boundaries—and yourself— Dropbox is ready for you.

Team Description

The Dropbox Engineering Team builds the technology that creates more enlightened ways of working for hundreds of millions of people. Every day, our platforms—including Dropbox Dash, Dropbox Sign, and our core sync engine—handle over a billion files for users worldwide, creating engineering challenges as great as the opportunity for impact. Our software engineering team uses a range of technologies to solve interesting problems, including Python, React, Node.js, JavaScript, MongoDB, PostgreSQL, and Android development. We think like a startup but build for an enterprise, exploring new possibilities that transform how people work. If you're excited about turning complex technical challenges into intuitive solutions at scale, join our Engineering team. Areas of work include Machine Learning Engineers, Infrastructure Engineer, Product SWE Frontend and Backend, Mobile Software Engineers (iOS and Android), Engineering Manager, Data Engineer, Software Development Engineer in Test, Security Engineering, Site Reliability Engineer, Technical Program Managers, Network Engineer, Datacenter Engineer, Technical Supply Chain Manager and more.

Role Description

Dropbox is seeking a highly skilled and motivated Data Engineer to join our dynamic Financial Data Engineering team. You will be responsible for building next-generation financial data pipelines that support crucial business decisions across the organization. The ideal candidate will have extensive experience migrating from other platforms to Databricks, a strong culture of innovation and accountability, and expertise in developing data health metrics that integrate with data governance, observability, and quality management tools.

If you enjoy thinking about how businesses can utilize data and figuring out how to build it, this role is perfect for you. With a solid foundation in test-driven development and experience in building scalable data pipelines, as well as familiarity with traditional data warehousing (DW) and ETL architectures, and significant experience with ecosystems like Databricks, Snowflake, EMR, and Airflow, you would be a great fit for our team. By collaborating with cross-functional teams, you will have the opportunity to drive substantial business impact, as high data quality and effective tooling are key to achieving significant growth at Dropbox.

Our Engineering Career Framework is viewable by anyone outside the company and describes what’s expected for our engineers at each of our career levels. Check out our blog post on this topic and more here.

Responsibilities

Participate in data migration from legacy platforms to Databricks and develop scalable, efficient, and cost-optimized data pipelines
Build and integrate data health metrics and quality management tools, ensuring robust data governance and consistent standards
Design and maintain tools for efficient data investigations, issue detection, and automated mitigation to uphold data quality and consistency
Replace outdated infrastructure with modern systems and provide operational support for critical data pipelines
Solve complex data integration challenges using optimal ETL patterns, frameworks, and techniques for structured and unstructured data
Collaborate with cross-functional teams to meet technical and business needs while fostering a culture of innovation and continuous improvement
Define and manage SLAs for high-priority datasets, including those driving critical (P0) business metrics
Apply Agile methodologies and industry best practices to ensure consistent delivery and alignment with business objectives

Many teams at Dropbox run Services with on-call rotations, which entails being available for calls during both core and non-core business hours. If a team has an on-call rotation, all engineers on the team are expected to participate in the rotation as part of their employment. Applicants are encouraged to ask for more details of the rotations to which the applicant is applying.

Requirements

5+ years of experience in data engineering or related roles
Bachelor’s degree or foreign equivalent in Computer Science or a closely related field
Proven experience with data migration projects, specifically to Databricks
Strong expertise in data health metrics, data governance, and quality management, with experience integrating tools like Monte Carlo and Atlan
Solid experience in building and maintaining data pipelines and infrastructure
Excellent problem-solving skills and the ability to troubleshoot complex data issues
Strong programming skills in Python, Scala, or Java
Demonstrated ability to innovate and drive accountability within a team
Experience with version control systems like Git and test automation and CICD

Preferred Qualifications

5+ years of Python or Java, Scala development experience
5+ years of SQL experience
5+ years of experience with schema design and dimensional data modeling

Compensation

Canada Pay Range

$125,000—$169,100 CAD

The range listed above is the expected annual salary/OTE for this role, subject to change.

Salary/OTE is just one component of Dropbox’s total rewards package. All regular employees are also eligible for the corporate bonus program or a sales incentive (target included in OTE) as well as stock in the form of Restricted Stock Units (RSUs).

Benefits

Dropbox is committed to investing in the holistic health and wellbeing of all Dropboxers and their families. Our benefits and perks programs include, but are not limited to:

Competitive medical, dental and vision coverage*
Retirement savings through a defined contribution pension or savings plan**
Flexible PTO/Paid Time Off policy in addition to statutory holidays, allowing you time to unplug, unwind, and refresh
Income Protection Plans: Life and disability insurance*
Business Travel Protection: Travel medical and accident insurance*
Perks Allowance to be used on what matters most to you, whether that’s wellness, learning and development, food & groceries, and much more
Parental benefits including: Parental Leave, Fertility Benefits, Adoptions and Surrogacy support, and Lactation support
Mental health and wellness benefits

Additional Benefits Details Are Available Upon Request.

Where group plans are not available, allowances may be provided
Benefit, amount, and type are dependent on geographical location, based upon applicable law or company policy

Dropbox is an equal opportunity employer. We are a welcoming place for everyone, and we do our best to make sure all people feel supported and connected at work.","{""role_summary"":""Design and maintain scalable data pipelines, ensuring high data quality and effective tooling to drive business growth at Dropbox."",""key_terms"":[{""term"":""Databricks"",""explanation"":""A cloud-based platform for data engineering, analytics, and machine learning.""},{""term"":""Data health metrics"",""explanation"":""Quantifiable measures to assess data quality, reliability, and performance.""},{""term"":""ETL architectures"",""explanation"":""Extract, Transform, Load architectures used for data integration and migration.""}],""skill_priorities"":{""must_have"":[""5+ years of experience in data engineering or related roles"",""Proven experience with data migration projects, specifically to Databricks"",""Strong expertise in data health metrics, data governance, and quality management"",""Solid experience in building and maintaining data pipelines and infrastructure"",""Excellent problem-solving skills and the ability to troubleshoot complex data issues"",""Strong programming skills in Python, Scala, or Java""],""nice_to_have"":[""5+ years of Python or Java, Scala development experience"",""5+ years of SQL experience"",""5+ years of experience with schema design and dimensional data modeling""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe your experience with data migration projects, specifically to Databricks?"",""example_answer"":""I have successfully migrated multiple datasets from legacy platforms to Databricks, ensuring minimal downtime and data loss.""},{""question"":""How do you approach building and maintaining data pipelines and infrastructure?"",""example_answer"":""I follow a test-driven development approach, ensuring scalability, efficiency, and cost optimization.""}],""red_flags"":[""Lack of experience with Databricks or similar data engineering platforms"",""Inability to troubleshoot complex data issues""],""confidence_score"":95.0}"
Data Scientist,Shannex Incorporated,"Halifax, Nova Scotia, Canada",July,2024,"If you take pride in being compassionate, honest, professional and safe, consider an exciting and rewarding career at Shannex. Our communities offer more than a place to work – they welcome and celebrate Great People who inspire meaningful connections while Leading the Way to Better Living™.

We are searching for a Data Scientist to join our Insights Lab Team based in Halifax, Nova Scotia.

Meaningful Benefits

You will be surrounded by supportive and talented team members who make our communities great places to live, work and visit. As an established and respected organization in the healthcare sector, Shannex offers opportunities for growth, development and advancement. And at the end of every day, you will know you’ve made a measured difference in the lives of our residents. Additional benefits include:

Comprehensive health and dental benefits plan including an Employee and Family Assistance Program
Access to virtual healthcare 24/7 for FREE through the group health benefit plan
RRSP program (with employer matching)
Vacation accrual (begins immediately) and travel insurance
Free onsite parking
Access to thousands of vendors offering perks and discounts through our WorkPerks program
Access to continuing education and training through Shannex’s Centre of Excellence
Opportunities to be part of sector innovation and continuous improvement initiatives
Recognition and Rewards for service excellence and safety

About The Opportunity

Collect, analyze, and interpret large datasets to derive meaningful insights.
Develop predictive models to forecast patient outcomes and optimize resource allocation.
Design and implement data experiments to test hypotheses and validate models.
Stay up-to-date with the latest data science techniques and tools.
Work closely with clinical staff, administrators, and BIA to understand data needs and deliver actionable insights.
Present findings and recommendations to stakeholders in a clear and concise manner
Ensure data integrity, accuracy, and security in compliance with regulatory standards.
Develop and maintain databases and data collection systems
Identify opportunities for process improvement and operational efficiency through data analysis
Implement machine learning algorithms to enhance decision making processes

About You

In addition to placing high value on continuous improvement, collaboration and accountability, you bring:

Bachelor's degree in Data Science, Statistics, Computer Science, or a related field. Master's degree preferred.
Minimum of 3 years of experience in data science or a related role.
Proficiency in programming languages such as Python, and SQL.
Experience with data visualization tools like Tableau, Power BI, or similar.
Knowledge of machine learning techniques and frameworks.
Experience working with data from wearable devices and Electronic Health Records (EHR) systems is an asset.
Experience with cloud computing platforms
A passion for the healthcare sector and/or ensuring seniors have access to quality accommodations, services and care.

About Us

It all began in 1988 when our Founder, Joseph Shannon, purchased a single nursing home in his hometown of Sydney, Cape Breton. For 35 years, Shannex has grown as a trusted provider of senior accommodations, services and care in Nova Scotia, New Brunswick, and Ontario. Our industry-leading services are inspired by residents and delivered by Parkland Retirement Living and Lifestyle Residences, Shannex Enhanced Care, Faubourg du Mascaret, and a home care division of team members who create an exceptional resident experience and a positive, fulfilling work environment where every voice matters.

If you’re ready to join the Shannex team of Great People, apply today!

Great People is a core value at Shannex based on the belief that our team members are the spirit and foundation of the organization. Shannex believes equity, diversity, inclusion and belonging is about creating a culture that embraces the uniqueness of individuals, where every person is treated fairly and where racism and discrimination are not tolerated. At Shannex, every team member belongs.

All applications are kept in strict confidentiality.

Only those selected for an nterview will be contacted.","{""role_summary"":""Join Shannex as a Data Scientist, working with large datasets to derive insights, develop predictive models, and optimize resource allocation, making a meaningful difference in the lives of residents."",""key_terms"":[{""term"":""Predictive models"",""explanation"":""Statistical models that forecast outcomes based on historical data, used to optimize resource allocation in healthcare.""},{""term"":""Data experiments"",""explanation"":""Controlled tests to validate hypotheses and models, ensuring data-driven decision-making in healthcare.""},{""term"":""Machine learning algorithms"",""explanation"":""Automated processes that enhance decision-making by analyzing large datasets, used in healthcare to improve patient outcomes.""},{""term"":""Data visualization tools"",""explanation"":""Software used to present complex data insights in a clear and concise manner, such as Tableau or Power BI.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in Data Science, Statistics, Computer Science, or a related field"",""Minimum of 3 years of experience in data science or a related role"",""Proficiency in programming languages such as Python, and SQL"",""Experience with data visualization tools like Tableau, Power BI, or similar""],""nice_to_have"":[""Master's degree"",""Experience working with data from wearable devices and Electronic Health Records (EHR) systems"",""Experience with cloud computing platforms""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement a data experiment to test a hypothesis in a healthcare setting?"",""example_answer"":""I would first identify the problem statement and objectives, then design an experiment with a clear hypothesis, and finally implement the experiment using tools like Python and SQL, ensuring data integrity and presenting findings in a clear and concise manner.""},{""question"":""How do you stay up-to-date with the latest data science techniques and tools?"",""example_answer"":""I regularly read industry blogs and research papers, participate in online forums and attend conferences to stay current with the latest developments in data science.""}],""red_flags"":[""Lack of experience working with healthcare data, specifically Electronic Health Records (EHR) systems"",""Inability to effectively communicate complex data insights to non-technical stakeholders""],""confidence_score"":85.0}"
Junior Data Scientist,Patterned Learning Career,Greater St. John's Metropolitan Area,July,2024,"This is a remote position.

Junior Data Scientist - Remote Job, 1+ Year Experience

Annual Income: $69K - $79K

A valid work permit is necessary in Canada

About us: Patterned Learning is a platform that aims to help developers code faster and more efficiently. It offers features such as collaborative coding, real-time multiplayer editing, and the ability to build, test, and deploy directly from the browser. The platform also provides tightly integrated code generation, editing, and output capabilities.

Responsibilities:

Partner with engineers, product managers, and business partners to identify algorithmic problems, brainstorm possible approaches, and recommend the best path forward.
Develop algorithms iteratively, building in the right level of complexity to solve the business problem at hand and support future improvements.
Define success criteria for your models so that you can measure impact and changes over time. You'll be expected to communicate findings and drive continuous improvements.
Collaborate with Software Engineers to implement algorithms in production that scale gracefully.
Collaborate with stakeholders to prioritize projects and define requirements.
Carry out analysis of data produced by our hardware systems and create insightful visualizations to share your findings.
Contribute to internal libraries to help other teams with their data science needs, including visualization, prediction, optimization, and inference.

Requirements & Experience:

Advanced proficiency with Python and libraries commonly used for data analysis, e.g., Pandas, NumPy, SciPy, and Diplomatist.
Strong understanding of data modeling and statistical analysis.
Knowledge of optimization and predictive modeling techniques and experience applying them to real-world problems.
Skilled at translating a general question or problem into a clearly defined algorithmic solution.
Ability to communicate clearly with both technical and non-technical audiences.
Ability to work independently and manage multiple projects simultaneously.

Nice to haves:

1-year Experience with Data Bricks or PySpark
1 year Experience with product ionizing data models

Why Patterned Learning LLC?

Patterned Learning can provide intelligent suggestions, automate repetitive tasks, and assist developers in writing code more effectively. This can help reduce coding errors, improve productivity, and accelerate the development process.

Pattern recognition is particularly relevant in the context of coding. Neural networks, especially deep learning models, are commonly employed for pattern detection and classification tasks. These models simulate human decision-making and can identify patterns in data, making them well-suited for tasks like code analysis and generation.","{""role_summary"":""Collaborate with cross-functional teams to develop and implement algorithms, analyze data, and drive continuous improvements to support business growth."",""key_terms"":[{""term"":""Algorithmic problems"",""explanation"":""Identifying complex business issues that require data-driven solutions.""},{""term"":""Real-time multiplayer editing"",""explanation"":""A collaborative coding feature that allows multiple users to edit code simultaneously.""},{""term"":""Code generation"",""explanation"":""The ability of the platform to automatically generate code based on user input.""},{""term"":""Pattern detection"",""explanation"":""The use of neural networks to identify patterns, particularly in code analysis and generation.""}],""skill_priorities"":{""must_have"":[""Advanced proficiency with Python"",""Strong understanding of data modeling and statistical analysis"",""Ability to communicate clearly with both technical and non-technical audiences""],""nice_to_have"":[""1-year Experience with Data Bricks or PySpark"",""1 year Experience with product ionizing data models""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach identifying algorithmic problems and recommending solutions?"",""example_answer"":""I would collaborate with cross-functional teams to understand business needs, brainstorm possible approaches, and recommend the most suitable solution based on data analysis and modeling.""},{""question"":""How do you ensure that your models are scalable and can support future improvements?"",""example_answer"":""I define success criteria for my models, measure impact and changes over time, and communicate findings to drive continuous improvements.""}],""red_flags"":[""Lack of experience with Python and data analysis libraries"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":85.0}"
Data Scientist I (Junior),Energy Jobline,"Calgary, Alberta, Canada",June,2024,"Data Scientist

Location: Calgary, Alberta

Duration: 12-Month Contract

Role Overview

We're in search of a skilled Data Scientist to join our Digital Manufacturing team. In this role, you'll leverage machine learning, statistical algorithms, and optimization techniques to support initiatives aimed at ensuring safe, reliable, and competitive operations of our manufacturing assets. Working closely with process, mechanical, and automation engineers, you'll solve complex problems and design predictive or prescriptive models.

Additionally, you'll collaborate with data architects and developers to build scalable data pipelines and deploy models in production environments, both on the edge and in the cloud. Ensuring timely analysis and testing for regular maintenance, you'll translate business requirements into technical prototypes and solutions and effectively communicate the design, functionality, and output of analytical models/solutions developed.

Why Join Us

Engage in impactful projects within a dynamic team environment.
Access professional growth opportunities and competitive compensation.
Contribute to a culture of innovation and excellence.

Key Responsibilities

Support initiatives to deliver safe, reliable, and competitive operations of manufacturing assets.
Collaborate with process, mechanical, and automation engineers to solve complex problems using data science methodologies.
Design and build explorative, predictive, or prescriptive models utilizing optimization, simulation, and machine learning techniques.
Collaborate with data architects and data developers to build scalable data pipelines and deploy models from development to production environments on edge or in the cloud.
Ensure timely analysis and testing for regular maintenance of solutions over time.
Translate business requirements into technical prototypes and solutions.
Communicate the design, functionality, and output of analytical models/solutions developed.

Qualifications

Bachelor’s or Graduate Degree in engineering, computer science, mathematics, physics, or a similar technical discipline.
0-5 years of experience in statistics and machine learning, including work with time series, images, and text data processing.
Proficiency in Python and related data science libraries (Pandas, Scikit-learn, Numpy, Matplotlib, etc.).
Experience in deploying models in a production environment, particularly using cloud platforms such as Azure Databricks.
Experience executing projects, both working independently and as part of a cross-functional team.
Excellent written and verbal communication skills.
Openness to learning and a commitment to safety, actively contributing to a safe working environment.

Apply now and join us in shaping the future of the industry.","{""role_summary"":""Work as a Data Scientist in a dynamic team, leveraging machine learning and statistical algorithms to ensure safe, reliable, and competitive operations of manufacturing assets."",""key_terms"":[{""term"":""Machine learning"",""explanation"":""Using algorithms to enable machines to learn from data and make predictions or decisions.""},{""term"":""Statistical algorithms"",""explanation"":""Using mathematical techniques to analyze and interpret data.""},{""term"":""Optimization techniques"",""explanation"":""Methods to find the best solution among available options, often used to improve efficiency.""},{""term"":""Data pipelines"",""explanation"":""A series of processes to extract, transform, and load data for analysis or deployment.""},{""term"":""Cloud platforms"",""explanation"":""Online services for storing, managing, and processing data, such as Azure Databricks.""}],""skill_priorities"":{""must_have"":[""Python"",""Machine learning"",""Statistical algorithms"",""Data processing"",""Cloud platforms""],""nice_to_have"":[""Experience with images and text data processing"",""Azure Databricks""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design a predictive model to optimize manufacturing asset performance?"",""example_answer"":""I would start by analyzing historical data, identifying key performance indicators, and then selecting an appropriate algorithm to train the model. I would also consider factors like data quality, seasonality, and potential biases.""},{""question"":""How do you ensure timely analysis and testing for regular maintenance of solutions?"",""example_answer"":""I prioritize tasks based on urgency and allocate sufficient time for testing. I also maintain a record of testing results and update the solution accordingly.""}],""red_flags"":[""Lack of experience with cloud platforms"",""Inability to communicate complex technical concepts effectively""],""confidence_score"":85.0}"
HDO Data Scientist-Canada,Zortech Solutions,"Toronto, Ontario, Canada",April,2024,"Role: HDO Data Scientist

Location: Remote/Canada

Duration: 6+ Months

Job Description

Key Responsibilities:

Collaborate with cross-functional teams to identify and prioritize quick win opportunities for data-driven insights and improvements.

Develop and implement ML models to analyze large datasets and extract valuable insights.

Apply advanced statistical techniques and algorithms to solve complex business problems.

Design and implement data transformation processes to ensure data quality and integrity.

Utilize genAI and LLM models to enhance data analysis and predictive capabilities.

Collaborate with Data Engineers to design and optimize data architecture for efficient data processing and storage.

Develop and deploy scalable and production-ready ML models.

Conduct exploratory data analysis to uncover patterns, trends, and correlations in the data.

Stay up-to-date with the latest advancements in ML, AI, and data science technologies.

Qualifications

What you bring

You are comfortable with high level of ambiguity and possess a continuous improvement mindset

Master's or Ph.D. degree in Computer Science, Data Science, or a related field.

Proven experience as a Data Scientist or similar role, working on data transformation and AI-related projects.

Strong programming skills in Python for data manipulation, analysis, and model development.

In-depth knowledge of ML algorithms, techniques, and frameworks.

Familiarity with genAI and LLM models and their implementation.

Experience in designing and optimizing data architecture for efficient data processing and storage.

Proficiency in SQL and database management systems.

Strong Problem-solving And Analytical Skills.

Excellent communication and collaboration skills to work effectively with cross-functional teams.

If you are passionate about leveraging data and AI to drive business outcomes and have the required skills and experience, we would love to hear from you. Join our team and contribute to the success of our data-driven initiatives","{""role_summary"":""Work with teams to identify opportunities for data-driven insights and improvements, develop and implement ML models, and design data transformation processes to ensure data quality."",""key_terms"":[{""term"":""ML models"",""explanation"":""Machine Learning models used to analyze large datasets and extract valuable insights.""},{""term"":""genAI and LLM models"",""explanation"":""Generative AI and Large Language Models used to enhance data analysis and predictive capabilities.""},{""term"":""Data transformation processes"",""explanation"":""Processes designed to ensure data quality and integrity.""}],""skill_priorities"":{""must_have"":[""Python programming skills"",""ML algorithms and techniques"",""Experience with genAI and LLM models"",""SQL and database management systems"",""Strong problem-solving and analytical skills""],""nice_to_have"":[""Ph.D. degree in Computer Science, Data Science, or a related field"",""Experience designing and optimizing data architecture""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach designing and implementing a data transformation process to ensure data quality?"",""example_answer"":""I would start by identifying the key data sources and understanding the requirements for data quality. Then, I would design and implement a data transformation process using Python and SQL, ensuring data integrity and quality.""},{""question"":""How do you stay up-to-date with the latest advancements in ML, AI, and data science technologies?"",""example_answer"":""I regularly read industry blogs and research papers, attend conferences, and participate in online forums to stay current with the latest advancements.""}],""red_flags"":[""Lack of experience with genAI and LLM models"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Machine Learning Engineer,DeepRec.ai,"Toronto, Ontario, Canada",June,2024,"Machine Learning Engineer
Healthcare, AI

DeepRec.ai are hiring for a talented Machine Learning Engineer to join a fantastic organisation in Canada who are using AI to improve patient experiences and the clinical workflow. This is an innovative and inspiring organisation who have specific clinical tasks they need to perform, where they use AI to execute them.

As well as creating datasets, you'll also be building bleeding-edge AI applications, aimed to assist clinicians in practice management, cost reduction, issue prevention and improved health care experiences.

This role reports into the Head of AI.

If you are an ML Engineer, with some experience in the healthcare sector, and you have experience in some of the following skills: LLamaIndex, HuggingFace, SentenceTransformers, PyTorch, Python, Apache Spark, we would love to chat

This is a hybrid role in Toronto and the chance to join a growing company!

We look forward to hearing from you","{""role_summary"":""Create AI applications to improve patient experiences and clinical workflow, building datasets and assisting clinicians in practice management."",""key_terms"":[{""term"":""LLamaIndex"",""explanation"":""A tool for efficient querying and indexing of large language models.""},{""term"":""HuggingFace"",""explanation"":""A popular open-source library for natural language processing and transformers.""},{""term"":""SentenceTransformers"",""explanation"":""A library for sentence embeddings and semantic search.""},{""term"":""PyTorch"",""explanation"":""A popular deep learning framework for building and training AI models.""},{""term"":""Apache Spark"",""explanation"":""A unified analytics engine for large-scale data processing.""}],""skill_priorities"":{""must_have"":[""ML Engineer"",""Python"",""experience in the healthcare sector""],""nice_to_have"":[""LLamaIndex"",""HuggingFace"",""SentenceTransformers"",""PyTorch"",""Apache Spark""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach building datasets for AI applications in healthcare?"",""example_answer"":""I would ensure data quality, annotate data correctly, and consider data privacy regulations.""},{""question"":""Can you explain a project where you used AI to improve clinical workflow?"",""example_answer"":""In my previous role, I built an AI model that reduced clinical workflow by 25% through automation.""}],""red_flags"":[""Lack of experience in healthcare sector"",""No experience with AI applications in clinical workflow""],""confidence_score"":85.0}"
AI/ML Engineer,Magical,"Toronto, Ontario, Canada",June,2024,"🏢 Locations: Hybrid Remote (1-2 days onsite) in Toronto (Bloor-Yonge)

Impact-Driven Senior/Staff AI/ML Engineer for Productivity Automation

We're seeking a passionate and impact-driven Senior or Staff Artificial Intelligence and Machine Learning Engineer to join our experienced founding team from Mozilla, Spotify, LinkedIn, and Apple and revolutionize productivity through automation.

Your mission will be to design and develop AI/ML models and algorithms that automate mundane, soul-crushing tasks.

As part of our team, you'll play a crucial role in shaping our data graph used by over 500K people across 30K companies in 150 countries. This data graph standardizes the internet, and you'll have direct input in shaping our roadmap as we grow to 1 million users.

What you'll do:

In this role you will collaborate with frontend and full-stack teams across the organization as we implement the machine learning functionalities you develop into our React.js and Redux applications. You will also:

Collaborate in integrating AI/ML solutions with existing Node.js applications.
Conduct data preprocessing, feature engineering, and model evaluation.
Optimize database interactions using PostgreSQL to efficiently handle large datasets.
Manage and query large datasets with PostgreSQL.
Leverage AWS services for deploying, scaling, and maintaining AI/ML models and data pipelines.
Deploy applications and manage data with AWS (Eg. EC2, S3, Lambda, Elastic Beanstalk and others).
Manage workflows and data pipelines (Eg. Apache Airflow, Camunda or similar)
Perform OCR tasks with Tesseract and advanced image and video analysis with Google Cloud Vision or Amazon Rekognition.
Use Docker for containerizing applications.

About you:

You are proficient in Python, or JavaScript and TypeScript
You have experience with any cloud provider such as AWS (we use AWS), GCP, or Azure.
You have a passion for building innovative solutions that drive impact and automate mundane tasks.
You have expertise in AI/ML model design and development, frameworks, and libraries such as TensorFlow, PyTorch, scikit-learn, Pandas, NumPy, NLTK or spaCy, OpenCV or similar.
You have experience working with RPA technologies such as Apache Airflow, Camunda, Tesseract, Google Cloud Vision, or Amazon Rekognition and AWS services like EC2, S3, Lambda, and Elastic Beanstalk.
You have knowledge of CI/CD tools and Docker.
You work collaboratively in a fast-paced environment.
You are excited about leveraging OpenAI and Gemini technologies

Join us and pioneer the first AI model to catalog the internet and take high ownership in productionizing research.

Tech Stack

Previous experience with all of these technologies is not required

Python
Typescript
React
Redux
RxJS
Emotion
Node.js
Postgres

Benefits

Interesting and challenging work
Competitive salary and equity
Regular team events and off-sites (Iceland, Lisbon, Dominican Republic, Mexico)
Unlimited PTO
Annual wellness credit
Productivity stipend","{""role_summary"":""Design and develop AI/ML models and algorithms to automate mundane tasks, collaborating with frontend and full-stack teams to implement machine learning functionalities."",""key_terms"":[{""term"":""AI/ML models"",""explanation"":""Artificial Intelligence and Machine Learning models that automate tasks""},{""term"":""Data graph"",""explanation"":""A standardized data structure that organizes data for over 500K users""},{""term"":""Node.js applications"",""explanation"":""Server-side JavaScript applications that integrate with AI/ML solutions""},{""term"":""PostgreSQL"",""explanation"":""A relational database that efficiently handles large datasets""},{""term"":""AWS services"",""explanation"":""Cloud computing services for deploying, scaling, and maintaining AI/ML models and data pipelines""},{""term"":""OCR tasks"",""explanation"":""Optical Character Recognition tasks that extract data from images and videos""},{""term"":""Tesseract"",""explanation"":""An OCR engine for extracting text from images""},{""term"":""Google Cloud Vision"",""explanation"":""A cloud-based image and video analysis service""},{""term"":""Apache Airflow"",""explanation"":""A workflow management system for managing data pipelines""}],""skill_priorities"":{""must_have"":[""Python or JavaScript and TypeScript"",""Experience with cloud providers (AWS, GCP, or Azure)"",""AI/ML model design and development"",""Experience with frameworks and libraries (TensorFlow, PyTorch, scikit-learn, Pandas, NumPy, NLTK or spaCy, OpenCV or similar)""],""nice_to_have"":[""Experience with RPA technologies (Apache Airflow, Camunda, Tesseract, Google Cloud Vision, or Amazon Rekognition)"",""Knowledge of CI/CD tools and Docker""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing and developing AI/ML models for automation?"",""example_answer"":""I follow a structured approach, starting with data preprocessing, feature engineering, and model evaluation to ensure the model is accurate and efficient.""},{""question"":""Can you explain how you would optimize database interactions using PostgreSQL?"",""example_answer"":""I would use indexing, caching, and query optimization techniques to minimize latency and improve performance.""}],""red_flags"":[""Lack of experience with cloud providers (AWS, GCP, or Azure)"",""Inability to work collaboratively in a fast-paced environment""],""confidence_score"":95.0}"
Junior Data Scientist Engineer,Patterned Learning Career,"Edmonton, Alberta, Canada",July,2024,"This is a remote position.

Junior Data Scientist Engineer - Remote Job, 1+ Year Experience

Annual Income: $64K - $74K

A valid work permit is necessary in Canada

About us: Patterned Learning is a platform that aims to help developers code faster and more efficiently. It offers features such as collaborative coding, real-time multiplayer editing, and the ability to build, test, and deploy directly from the browser. The platform also provides tightly integrated code generation, editing, and output capabilities.

Skills and Abilities:

Strong knowledge of R or Python for data analysis and modeling.
Proficiency in statistical programs such as R, SAS, MATLAB, or Python.
Familiarity with spreadsheets (VBA) and database applications (Access, Oracle, SQL, or equivalent technology).
Basic understanding of SQL, Javascript, XML, JSON, and HTML.
Ability to learn new methods quickly and work under deadlines.
Excellent teamwork and communication skills.
Strong analytical and problem-solving abilities.
Basic understanding of SQL, Javascript, XML, JSON, and HTML.

Preferred:

Knowledge of actuarial concepts and life, health, and/or annuity products.
Experience with statistical modeling techniques such as GLM, Decision Trees, Time Series, Regression, etc.
Familiarity with Microsoft DeployR.
Exposure to insurance risk analysis.
Basic experience in computational finance, econometrics, statistics, and math.
Knowledge of SQL and VBA.
Familiarity with R or Python for predictive modeling

Why Patterned Learning LLC?

Patterned Learning can provide intelligent suggestions, automate repetitive tasks, and assist developers in writing code more effectively. This can help reduce coding errors, improve productivity, and accelerate the development process.

Pattern recognition is particularly relevant in the context of coding. Neural networks, especially deep learning models, are commonly employed for pattern detection and classification tasks. These models simulate human decision-making and can identify patterns in data, making them well-suited for tasks like code analysis and generation.","{""role_summary"":""Assist in developing a platform that enables efficient coding by providing features such as collaborative coding, real-time editing, and deployment from the browser."",""key_terms"":[{""term"":""R"",""explanation"":""A programming language used for data analysis and modeling.""},{""term"":""Python"",""explanation"":""A programming language used for data analysis, modeling, and predictive modeling.""},{""term"":""SQL"",""explanation"":""A language used for managing and manipulating data in databases.""},{""term"":""JSON"",""explanation"":""A data format used for exchanging data between web servers and web applications.""},{""term"":""XML"",""explanation"":""A markup language used for storing and transporting data.""},{""term"":""HTML"",""explanation"":""A markup language used for creating web pages.""},{""term"":""GLM"",""explanation"":""A statistical technique used for modeling the relationship between variables.""},{""term"":""Decision Trees"",""explanation"":""A machine learning technique used for making predictions based on data.""},{""term"":""Time Series"",""explanation"":""A sequence of data points measured at regular time intervals.""},{""term"":""Regression"",""explanation"":""A statistical technique used for modeling the relationship between variables.""},{""term"":""Microsoft DeployR"",""explanation"":""A platform used for deploying and managing R-based analytics.""},{""term"":""Insurance risk analysis"",""explanation"":""The process of identifying and assessing potential risks in insurance.""},{""term"":""Computational finance"",""explanation"":""The use of computational methods for analyzing and modeling financial systems.""},{""term"":""Econometrics"",""explanation"":""The application of statistical methods for analyzing economic systems.""},{""term"":""Statistics"",""explanation"":""The study of the collection, analysis, interpretation, presentation, and organization of data.""},{""term"":""Math"",""explanation"":""The study of numbers, quantities, and shapes.""}],""skill_priorities"":{""must_have"":[""R or Python for data analysis and modeling"",""Statistical programs such as R, SAS, MATLAB, or Python"",""Familiarity with spreadsheets (VBA) and database applications (Access, Oracle, SQL, or equivalent technology)"",""Basic understanding of SQL, Javascript, XML, JSON, and HTML"",""Ability to learn new methods quickly and work under deadlines"",""Excellent teamwork and communication skills"",""Strong analytical and problem-solving abilities""],""nice_to_have"":[""Knowledge of actuarial concepts and life, health, and/or annuity products"",""Experience with statistical modeling techniques such as GLM, Decision Trees, Time Series, Regression, etc."",""Familiarity with Microsoft DeployR"",""Exposure to insurance risk analysis"",""Basic experience in computational finance, econometrics, statistics, and math"",""Knowledge of SQL and VBA"",""Familiarity with R or Python for predictive modeling""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach data analysis and modeling using R or Python?"",""example_answer"":""I would first import the necessary libraries, then load and clean the data, followed by exploratory data analysis and finally build a model using R or Python.""},{""question"":""How do you stay up-to-date with new techniques and tools in the field of data science?"",""example_answer"":""I regularly read articles and blogs, attend webinars and conferences, and participate in online forums to stay current with the latest developments.""},{""question"":""Can you describe a project where you had to work with a new technology or programming language?"",""example_answer"":""In my previous role, I had to learn Python for a project involving data analysis and modeling. I was able to apply my knowledge of R to learn Python quickly and deliver the project on time.""}],""red_flags"":[""Lack of experience with R or Python"",""Inability to learn new methods quickly"",""Poor teamwork and communication skills""],""confidence_score"":85.0}"
"Data Scientist, Decisions - Safety",Lyft,"Toronto, Ontario, Canada",June,2024,"At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization.

Data Science is at the heart of Lyft’s products and decision-making. As a member of the Rider & Safety Science team, you will work in a dynamic environment, where we embrace moving quickly to build the world’s best transportation. Data Scientists take on a variety of problems ranging from shaping critical business decisions to building algorithms that power our internal and external products. We’re looking for passionate, driven Data Scientists to take on some of the most interesting and impactful problems in ridesharing.

As a Data Scientist, Decisions in the Rider & Safety team, you will leverage data and rigorous, analytical thinking to shape our rider app and make business decisions that put our customers first. You will identify and scope opportunities, shape priorities, recommend technical solutions, design experiments, and measure impact. You will bring a quantitative mindset to decision-making in partnership with product, design, engineering, business, and operations stakeholders throughout the organization.

You will report to a Data Science Manager in the Rider & Safety Science team.

Responsibilities:

Leverage data and analytic frameworks to identify opportunities for growth and efficiency
Partner with product managers, engineers, marketers, designers, and operators to translate data insights into decisions and action
Design and analyze online experiments; communicate results and act on launch decisions
Develop analytical frameworks to monitor business and product performance
Establish metrics that measure the health of our products, as well as rider and driver experience

Experience:

Degree in a quantitative field such as statistics, economics, applied math, operations research or engineering (advanced degrees preferred), or relevant work experience
3+ years of industry experience in a data science or analytics role
Proficiency in SQL - able to write structured and efficient queries on large data sets
Experience in programming, especially with data science and visualization libraries in Python or R is helpful
Experience in online experimentation and statistical analysis
Strong oral and written communication skills, and ability to collaborate with and influence cross-functional partners

Benefits:

Extended health and dental coverage options, along with life insurance and disability benefits
Mental health benefits
Family building benefits
Access to a Health Care Savings Account
In addition to provincial observed holidays, team members get 15 days paid time off, with an additional day for each year of service
4 Floating Holidays each calendar year prorated based off of date of hire
10 paid sick days per year regardless of province
18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible

Lyft proudly pursues and hires a diverse workforce. Lyft believes that every person has a right to equal employment opportunities without discrimination because of race, ancestry, place of origin, colour, ethnic origin, citizenship, creed, sex, sexual orientation, gender identity, gender expression, age, marital status, family status, disability, pardoned record of offences, or any other basis protected by applicable law or by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Accommodation for persons with disabilities will be provided upon request in accordance with applicable law during the application and hiring process. Please contact your recruiter now if you wish to make such a request.

This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid","{""role_summary"":""As a Data Scientist in the Rider & Safety team, you will leverage data and analytical thinking to shape the rider app and make business decisions that put customers first, identifying opportunities, shaping priorities, and measuring impact."",""key_terms"":[{""term"":""Data Science"",""explanation"":""The practice of extracting insights from data to inform business decisions.""},{""term"":""Rigorous analytical thinking"",""explanation"":""A systematic approach to analyzing data to draw meaningful conclusions.""},{""term"":""Online experiments"",""explanation"":""Testing hypotheses on a live platform to measure the impact of changes.""}],""skill_priorities"":{""must_have"":[""Degree in a quantitative field"",""3+ years of industry experience in data science or analytics"",""Proficiency in SQL"",""Strong oral and written communication skills""],""nice_to_have"":[""Experience in programming with data science and visualization in Python or R"",""Experience in online experimentation and statistical analysis""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a time when you had to communicate complex data insights to a non-technical stakeholder?"",""example_answer"":""I worked with a product manager to develop a dashboard to measure customer engagement. I had to explain the insights to the product team, and we were able to increase engagement by 15%.""},{""question"":""How do you approach designing and analyzing online experiments to measure the impact of changes on a live platform?"",""example_answer"":""I use a structured approach to identify the problem, design the experiment, and analyze the results. I also consider potential biases and ensure the results are actionable.""}],""red_flags"":[""Lack of experience in online experimentation and statistical analysis"",""Inability to communicate complex insights to non-technical stakeholders""],""confidence_score"":90.0}"
ML Engineer / Toronto,Intersog,"Toronto, Ontario, Canada",May,2024,"Intersog® is a Chicago-based provider of ROI-driven custom web and mobile development specializing in the delivery of full-service, end-to-end solutions, and project resources to Fortune 500 companies, SMEs, and startups. We help our clients attack their ambitious business goals, solve skills shortage issues, and become innovative by building Dedicated Software Development Teams in Mexico, Canada, the U.S.A., and Ukraine and/or providing on-demand IT project resources to complete required skills on their in-house teams.

About The Role

We seek an ML Engineer to join the AI Practice team dedicated to pioneering AI-driven solutions, encompassing hyper-personalization, AI-powered selling strategies, extensive unstructured data analysis through NLP, and innovative dynamic pricing approaches. Utilizing the latest in machine learning and deep learning technologies alongside comprehensive engineering platforms, they are committed to developing impactful products and client-centered solutions.

Requirements

Develop and manage ML model pipelines, focusing on feature engineering, model training, and inferencing
Scale ML algorithms for large data sets under strict service level agreements (SLAs)
Enhance ML Engineering platforms and ensure the implementation of MLOps practices for model monitoring and feedback loops
Write clean, production-quality code that adheres to best practices and design guidelines
Work collaboratively with global teams to deliver projects, utilizing development and project management tools to maintain organization and communication
Engage in continuous learning to stay abreast of new technologies and methodologies in ML architecture and design

Qualifications:

Bachelor's or Master's in Computer Science, MIS, IT, or related fields
2-4 years of experience in deploying production-level ML models
Proficiency in Python / PySpark and experience with ML platforms (e.g., Dataiku, Sagemaker, MLFlow)
Skilled in deploying models to cloud services (AWS, Azure, GCP) and optimizing ML models for performance and scalability
Solid understanding of machine learning, deep learning fundamentals, common data structures, algorithms, and design patterns
Excellent communication skills, both verbal and written","{""role_summary"":""Develop and manage machine learning model pipelines, focusing on feature engineering, model training, and inferencing, to deliver impactful products and client-centered solutions."",""key_terms"":[{""term"":""MLOps"",""explanation"":""Machine Learning Operations, a set of practices that combines machine learning and DevOps to streamline the machine learning lifecycle.""},{""term"":""NLP"",""explanation"":""Natural Language Processing, a subfield of artificial intelligence that deals with the interaction between computers and humans in natural language.""},{""term"":""Hyper-personalization"",""explanation"":""The use of data and analytics to create highly targeted and relevant content, offers, or experiences for each customer or user.""}],""skill_priorities"":{""must_have"":[""Python"",""PySpark"",""Experience with ML platforms (e.g., Dataiku, Sagemaker, MLFlow)"",""Skilled in deploying models to cloud services (AWS, Azure, GCP)""],""nice_to_have"":[""Experience with deep learning"",""Knowledge of machine learning fundamentals, common data structures, algorithms, and design patterns""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach feature engineering for a machine learning model?"",""example_answer"":""I typically start by understanding the problem and the data, then I use techniques such as feature scaling, normalization, and dimensionality reduction to create meaningful features for the model.""},{""question"":""Can you explain how you would deploy a machine learning model to a cloud service like AWS?"",""example_answer"":""I would use AWS SageMaker to deploy the model, ensuring that it is containerized and meets the required security and scalability standards.""}],""red_flags"":[""Lack of experience with cloud services (AWS, Azure, GCP)""],""confidence_score"":90.0}"
Engineer - AI/ML,Huawei Canada,"Markham, Ontario, Canada",June,2024,"Our team has an immediate 12-month contract opening for an Engineer.

Responsibilities:

Development of next-gen PaaS platform, including PaaS Middleware, Application Platform and Application Integration Services.
Collaborate with PaaS Engineers for integrating advanced AI/ML models (e.g., LLMs) into existing solutions.
Analyze, investigate, and implement (Generative) AI solutions for Cloud Service features and technologies.
Conduct technical research, and assist in POCs development and deliveries.

Job requirements

What you’ll bring to the team:

2+ years of Data Science and Machine Learning development experience.
A strong foundation in algorithms, data structure, and object-oriented-programming along with proficiency in Python, R, Java and SQL.
Experience in using ML algorithms (i.e., supervised, unsupervised, and reinforcement learning) and exploratory data analysis (EDA) tools and libraries including Numpy, Pandas, Matplotlib, Seaborn, and Scikit-learn.
Solid knowledge of Artificial Neural Networks like CNN, RNN, LSTM, and GRU, along with expertise in Deep Learning frameworks such as PyTorch and TensorFlow.
Familiarity with NLP and Generative AI concepts and tools including Transformers, (Mutlimodal) Large Language Models, Vector databases.
Excellent organization skills, attention to detail, and ability to multi-task under considerable pressure and changing priorities.
Strong interpersonal and team communications skills.
BS degree in Computer Science or equivalent; advanced degree is an asset.","{""role_summary"":""Develop and integrate AI/ML models into a PaaS platform, conducting technical research and assisting in proof-of-concept developments."",""key_terms"":[{""term"":""PaaS"",""explanation"":""Platform as a Service, a cloud computing model that provides a platform for developing, running, and managing applications.""},{""term"":""LLMs"",""explanation"":""Large Language Models, a type of artificial intelligence model trained on large amounts of text data to generate language outputs.""},{""term"":""AI/ML"",""explanation"":""Artificial Intelligence and Machine Learning, a subfield of computer science that involves developing intelligent systems that can learn from data.""},{""term"":""Generative AI"",""explanation"":""A type of AI that involves generating new data, such as images, text, or music, based on patterns learned from existing data.""},{""term"":""NLP"",""explanation"":""Natural Language Processing, a subfield of AI that involves developing systems that can understand, interpret, and generate human language.""}],""skill_priorities"":{""must_have"":[""Data Science and Machine Learning development experience"",""Python, R, Java"",""ML algorithms and exploratory data analysis tools"",""Artificial Neural Networks and Deep Learning frameworks"",""NLP and Generative AI concepts and tools""],""nice_to_have"":[""Advanced degree in Computer Science or equivalent""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would integrate a large language model into an existing PaaS platform?"",""example_answer"":""I would start by analyzing the model's requirements and the platform's architecture, then design a plan for integration, considering scalability and performance.""},{""question"":""How do you stay current with advancements in AI/ML, and can you give an example of a recent development that interests you?"",""example_answer"":""I regularly read industry blogs and research papers, and I'm excited about the recent developments in multimodal large language models, which have the potential to revolutionize human-computer interaction.""}],""red_flags"":[""Lack of hands-on experience with AI/ML development"",""Inability to explain complex AI/ML concepts in simple terms""],""confidence_score"":90.0}"
Software Engineer (Python) - Up to CAD$200k + Huge Bonus Montreal,Hunter Bond,Greater Montreal Metropolitan Area,June,2024,"Job title: Software Engineer (Python)- Up to $200,000 + Bonus + Package
Client: Elite Fintech Client
Experience Level: 1+ years
Salary: Up to $200,000 + Bonus + Package
Location: Montreal (hybrid)

Sells: Cutting-edge tech, a collaborative environment fostering Python/ React knowledge growth and development, fantastic office space in the heart of Montreal
An elite Fintech client are searching for Python/ React Developers to join elite talent and expertise.
This team has an unlimited tech budget, promotes a great culture, and is made up of incredible like-minded individuals.

Role
· Working on highly scalable, low latency infrastructure
· Provides the chance not only to work in Python or React, but gain exposure to a lot more from some of the best developers worldwide

Skills/Experience
· Strong knowledge of Python, FAST APIs
· Strong Computer Science fundamentals
If you're interested in this role, you can contact me (hogundapo@hunterbond.com) to learn more and express your interest.","{""role_summary"":""Develop scalable, low-latency infrastructure as a Software Engineer, utilizing Python and React, and collaborating with elite talent in a cutting-edge fintech environment."",""key_terms"":[{""term"":""FAST APIs"",""explanation"":""A type of API that enables fast and scalable development, commonly used in high-performance applications.""},{""term"":""Scalable infrastructure"",""explanation"":""A system designed to handle increased load and traffic, ensuring high performance and reliability.""},{""term"":""Low latency infrastructure"",""explanation"":""A system optimized for fast response times, critical in applications requiring real-time data processing.""}],""skill_priorities"":{""must_have"":[""Strong knowledge of Python"",""Strong Computer Science fundamentals""],""nice_to_have"":[""Experience with React"",""Knowledge of FAST APIs""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing scalable infrastructure in Python?"",""example_answer"":""I would consider using microservices architecture, load balancing, and queuing systems to handle high traffic and ensure scalability.""},{""question"":""Can you explain the importance of low latency in fintech applications?"",""example_answer"":""Low latency is crucial in fintech as it directly impacts user experience, and high latency can lead to lost trades, revenue, and customer satisfaction.""}],""red_flags"":[""Lack of experience with Python or React"",""Limited understanding of scalable infrastructure design""],""confidence_score"":90.0}"
HDO ML Engineer- Canada,Zortech Solutions,"Toronto, Ontario, Canada",March,2024,"Role: HDO ML Engineer

Location: Remote/Canada

Duration: 6+ Months

Job Description

Key Responsibilities:

Collaborate with cross-functional teams to identify and prioritize quick win opportunities for data-driven insights and improvements.
Design, develop, and maintain ETL processes to extract, transform, and load data from various sources into our data infrastructure.
Implement and optimize genAI LLM models to enhance data analysis and predictive capabilities.
Ensure data quality and integrity by implementing data validation and cleansing processes.
Develop and maintain data pipelines to support real-time and batch data processing.
Collaborate with Data Scientists and Machine Learning Engineers to deploy and operationalize AI models.
Monitor and troubleshoot data pipelines and resolve any issues or bottlenecks.
Stay up-to-date with the latest trends and advancements in data engineering, AI, and machine learning technologies

Qualifications

What you bring
You are comfortable with high level of ambiguity and possess a continuous improvement mindset
You are known for strong leadership, project and process management
You enjoy quantitative analysis and have a reputation for being a problem solver and creative thinker
You have the ability to maintain high workloads, including the management of competing priorities and multiple projects at once
University degree, preferably in business, commerce or a related field
You have experience in successfully launching new products
4+ years of progressive experience in product or project management, business strategy or product marketing
Please note that this role is not IT product or project management. Some knowledge of or experience with data and analytics technologies or offerings is preferred, but not necessary
English verbal and written is required for this opportunity.","{""role_summary"":""The HDO ML Engineer role involves collaborating with teams to identify opportunities, designing and maintaining data pipelines, and ensuring data quality. The role also requires staying updated with the latest trends in data engineering, AI, and machine learning."",""key_terms"":[{""term"":""ETL"",""explanation"":""Extract, Transform, and Load processes to manage data from various sources into a data infrastructure.""},{""term"":""genAI LLM"",""explanation"":""General Artificial Intelligence Large Language Models for enhancing data analysis and predictive capabilities.""},{""term"":""Data Pipelines"",""explanation"":""Real-time and batch data processing to support data-driven insights and improvements.""}],""skill_priorities"":{""must_have"":[""Strong leadership and project management skills"",""Quantitative analysis and problem-solving skills"",""Ability to manage competing priorities and multiple projects"",""University degree in business, commerce, or a related field"",""English verbal and written communication skills""],""nice_to_have"":[""Experience in launching new products"",""Knowledge of data and analytics technologies or offerings"",""4+ years of progressive experience in product or project management, business strategy, or product marketing""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to optimize a data pipeline for real-time processing?"",""example_answer"":""In my previous role, I optimized a data pipeline by implementing parallel processing and caching, resulting in a 30% reduction in processing time.""},{""question"":""How do you ensure data quality and integrity in your ETL workflows?"",""example_answer"":""I implement data validation and cleansing processes, and perform regular data audits to ensure data accuracy and consistency.""}],""red_flags"":[""Lack of experience in data engineering, AI, or machine learning"",""Inability to manage competing priorities and multiple projects"",""Poor communication skills""],""confidence_score"":85.0}"
"Data Science, Decisions - Airports",Lyft,"Toronto, Ontario, Canada",June,2024,"At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization.

Data Science is at the heart of Lyft’s products and decision-making. You will leverage data and rigorous, analytical thinking to shape our products and make business decisions. This will involve identifying and scoping opportunities, shaping team priorities, recommending and implementing technical solutions, designing experiments, and measuring the impact of new features.

Airports are one of the most important, impactful, and complex parts of Lyft’s Rideshare business, as they are a key part of both the rider and driver Lyft experiences and have unique marketplaces with special considerations and dynamics. As a Data Scientist on the Airports team, you will collaborate with engineering, product, design, and operations to think critically about the current airport experience and implement product enhancements to facilitate market growth. The ideal candidate can apply strong business acumen to propose product changes, develop end-to-end technical solutions, and is comfortable working with a highly cross functional team. In this role, you will help us tackle problems at airports such as:

How do we efficiently match drivers and riders at the airport to reduce wait times?
Are we able to forecast ride demand and implement driver guidance to ensure riders can rely on Lyft for an airport ride at all times of the day?
How can we develop a technical model to predict ride wait times and communicate this to drivers?
What is the most helpful way to display ride information to drivers so they can make informed decisions?

Responsibilities

Leverage data and analytic frameworks to identify opportunities for growth and efficiency
Partner with product managers, engineers, marketers, designers, and operators to translate data insights into decisions and action
Construct and fit statistical, machine learning, or optimization models
Design and analyze online experiments; communicate results and act on launch decisions
Develop analytical frameworks to monitor business and product performance
Establish metrics that measure the health of our products, the business, as well as the driver experience

Experience

Degree in a quantitative field such as statistics, economics, applied math, operations research or engineering (advanced degrees preferred), or relevant work experience
3+ years of industry experience in a data science, analytics, or management consulting role.
End-to-end experience with data, including querying, aggregation, analysis, and visualization
Ability to manage, influence, negotiate, and inspire others in a fast-moving environment
Proficiency in SQL and Python
Strong oral and written communication skills, and ability to collaborate with cross-functional partners

Benefits

Extended health and dental coverage options, along with life insurance and disability benefits
Mental health benefits
Family building benefits
Access to a Health Care Savings Account
In addition to provincial observed holidays, team members get 15 days paid time off, with an additional day for each year of service
4 Floating Holidays each calendar year prorated based off of date of hire
10 paid sick days per year regardless of province
18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible

Lyft proudly pursues and hires a diverse workforce. Lyft believes that every person has a right to equal employment opportunities without discrimination because of race, ancestry, place of origin, colour, ethnic origin, citizenship, creed, sex, sexual orientation, gender identity, gender expression, age, marital status, family status, disability, pardoned record of offences, or any other basis protected by applicable law or by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Accommodation for persons with disabilities will be provided upon request in accordance with applicable law during the application and hiring process. Please contact your recruiter now if you wish to make such a request.

This role will be in-office on a hybrid schedule following the establishment of a Lyft office in Toronto — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid","{""role_summary"":""As a Data Scientist at Lyft, you will leverage data and analytical thinking to shape products and make business decisions, focusing on the airport experience and implementing product enhancements to facilitate market growth."",""key_terms"":[{""term"":""Rigorous analytical thinking"",""explanation"":""Using data and logical reasoning to make informed decisions.""},{""term"":""Technical solutions"",""explanation"":""Implementing data-driven solutions to improve the airport experience.""},{""term"":""Cross-functional team"",""explanation"":""Collaborating with various teams, including engineering, product, design, and operations.""}],""skill_priorities"":{""must_have"":[""Degree in a quantitative field"",""3+ years of industry experience in data science or analytics"",""End-to-end experience with data"",""Ability to manage and communicate effectively"",""Proficiency in SQL and Python""],""nice_to_have"":[""Advanced degrees"",""Management consulting experience""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you approach forecasting ride demand and implementing driver guidance?"",""example_answer"":""I would use historical data and machine learning models to predict ride demand, and then develop a system to communicate this information to drivers, ensuring they can make informed decisions.""},{""question"":""Can you give an example of a time when you had to develop an analytical framework to monitor business performance?"",""example_answer"":""In my previous role, I created a dashboard to track key metrics, which helped the business make data-driven decisions.""}],""red_flags"":[""Lack of experience working with cross-functional teams"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":95.0}"
Data Scientist with MI- Canada,Zortech Solutions,"Toronto, Ontario, Canada",May,2024,"Role: Data Scientist with MI

Location: Canada/Remote

Duration: 6+ Months

Job Description

Research,identify,and analyze data to evaluate existing and potential trends
Good Exposure working with Business stakeholders on understanding Product Scope, Lifecycle and able to create Prototypes & Roadmap based on customer use cases
Create or use existing frameworks to test and validate new models
Apply statistical techniques to analyze data
Apply machine learning techniques to streamline data analysis

Skills/Experience Required

Strong background in data mining and statistical analysis
Experience developing Al/ML models using Python and open source frameworks like: sklearn, keras,pytorch, numpy,pandas
Ability to work with large amounts of data
Good Exposure to multiple SOL and NOSQL databases
Abilty to quickly learn and implement new data science algorithms
Experience with machine learning techniques and creat ng algorithms
Experience in any cloud environments (AWS, Azure, GCP)
Exposure to MLOps is added advantage.
Exposure to NLP concepts & implementation will be a good to have skill","{""role_summary"":""A Data Scientist with MI will research, identify, and analyzing data to evaluate existing and potential trends, working closely with business stakeholders to create prototypes and roadmaps based on customer use cases."",""key_terms"":[{""term"":""MI"",""explanation"":""MI stands for Machine Intelligence, which is a subset of Artificial Intelligence focused on developing intelligent systems that can learn and adapt.""},{""term"":""SOL and NOSQL databases"",""explanation"":""SOL (Structured Query Language) databases store data in a structured format, whereas NOSQL databases store data in a variety of formats such as key-value, document, or graph.""},{""term"":""MLOps"",""explanation"":""MLOps is a set of practices that combines machine learning and operations to streamline the deployment and management of machine learning models.""},{""term"":""NLP concepts"",""explanation"":""NLP (Natural Language Processing) concepts refer to the ability of computers to understand, interpret, and generate human language.""}],""skill_priorities"":{""must_have"":[""Strong background in data mining and statistical analysis"",""Experience developing Al/ML models using Python and open source frameworks"",""Ability to work with large amounts of data"",""Experience with machine learning techniques"",""Experience in any cloud environments (AWS, Azure, GCP)""],""nice_to_have"":[""Exposure to MLOps"",""Exposure to NLP concepts & implementation""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach developing a machine learning model using Python and open source frameworks?"",""example_answer"":""I would start by importing the necessary libraries such as scikit-learn and then proceed to preprocess the data, followed by training and testing the model.""},{""question"":""How do you handle working with large amounts of data?"",""example_answer"":""I would use distributed computing techniques such as parallel processing or Hadoop to handle large amounts of data.""}],""red_flags"":[""Avoid candidates without experience in cloud environments"",""Be cautious of candidates with limited experience in machine learning techniques""],""confidence_score"":90.0}"
Data scientist et développeur en Intelligence Artificielle,EOS imaging,"Montreal, Quebec, Canada",June,2024,"EOS imaging est une société internationale spécialisée dans les solutions innovantes en imagerie et logiciels pour les soins ostéo-articulaires et la chirurgie orthopédique. La société dédie ses efforts et compétences à l'amélioration des soins ostéo-articulaires via des images médicales moins irradiantes du corps entier en position fonctionnelle, des données patients 2D/3D complètes et précises, et des outils de planification chirurgicale fondés sur l'anatomie réelle, 3D, du patient.

Elle fait partie du groupe Alphatec Spine.

Au sein du département développement IA, l'ingénieur développement en Intelligence Artificielle contribue à la mise en place des solutions de détection et de localisation de structures anatomiques et structures d'intérêts.

Missions principales

Vos activités seront les suivantes :
Contribuer à l'élaboration des spécifications techniques
Participer à la définition des architectures techniques
Concevoir, développer, industrialiser et optimiser des algorithmes par apprentissage profond
Réaliser des phases de test et de validation
Rédiger de la documentation technique
Participer à la veille scientifique et technique dans votre domaine d'expertise


Requirements

Compétences et capacités requises

Solide compétence en python
Apprentissage machine et en particulier l'apprentissage profond (Deep Convolutional Neural Networks)
Algorithmique de traitement d'image (filtrage, segmentation, reconstruction 3D)
Maitrise de librairies de machine learning (scikit-learn) et de frameworks de deep Learning (tensorflow ou pytorch)
Utilisation d'outils de développement et de partage de code tels que Git et SVN
Capacité d'analyse et de synthèse d'informations et problèmes complexes
Communication synthétique
Capacité à travailler en équipe avec les autres métiers et les autres fonctions impliquées dans les projets
Autonome
Rigoureux
Anglais courant


Formation et expérience

Formation Bac+5 (école d'ingénieur ou master des Universités) avec une spécialisation en Intelligence Artificielle
Minimum 3 ans d'expérience en intelligence artificielle dans un milieu industriel","{""role_summary"":""Contribute to the development of AI solutions for osteo-articular care and orthopedic surgery, focusing on image processing and machine learning algorithms."",""key_terms"":[{""term"":""Deep Convolutional Neural Networks"",""explanation"":""A type of machine learning algorithm used for image processing and analysis.""},{""term"":""Algorithmique de traitement d'image"",""explanation"":""Image processing techniques, including filtering, segmentation, and 3D reconstruction.""},{""term"":""Librairies de machine learning"",""explanation"":""Software libraries used for machine learning, such as scikit-learn and PyTorch.""}],""skill_priorities"":{""must_have"":[""Python"",""Machine learning"",""Deep learning"",""Image processing algorithms"",""scikit-learn"",""TensorFlow or PyTorch"",""Git and SVN""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of Deep Convolutional Neural Networks and its application in image processing?"",""example_answer"":""Deep Convolutional Neural Networks are a type of machine learning algorithm that uses multiple layers to analyze and interpret image data. They are particularly useful for image classification, object detection, and image segmentation tasks.""},{""question"":""How do you approach image processing tasks, such as filtering and segmentation?"",""example_answer"":""I would use a range of techniques, including convolutional neural networks, to develop an efficient and accurate image processing pipeline.""}],""red_flags"":[""Lack of experience with deep learning frameworks such as TensorFlow or PyTorch."",""Inability to work collaboratively with cross-functional teams.""],""confidence_score"":90.0}"
Machine Learning Engineer (LLM Infrastructure) - Toronto,Prodigy Labs (Acquired by UST),"Toronto, Ontario, Canada",June,2024,"We are looking for a Machine Learning Engineer who has strong experience in building systems that accelerate the development and deployment of machine learning models, especially large language models (LLMs). You will partner closely with Machine Learning researchers and internal users to understand requirements and apply strong ML fundamentals to build high performance and reusable APIs and can also apply them in real production settings.

Please Note: This is a hybrid position and will require at least 2 days in the office per week. Successful candidates will need to complete a background check.

Responsibilities

Architect/Enable distributed compute aligning workloads to Small/Mid/High end GPUs
Leverage appropriate storage hardware and data formats to improve read/re-read efficiency
Identify and remediate latency contributors especially IO bottlenecks, inefficient data shuffling, under/over utilized compute
Scale models by employing distributed training using Data / Model Parallelism techniques
Parallelize inference processing to improve prediction latency.
Provide Subject Matter Expertise in Graph and Vector databases for various use cases including Knowledge Graphs, RAG etc.
Implement LLM observability and monitoring solutions
Manage infrastructure and large-scale system design and diagnose both model and system failures
Mitigate reputation risk through AI driven Data Quality to ensure highest quality data and services are offered to clients


Requirements

5-6 years of AI, Big Data and cloud expertise
3-4 years of Alternative data experience
2+ years of experience building machine learning training pipelines or inference services in a production setting
Experience with LLM deployment, fine tuning, training, prompt engineering, etc
Experience with LLM inference latency optimization techniques, e.g. kernel fusion, quantization, dynamic batching, etc.
Experience with CUDA, model compilers, and other model-specific optimizations
Experience building, deploying, and monitoring complex microservice architectures.
Degree in Computer Science or Engineering
Prior Experience with: -Docker, Kubernetes, Infrastrure as code (Terraform)and containerization, Agile Methodology, Distributed systems, Databricks ML, Cloud (Azure (preferred) or AWS)
Expert level - Python, SQL
Experience (or knowledge of) Mosaic ML, Ray Framework
Experience with Lang Chain or LlamaIndex
Experience with any vector database


Nice to have

Experience building front to back data pipelines comprising of data ingestion, enrichment, data quality, Analytics and reporting
Experience with company KPIs and back testing of alternative data factors against company KPIs
Experience with NLP techniques and transfer learning frameworks like BERT
Experience with using HuggingFace Model Artifacts


Benefits

Why You'll Love Working at Prodigy

We are a collective group of people and collaboration is key to our process
We don't work for our clients, we work with them
A Flexible Hybrid Working Environment
Easily accessible downtown location
Competitive compensation commensurate with experience
Everyone brings something valuable to the table in our supportive, challenging, and collaborative, diverse work environment


All Employees Can Participate in:

Company paid health benefits: 100% medical, dental and vision coverage
Corporate-discounted Gym Membership through GoodLife
Company discount program including Travel, Shopping, Attractions, Wellness, & Sporting events, just to name a few
Access to an Employee & Family Assistance program (EAP)
Employee Referral Program
Employee Opportunity Program
Professional Development Program
Town Halls
Philanthropic Events
Social Events


Accessibility

Prodigy is committed to providing equitable treatment and accommodation to ensure a barrier-free recruitment process and workplace. If you require accommodation at any stage during the recruitment process, please contact us at accessibility@prodigylabs.net or call 416-488-7700 ext. 4

Inclusion & Diversity

At Prodigy we foster an inclusive and diverse workforce, believing our strength stems from our individual differences. Our employees, partners, and clients continuously benefit from the innovation and creativity grounded in these values. We strive to be a company that attracts a diverse group of highly skilled people who know that their contributions will be valued and that they will be heard. We are committed to building a corporate culture with people who are excited to join our team, do their best work, and grow with us!","{""role_summary"":""Design and deploy machine learning models, focusing on large language models, and partner with researchers to build high-performance APIs for production settings."",""key_terms"":[{""term"":""LLMs"",""explanation"":""Large Language Models, used for natural language processing and machine learning applications.""},{""term"":""Data / Model Parallelism"",""explanation"":""Techniques used to scale machine learning models by distributing data or model components across multiple computing resources.""},{""term"":""Graph and Vector databases"",""explanation"":""Specialized databases optimized for storing and querying complex data structures, such as knowledge graphs and vector embeddings.""}],""skill_priorities"":{""must_have"":[""5-6 years of AI, Big Data, and cloud expertise"",""2+ years of building machine learning training pipelines or inference services in a production setting"",""Experience with LLM deployment, fine-tuning, training, prompt engineering, etc."",""Expert-level Python and SQL skills""],""nice_to_have"":[""Experience building front-to-back data pipelines"",""Experience with company KPIs and back-testing of alternative data factors against company KPIs"",""Experience with NLP techniques and transfer learning frameworks like BERT"",""Experience with using HuggingFace Model Artifacts""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize the performance of large language models in production settings?"",""example_answer"":""I would employ distributed training using Data/Model Parallelism techniques and leverage kernel fusion, quantization, and dynamic batching for inference latency optimization.""},{""question"":""Can you explain your experience with graph and vector databases?"",""example_answer"":""I have worked with vector databases like Mosaic ML and Lang Chain, and have experience with knowledge graph use cases.""}],""red_flags"":[""Lack of experience with LLM deployment and fine-tuning"",""Inability to optimize inference latency using kernel fusion, quantization, and dynamic batching""],""confidence_score"":90.0}"
"Software Engineer, NLP/ML","Calabrio, Inc.",Canada,June,2024,"Calabrio is looking for a highly skilled and experienced Software Engineer, NLP/ML to perform a key role in our digital transformation program, and deliver exceptional customer experience supported by trusted, and resilient business solutions. As an NLP/ML Software Engineer, you will play a pivotal role in developing and implementing cutting-edge NLP models and solutions. The ideal candidate should have a strong background in machine learning, natural language processing, and a proven track record of delivering successful projects in the field. Calabrio has embarked journey and is truly committed to establishing a value fabric that transforms its customer, employee, and stakeholder experiences through seamless integrated, agile, data-driven, and secure Digital Services. Such an endeavor requires leaders passionate about customer experience and committed to consistently delivering value while focusing on digital services with inherent trust and resilience.
  What you'll be doing{{:}}
·       Design, develop, and implement advanced NLP algorithms and models to solve complex problems in Conversation Analytics with classification, information extraction, clustering, topic modeling, text generation, and data processing.
·       Work on data engineering and processing to gather and preprocess large-scale conversation datasets for training and evaluation of NLP models.
·       Train, fine-tune, and optimize machine learning models for NLP applications.
·       Optimize models for deployment in real-world applications, considering factors such as latency, scalability, and resource efficiency.
·       Stay current with state-of-the-art research in NLP and contribute to the development of new approaches and methodologies for Conversation analytics problems.
·       Evaluate emerging technologies and tools to enhance the overall capabilities of our Conversation Analytics systems.
·       Work closely with cross-functional teams, including data scientists, software engineers, and product managers, to drive successful project outcomes. 
We're looking for{{:}}
·       Problem solving skills and an ability to devise and implement advanced NLP algorithms and models to address intricate challenges in Conversation analytics.
·       Strong team player who works with internal and external stakeholders to solve problems and actively incorporate input from various sources.
·       Excellent communication skills and collaborative working style.
·       Ability to think ""out of the box"", strong critical thinking, and analytical skills.

Requirements

·       Bachelor's Degree (MSc+ is preferred) in Computer Science/Engineering or related field.
·       2+ years of end-to-end experience of ML model training, evaluating, testing, and deploying machine learning models.
·       Strong experience working with Python, Flask(Django), Numpy and Pandas.
·       Expertise in NLP tasks such as Text classification, NER, Clustering, and Topic-modeling.
·       Robust understanding of Machine Learning fundamentals.
·       Experience with Prompt Engineering for LLM models.
·       Experience with Fine-tuning LLM models.
·       Experience with TextCNN, LSTM, Seq2Seq, and BERT models.
·       Strong understanding of transformers (tokenizers, pre-trained models, fine-tuning).
·       Experience with PyTorch, TensorFlow, and Scikit-learn.
·       Experience with NLP libraries like spaCy, etc.
·       Experience with SQL and NOSQL DB.
·       Familiarity with Linux systems.
Preferred Qualifications{{:}} 
·       Experience with AWS, Azure, or GCP.
·       Experience with Docker and Kubernetes.
·       Experience with ETL and Data Engineering projects.
·       Experience with PySpark and MapReduce.
·       Experience with PostgreSQL, Snowflake, or MongoDB.
·       Experience with Kubeflow, or Airflow.


Benefits

Calabrio People are{{:}} Open, Clear, Ambitious, Accountable, Collaborative, Consistent
What we value most...workplace diversity and ensuring an environment of mutual respect.  We believe that diversity and inclusion are critical to our success, and we are proud to be an equal opportunity employer. Our commitment is to continue to keep our people healthy, focused, and inspire creativity.  Our team members are offered comprehensive benefits for various life circumstances and needs, great opportunities for career development, and a balanced work-life to achieve personal and professional success (all benefits are subject to eligibility requirements).  As an Innovator with Purpose, you'll feel motivated and truly excited to come to work!
About Calabrio{{:}} 
Calabrio is the customer experience intelligence company that empowers organizations to enrich human interactions. The scalability of our cloud platform and our AI-driven analytics tools make it easy for contact centers to uncover customer sentiment and share compelling insights with other parts of the organization. Our solutions are built on an intuitive, web-based architecture that positions and accelerates the contact center as an epicenter for customer insight.
Awards & Accolades{{:}}
Calabrio has 300 Global Partners, more than 2.25 million agents, and over 7,000 customers worldwide. We've been doing this for more than two decades and have been recognized by leading independent third parties such as Gartner, Forrester, and G2 Crowd as a leader and visionary. Thanks to the hard work and dedication of every Calabrio team member, we have been recognized by the Star Tribune Top Workplace for 9 years in a row, a 2022 certified Great Place to Work UK, named one of BC's Top Employers for 2023, and recognized as a top 50 fast-growth company by Minneapolis/St Paul Business Journal. 
Calabrio celebrates and fosters a culture that thrives on diversity. We are an Equal Opportunity Employer that prohibits discrimination and harassment of any kind. We provide employees with a work environment free of discrimination and harassment. All employment decisions at Calabrio are based on business needs, job requirements, and individual qualifications, without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status, parental status, or any other status protected by the laws or regulations in the locations where we operate. We celebrate the >40 nationalities of team members that contribute to our success.
 ","{""role_summary"":""Design, develop, and implement advanced NLP algorithms and models to solve complex problems, working closely with cross-functional teams to drive successful project outcomes."",""key_terms"":[{""term"":""NLP"",""explanation"":""Natural Language Processing, a subfield of artificial intelligence that deals with the interaction between computers and humans in natural language.""},{""term"":""ML"",""explanation"":""Machine Learning, a subfield of artificial intelligence that involves training models to make predictions or decisions based on data.""},{""term"":""Conversation Analytics"",""explanation"":""The process of analyzing and extracting insights from customer conversations to improve customer experience.""},{""term"":""LLM"",""explanation"":""Large Language Models, a type of AI model trained on large amounts of text data to generate language outputs.""},{""term"":""Transformer"",""explanation"":""A type of neural network architecture used in NLP tasks, such as language translation and text classification.""}],""skill_priorities"":{""must_have"":[""Python"",""Flask(Django)"",""Numpy"",""Pandas"",""NLP tasks such as Text classification, NER, Clustering, and Topic-modeling"",""Machine Learning fundamentals"",""Experience with Prompt Engineering for LLM models"",""Experience with Fine-tuning LLM models"",""Experience with TextCNN, LSTM, Seq2Seq, and BERT models""],""nice_to_have"":[""Experience with AWS, Azure, or GCP"",""Experience with Docker and Kubernetes"",""Experience with ETL and Data Engineering projects"",""Experience with PySpark and MapReduce"",""Experience with PostgreSQL, Snowflake, or MongoDB"",""Experience with Kubeflow, or Airflow""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach implementing a new NLP model for conversation analytics?"",""example_answer"":""I would start by gathering and preprocessing the conversation dataset, then train and fine-tune the model, considering factors such as latency and scalability.""},{""question"":""How do you stay current with state-of-the-art research in NLP?"",""example_answer"":""I regularly read research papers and articles, attend conferences, and participate in online forums to stay updated on the latest developments in NLP.""}],""red_flags"":[""Lack of experience with NLP tasks such as Text classification, NER, Clustering, and Topic-modeling"",""Inability to work with cross-functional teams""],""confidence_score"":90.0}"
ML Engineer,Epsilon Solutions Ltd.,"Toronto, Ontario, Canada",June,2024,"Role - Client Engineer

Location- Remote (Canada)

Jd

Client Engineer will enable AI impact at scale by transforming prototypes into production-grade AI pipelines, maintaining models in production, and contributing to our AI platform and engineering practices.

1/ Transform prototypes into production-grade models

Work with data scientists and AI strategists to develop requirements for production models
Design and develop robust applications to manage production models
Collaborate with data governance and technical teams to ensure compliance with Client AI and engineering standards

2/ Maintain models in production

Manage the full CI/CD cycle for live models including testing and deployment
Manage label feedback and model retraining processes
Develop logging, alerting, and mitigation strategies for handling model errors
Collaborate with data scientists to design and develop drift detection and accuracy measurements for live models

3/ Contribute to AI platform and engineering practices

Collaborate with DS and Client engineering leadership to develop coding standards and practices across the applied AI team
Research, test, and help train the team on using leading edge AI platforms, such as auto Client libraries, graph databases, and cloud execution frameworks
Contribute to the team's AI infrastructure strategy and management
3+ years of industry experience in Client engineering
Strong experience in Python
Experience in data product development, analytical models, and model governance
Experience with AI workflow management tools such as Airflow, Kedro, or Luigi
Exposure statistical modeling, machine learning algorithms, and predictive analytics.
Highly structured and organized work planning skills
Strong understanding of the AI development lifecycle and Agile practices
Proficiency in big data technologies like Hadoop, Spark, or similar frameworks. Experience with graph databases a plus.
Experience in working with cloud computing platforms like AWS, Azure, or Google Cloud.
Proven track record of delivering data products in environments with strict adherence to security and model governance standards.
Bachelor's degree in computer science, analytics, mathematics, statistics, economics, industrial engineering, or physical sciences.

Thanks and Regards

Saurabh Srivastava

Account Manager

E: Saurabh.srivastava@epsilonsolutions.ca","{""role_summary"":""The Client Engineer transforms prototypes into production-grade AI pipelines, maintains models in production, and contributes to the AI platform and engineering standards."",""key_terms"":[{""term"":""AI pipelines"",""explanation"":""Production-grade infrastructure for deploying and managing artificial intelligence models.""},{""term"":""CI/CD cycle"",""explanation"":""Continuous Integration and Continuous Deployment process for ensuring smooth testing and deployment of models.""},{""term"":""Auto Client libraries"",""explanation"":""Automated libraries for client-side AI development.""},{""term"":""Graph databases"",""explanation"":""Databases optimized for storing and querying complex relationships between data entities.""},{""term"":""Cloud execution frameworks"",""explanation"":""Platforms for deploying and managing AI models in cloud environments.""}],""skill_priorities"":{""must_have"":[""Python"",""Data product development"",""Analytical models"",""Model governance"",""AI workflow management tools (e.g., Airflow, Kedro, or Luigi)"",""Data technologies (e.g., Hadoop, Spark)"",""Cloud computing platforms (e.g., AWS, Azure, Google Cloud)""],""nice_to_have"":[""Graph databases"",""Statistical modeling"",""Machine learning algorithms"",""Predictive analytics"",""Big data technologies"",""Cloud computing platforms""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure model governance in production-grade AI pipelines?"",""example_answer"":""I collaborate with data governance teams to ensure compliance with Client AI and engineering standards, and implement logging, alerting, and mitigation strategies for handling model errors.""},{""question"":""Can you explain your experience with AI workflow management tools like Airflow or Luigi?"",""example_answer"":""I have used Airflow to manage the full CI/CD cycle for live models, including testing and deployment.""}],""red_flags"":[""Lack of experience with Python or data product development skills"",""Inability to work with cloud computing platforms"",""Insufficient understanding of AI development lifecycle and Agile practices""],""confidence_score"":90.0}"
AI / ML Engineer,"Triunity Software, Inc.","Toronto, Ontario, Canada",June,2024,"Experience: 10 + yrs.

Job Type: Full time

Responsibilities:

Design, develop, and deploy machine learning models and algorithms to solve business problems.
Collaborate with cross-functional teams to gather requirements, understand business objectives, and deliver AI/ML solutions.
Explore and experiment with new machine learning techniques, frameworks, and libraries to improve model performance and accuracy.
Optimize and scale machine learning algorithms to handle large volumes of data efficiently.
Conduct thorough testing and validation to ensure the quality and reliability of AI/ML models.
Stay up-to-date with the latest advancements in artificial intelligence and machine learning research and technologies.


Qualifications:

Bachelor's or Master's degree in computer science, engineering, mathematics, or a related field.
Strong proficiency in Python and experience with libraries such as TensorFlow, PyTorch, scikit-learn, etc.
Solid understanding of machine learning algorithms and techniques, including supervised and unsupervised learning, deep learning, reinforcement learning, etc.
Experience with data preprocessing, feature engineering, and model evaluation.
Familiarity with cloud platforms such as AWS, Azure, or Google Cloud for model deployment and management.
Excellent problem-solving skills and attention to detail.
Strong communication and collaboration skills, with the ability to work effectively in a team environment.


Preferred Qualifications:

Experience with natural language processing (NLP), computer vision, or other specialized areas of machine learning.
Knowledge of software development best practices, including version control, testing, and code review.
Experience with big data technologies such as Hadoop, Spark, etc.","{""role_summary"":""Design, develop, and deploy machine learning models to solve business problems, collaborating with cross-functional teams and staying up-to-date with the latest advancements in AI/ML research and technologies."",""key_terms"":[{""term"":""Machine learning algorithms and techniques, including supervised and unsupervised learning, deep learning, reinforcement learning, etc."",""explanation"":""These are methods used to train machine learning models to make predictions or take actions.""},{""term"":""Cloud platforms"",""explanation"":""Cloud-based services like AWS, Azure, or Google Cloud used for deploying and managing machine learning models.""},{""term"":""Natural Language Processing (NLP)"",""explanation"":""A subfield of machine learning that deals with the interaction between computers and humans in natural language.""},{""term"":""Big data technologies"",""explanation"":""Tools like Hadoop and Spark that enable handling and processing of large datasets.""}],""skill_priorities"":{""must_have"":[""Python"",""Machine learning algorithms and techniques"",""Data preprocessing"",""Feature engineering"",""Model evaluation"",""Cloud platforms"",""Problem-solving skills"",""Communication and collaboration skills""],""nice_to_have"":[""Natural Language Processing (NLP)"",""Computer vision"",""Big data technologies"",""Software development best practices"",""Version control"",""Testing"",""Code review""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the difference between supervised and unsupervised machine learning?"",""example_answer"":""In supervised learning, the model is trained on labeled data to make predictions, whereas in unsupervised learning, the model is trained on unlabeled data to discover patterns or relationships.""},{""question"":""How do you optimize machine learning models for deployment on cloud platforms?"",""example_answer"":""I would consider factors like model size, data volume, and computational resources, and use techniques like model pruning, knowledge distillation, or distributed training.""}],""red_flags"":[""Lack of experience with cloud platforms"",""Inability to explain machine learning concepts"",""Poor communication and collaboration skills""],""confidence_score"":95.0}"
Python Developer,Genpact,"Montreal, Quebec, Canada",June,2024,"Inviting applications for the role of Lead Consultant, Python Developer!

As a Senior Python Developer, you will be a key member of the IT Applications Development team driving the quality of the solution and services meant to run the business. you will be responsible for designing and developing solutions for client business. You should have an end-to-end understanding of business use cases, to transform them into an effective and strategic solution. You will have the opportunity to work with the latest platform and applications on the given stack.
Responsibilities
Responsible for crafting clean, functional code that flawlessly suits the needs of the company. Your main focus will be translating the design concepts and requirements into simpler implementation level details & designing and developing Python applications.
Collaborate with product owners to create and define user stories and acceptance criteria.
Translate the design concepts, requirements into simpler implementation level details
Initiating collaboration with technical and product teams to identify development requirements and terms
Analysing the clients’ requirements and prioritising their suggested features
Writing well-structured, well-tested, clean quotes with Python programming language to create new applications or add features & improvements to existing services
Working in an Agile environment, following Scrum principles to break silos and support faster iteration and implementation of codes & apps.
Excellent written and verbal communication skills.
Excellent customer facing skills that include conducting compelling technical briefing & demonstrations.
Perform code reviews and check code coverage to ensure the modularity and quality of the code and application.
Work independently with limited or no handholding.
Responsible for troubleshooting issues found during development and providing necessary resolution.
Engage in technical discussions; participate in technical designs and present technical ideas through white board.
Seed and provide feedback on design and development.
Development of features and ALM integrations REST API use
Development test cases using the BDD framework.
Creating incremental SDLC-related functionality.
Preparation and deployment to production, deployment to go live, and postproduction support, as well as bug fixes and the correction of any new or existing issues.
Qualification(Minimum Qualification)
B.Tech/B.E/ MCA
Excellent written and verbal communication skills.
Preferred Qualifications
Good Python experience (REST APIs/Flask)
Design and develop Microservices systems with Python.
AWS Compute, S3, API Gateway.
AWS Lambda based development.
Programming for backend databases like AWS DynamoDB or any other RDBMS or NoSQL DBs.
Front-end development utilizing Electron VUE
Experience with Elastic Search
Exposure to Continuous integration using DevOps - Jenkins and other CI/CD tools.
Exposure to Linux, Apache/httpd, Networking, Firewalls, security, etc.
Good Analytical, Problem-solving and design skills (HLD/LLD) skills
Fluent with object-oriented programming principles.
Familiarity with common stacks
Understanding of fundamental design principles behind a scalable application
Good Understanding of Agile Delivery Methodology & experience in working with Scrum teams
Selection Process
CV screening on the basis of basic requirements
Interview by the Function Head.","{""role_summary"":""Lead Consultant, Python Developer responsible for designing and developing Python applications, collaborating with product owners, and ensuring high-quality code delivery in an Agile environment."",""key_terms"":[{""term"":""Microservices"",""explanation"":""An architectural approach to building applications as a collection of small, independent services.""},{""term"":""REST API"",""explanation"":""A type of API that uses simple, stateless communication to interact with services.""},{""term"":""AWS Lambda"",""explanation"":""A serverless computing service that runs code in response to events.""},{""term"":""BDD framework"",""explanation"":""A testing approach that focuses on defining application behavior through examples.""},{""term"":""Scrum principles"",""explanation"":""An Agile framework that emphasizes teamwork, collaboration, and iterative progress toward goals.""}],""skill_priorities"":{""must_have"":[""Python development"",""Agile environment experience"",""Scrum principles"",""Excellent communication skills""],""nice_to_have"":[""AWS Compute, S3, API Gateway experience"",""Microservices system development"",""Front-end development with Electron VUE"",""Experience with Elastic Search"",""Exposure to Continuous integration using DevOps - Jenkins and other CI/CD tools""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach designing a scalable Python application?"",""example_answer"":""I would focus on applying fundamental design principles, such as separation of concerns and loose coupling, to ensure the application can handle increased traffic and user activity.""},{""question"":""How do you ensure high-quality code delivery in an Agile environment?"",""example_answer"":""I prioritize writing clean, well-structured code, and perform regular code reviews to ensure modularity and quality issues early on.""}],""red_flags"":[""Lack of experience with Agile development methodologies"",""Insufficient Python development skills""],""confidence_score"":90.0}"
"Data Scientist, Decisions - Driving Experience",Lyft,"Toronto, Ontario, Canada",June,2024,"At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization.

As a Data Scientist on the Driving XP team, you will collaborate with our world class team of engineers, product managers, and designers to design the end-to-end driving experience for hundreds of thousands of drivers who interact deeply with our app every day. This includes building tools to set personal driving preferences, guidance on when and where to drive, and designing the best UI and personalized XP to get the right rides to the right drivers quickly.

Data Science is at the heart of Lyft’s products and decision-making. You will leverage data and rigorous, analytical thinking to shape our Driving XP products and make business decisions that put drivers first. This will involve identifying and scoping opportunities, shaping priorities, recommending technical solutions, designing experiments, and measuring the impact of new features.

Responsibilities:

Leverage data and analytic frameworks to identify opportunities for growth and efficiency
Partner with product managers, engineers, marketers, designers, and operators to translate data insights into decisions and action
Design and analyze online experiments; communicate results and act on launch decisions
Develop analytical frameworks to monitor business and product performance
Establish metrics that measure the health of our products, as well as rider and driver experience

Experience:

Degree in a quantitative field such as statistics, economics, applied math, operations research or engineering (advanced degrees preferred), or relevant work experience
5+ years of industry experience in a data science or analytical role
Proficiency in SQL - able to write structured and efficient queries on large data sets
Experience in programming, especially with data science and visualization libraries in Python or R
Experience in online experimentation and statistical analysis
Experience in applying Machine Learning techniques (e.g. reinforcement learning) to solve customer problems (e.g. personalization, segmentation)
Strong oral and written communication skills, and ability to collaborate with and influence cross-functional partners

Benefits:

Extended health and dental coverage options, along with life insurance and disability benefits
Mental health benefits
Family building benefits
Access to a Health Care Savings Account
In addition to provincial observed holidays, team members get 15 days paid time off, with an additional day for each year of service
4 Floating Holidays each calendar year prorated based off of date of hire
10 paid sick days per year regardless of province
18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible

Lyft proudly pursues and hires a diverse workforce. Lyft believes that every person has a right to equal employment opportunities without discrimination because of race, ancestry, place of origin, colour, ethnic origin, citizenship, creed, sex, sexual orientation, gender identity, gender expression, age, marital status, family status, disability, pardoned record of offences, or any other basis protected by applicable law or by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Accommodation for persons with disabilities will be provided upon request in accordance with applicable law during the application and hiring process. Please contact your recruiter now if you wish to make such a request.

This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid","{""role_summary"":""As a Data Scientist, you will collaborate with engineers, product managers, and designers to design the end-to-end driving experience for hundreds of thousands of drivers, leveraging data and analytical thinking to shape products and make business decisions that put drivers first."",""key_terms"":[{""term"":""Data Science"",""explanation"":""The practice of extracting insights and knowledge from data using various techniques, including machine learning and statistical analysis.""},{""term"":""Driving XP"",""explanation"":""The end-to-end driving experience for Lyft drivers, encompassing tools, guidance, and personalized UI to optimize ride allocation.""},{""term"":""Online Experiments"",""explanation"":""A method of testing hypotheses by randomly assigning users to different groups and measuring the impact of new features or changes.""},{""term"":""Machine Learning"",""explanation"":""A subset of artificial intelligence that enables systems to learn from data and improve their performance over time.""}],""skill_priorities"":{""must_have"":[""5+ years of industry experience in a data science or analytical role"",""Proficiency in SQL"",""Experience in programming, especially with data science and visualization libraries in Python or R"",""Strong oral and written communication skills""],""nice_to_have"":[""Advanced degree in a quantitative field"",""Experience in applying Machine Learning techniques to solve customer problems""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to communicate complex data insights to a non-technical stakeholder?"",""example_answer"":""In my previous role, I had to present findings on customer behavior to our marketing team. I created a clear, concise report that highlighted key takeaways and recommendations, which led to a change in our marketing strategy.""},{""question"":""How do you approach designing and executing online experiments?"",""example_answer"":""I follow a structured approach, starting with hypothesis formation, experiment design, and analysis. I also ensure that experiments are properly randomized and that I'm measuring the right metrics to inform business decisions.""}],""red_flags"":[""Lack of experience working with large datasets"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":95.0}"
Senior Data Scientist,Techedin,Canada,June,2024,"Come aboard a multinational Fortune 500 project in Canada as a Senior Data Scientist. Help craft groundbreaking solutions and lead the charge in technology. Apply today to become an essential part of the client's dynamic team.

Minimum Qualifications

MS/PhD in a quantitative field: Mathematics, Physical Sciences, Statistics/Analytics, Computer Science, or other relevant fields.
Solid experience and a passion for designing, analyzing, and deploying machine learning-based solutions.
Experience with Large Language Models (RAG, Generative AI) and NLP.
Fluency with one or more programming languages: Python, Java, Scala, etc.
Experience with data science toolkits like: pandas, Jupyter, scikit, TensorFlow, etc.
Experience working with big data platforms (Hadoop, Spark, Hive).
Experience working with relational SQL and/or NoSQL databases.
Ability to write high quality, well-documented, scalable code - Python preferred.
Familiarity with cloud computing (AWS).
Familiarity with Machine Learning techniques, e.g., classification, clustering, regularization, optimization, dimension reduction, etc.
Strong communication skills with the ability to explain complex/technical work to a non-technical audience and to present data effectively.
Experience with recommender systems.

Share your resume at hr@techedinlabs.com

Thank you for applying!

Techedin is a global IT Services company complementing the efforts of technology-driven enterprises in developing cutting-edge solutions for humans. We offer services in enterprise app development, content management solutions (CMS), customer relationship management (CRM), cloud engineering, custom software development, and data engineering. Our services include IT Consulting, project management, Software Quality Assurance, and data and analytics services. We develop and maintain various software applications and all other computer-related ancillary services. We have excellent professionals working round the clock to build the best technology teams and products for our customers.","{""role_summary"":""Lead the development of groundbreaking solutions as a Senior Data Scientist, utilizing machine learning and NLP expertise to drive technology advancements."",""key_terms"":[{""term"":""Large Language Models (RAG, Generative AI)"",""explanation"":""Advanced AI models used for natural language processing and machine learning applications.""},{""term"":""NLP"",""explanation"":""Natural Language Processing, a subfield of AI that deals with human language understanding and generation.""},{""term"":""Cloud computing (AWS)"",""explanation"":""Using cloud-based services, such as Amazon Web Services, for scalable and on-demand computing resources.""},{""term"":""Recommender systems"",""explanation"":""Algorithms that suggest personalized content or products based on their past behavior and preferences.""}],""skill_priorities"":{""must_have"":[""MS/PhD in a quantitative field"",""Experience with machine learning-based solutions"",""Fluency with one or more programming languages"",""Experience with data science toolkits"",""Experience working with big data platforms"",""Experience working with relational SQL and/or NoSQL databases"",""Ability to write high-quality, well-documented, scalable code"",""Familiarity with cloud computing (AWS)"",""Familiarity with Machine Learning techniques""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you've applied machine learning techniques to solve complex business problems?"",""example_answer"":""In my previous role, I used clustering to identify customer segments and developed a recommendation system that increased sales by 15%.""},{""question"":""How do you ensure the scalability and maintainability of your code?"",""example_answer"":""I follow best practices for coding, use modular design, and implement automated testing to ensure my code is efficient and easy to maintain.""}],""red_flags"":[""Lack of experience with machine learning-based solutions"",""Inability to explain complex technical concepts to non-technical audiences""],""confidence_score"":90.0}"
"Data Scientist, Decisions - Rider Experience",Lyft,"Toronto, Ontario, Canada",June,2024,"At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization.

Data Science is at the heart of Lyft’s products and decision-making. As a member of the Rider team, you will work in a dynamic environment, where we embrace moving quickly to build the world’s best transportation. Data Scientists take on a variety of problems ranging from shaping critical business decisions to building algorithms that power our internal and external products. We’re looking for passionate, driven Data Scientists to take on some of the most interesting and impactful problems in ridesharing.

As a Data Scientist, Decisions in the Rider team, you will leverage data and rigorous, analytical thinking to shape our rider app and make business decisions that put our customers first. You will identify and scope opportunities, shape priorities, recommend technical solutions, design experiments, and measure impact. You will bring a quantitative mindset to decision-making in partnership with product, design, engineering, business, and operations stakeholders throughout the organization.

You will report to a Data Science Manager in the Rider Science team.

Responsibilities:

Leverage data and analytic frameworks to identify opportunities for growth and efficiency
Partner with product managers, engineers, marketers, designers, and operators to translate data insights into decisions and action
Design and analyze online experiments; communicate results and act on launch decisions
Develop analytical frameworks to monitor business and product performance
Establish metrics that measure the health of our products, as well as rider and driver experience

Experience:

Degree in a quantitative field such as statistics, economics, applied math, operations research or engineering (advanced degrees preferred), or relevant work experience
3+ years of industry experience in a data science or analytics role
Proficiency in SQL - able to write structured and efficient queries on large data sets
Experience in programming, especially with data science and visualization libraries in Python or R is helpful
Experience in online experimentation and statistical analysis
Strong oral and written communication skills, and ability to collaborate with and influence cross-functional partners

Benefits:

Extended health and dental coverage options, along with life insurance and disability benefits
Mental health benefits
Family building benefits
Access to a Health Care Savings Account
In addition to provincial observed holidays, team members get 15 days paid time off, with an additional day for each year of service
4 Floating Holidays each calendar year prorated based off of date of hire
10 paid sick days per year regardless of province
18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible

Lyft proudly pursues and hires a diverse workforce. Lyft believes that every person has a right to equal employment opportunities without discrimination because of race, ancestry, place of origin, colour, ethnic origin, citizenship, creed, sex, sexual orientation, gender identity, gender expression, age, marital status, family status, disability, pardoned record of offences, or any other basis protected by applicable law or by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Accommodation for persons with disabilities will be provided upon request in accordance with applicable law during the application and hiring process. Please contact your recruiter now if you wish to make such a request.

This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #Hybrid","{""role_summary"":""As a Data Scientist in the Rider team, you will leverage data and analytical thinking to shape the rider app and put customers first, working closely with cross-functional stakeholders to drive business decisions and product development."",""key_terms"":[{""term"":""Data Science"",""explanation"":""The practice of extracting insights from data to inform business decisions and product development.""},{""term"":""Rigorous analytical thinking"",""explanation"":""A methodical approach to analyzing data to draw meaningful conclusions and drive business decisions.""},{""term"":""Online experimentation"",""explanation"":""A method of testing hypotheses by exposing different groups of users to different experiences and measuring the impact on business outcomes.""}],""skill_priorities"":{""must_have"":[""Degree in a quantitative field"",""3+ years of industry experience in data science or analytics"",""Proficiency in SQL"",""Strong oral and written communication skills""],""nice_to_have"":[""Experience in programming with data science and visualization libraries in Python or R"",""Experience in online experimentation and statistical analysis""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through a time when you had to communicate complex data insights to a non-technical stakeholder?"",""example_answer"":""I worked with a product manager to develop a dashboard to measure user engagement. I had to explain the methodology and results to the product team, and we were able to increase engagement by 20%.""},{""question"":""How do you approach designing and analyzing online experiments?"",""example_answer"":""I follow a structured approach to identify the problem, design the experiment, and analyze the results. I also consider potential biases and ensure the experiment is statistically significant.""}],""red_flags"":[""Lack of experience working with cross-functional stakeholders"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Data Scientist for Biomedical Signals,Myant,"Mississauga, Ontario, Canada",February,2024,"About Us

At Myant, we are creating the world’s first expressive and continuous digital presence platform, enabled by integrating technology directly into clothing and augmented by other devices, wearables, and IOT. We see the evolution of society where every member gets to participate from anywhere and anytime through a whole-body experience, mostly in a passive or ambient manner to foster ubiquitous accessibility. Humans have a fundamental desire and need to be connected to our environment, family, community, and technology. This level of connection will create a paradigm shift in the way we deal with each other, especially from afar, allowing for more meaningful relationships, and more in-depth representation of ourselves.

The need for this type of connection is not new. There are many companies working on ways to connect humans in singularity with technology, however most of these technologies are based on devices that are often used in episodical ways hence, leading to poor adoption or reliability. In general, innovation and technology have delivered significant benefits for many members of society. However, there are those who are left behind, namely the very young, the marginalized, the old and the sick. The challenge of inclusion for those left behind requires us to move beyond device focused strategies, towards an interface that we use naturally, every day. We believe that textile is that primary interface, used in clothing, coverings, carpeting and more, we wear and are surrounded by textiles universally, at all times.

Such an interface could fuse data with other devices that we use periodically and data with other IoTs in the environment. People could then leverage their physical presence over their digital presence to communicate and share personal wellbeing. This could unlock healthcare that is proactive and preventative, social connectedness that is more profound, enable care distribution models to be seamless and on demand, better fitness insights, safer working environments and more.

The vision for SKIIN -our first consumer-facing brand- is to enhance human ability through connected clothing and textiles. Skiin is in beta-phase market launch and has been recently granted Health Canada medical device license and submitted to FDA for regulatory approval in the US market. The sensors and actuators embedded within our apparel create your Digital Identity, which will be consumed by those who matter to you - your family members, physicians, trainers, other IoT devices - without you consciously having to think about it. The line between the digital and physical world is becoming increasingly blurry and we believe textile is the next medium to bridge that gap.

We are a multi-disciplinary technology team solving big challenges at the intersection of electronics, deep tech., software, design, advanced manufacturing and data science.

What we offer at Myant:

Employee stock options
Paid Sick Days and Floating Days
Group Health Insurance Plan
RRSP matching Plan
Corporate Events
Exposure working in one of the most innovative and forward-thinking tech company

Myant is a diversified, equal opportunity employer. People with disability or a special accommodation request may send an email to hr@myant.ca.

Project Description:

You will be involved in Myant’s project with the Canadian Space Agency for development of mental health and sleep monitoring tools for deep space exploration. You will have to design protocols, collect and analyze data to validate the prediction capabilities of various metrics using Myant’s smart-textile based form factors. These metrics include sleep and mental health parameters. You will also be involved in integration of Myant’s system with mental health management solutions provided by other subcontractors.

Responsibilities:

Use tools and algorithms for data collection, testing and validation of our products for biosignal monitoring (e.g. sleep, activity, fatigue and stress)
Clean and organize study data and assess quality and integrity of data collected
Visualize data statistics and perform exploratory data analysis to understand relevant feature engineering approaches
Develop Signal Processing and Machine Learning Algorithms for extracting information and valuable metrics from bio-signals including ECG, activity, temperature, for continuous long-term monitoring;
Collaborate with academic and industrial partners for integration of Myant Products
Evaluate the algorithms and the system as a whole in real-world scenarios and do troubleshooting to cover corner cases
Take ownership of all your deliverables and communicate your results for timely project delivery
Working in an ISO-13485 and HIPAA regulated environment, following quality procedures for design and development as well as verification and validation for clinical use, including to support regulatory approval

Qualifications:

PhD in Biomedical, Electrical/Electronics Engineering, Computer Engineering, Computer Science, or related discipline.
Extensive experience in modern scripting languages including Python. Working familiarity with Python is a must
Knowledge and experience in Bio-signal processing, feature extraction, feature selection, sampling strategies using machine learning algorithms, and systematic hyperparameter optimization
Familiarity with following libraries is desired: scikit-learn, seaborn, plotly, pytorch/tensorflow
Previous experience working on bio-signals such as electrocardiogram, electromyogram, electroencephalogram, photoplethysmogram, IMU signals, etc
Experience on long term biomedical recording and data analysis, from wearable systems and related signal analysis, handling of noise, missing data etc.
Background in time-domain, frequency-domain, and discrete-time signal processing algorithms
Previous experience on planning and coordinating clinical studies, data collection and operating medical devices is a plus

Bonus:

Experience in implementing algorithms in C/C++, Java, Javascript and Swift
Experience in any of the following industries: pharmaceutical, medical technology, healthcare, consumer electronics, and wearables
Experience working in start-ups or growth companies

Powered by JazzHR

yB39rJuEWg","{""role_summary"":""Design and develop signal processing and machine learning algorithms for mental health and sleep monitoring tools using Myant's smart-textile based form factors, integrating with mental health management solutions and collaborating with partners."",""key_terms"":[{""term"":""Bio-signal processing"",""explanation"":""The process of extracting valuable information from biological signals, such as ECG, activity, and temperature, for continuous long-term monitoring.""},{""term"":""Feature engineering"",""explanation"":""The process of selecting and transforming raw data into features that are more suitable for modeling and analysis.""},{""term"":""Signal Processing and Machine Learning Algorithms"",""explanation"":""Algorithms used to extract information and valuable metrics from bio-signals, including ECG, activity, temperature, for continuous long-term monitoring.""},{""term"":""ISO-13485 and HIPAA regulated environment"",""explanation"":""A regulated environment that follows quality procedures for design, development, and validation for clinical use, including supporting regulatory approval.""}],""skill_priorities"":{""must_have"":[""PhD in Biomedical, Electrical/Electronics Engineering, Computer Engineering, Computer Science, or related discipline"",""Experience in modern scripting languages including Python"",""Knowledge and experience in Bio-signal processing, feature extraction, feature selection, sampling strategies using machine learning algorithms, and systematic hyperparameter optimization""],""nice_to_have"":[""Experience in implementing algorithms in C/C++, Java, Javascript and Swift"",""Experience in any of the following industries: pharmaceutical, medical technology, healthcare, consumer electronics, and wearables"",""Experience working in start-ups or growth companies""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of bio-signal processing and its application in mental health monitoring?"",""example_answer"":""Bio-signal processing involves extracting valuable information from biological signals, such as ECG, activity, and temperature, for continuous long-term monitoring. In mental health monitoring, it can be used to detect early signs of mental health conditions.""},{""question"":""How do you handle noise and missing data in bio-signal processing?"",""example_answer"":""I use techniques such as filtering, normalization, and imputation to handle noise and missing data in bio-signal processing.""}],""red_flags"":[""Lack of experience in bio-signal processing and machine learning algorithms"",""Inability to work in an ISO-13485 and HIPAA regulated environment""],""confidence_score"":90.0}"
Junior Python Engineer – up to $130k + Bonus – Montreal (Hybrid),Hunter Bond,"Montreal, Quebec, Canada",June,2024,"Python Padawans Wanted: Kickstart Your Fintech Journey in Montreal
Are you a junior Python pro with 1-4 years under your belt? Ready to join the ranks of an Elite Fintech firm and embark on an epic coding adventure? I am on the hunt for rising stars with an insatiable appetite for learning and a passion for financial technology.

Your Mission (Should You Choose to Accept It):
Develop cutting-edge financial applications using your Python skills
Gain valuable experience in distributed systems and database management
Collaborate with cross-functional teams to solve complex challenges

Your Budding Superpowers:
Bachelor's degree in Computer Science or a related field
1-4 years of professional Python development experience
Strong foundation in object-oriented programming, data structures, and algorithms
Familiarity with Django or FastAPI (a bonus, but not required)
Eagerness to learn about distributed systems and database technologies

What You'll Bring:
Unwavering problem-solving abilities and an analytical mindset
A commitment to writing clean, maintainable code
Excellent communication and collaboration skills
Adaptability to thrive in a fast-paced, dynamic environment
An insatiable thirst for learning and professional growth

The Rewards:
Join a team of coding crusaders working on cutting-edge fintech solutions
Hybrid work environment with a balance of in-office and remote flexibility
Competitive compensation and benefits package
Opportunities for professional development and career advancement

Ready to ignite your coding journey? Apply now and let's conquer the world of fintech together!","{""role_summary"":""Develop cutting-edge financial applications as a junior Python developer in a fintech company, collaborating with cross-functional teams and learning about distributed systems and database management."",""key_terms"":[{""term"":""Distributed systems"",""explanation"":""A computer system that is spread across multiple computers or locations, often used in fintech applications.""},{""term"":""Database management"",""explanation"":""The process of designing, implementing, and maintaining databases to store and manage data.""},{""term"":""Object-oriented programming"",""explanation"":""A programming paradigm that organizes code into objects that contain data and functions that operate on that data.""},{""term"":""FastAPI"",""explanation"":""A modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.""}],""skill_priorities"":{""must_have"":[""Python development experience"",""Strong foundation in object-oriented programming, data structures, and algorithms"",""Bachelor's degree in Computer Science or a related field""],""nice_to_have"":[""Familiarity with Django or FastAPI""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of object-oriented programming and how you've applied it in your previous projects?"",""example_answer"":""In my previous project, I used object-oriented programming to create a class for handling user authentication, which improved code reusability and reduced errors.""},{""question"":""How do you approach problem-solving in a fast-paced, dynamic environment?"",""example_answer"":""I prioritize breaking down complex problems into smaller, manageable tasks, and then collaborate with my team to find the most efficient solution.""}],""red_flags"":[""Lack of experience with Python development"",""Inability to explain object-oriented programming concepts""],""confidence_score"":90.0}"
Senior Machine Learning Engineer,Tali AI,"Toronto, Ontario, Canada",May,2024,"Physicians, the backbone of our healthcare system, have long been burdened by excessive administrative tasks and documentation requirements compounded by EMR regulations resulting in the widespread issue of physician burnout. The toll of spending 10-15 hours per week on these tasks has led to a concerning trend known as the ""great resignation of healthcare,"" with doctors leaving their positions due to overwhelming stress and exhaustion.

Tali AI is dedicated to tackling the issue of physician burnout through the development of a voice-enabled virtual assistant designed specifically for physicians. Our voice enabled AI innovative assistant streamlines their professional lives by significantly minimizing the time spent on documentation and administrative tasks.

Tali AI is looking for a Senior Machine Learning Engineer to play a crucial role in advancing our capabilities in understanding, processing and generating natural language, as well as improving the accuracy and efficiency of our speech recognition systems.

Who You Are:

You have a degree in Computer Science, Engineering, or a related field with a focus on machine learning, NLP, ASR, or equivalent practical experience
You have at least 8 years of professional experience in machine learning engineering, with a strong emphasis on NLP and ASR
Proficiency in programming languages such as Python, Java, or C++ for implementing machine learning algorithms and building scalable systems
Deep understanding of NLP techniques including text classification, named entity recognition, sentiment analysis, and machine translation
Solid grasp of ASR concepts such as acoustic modeling, language modeling, and speech signal processing
Strong problem-solving skills and the ability to think creatively to overcome challenges in machine learning projects
Excellent communication skills and the ability to collaborate effectively in a team environment

What You'll Do:

Lead the design, development, and implementation of state-of-the-art machine learning models and algorithms for NLP and ASR applications
Conduct research and stay up-to-date with the latest advancements in NLP and ASR to continuously enhance our technology stack
Collaborate with cross-functional teams including software engineers, data scientists, and product managers to integrate machine learning solutions into our products and services
Analyze and preprocess large volumes of text and speech data to extract meaningful insights and features for model training
Optimize model performance and scalability to meet stringent latency and throughput requirements
Conduct thorough experimentation and evaluation to assess the performance of NLP and ASR models and identify areas for improvement
Provide mentorship and guidance to junior members of the machine learning team, fostering a culture of continuous learning and innovation

Our Core Values

Growth: we have a growth mindset; we want to learn and improve a little (or a lot!) every day
Purpose: we care about our team and our community; we understand the purpose of our work and take it seriously
Innovation: we're all about innovation and cutting edge technology; we don't shy away from a challenge

Perks and Benefits

Comprehensive health and wellness benefits package from day one
Three weeks paid vacation and additional company-wide holiday between Dec 25 - Jan 1
Half day Fridays (35-hour work week)
“Knowledge Dollars” to invest in annual professional development
Quarterly socials & company outings
Fully remote work

Recruitment Process

Here’s what to expect from the recruitment process:

Selected candidates will be contacted for an initial 30-minute interview
Hiring Manager Interview
Interview with a Co-Founder/Executive Leader
Decision Stage

Working at Tali:

Our core values:

Growth: we have a growth mindset; we want to learn and improve a little (or a lot!) every day
Purpose: we care about our team and our community; we understand the purpose of our work and take it seriously
Innovation: we're all about innovation and cutting edge technology; we don't shy away from a challenge

Recruitment Process

Here’s what to expect from the recruitment process:
Selected candidates will be contacted for an initial 30-minute interview
Hiring Manager Interview
Interview with a Co-Founder/Executive Leader
Decision Stage

We thank all applicants for their interest; only those candidates selected for an interview will be contacted. Tali is committed to providing a barrier-free recruitment process for all candidates. Should you require accommodations at any point throughout the hiring process, please contact the Human Resources team at

Powered by JazzHR

8EDI4E3n59","{""role_summary"":""Lead the development and implementation of machine learning models and algorithms for natural language processing and automatic speech recognition applications, contributing to the reduction of physician burnout."",""key_terms"":[{""term"":""NLP"",""explanation"":""Natural Language Processing, a subfield of artificial intelligence that deals with the interaction between computers and humans in natural language.""},{""term"":""ASR"",""explanation"":""Automatic Speech Recognition, a technology that enables computers to recognize and transcribe spoken language into text.""},{""term"":""EMR"",""explanation"":""Electronic Medical Record, a digital version of a patient's medical chart, containing their medical history, diagnoses, medications, test results, and other relevant information.""}],""skill_priorities"":{""must_have"":[""Machine learning engineering experience with a focus on NLP and ASR"",""Proficiency in programming languages such as Python, Java, or C++"",""Deep understanding of NLP techniques and ASR concepts""],""nice_to_have"":[""Experience with voice-enabled AI assistants"",""Knowledge of acoustic modeling, language modeling, and speech signal processing""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of acoustic modeling in ASR and how it improves speech recognition accuracy?"",""example_answer"":""Acoustic modeling is a crucial component of ASR systems. It involves the use of statistical models to map acoustic features of speech signals to phonetic transcriptions. By accurately modeling the acoustic properties of speech, we can improve the robustness of speech recognition systems to varying speaking styles, accents, and environmental noise.""},{""question"":""How do you approach optimizing the performance of NLP models for real-time applications?"",""example_answer"":""To optimize NLP model performance for real-time applications, I employ techniques such as model pruning, knowledge distillation, and quantization. These methods enable us to reduce the computational complexity and memory requirements of NLP models while maintaining their accuracy and reliability.""}],""red_flags"":[""Lack of experience with NLP and ASR applications"",""Inability to communicate complex technical concepts effectively""],""confidence_score"":95.0}"
"Data Scientist, Canada - BCG X",Boston Consulting Group (BCG),"Montreal, Quebec, Canada",June,2024,"Locations: Toronto | Montreal

Who We Are

***To submit an application in French, please go to your settings at the top of the page and select French as your language preference. This will enable you to view the portal and application questions in French.***

***Pour soumettre une candidature en français, veuillez accéder à vos paramètres en haut de la page et sélectionner le français comme langue de préférence. Cela vous permettra de consulter le portail et les questions relatives à la candidature en français.***

Boston Consulting Group (BCG) is a global management consulting firm and the world’s leading advisor on business strategy. We partner with clients from the private, public, and not-for-profit sectors in all regions to identify their highest-value opportunities, address their most critical challenges, and transform their enterprises. Our customized approach combines deep insight into the dynamics of companies and markets with close collaboration at all levels of the client organization. This ensures that our clients achieve sustainable competitive advantage, build more capable organizations, and secure lasting results. Founded in 1963, BCG is a private company with offices in more than 90 cities in 50 countries. For more information, please visit bcg.com.

BCG’s clients are the world’s top business leaders. From computers to retailing, our professional expertise spans over 50 industries. The vast majority of our clients rank among the 500 largest companies in each of our three major regions–Americas (North and South), Europe Middle East and Africa, and Asia Pacific. Additionally, we work with a number of small- to medium-sized companies, both public and private.

The success of our assignments routinely leads our clients to maintain long-term relationships with us. Over 85 percent of our revenues come from clients who continue to work with us from one year to the next to maintain the momentum for change and to continually improve bottom-line results they have achieved with our help.

We pride ourselves on our fresh thinking. Our evolving ideas profoundly change the way most businesses think about competition. Many leading business concepts over the past three decades originated with BCG–including, experience curve, time-based competition, Segment-of-One® marketing, deconstruction, and trading up. Our recent Collateral Damage publication series has addressed the implications for managers of the on-going financial crisis.

We believe that no other consulting organization has concentrated as thoroughly on understanding business competition and helping companies make the changes necessary to succeed in increasingly competitive markets.

La réputation mondiale du cabinet de conseil en gestion Boston Consulting Group (BCG), comme l'un des meilleurs en gestion, découle de plus de cinquante années d'expérience à aider les cadres supérieurs à découvrir et réaliser tout le potentiel de leur entreprise. Notre mission consiste à appuyer nos clients à réaliser des avantages concurrentiels durables en offrant des solutions personnalisées. Nous croyons fermement qu'il faut travailler avec nos clients, pas à leurs dépens. Nous collaborons avec chaque client pour l'aider à prendre une direction et à faire face aux défis organisationnels et opérationnels.

Fondé en 1963, BCG compte maintenant plus de 11,000 experts-conseils, et ce, dans plus de 90 bureaux dans le monde entier. Les clients du BCG sont les dirigeants des plus importantes entreprises du monde. Des ordinateurs jusqu'à la vente au détail, notre expertise professionnelle s'étend à plus de 50 industries. La grande majorité de nos clients figurent parmi les 500 plus grandes entreprises dans chacune de nos trois régions principales – Les Amériques (nord et sud), l'Europe (incluant le Moyen-Orient et l'Afrique) et l'Asie-Pacifique. De plus, nous travaillons avec un certain nombre de petites et moyennes entreprises, tant publiques que privées.

Notre succès, provenant des mandats qui nous sont assignés, nous permet d'établir des relations à long terme avec nos clients. Plus de 85 pourcents de nos revenus proviennent de clients qui continuent à travailler avec nous d'une année à l'autre pour conserver l'élan de changement et pour améliorer continuellement les résultats nets qu'ils ont réalisés grâce à notre aide.

Nous sommes fiers de notre approche innovatrice. Nos idées évolutives changent profondément la manière dont la plupart des entreprises considèrent la concurrence. Plusieurs des principaux concepts d'affaires, au cours des trois dernières décennies, ont commencé avec BCG, y compris la courbe d'apprentissage, la concurrence calculée sur le temps, le marketing Segment-of-One®, le démantèlement et l'extension ascendante. Nos récentes publications de la série Collateral Damage ont traité de l'implication des dirigeants face à la crise financière en cours.

Nous croyons qu'aucune autre organisation de conseil en gestion ne s'est concentrée aussi attentivement à la compréhension de la concurrence en affaires et à aider les entreprises à effectuer les changements nécessaires pour réussir sur des marchés de plus en plus compétitifs.

We Are BCG X

We’re a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world’s most complex problems. Leveraging BCG’s global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.

What You'll Do

Our BCG X teams own the full analytics value-chain end to end: framing new business challenges, designing innovative algorithms, implementing, and deploying scalable solutions, and enabling colleagues and clients to fully embrace AI. Our product offerings span from fully custom-builds to industry specific leading edge AI software solutions.

As a Data Scientist, you'll be part of our rapidly growing team. You'll have the chance to apply data science methods and analytics to real-world business situations across a variety of industries to drive significant business impact. You'll have the chance to partner with clients in a variety of BCG regions and industries, and on key topics like climate change, enabling them to design, build, and deploy new and innovative solutions.

Additional responsibilities will include developing and delivering thought leadership in scientific communities and papers as well as leading conferences on behalf of BCG X. Successful candidates are intellectually curious builders who are biased toward action, scrappy, and communicative.

We are looking for talented individuals with a passion for data science, statistics, operations research and transforming organizations into AI led innovative companies. Successful candidates possess the following:

Comfortable in a client-facing role with the ambition to lead teams
Likes to distill complex results or processes into simple, clear visualizations
Explain sophisticated data science concepts in an understandable manner
Love building things and are comfortable working with modern development tools and writing code collaboratively (bonus points if you have a software development or DevOps experience)
Significant experience applying advanced analytics to a variety of business situations and a proven ability to synthesize complex data
Deep understanding of modern machine learning techniques and their mathematical underpinnings, and can translate this into business implications for our clients
Have strong project management skills

Nos équipes BCG X sont responsables de l’ensemble de la chaîne de valeur de l’analyse de bout en bout : encadrer de nouveaux défis commerciaux, concevoir des algorithmes d’innovation, mettre en œuvre et déployer des solutions évolutives, et permettre à nos collègues et clients d’adopter pleinement l’IA. Nos offres de produits s’étendent des versions entièrement personnalisées aux solutions logicielles d’IA de pointe spécifiques à l’industrie.

En tant que scientifique des données, vous ferez partie de notre équipe en pleine croissance. Vous aurez l’occasion d’appliquer des méthodes et des analyses de science des données à des situations commerciales réelles dans une variété d’industries pour avoir un impact commercial important. Vous aurez l’occasion de collaborer avec des clients de diverses régions et industries du BCG et sur des sujets clés comme le changement climatique, leur permettant de concevoir, de construire et de déployer des solutions nouvelles et d’innovation.

Les responsabilités supplémentaires comprendront le développement et la prestation d’un leadership éclairé dans les communautés et les articles scientifiques, ainsi que la direction de conférences au nom du BCG X. Les candidats à succès sont des bâtisseurs intellectuels curieux qui ont un parti pris vers l’action, sont ambitieux et ont le sens de la communication.

Nous sommes à la recherche de personnes talentueuses passionnées par la science des données, les statistiques, la recherche sur les opérations et la transformation d’organisations en entreprises innovantes dirigées par l’IA. Les candidats à succès possèdent les compétences suivantes :

Aisance à occuper un rôle de contact avec les clients et ambition de diriger des équipes
Aime distiller des résultats ou des processus complexes en visualisations simples et claires
Capacité d’expliquer les concepts sophistiqués de la science des données de manière compréhensible
Aime construire des choses et est à l’aise de travailler avec des outils de développement modernes et de rédiger des codes en collaboration (points en prime si vous avez une expérience en développement de logiciels ou DevOps)
Vaste expérience dans l’application d’analyses avancées dans diverses situations d’affaires et capacité reconnue de synthétiser des données complexes
Compréhension approfondie des techniques modernes d’apprentissage automatique et de leurs fondements mathématiques, et capacité de traduire cela en implications commerciales pour nos clients
Solides compétences pour la gestion de projets

What You'll Bring

TECHNOLOGIES:

Programming Languages: Python

Ce que vous apporterez

TECHNOLOGIES :

Langues de programmation : Python

Additional info

Additional info

We seek people with drive, energy, first-rate minds, and ability to lead and persuade. In selecting people to join the firm, we carry out an intensive interviewing process. Candidates should demonstrate success in their academic and extracurricular activities, whether that be through volunteer work, professional experiences, or through personal initiatives. Compensation for associates entering the firm is extremely competitive and grows rapidly with strong performance.

Language of work for positions permanently located in Quebec

Knowledge of French is required for positions permanently located in Quebec so incumbents can communicate with their colleagues and suppliers in Quebec as necessary. French-language training is offered to all incumbents in permanent positions in Quebec who do not have a good knowledge of French.

Other Language Requirement

Fluent English is required for this position in order to communicate with clients, partners and colleagues, who are predominantly located outside Quebec.

How To Apply

Candidates interested in applying must submit an application including a cover letter and résumé.

Nous recherchons des personnes ambitieuses, énergiques, avec de la capacité intellectuelle à mener au bout des projets et à persuader. En choisissant des personnes à se joindre à l'entreprise, nous procédons à un processus intensif d'entrevue.

Les candidats doivent démontrer leur succès dans leurs activités universitaires ou parascolaires, que ce soit par un travail bénévole, des stages professionnels ou encore des initiatives personnelles. La rémunération pour les analystes qui se joignent à l'entreprise est extrêmement concurrentielle et augmente rapidement en fonction de performance.

Langue de travail pour les postes situés en permanence au Québec

La connaissance du français est requise pour les postes situés en permanence au Québec afin que le titulaire puisse communiquer au besoin avec ses collègues et les fournisseurs au Québec. Une formation en français est offerte à tout titulaire d’un poste permanent au Québec qui ne possède pas une bonne connaissance du français.

Autre exigence linguistique

La maîtrise de l’anglais est requise pour ce poste afin de pouvoir communiquer avec les clients, partenaires et collègues qui sont majoritairement situés à l’extérieur du Québec.

Comment postuler?

Les candidats intéressés à postuler un poste d'analyste à l'un de nos bureaux canadiens du BCG doivent soumettre une demande, qui consiste en une lettre de présentation, un curriculum vitae, et un relevé de notes le plus récent.

Boston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.

BCG is an E - Verify Employer. Click here for more information on E-Verify.","{""role_summary"":""As a Data Scientist at BCG X, you will apply data science methods and analytics to real-world business situations across various industries, driving significant business impact. You will partner with clients, design, build, and deploy new and innovative solutions, and develop thought leadership in scientific communities."",""key_terms"":[{""term"":""Data Science"",""explanation"":""The process of extracting insights and knowledge from structured and unstructured data using various techniques, including machine learning and statistics.""},{""term"":""AI"",""explanation"":""The positive impact of artificial intelligence on business operations, leading to increased efficiency and innovation.""},{""term"":""Machine Learning"",""explanation"":""A subset of AI that enables machines to learn from experience and improve their performance on a task without being explicitly programmed.""},{""term"":""DevOps"",""explanation"":""A set of practices that combines software development (Dev) and IT operations (Ops) to improve collaboration and efficiency.""}],""skill_priorities"":{""must_have"":[""Python programming language"",""Data science and analytics"",""Machine learning techniques and their mathematical underpinnings"",""Project management skills"",""Ability to communicate complex data science concepts""],""nice_to_have"":[""Software development or DevOps experience"",""Leadership and team management experience"",""Experience with industry-specific leading-edge AI software solutions""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a complex data science concept to a non-technical audience?"",""example_answer"":""I'd be happy to explain how machine learning can be used to improve customer segmentation. Essentially, we can use algorithms to analyze customer data and identify patterns that would be difficult for humans to detect. This allows us to create more targeted marketing campaigns and increase customer engagement.""},{""question"":""How do you stay current with new developments in AI and machine learning?"",""example_answer"":""I regularly read industry publications, attend conferences, and participate in online forums to stay up-to-date on the latest advancements in AI and machine learning. I also network with other professionals in the field to learn from their experiences and share my own knowledge.""}],""red_flags"":[""Lack of ability to explain complex data science concepts in simple terms"",""current with industry developments in AI and machine learning"",""Inability to work collaboratively with cross-functional teams""],""confidence_score"":90.0}"
Python/Data Scientist-Canada,Zortech Solutions,"Mississauga, Ontario, Canada",May,2024,"Role: Python/Data Scientist

Location: Mississauga, ON, Canada(from day 1 should be able to work at client site)

Duration: 6+ Months

Job Description

Roles and Responsibilities:

8-10+ years total work experience
5+ years of experience in developing scalable distributed machine learning systems
Should be able to work with a distributed multi-vendor team in a multi-cultural environment across multiple geographies taking care of a complex web application
Should be extremely good at communication and be able to manage conflicts constructively and proactively
Should be self driven and be able to take ownership of tasks end to end
Should have a researcher attitude
5+ years of experience in developing and deploying machine learning models and algorithms for time series data analysis, e.g., anomaly detection and forecasting.
Expertise in Python programming and machine learning libraries such as PyTorch, Scikit-learn, and Pandas.
Strong understanding of time series models such as ARIMA, SARIMA, Prophet, and LSTM, and experience in building custom models.
Experience with anomaly detection techniques

Skills

Python , machine learning libraries such as PyTorch, Scikit-learn, and Pandas
Models: ARIMA, SARIMA, Prophet, and LSTM

Note

A master's degree in business or a technical discipline (Computer Science, Information Systems, Engineering) required.
This is an independent contributor role from day 1 and should be able to work at client site from day 1
Travel option is not provided","{""role_summary"":""A Python/Data Scientist will develop and deploy machine learning models for time series data analysis, working independently with a distributed team across multiple geographies."",""key_terms"":[{""term"":""Scalable distributed machine learning systems"",""explanation"":""Machine learning systems that can handle large amounts of data and scale up or down as needed.""},{""term"":""Time series data analysis"",""explanation"":""Analyzing data that is ordered in time to identify patterns, trends, and anomalies.""},{""term"":""Anomaly detection"",""explanation"":""Identifying data points that are unusual or do not conform to expected patterns.""},{""term"":""ARIMA, SARIMA, Prophet, and LSTM"",""explanation"":""Machine learning models used for time series forecasting and analysis.""}],""skill_priorities"":{""must_have"":[""Python"",""Machine learning libraries (PyTorch, Scikit-learn, Pandas)"",""Experience with time series models (ARIMA, SARIMA, Prophet, LSTM)""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach developing a scalable machine learning system for time series data analysis?"",""example_answer"":""I would start by identifying the key features of the data, then select the most suitable machine learning models for the task. I would also consider scalability and deploy it using a distributed architecture.""},{""question"":""How do you handle conflicts within a distributed team?"",""example_answer"":""I would communicate proactively and transparently with the team, identify the root cause of the conflict. Then, I would work collaboratively to find a constructive solution that aligns with the project goals.""}],""red_flags"":[""Lack of experience with distributed machine learning systems"",""Inability to work independently with a distributed team""],""confidence_score"":90.0}"
Biomedical Big Data Engineer,Myant,"Mississauga, Ontario, Canada",February,2024,"About Us:

At Myant, we are creating the world’s first expressive and continuous digital presence platform, enabled by integrating technology directly into clothing and augmented by other devices, wearables, and IOT. We see the evolution of society where every member gets to participate from anywhere and anytime through a whole-body experience, mostly in a passive or ambient manner to foster ubiquitous accessibility. Humans have a fundamental desire and need to be connected to our environment, family, community, and technology. This level of connection will create a paradigm shift in the way we deal with each other, especially from afar, allowing for more meaningful relationships, and more in-depth representation of ourselves.

The need for this type of connection is not new. There are many companies working on ways to connect humans in singularity with technology, however most of these technologies are based on devices that are often used in episodical ways hence, leading to poor adoption or reliability. In general, innovation and technology have delivered significant benefits for many members of society. However, there are those who are left behind, namely the very young, the marginalized, the old and the sick. The challenge of inclusion for those left behind requires us to move beyond device focused strategies, towards an interface that we use naturally, every day. We believe that textile is that primary interface, used in clothing, coverings, carpeting and more, we wear and are surrounded by textiles universally, at all times.

Such an interface could fuse data with other devices that we use periodically and data with other IoTs in the environment. People could then leverage their physical presence over their digital presence to communicate and share personal wellbeing. This could unlock healthcare that is proactive and preventative, social connectedness that is more profound, enable care distribution models to be seamless and on demand, better fitness insights, safer working environments and more.

The vision for SKIIN -our first consumer-facing brand- is to enhance human ability through connected clothing and textiles. Skiin is in beta-phase market launch and has been recently granted Health Canada medical device license and submitted to FDA for regulatory approval in the US market. The sensors and actuators embedded within our apparel create your Digital Identity, which will be consumed by those who matter to you - your family members, physicians, trainers, other IoT devices - without you consciously having to think about it. The line between the digital and physical world is becoming increasingly blurry and we believe textile is the next medium to bridge that gap.

We are a multi-disciplinary technology team solving big challenges at the intersection of electronics, deep tech., software, design, advanced manufacturing and data science.

What we offer at Myant:

Employee stock options
Paid Sick Days and Floating Days
Group Health Insurance Plan
RRSP matching Plan
Corporate Events
Exposure working in one of the most innovative and forward-thinking tech company

Myant is a diversified, equal opportunity employer. People with disability or a special accommodation request may send an email to hr@myant.ca.

Position Overview:

As a Biomedical Big Data Engineer at Myantx, you will play a key role in designing, developing, and maintaining our big data infrastructure. You will work closely with datascience, biomedical systems and software teams to implement scalable and efficient data processing solutions, ensuring the availability and reliability of our data pipelines. You will also contribute in defining along with all stake holders the efforts on big data analysis, planning for execution, providing the timeline and leading the efforts. This is an exciting opportunity to contribute to the advancement of our data architecture and analytics capabilities.

Responsibilities:

Take ownership of all your deliverables and communicate your results for timely project delivery
Design, implement, and optimize big data processing systems and infrastructure both for offline analysis and as part of the Myant Health platform
Develop and maintain scalable ETL (Extract, Transform, Load) processes for large volumes of structured and unstructured data from wearable systems including noise and missed data
Collaborate with data scientists and analysts to understand data requirements and ensure data availability for analytical purposes
Implement data governance and security best practices to safeguard sensitive information
Troubleshoot and optimize existing data pipelines for performance and reliability
Prepared and organize large scale biomedical datasets gathered by Skiin or other devices, as well as clinical datasets to be used for data analysis and development of medical and health related algorithms/models
Contribute in big data analysis using statistical methods, causal inference techniques and machine learning approaches.
Creating and managing data warehouses and data lakes to facilitate efficient data storage and retrieval
Stay current with emerging technologies and industry trends in big data and analytics
Collaborate with cross-functional teams, partners and external researchers/companies to define and execute data-driven projects
Working in an ISO-13485 and HIPAA regulated environment, following quality procedures for design and development as well as verification and validation for clinical use, including to support regulatory approval

Qualifications:

PhD in Computer Science, Electrical or Biomedical Engineering, or MSc plus equivalent experience in relevant industry.
Extensive experience in modern scripting languages including Python and Java.
Proven experience as a Big Data Engineer or similar role, with expertise in designing and implementing large-scale data processing solutions
Familiarity with data modeling, database design, and SQL
Experience with big data technologies, including Hadoop, Spark, Kafka, and related ecosystems
Strong understanding of distributed computing principles and cloud platforms (e.g., AWS, Azure, GCP)
Excellent communication skills, with the ability to convey complex technical concepts to non-technical stakeholders

Preferred Qualifications:

Experience working in the medical device industry, or working with industrial partners on large scale biomedical datasets.
Familiarity with streaming data processing and real-time analytics
Experience in implementing algorithms in C/C++, Javascript and Swift
Experience in biomedical data analysis from wearable systems and related signal analysis, handling of noise, missing data etc.
Experience working on bio-signals such as electrocardiogram, electromyogram, electroencephalogram, photo-plethysmogram, accelerometry signals

What We Offer

Employee stock options
Paid Sick Days and Floating Days
Group Health Insurance Plan
RRSP matching Plan
Corporate Events
Exposure working in one of the most innovative and forward-thinking tech company

We are a diversified, equal opportunity employer. People with disability or a special accommodation request may send an email to hr@myant.ca.

Powered by JazzHR

fbGBqFuHQJ","{""role_summary"":""Design, develop, and maintain big data infrastructure, ensuring data pipeline availability and reliability, and contribute to big data analysis and planning."",""key_terms"":[{""term"":""Big Data Engineer"",""explanation"":""A professional responsible for designing, developing, and maintaining large-scale data processing solutions.""},{""term"":""Biomedical Big Data"",""explanation"":""A specialist who works with biomedical data, including data from wearable systems, and develops algorithms for medical and health-related applications.""},{""term"":""ETL (Extract, Transform, Load)"",""explanation"":""A process of extracting data from various sources, transforming it into a standardized format, and loading it into a target system for analysis.""},{""term"":""Data Governance"",""explanation"":""A set of practices and policies that ensure the quality, security, and integrity of an organization's data.""},{""term"":""Data Lakes"",""explanation"":""A centralized repository that stores all types of data in its native format, allowing for flexible and scalable data storage and retrieval.""}],""skill_priorities"":{""must_have"":[""PhD in Computer Science, Electrical or Biomedical Engineering, or MSc plus equivalent experience"",""Extensive experience in Python and Java"",""Proven experience in designing and implementing large-scale data processing solutions"",""Familiarity with data modeling, database design, and SQL"",""Experience with big data technologies, including Hadoop, Spark, Kafka, and related ecosystems""],""nice_to_have"":[""Experience working in the medical device industry"",""Familiarity with streaming data processing and real-time analytics"",""Experience in implementing algorithms in C/C++, Javascript and Swift"",""Experience in biomedical data analysis from wearable systems and related signal analysis""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with big data technologies, including Hadoop, Spark, Kafka, and related ecosystems?"",""example_answer"":""I have worked with Hadoop for 3 years, implementing data pipelines and ensuring data quality. I'm familiar with Spark and Kafka, and have used them in previous projects.""},{""question"":""How do you approach data governance and security in your previous roles?"",""example_answer"":""I have implemented data governance policies and ensured data security by following best practices and industry standards.""}],""red_flags"":[""Lack of experience with big data technologies"",""Inability to communicate complex technical ideas to non-technical stakeholders""],""confidence_score"":90.0}"
AI/ML and MLOps Field Engineer,Canonical,"Montreal, Quebec, Canada",June,2024,"Canonical is a leading provider of open source software and operating systems to the global enterprise and technology markets. Our platform, Ubuntu, is very widely used in breakthrough enterprise initiatives such as public cloud, data science, AI, engineering innovation and IoT. Our customers include the world's leading public cloud and silicon providers, and industry leaders in many sectors. The company is a pioneer of global distributed collaboration, with 1000+ colleagues in 70+ countries and very few roles based in offices. Teams meet two to four times yearly in person, in interesting locations around the world, to align on strategy and execution.

The company is founder led, profitable and growing.

We are hiring an AI/ML and MLOps Field Engineer to help global companies embrace AI in their business, using the latest open source capabilities on public and private cloud infrastructure, Linux and Kubernetes. Our team applies expert insights to real-world customer problems, enabling the enterprise adoption of Ubuntu, Kubeflow, MLFlow, Feast, DVC and related analytics, machine learning and data technologies. We are working to create the world's best open source data platform, covering traditional SQL databases and today's NoSQL data stores, as well as the machinery which turns data into insights and executable models.

The people who love this role are software engineers who enjoy customer conversations and solving customer problems during the presales cycle. They are are developers who like to solve customer problems through architecture, presentations and training. Ubuntu is used by pretty much every enterprise in the world, in every industry. This is a fantastic opportunity to learn about the open source technology landscape and develop your business technology insights. You will see first hand in various industries how Linux - and Ubuntu in particular - is shaping innovation and changing the world for the better.

This role is particularly suited to candidates with a technical background who are business minded and driven by commercial success. This role is on our global Field Engineering team and will work closely with enterprise sales leads. We are specifically looking for people interested in solving the most difficult problems in modern data architectures. Training LLMs on multiple K8s clusters deployed on a hybrid cloud infrastructure with GPU sharing across multiple teams? Processing 10M events in real time for financial transactions? Object detection on 10k parallel 4K video streams? These are the problems we solve day to day.

Location: Most of our colleagues work from home. We are growing teams in EMEA, Americas and APAC time zones, so can accommodate candidates from almost any country.

What your day will look like

The global Field Engineering team members are Linux and cloud solutions architects for our customers, designing private and public cloud solutions fitting their workload needs. They are the cloud consultants who work hands-on with the technologies by deploying, testing and handing over the solution to our support or managed services team at the end of a project. They are also software engineers who use Python to develop Kubernetes operators and Linux open source infrastructure-as-code.

Work across the entire Linux stack, from kernel, networking, storage, to applications
Architect cloud infrastructure solutions like Kubernetes, Kubeflow, OpenStack, and Spark
Deliver solutions either on-premise or in public cloud (AWS, Azure, Google Cloud)
Collect customer business requirements and advise them on Ubuntu and relevant open source applications
Grow a healthy, collaborative engineering culture in line with the company values
Deliver presentations and demonstrations of Ubuntu Pro and AI/ML capabilities to prospective and current clients
Liaise with product teams to give them feedback on requirements to influence roadmap
Work collaboratively with your sales team to reach our common targets
Global travel up to 25% of time for internal and external events and 25% to customer meetings

What we are looking for in you

Exceptional academic track record from both high school and university
Undergraduate degree in a technical subject or a compelling narrative about your alternative chosen path
Experience in data engineering, MLOps, or big data solutions deployment
Experience with a relevant programming language, like Python, R, or Rust.
Confidence to respectfully speak up, exchange feedback, and share ideas without hesitation
Track record of going above-and-beyond expectations to achieve outstanding results
Demonstrated personal interest in continuous learning and development
Practical knowledge of Linux, virtualisation, containers and networking
Business-minded technology thinker and problem solver
Knowledge of cloud computing concepts & leaders, such as Kubernetes, AWS, Azure, GCP
Interest in large-scale enterprise open source - private clouds, machine learning and AI, data and analytics
Intermediate level Python programming skills
Passion for technology evidenced by personal projects and initiatives
The work ethic and confidence to shine alongside motivated colleagues
Professional written and spoken English with excellent presentation skills
Experience with Linux (Debian or Ubuntu preferred)
Excellent interpersonal skills, curiosity, flexibility, and accountability
A dynamic person who loves to jump in new projects and interact with people
Appreciative of diversity, polite and effective in a multi-cultural, multi-national organisation
Thoughtfulness and self-motivation
Result-oriented, with a personal drive to follow up and meet commitments
Ability to travel internationally, for company events up to two weeks long, and customer or industry meetings

What you'll learn

Architect and deploy AI/ML infrastructures, data processing pipelines and multi-cluster distributed training
Wide range of open source applications and skills
Work directly with customers in a range of different businesses
Real-life and hands-on exposure to a wide range of emerging technologies and tools

What we offer colleagues

We consider geographical location, experience, and performance in shaping compensation worldwide. We revisit compensation annually (and more often for graduates and associates) to ensure we recognise outstanding performance. In addition to base pay, we offer a performance-driven annual bonus or commission. We provide all team members with additional benefits, which reflect our values and ideals. We balance our programs to meet local needs and ensure fairness globally.

Distributed work environment with twice-yearly team sprints in person
Personal learning and development budget of USD 2,000 per year
Annual compensation review
Recognition rewards
Annual holiday leave
Maternity and paternity leave
Employee Assistance Programme
Opportunity to travel to new locations to meet colleagues
Priority Pass, and travel upgrades for long haul company events

About Canonical

Canonical is a pioneering tech firm at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world of software. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do. Most colleagues at Canonical have worked from home since its inception in 2004. Working here is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game.

Canonical is an equal opportunity employer

We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.","{""role_summary"":""Work as an AI/ML and MLOps Field Engineer to help global companies adopt AI using open source capabilities on public and private cloud infrastructure, Linux, and Kubernetes."",""key_terms"":[{""term"":""MLOps"",""explanation"":""Machine Learning Operations, a set of practices that combines machine learning and DevOps to streamline the machine learning lifecycle.""},{""term"":""Kubeflow"",""explanation"":""An open-source machine learning platform that enables easy deployment of machine learning pipelines on Kubernetes.""},{""term"":""DVC"",""explanation"":""Data Version Control, a tool that helps manage machine learning models, data, and experiments.""},{""term"":""Feast"",""explanation"":""An open-source feature store that enables data scientists and engineers to manage and serve machine learning features.""}],""skill_priorities"":{""must_have"":[""Experience in data engineering, MLOps, or big data solutions deployment"",""Practical knowledge of Linux, virtualisation, containers and networking"",""Business-minded technology thinker and problem solver"",""Intermediate level Python programming skills""],""nice_to_have"":[""Experience with a relevant programming language, like R, or Rust"",""Knowledge of cloud computing concepts & leaders, such as AWS, Azure, GCP"",""Interest in large-scale enterprise open source - private clouds, machine learning and AI, data and analytics""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would architect a cloud infrastructure solution using Kubernetes and Kubeflow?"",""example_answer"":""I would start by understanding the customer's workload needs, then design a scalable and secure Kubernetes cluster on a public or private cloud infrastructure. I would also ensure seamless integration with Kubeflow for efficient machine learning pipeline management.""},{""question"":""How do you stay updated with the latest developments in AI, ML, and data technologies?"",""example_answer"":""I regularly follow industry leaders and blogs, participate in online forums, and attend conferences to stay current with emerging trends and technologies.""}],""red_flags"":[""Lack of experience in data engineering, MLOps, or big data solutions deployment"",""Inability to communicate technical concepts to non-technical stakeholders"",""Limited knowledge of cloud computing concepts and leaders""],""confidence_score"":90.0}"
Data Scientist Specialist,US Tech Solutions,"Toronto, Ontario, Canada",June,2024,"Job Description:

The Opportunity:

's Data Product Development group specializes in creating unique and insightful data products. Utilizing data from both internal and external sources, we deliver innovative products that power some of the world’s most successful organizations.

We’re currently seeking a Data Scientist - NLP, LLM, and GenAI (contract) to join our team and to help create new products and services powered by modern AI technologies, including Large Language Models (LLM). The ideal candidate is autonomous, creative, and laser-focused on driving tangible business value through their ingenuity.

The Role:

Collaborate with Product, Data, and Technology teams to design and create new products and services powered by AI
Work alongside a team of data scientists in applying state-of-the-art LLMs from OpenAI, Anthropic, Meta, and Mistral to address the unique challenges of financial data
Create models and pipelines for Named Entity Recognition and Entity Resolution
Assess the quality and robustness of your solutions and iterate to optimize performance
Apply best practices of MLOps / LLMOps in deploying new products and services to production

Qualifications and Skills:

5+ years of experience processing structured and unstructured data using NLP
1+ years of experience applying LLMs to solve real-world, industry problems
Solid understanding of NLP and related concepts such as vectorization, entity recognition, semantic search, and so forth
Experience with RAG and LLM fine-tuning is a strong plus
Python experience is required, AWS/FastAPI/Gradio/Docker is a plus
Passionate about Generative AI, consistently tracking the latest industry developments
Bachelors Degree in Computer Science, Computer Engineering, or related discipline

*** This is a contract role for immediate hire with a scheduled end date of Sept 30, 2024 ***

About US Tech Solutions:

US Tech Solutions is a global staff augmentation firm providing a wide range of talent on-demand and total workforce solutions. To know more about US Tech Solutions, please visit www.ustechsolutions.com.

US Tech Solutions is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.","{""role_summary"":""Collaborate with teams to design and create new products and services powered by AI, focusing on driving tangible business value through ingenuity."",""key_terms"":[{""term"":""LLM"",""explanation"":""Large Language Model, a type of AI technology used for natural language processing.""},{""term"":""NLP"",""explanation"":""Natural Language Processing, a subfield of AI that deals with human-computer interaction.""},{""term"":""GenAI"",""explanation"":""Generative Artificial Intelligence, a type of AI that generates new content, such as text or images.""},{""term"":""MLOps / LLMOps"",""explanation"":""Machine Learning Operations / Large Language Model Operations, practices for deploying and managing AI models in production.""},{""term"":""RAG"",""explanation"":""Reasoning and Generation, a type of AI model fine-tuning for specific tasks.""}],""skill_priorities"":{""must_have"":[""5+ years of experience processing structured and unstructured data using NLP"",""Python experience"",""Bachelors Degree in Computer Science, Computer Engineering, or related discipline""],""nice_to_have"":[""1+ years of experience applying LLMs to solve real-world, industry problems"",""Experience with RAG and LLM fine-tuning"",""AWS/FastAPI/Gradio/Docker experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you've applied NLP to solve real-world problems in the past?"",""example_answer"":""I used NLP to develop a sentiment analysis tool for a financial institution, which improved their customer service.""},{""question"":""How do you stay up-to-date with the latest developments in Generative AI?"",""example_answer"":""I regularly read industry blogs and attend conferences to stay current with the latest advancements in GenAI.""}],""red_flags"":[""Avoid candidates without experience in NLP and LLMs"",""Be cautious of candidates who lack experience in deploying AI models to production""],""confidence_score"":90.0}"
Data Scientist - WECJP00028799,Randstad Canada,"Mississauga, Ontario, Canada",June,2024,"Are you a Data Scientist looking for a new opportunity?

Are you looking for a new contract opportunity?

We are pleased to offer you a new contract opportunity for you to consider: Data Scientist

Start: ASAP
Estimated length: 6 months
Location: Mississauga
Hybrid role- 2-3 days in office, Tuesdays and Thursdays.

Advantages

You will have an opportunity to work with a leading employer in the local market.

Responsibilities

Collect, clean, and transform data from diverse sources to be used for training or evaluation datasets.
Develop, validate, and implement predictive models and machine learning algorithms.
Familiarize and utilize end-to-end ML product to develop data science models.
Perform exploratory data analysis to understand the data and develop hypotheses.
Propose solutions and strategies to business challenges.
Present findings to both technical and non-technical stakeholders.

Qualifications

Bachelor’s or Master’s degree in Computer Science, Data Science, Statistics, Mathematics, or a related field.
1-2 years of experience in data science or a related field.
Experience with Python and its primary data science libraries, alongside essential SQL knowledge for database management.
Proficiency in building and fine-tuning machine learning models.
Deep understanding of model confidence measurements and where to utilize one model over the other.
Robust understanding of various machine learning algorithms
Strong skills in data preprocessing, data exploration, and feature engineering.

Preferred Skills

Experience with sequence classification, named entity recognition, image classification, and object detection models
Proficiency with cloud services, specifically Vertex AI and BigQuery (GCP)
Strong problem-solving skills with an emphasis on product development.
Excellent written and verbal communication skills.
Experience with regular expressions is an asset.

Summary

Do you have this experience? If you answer YES, then please apply IMMEDIATELY to so we can then discuss your experience and interest in this opportunity!

Randstad Technologies Group

Canada's largest provider of IT Staffing Solutions, offering hundreds of permanent and contract opportunities across all roles, levels and platforms. Our Web-based tools help you see and apply for jobs matched automatically to your skills and preferences. When you're ready to interview we meet with you in person to help you build the technology career path you've always wanted. Visit www.randstad.ca to get started!

Randstad Canada is committed to fostering a workforce reflective of all peoples of Canada. As a result, we are committed to developing and implementing strategies to increase the equity, diversity and inclusion within the workplace by examining our internal policies, practices, and systems throughout the entire lifecycle of our workforce, including its recruitment, retention and advancement for all employees. In addition to our deep commitment to respecting human rights, we are dedicated to positive actions to affect change to ensure everyone has full participation in the workforce free from any barriers, systemic or otherwise, especially equity-seeking groups who are usually underrepresented in Canada's workforce, including those who identify as women or non-binary/gender non-conforming; Indigenous or Aboriginal Peoples; persons with disabilities (visible or invisible) and; members of visible minorities, racialized groups and the LGBTQ2+ community.

Randstad Canada is committed to creating and maintaining an inclusive and accessible workplace for all its candidates and employees by supporting their accessibility and accommodation needs throughout the employment lifecycle. We ask that all job applications please identify any accommodation requirements by sending an email to accessibility@randstad.ca to ensure their ability to fully participate in the interview process.","{""role_summary"":""Work as a Data Scientist on a 6-month contract in a hybrid role, collecting and transforming data, developing predictive models, and presenting findings to stakeholders."",""key_terms"":[{""term"":""Predictive models"",""explanation"":""Statistical models that forecast outcomes based on data analysis.""},{""term"":""Machine learning algorithms"",""explanation"":""Programs that automatically improve their performance on a task by learning from data.""},{""term"":""Vertex AI"",""explanation"":""A cloud-based platform for building, deploying, and managing machine learning models.""},{""term"":""BigQuery"",""explanation"":""A fully-managed enterprise data warehouse service for analytics.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Data preprocessing"",""Data exploration"",""Feature engineering""],""nice_to_have"":[""Sequence classification"",""Named entity recognition"",""Image classification"",""Object detection"",""Cloud services"",""Regular expressions""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach data preprocessing for a machine learning model?"",""example_answer"":""I would start by cleaning the data, handling missing values, and then transform the data into a suitable format for the model.""},{""question"":""How do you evaluate the performance of a machine learning model?"",""example_answer"":""I would use metrics such as accuracy, precision, recall, and F1-score to evaluate the model's performance and identify areas for improvement.""}],""red_flags"":[""Lack of experience with Python and its primary data science libraries"",""Inability to explain machine learning algorithms"",""No experience with cloud services, specifically Vertex AI and BigQuery""],""confidence_score"":90.0}"
Research Scientist,Carbon Engineering,"Squamish, British Columbia, Canada",June,2024,"Grow your career. Be the difference. Leading the commercialization of ground-breaking technology that captures CO₂ directly from air is challenging and exhilarating. As a member of the CE team, you’ll be surrounded by smart, adventurous, curious people committed to progressing our Direct Air Capture (DAC) and AIR TO FUELS TM technologies. We’re a diverse team of innovators hailing from around the world with a shared vision, purpose, and commitment to deliver large scale climate change solutions. Our headquarters is in Squamish, B.C., and our presence is expanding in many other markets around the world as we commercialize our technologies

Our culture combines our heritage as a small company with our ambitious goals. We have a passion for what we do and believe our work will have a true and lasting impact on the world. Many of our employees are drawn to CE because of the direct connection between the game-changing work we do and their own personal values.

At our core, Carbon Engineering values integrity, growth, excellence in execution, and fun. This is an environment where people matter, and contributions are noticed. Our employees work hard and are given the opportunity to learn and grow from mistakes. Diversity is embraced, and we value an inclusive work environment where every employee has an equal opportunity to be heard. We work in a dynamic environment and thrive on tackling rewarding and complex problems as a team.

The Technology Development Group

The Technology Development Group is Carbon Engineering’s core research and development team. We are a multidisciplinary team of research scientists and engineers responsible for driving next-generation DAC technology improvements through evolutionary and revolutionary innovation. We value a collaborative and inclusive research environment which fosters curious and explorer-driven mindsets.

Position Scope

As a Research Scientist in the Technology Development group, you will join an elite, multidisciplinary team of scientists and engineers who are responsible for the development of Carbon Engineering’s next-generation technologies. You will work within collaborative research teams on projects spanning fundamental laboratory studies to process validation at pilot scale. Your objective will be to conceptualize, develop, and demonstrate technology solutions that drive cost reductions, enabling new market opportunities and accelerating widespread adoption of DAC technology.

We would love to hear from you if:

You thrive in a collaborative, team-centric work environment
You are excited by the prospect of advancing a technology from the conceptualization stage through to demonstration
You have a strong chemistry background in a research laboratory environment
You are a self-motivated, curious, and creative problem solver
You value a rigorous, data-driven approach to decision-making
You are passionate about leading the future of clean technologies for carbon-circular economies to address the social and environmental impacts of climate change

Responsibilities

Technical:

Perform experiments in the laboratory, bench, or pilot scales
Perform standard and unique analytical chemistry methods
Process and analyze experimental data using appropriate statistical methods
Stay up to date on emerging research and new technology development
Connect existing knowledge, new learnings, and original ideas to create new concepts
Continuously contribute to the company’s intellectual property portfolio
Rapidly assess the high-level technical and economic feasibility of new concepts to understand opportunities and roadblocks
Define the key questions that need to be answered to gain a strong fundamental understanding of new concepts, and plan, design, and execute the experiments required to answer them
Interpret the results and communicate the learnings in both written and verbal formats to a diverse audience to support rigorous, data-driven decision making
Use the learnings to define the logical next steps for the project
Perform necessary design calculations when selecting new equipment or instrumentation, and if applicable, identify third party consultants for technical review or independent design consultation

Safety:

Demonstrate and champion a positive culture of environmental and personal health and safety
Follow all company safety requirements and procedures
Implement and maintain safe work procedures for unique Technology Development equipment and experiments
Identify, report, and resolve unsafe conditions, processes, or actions within the workplace
Ensure that all safety related incidents, accidents and near misses are reported and investigated in line with company policy
Complete training curriculum and maintain required certifications
Contribute to laboratory upkeep and safety reviews

Qualifications & Experience

Education:

B.Sc. (minimum) or M.Sc./PhD (preferred) in Chemistry, Materials Science, Physics or related disciplines

Experience:

Minimum of 2+ years research experience in academic or industrial laboratory environments
Experience designing and constructing test equipment at the laboratory, bench, or pilot scales is an asset
Experience in CO2, other gas scrubbing, or mass transfer technologies is an asset
Experience in industrial process chemistry is an asset

Key Competencies:

Key competencies of interest include, but are not limited to:

Analytical methods including spectroscopic, crystallographic and gravimetric techniques
Materials characterization
Inorganic and organic synthetic techniques
Electrochemistry and membrane science
Statistical methods and regression analysis
Reaction kinetics elucidation and modeling

Offers And Benefits

Carbon Engineering offers a competitive compensation package including extended health benefits.

Base Salary for an Intermediate to Advanced level role is $81,000 to $140,000 with additional bonus pay.

This position is eligible for our standard 40 hours/week work schedule, or our 9/80 work schedule which provides every second Friday off.

Our location in the outdoor recreation hub of Squamish gives you access to world class skiing, mountain biking, climbing, hiking, and other outdoor activities within minutes of the office, while in close proximity to Vancouver, one of the most beautiful and culturally diverse cities in Canada.

Joining Carbon Engineering provides you more than a career – it’s a calling for those who are ready to make a difference in climate action. We provide hope.

Carbon Engineering is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants are encouraged to apply and will receive equal consideration for employment regardless of race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, disability, or age.

Powered by JazzHR

0xLqBmlkrc","{""role_summary"":""Conduct research and experiments to develop next-generation technologies for Direct Air Capture, collaborating with a multidisciplinary team to drive cost reductions and accelerate widespread adoption."",""key_terms"":[{""term"":""Direct Air Capture (DAC)"",""explanation"":""A technology that captures CO2 directly from the air.""},{""term"":""AIR TO FUELS TM"",""explanation"":""A technology that converts air into fuels.""},{""term"":""CO2 scrubbing"",""explanation"":""A process that removes CO2 from the air or other gases.""},{""term"":""Mass transfer technologies"",""explanation"":""Technologies that facilitate the transfer of mass or substances from one phase to another.""}],""skill_priorities"":{""must_have"":[""Strong chemistry background in a research laboratory environment"",""Experience with analytical chemistry methods"",""Ability to process and analyze experimental data"",""Strong problem-solving skills""],""nice_to_have"":[""Experience with CO2 scrubbing, mass transfer technologies, or industrial process chemistry"",""Experience designing and constructing test equipment at laboratory, bench, or pilot scales"",""Knowledge of electrochemistry and membrane science""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you had to design and execute an experiment to answer a complex research question?"",""example_answer"":""In my previous role, I designed an experiment to study the effects of pH on the reaction rate of a certain catalyst. I had to consider multiple variables and optimize the experimental conditions to obtain reliable results.""},{""question"":""How do you stay current with emerging research and developments in your field?"",""example_answer"":""I regularly read scientific articles and attend conferences to stay up-to-date with the latest developments. I also network with colleagues and collaborators to learn about new techniques and methodologies.""}],""red_flags"":[""Lack of experience in a research laboratory environment"",""Inability to work collaboratively in a team"",""Limited knowledge of statistical methods and regression analysis""],""confidence_score"":90.0}"
Data Scientist (L5) - Content,Netflix,United States,March,2025,"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

TUDUM is Netflix’s home for fans, where our daily breaking news, original videos, exclusive interviews, and behind-the-scenes storytelling reach millions of fans every month. We aim to bring members joy by deepening their connections to their favorite movies and series and helping them discover their next obsession.

Data is a crucial component in shaping TUDUM’s strategy. In Content & Conversation Applied Science and Analytics (CASAS) DSE, we focus on delivering data products and insights that support our business partners in their complex and nuanced decision-making processes. We are a highly collaborative team that partners across Netflix to drive impact.

We are seeking a talented Senior Data Scientist to provide key insights and thought partnership to our TUDUM decision makers. You will generate insights by scoping and executing deep dive analysis and experimentation with the TUDUM product, engineering, and editorial teams. In success, you will collaborate on existing priorities but also will propose and execute on new opportunities. This role features ample opportunity for project ownership, leadership and direct influence on impactful business decisions.

In This Role, You Will

Be a strategic thought partner with business stakeholders to define high impact problems and innovative ways to solve them with data.
Develop statistical models explaining TUDUM engagement, impact, and other key behavioral patterns and drive causal inferences between TUDUM and the engagement with other netflix channels
Translate insights into actionable recommendations for business improvement, and communicate these findings clearly to a broad audience
Identify and proactively socialize TUDUM insights, especially those that may be impactful to other business areas

What You’ll Bring

Exceptional interpersonal and communication skills to influence stakeholders using clear insights and recommendations
Adept at cultivating strong partnerships
Exceptional thought partnership and engagement abilities with a diverse set of stakeholders and passionate about communicating difficult concepts to non-technical audiences
Highly skilled in leading through influence
Exceptional facilitation, planning and organization skills
Strong statistical knowledge: understanding of predictive modeling; ability to tease out incrementality vs. correlations, confounder identification and amelioration, etc.
Strong understanding of experimentation including power calculations and interpretation of results
Strong SQL skills and experience with distributed analytic processing technologies (S3, Presto, Hive & Spark)
Strong skills in Python or R
Self-starter who thrives under a high level of autonomy.
Enthusiastic about Netflix culture

Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.","{""role_summary"":""Provide key insights and thought partnership to TUDUM decision makers, generating insights through deep dive analysis and experimentation with product, engineering, and editorial teams."",""key_terms"":[{""term"":""Predictive modeling"",""explanation"":""A statistical technique used to forecast outcomes based on historical data.""},{""term"":""Confounder identification and amelioration"",""explanation"":""Identifying and addressing factors that affect the outcome of an experiment, ensuring accurate results.""},{""term"":""Power calculations"",""explanation"":""Determining the sample size required for an experiment to achieve statistically significant results.""},{""term"":""Distributed analytic processing technologies"",""explanation"":""Tools like S3, Presto, and Spark that enable fast processing of large datasets across multiple systems.""}],""skill_priorities"":{""must_have"":[""Strong statistical knowledge"",""Strong SQL skills"",""Strong skills in Python or R"",""Exceptional interpersonal and communication skills""],""nice_to_have"":[""Experience with experimentation"",""Facilitation, planning, and organization skills""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a complex statistical concept to a non-technical audience?"",""example_answer"":""I'd be happy to explain the concept of confounding variables in a way that's easy to understand.""},{""question"":""How do you approach identifying and addressing confounders in an experiment?"",""example_answer"":""I use techniques like matching and regression adjustment to identify confounders and then apply methods like stratification or weighting to address them.""}],""red_flags"":[""Lack of experience with distributed analytic processing technologies"",""Inability to communicate complex concepts to non-technical""],""confidence_score"":95.0}"
Data Scientist (Energy Systems),Paces,"Brooklyn, NY",March,2025,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time. However, there are problems!

The Problem

80% of clean energy projects that developers start never actually get built because most projects are started without deep due diligence on zoning and interconnection due to the cost of collecting that data. This means $17B worth of canceled projects per year.

Our Solution

Paces is software for green infrastructure developers to identify the best places to build and manage their projects. First we collect environmental, permitting, zoning, energy grid data from various different sources; then we analyze the data and use AI to identify the best places for developers to build their next projects.

Our Team

We are building a team where people can proudly say their time at Paces is the most impactful, meaningful work of their career. Our amazing team in Brooklyn, New York includes incredible engineers and growth team members from companies like Facebook, AWS, Replika, DataDog, Yotpo, Rent The Runway & Leap.

Paces is growing rapidly and looking for exceptional people to join who want to have a massive positive climate impact while building a great culture! We are looking for a Data Scientist with deep expertise in energy system modeling to join our Product team, reporting directly to the Head of Product. This role is a unique opportunity to bridge power engineering with cutting-edge software and product development.

🏆 What You’ll Achieve

Model transmission system dynamics with rapid load growth under high penetrations of renewables
Scrape and process generation and transmission upgrade queues, utility planning documents, and other unstructured and semi-structured data sources
Probabilistically model interconnection scenarios and develop technically rigorous study assumptions
Analyze output data from power flow simulations to consider the technical and commercial viability of new generation and large loads and identify the most favorable locations
Develop software solutions and data pipelines that enhance and automate power system analysis at scale
Act as an internal domain expert at Paces, developing proprietary methodologies and shaping product development

📈 Requirements

3+ years experience in data science, research science, machine learning, or a similar technical role
3+ years experience with python and the supporting computational and geospatial science tool suite (e.g. numpy, scipy, geopandas, GDAL, scikit-learn, tensorflow, etc.)
4+ years experience in the electricity and energy domain (e.g. electricity grid modeling and optimization, power system planning and operation, energy markets and regulation, price forecasting, congestion prediction, etc.)
Familiarity with at least one major ISO/RTO or wholesale market (e.g., PJM, MISO, ERCOT, CAISO, WECC, etc.).
Familiarity with at least one third party power flow or production cost modeling software (PSS/E, TARA, PLEXOS, etc.)
Strong quantitative and data wrangling abilities
Ability to think beyond traditional engineering approaches and contribute to product innovation through creative, iterative thinking

✨ About You

You will thrive in our culture if you:

You love deep in person collaboration
You get a thrill out drawing insights from messy data
You have a strong bias towards action and a high learning rate
You are always looking for better ways to automate tedious tasks

🚀 Bonus Points

Previous experience at a high-growth, fast-paced startup
Previous experience at a battery storage, solar, or datacenter developer
Degree in electrical or power engineering
Expertise in energy policy and regulatory analysis

💰 Compensation And Benefits

$130,000 - 150,000 annual compensation
Competitive equity compensation
401(k) match (4%)
Health, dental and vision insurance
Paid company holidays & unlimited PTO (minimum 15 days per year)
Hybrid work in the office in Williamsburg, Brooklyn 2-4x per week","{""role_summary"":""A Data Scientist role at Paces, responsible for modeling energy systems, developing software solutions, and enhancing power system analysis to support green infrastructure development."",""key_terms"":[{""term"":""ISO/RTO"",""explanation"":""Independent System Operator/Regional Transmission Organization, responsible for managing wholesale electricity markets and transmission grid management.""},{""term"":""Power flow simulations"",""explanation"":""Computer-based analysis of electricity transmission and distribution systems to identify potential issues and optimize performance.""},{""term"":""Geospatial science tool suite"",""explanation"":""A collection of software tools used for geographic data analysis, such as numpy, scipy, and GDAL.""}],""skill_priorities"":{""must_have"":[""3+ years experience in data science, research science, or a similar technical role"",""3+ years experience with python and supporting computational and geospatial science tool suite"",""4+ years experience in the electricity and energy domain"",""Familiarity with at least one major ISO/RTO or wholesale market"",""Familiarity with at least one third party power flow or production cost modeling software""],""nice_to_have"":[""Previous experience at a high-growth, fast-paced startup"",""Previous experience at a battery storage, solar, or datacenter developer"",""Degree in electrical or power engineering"",""Expertise in energy policy and regulatory analysis""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would model transmission system dynamics with rapid load growth?"",""example_answer"":""I would use a combination of power flow simulations and probabilistic modeling to analyze the technical and commercial viability of new generation and large loads, identifying the most favorable locations.""},{""question"":""How do you stay up-to-date with developments in energy policy and regulatory analysis?"",""example_answer"":""I regularly review industry publications, attend conferences, and engage with experts in the field to stay current on the latest developments and trends.""}],""red_flags"":[""Lack of experience with power flow simulations and probabilistic modeling"",""Inability to work collaboratively in a fast-paced startup environment""],""confidence_score"":95.0}"
Stanowisko ds. zarządzania obszarem BI i HD-specjalność inżynierii systemów Hurtowni Danych,ZUS,"Left Hand, WV",March,2025,"Nazwa jednostki organizacyjnej

ZUS III Oddział w Warszawie

Nazwa komórki organizacyjnej

Departament Statystyki i Prognoz Aktuarialnych

Miejsce pracy

ZUS III Oddział w Warszawie

Adres miejsca pracy

ul. Czerniakowska 16, 00-701 Warszawa

Województwo

mazowieckie

Nazwa stanowiska

Stanowisko ds. zarządzania obszarem BI i HD-specjalność inżynierii systemów Hurtowni Danych

Zadania

Zadania

zapewniać utrzymanie i rozwój architektury biznesowej i technicznej obszaru Hurtowni Danych
odpowiadać za proponowanie, budowanie i wdrażanie rozwiązań z zakresu technologii przetwarzania dużych zbiorów danych (Big Data), m.in. modelowania danych, projektowanie modelów ekstrakcji danych, projektowania i utrzymanie systemów magazynowania danych
odpowiadać za analizowanie wydajności sprzętu i oprogramowania w obszarze Hurtowni Danych
uczestniczyć w planowaniu inicjatyw i projektów mających na celu rozbudowę i optymalizację wykorzystywanych rozwiązań w obszarze Hurtowni Danych
współpracować przy projektowanie procesów ETL (Extract, Transform, Load), ELT (Extract, Load, Transform) w celu pozyskiwania, przetwarzania i ładowania danych z różnych źródeł do systemów klasy Hurtowni Danych
uczestniczyć w pracach projektowych, wdrożeniowych i testowych w obszarze Hurtowni Danych
wspierać użytkowników w ramach wdrożeń systemów i narzędzi w obszarze Hurtowni Danych
uczestniczyć w przygotowaniu planu rozwoju (roadmapy) dla środowiska Business Intelligence i Hurtowni Danych
proponować usprawnienia dla realizowanych procesów i zmiany w dokumentacji
Wymagania

Wymagania Niezbędne

wykształcenie wyższe
doświadczenie zawodowe minimum 1 rok (w pracy związanej z planowaniem, tworzeniem i rozwojem w obszarach Business Intelligence i\lub Hurtowni Danych)
staż pracy ogółem minimum 2 lata

Mile Widziane

wykształcenie wyższe (matematyka, informatyka, statystyka)
doświadczenie zawodowe minimum 2 lata (w pracy związanej z planowaniem, tworzeniem i rozwojem w obszarach Business Intelligence i\lub Hurtowni Danych)

Wymagania Dodatkowe

umiejętność obsługi programów MS Office
Znajomość języka SQL
orientacja na cel
orientacja na jakość
komunikacja
współpraca
elastyczność
nastawienie na rozwój
negocjowanie i wywieranie wpływu
podejmowanie decyzji
umiejętność rozwiązywania problemów
innowacyjność

Wymagane Dokumenty

CV
listu motywacyjnego
skan dokumentów potwierdzających wykształcenie
skan dokumentów potwierdzających wymagane doświadczenie zawodowe
skan świadectw pracy dokumentujących wymagany staż pracy lub zaświadczenie o zatrudnieniu zawierające okresy zatrudnienia, w przypadku pozostania w stosunku pracy

Dokumenty należy przesyłać poprzez formularz aplikacyjny 'Aplikuj', znajdujący się na dole oferty

Dodatkowe Informacje

proces rekrutacji obejmować będzie rozmowę kwalifikacyjną (przeprowadzoną w formie zdalnej przez komunikator internetowy - wywiad on-line) lub stacjonarnie
skontaktujemy się tylko z kandydatami spełniającymi wymagania formalne
oferty niekompletne tj. niezawierające skanu, któregokolwiek wymaganego dokumentu nie będą rozpatrywane
oferty przesłane po terminie nie będą rozpatrywane
miejscem świadczenia pracy będzie Centrala ZUS lub dowolny Oddział ZUS
możliwość pracy w trybie stacjonarnym, zdalnym lub hybrydowym
Termin, do którego należy składać dokumenty

12-02-2025

Oferujemy

Oferujemy

stabilne zatrudnienie na podstawie umowy o pracę
możliwość rozwoju zawodowego
bogaty pakiet świadczeń socjalnych
system premiowy

Zakład Ubezpieczeń Społecznych jest pracodawcą przyjaznym osobom z niepełnosprawnościami. Stwarza pracownikom optymalne środowisko pracy, uwzględniając ich potrzeby. Istnieje możliwość dostosowania stanowiska pracy i jego wyposażenia do indywidualnych potrzeb osób z niepełnosprawnościami

Wyposażenie Stanowiska Pracy

sprzęt komputerowy,
sprzęt biurowy.

Warunki Wykonywania Pracy

spełniają warunki określone wymogami bhp i ppoż.,
polegają na obsłudze komputera powyżej 4 godzin na dobę,
konieczność poruszania się po całym obiekcie,
konieczność wykonywania pracy poza biurem,
konieczność odbywania podróży służbowych,
budynek 3-piętrowy z windą oraz pomieszczeniami sanitarnymi dostosowanymi do potrzeb osób niepełnosprawnych,
stanowisko pracy zlokalizowane w pomieszczeniach biurowych na 3- piętrze,
miejsce pracy dostosowane do osób poruszających się przy pomocy wózka inwalidzkiego,
wejście do budynku jest zorganizowane z poziomu chodnika,
drzwi przy wejściu do budynku otwierają się automatycznie,
w bezpośrednim sąsiedztwie wejścia do budynku znajdują się miejsca parkingowe dla osób z niepełnosprawnościami","{""role_summary"":""Manage and develop the Business Intelligence and Data Warehouse, ensuring the maintenance and growth of the architecture, proposing and implementing solutions for big data processing, and collaborating with teams to optimize data management."",""key_terms"":[{""term"":""Big Data"",""explanation"":""Large and complex datasets that require specialized processing and analysis.""},{""term"":""Business Intelligence"",""explanation"":""The process of gathering, analyzing, and reporting business data to inform business decisions.""},{""term"":""Data Warehouse"",""explanation"":""A centralized repository that stores data from various sources in a single location for reporting and analysis.""},{""term"":""ETL (Extract, Transform, Load)"",""explanation"":""A process of extracting data from various sources, transforming it into a standardized format, and loading it into a target system.""},{""term"":""Hurtowni Danych"",""explanation"":""A Polish term for Data Warehouse, a centralized repository that stores data from various sources for reporting and analysis.""}],""skill_priorities"":{""must_have"":[""Experience with Business Intelligence and Data Warehouse"",""SQL skills"",""MS Office proficiency""],""nice_to_have"":[""Mathematics, Informatics, or Statistics degree"",""2+ years of experience"",""Innovative problem-solving skills""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain your experience with Business Intelligence and Data Warehouse?"",""example_answer"":""I have worked on several projects involving data warehousing and business intelligence, and have experience with ETL, data modeling, and reporting.""},{""question"":""How do you approach data analysis and problem-solving?"",""example_answer"":""I use a structured approach, identifying the problem, gathering data, analyzing it, and presenting findings and recommendations.""}],""red_flags"":[""Lack of experience with Business Intelligence and Data Warehouse"",""Inability to work with large datasets"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
"Data Scientist, Investing",Wealthfront,"Palo Alto, CA",March,2025,"The Wealthfront Data Science Team utilizes our rich financial and behavioral data to influence key product and marketing decisions, as well as to safeguard our client’s information and assets. The team draws from backgrounds in Computer Science, Statistics, Operations Research, Economics, and Natural Sciences. We value analytical rigor, clear communication, and proactivity. We believe that good ideas can come from anywhere and encourage Data Scientists to pursue self-directed explorations in search of business value. 
The Data Scientist in this role will be primarily embedded within Wealthfront’s Investing area. The vision of this area is to enable our clients to confidently grow, preserve, and manage their wealth by making the most effective investing strategies more convenient, accessible, and affordable.
Potential project areas for this role include (but are not limited to):
• Analysis of client and prospect behavior such as funnel drop-off, cross-product-adoption, deposit patterns, asset allocation, and product usage
• Opportunity sizing for new products
• Creating dashboards to visualize and track product and area metrics
• Building pipelines to ingest and organize data
• Collaborating on blog posts discussing Wealthfront products and general investing
• Research and development of predictive models to forecast product interest and demand

Responsibilities
Formulate project plans with clear rationale, candidate approaches and milestones.
Employ a high degree of mathematical rigor and best practices for software development.
Collaborate with cross functional stakeholders to identify key initiatives for the Investing area and champion the role of Data Science within these initiatives.
Formulate project plans with clear rationale, candidate approaches and milestones.
Guide execution of project plans with a combination of delegation and hands-on work.
Interpret and contextualize statistical results for business stakeholders and help translate numbers into recommendations.
Enhance overall Data Science team execution through hands-on help, design feedback and peer review.
Identify and formulate steps to automate repetitive manual work (toil).

Requirements
A Bachelor's degree in Computer Science, Statistics, Mathematics, Economics, Operations Research, or Natural Sciences with 4+ years of prior experience in a Data Science role. Exceptions to these requirements may be considered on a case-by-case basis.  
Prior experience in financial services or knowledge of finance basics is helpful but not required.
Strong communication and collaboration skills and a record of partnering across organizations to sharpen project requirements. Sometimes this includes re-framing the original request to solve a more general problem with similar effort. 
Hands-on mathematical and software engineering skills to execute on complex projects.
Proficiency in Python and SQL.
Desire and ability to mentor junior Data Scientists within the team by exemplifying math, engineering and technical communication skills.


Estimated annual salary range: $164,000 - $184,000 USD plus equity and a discretionary bonus.
Benefits include medical, vision, dental, 401K plan, generous time off, parental leave, wellness reimbursements, professional development, employee investing discount, and more!

About Wealthfront
Here at Wealthfront, our mission is to create a financial system that favors people, not institutions. We do this by leveraging technology to build powerful, low-cost, and easy-to-use financial products that help modern investors grow and manage their money.
We started with the ambition to transform the investment advisory business. By automating strategies typically reserved for the wealthy, we unlocked access to high quality investment advice for a digitally-native generation that was underserved by traditional institutions. Since then, we've expanded to a full suite of products designed to help our clients turn their savings into long-term wealth, including:
• A Cash Account that, through our partner banks, offers one of the highest annual percentage yields on uninvested cash in the industry, while providing instant and secure access to your money with no account fees and a full suite of checking features.
• A zero-commission Stock Investing Account with 50+ handpicked collections that help DIY investors discover new companies and make smarter investing decisions.
• Multiple automated investing portfolios designed to unlock tax savings through sophisticated strategies like fixed income, tax-loss harvesting, and direct indexing—which we offer at industry-leading low costs and accessible minimums.
Our award-winning products have attracted over 1 million clients who trust us with more than $80 billion of their hard earned savings—and we're far from done. If you’re inspired to help us reshape the financial industry as we create our next chapter, let’s talk!
For more information please visit www.wealthfront.com.We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
Please review our candidate privacy notice. 
Disclosures: All investing involves risk, including the possible loss of principal. Tax-Loss Harvesting benefits vary depending on the client's entire tax and investment profile. Wealthfront doesn’t provide tax advice. The Cash Account is offered by Wealthfront Brokerage LLC (“Wealthfront Brokerage”), Member of FINRA/SIPC. Wealthfront Brokerage is not a bank. We convey funds to partner banks who accept and maintain deposits, provide the variable interest rate, and provide access to FDIC pass-through insurance. Investment management and advisory services–which are not FDIC insured–are provided by Wealthfront Advisers LLC (“Wealthfront Advisers”), an SEC-registered investment adviser. The checking features offered in the Wealthfront Cash Account are provided by Green Dot Bank, Member FDIC. Fees and Eligibility requirements may apply to certain checking features, please see the Deposit Account Agreement for details.
By “award-winning products”, please refer to www.wealthfront.com/reviews for more information. Wealthfront Corporation oversees Total Client Assets and Trusted Clients through Wealthfront Advisers and Wealthfront Brokerage. Wealthfront Advisers and Wealthfront Brokerage are wholly owned subsidiaries of Wealthfront Corporation.  ","{""role_summary"":""The Data Scientist will analyze client behavior, develop predictive models, and collaborate with stakeholders to drive business growth in the Investing area at Wealthfront."",""key_terms"":[{""term"":""Predictive models"",""explanation"":""Statistical models that forecast future events or behaviors, such as product interest and demand.""},{""term"":""Cross-functional stakeholders"",""explanation"":""Individuals from different departments or teams who work together to achieve a common goal.""},{""term"":""Mathematical rigor"",""explanation"":""The application of mathematical principles and methods to ensure accuracy and precision in data analysis.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Strong communication and collaboration skills"",""Hands-on mathematical and software engineering skills""],""nice_to_have"":[""Prior experience in financial services"",""Knowledge of finance basics""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing client behavior to inform product development?"",""example_answer"":""I would start by identifying key metrics to track, such as funnel drop-off and deposit patterns. Then, I would develop predictive models to forecast product interest and demand, and finally, I would collaborate with stakeholders to translate insights into actionable recommendations.""},{""question"":""How do you ensure the accuracy and precision in your data analysis?"",""example_answer"":""I apply mathematical rigor to ensure that my analysis is sound and reliable. I also peer-review my work and seek feedback from colleagues to catch any potential errors or biases.""}],""red_flags"":[""Lack of experience in data science or a related field"",""Poor communication and collaboration skills"",""Inability to work with complex data sets and develop predictive models""],""confidence_score"":90.0}"
Decision Scientist,Fractal,"Sunnyvale, CA",March,2025,"Decision Scientist

Job Summary:
We are seeking a talented and dynamic Decision Scientist with strong expertise in Tableau and SQL to join our dynamic team. The candidate will leverage a mix of data engineering, analytics, dashboarding and storytelling to derive actionable insights and help improve customer experience across digital journeys.
Our ideal candidate is someone who is proficient at execution, adept at managing timelines and roadmaps and is constantly looking to innovate and automate to bring greater efficiencies and drive strong business outcomes

Key Responsibilities:
Extract, process, and analyze large datasets from multiple sources to identify trends and patterns.
Create and maintain visually compelling dashboards and reports using Tableau to present insights to stakeholders.
Develop compelling presentations on Keynote to communicate strategic insights to leadership
Collaborate with cross-functional teams to understand business needs and translate them into data solutions.
Perform exploratory data analysis (EDA) and apply statistical techniques for hypothesis testing.
Optimize data models and enhance data processing pipelines for efficiency and scalability.
Communicate findings clearly to both technical and non-technical audiences.
Stay updated with the latest trends and advancements in data analytics and visualization.
Identify growth opportunities in form of automation, new solutions, enhancements etc. and follow an agile approach to translate ideas into outcomes

Required Qualifications:
Master’s degree in Data Science, Computer Science, Statistics, or a related field, or equivalent work experience.
Proven experience with data visualization and storytelling.
Proficiency in Tableau for creating dashboards, reports, and data models.
Strong skills in SQL for data extraction and manipulation, with a strong emphasis on self-driven and structured quality check process
Familiarity with data integration tools and ETL processes.
Excellent analytical, problem-solving, and communication skills.
Excellent at cross-functional collaboration working with global teams, as well as independent execution and proactive management of timelines and dependencies
(Strongly preferred) Experience with digital analytics (Adobe Workspace or Google Analytics)
(Good to have) Hands-on experience with programming languages such as Python or R.
(Good to have) Solid understanding of statistical methods and machine learning algorithms.","{""role_summary"":""A Decision Scientist who uses data analysis and visualization to drive business outcomes and improve customer experience."",""key_terms"":[{""term"":""Tableau"",""explanation"":""A data visualization tool used to create dashboards and present insights to stakeholders.""},{""term"":""SQL"",""explanation"":""A programming language used for data extraction, manipulation, and analysis.""},{""term"":""ETL"",""explanation"":""A process of extracting, transforming, and loading data for analysis.""},{""term"":""Data Visualization"",""explanation"":""The process of presenting data insights in a visually appealing way.""},{""term"":""Statistical Techniques"",""explanation"":""Methods used to test hypotheses and draw conclusions from data.""},{""term"":""Machine Learning Algorithms"",""explanation"":""Mathematical models used to make predictions and automate decision-making.""}],""skill_priorities"":{""must_have"":[""Data Visualization"",""SQL"",""Tableau"",""Analytical Skills"",""Communication Skills"",""Cross-functional Collaboration""],""nice_to_have"":[""Python"",""R"",""Statistical Methods"",""Machine Learning Algorithms"",""Digital Analytics (Adobe Workspace or Google Analytics)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you walk me through your process for creating a dashboard in Tableau?"",""example_answer"":""I'd start by identifying the key insights I want to present, and then use Tableau's drag-and-drop interface to build a visually appealing dashboard that effectively communicates those insights.""},{""question"":""How do you ensure the quality of your data analysis?"",""example_answer"":""I use a structured approach, including self-driven quality checks, to ensure that my data is reliable and actionable.""}],""red_flags"":[""Lack of experience with data visualization tools like Tableau."",""Inability to communicate complex data insights to non-technical stakeholders.""],""confidence_score"":90.0}"
Jr. Data Scientist,Center for Sustainable Energy (CSE),United States,March,2025,"The Junior Data Scientist is an essential member of the CSE's Transparency and Insights (T&I) team, supporting the organization's analysis, evaluation, and implementation of decarbonization programs. This role enhances the team's capabilities by ensuring efficient and reliable access to program data, managing, analyzing, and interpreting data, and contributing to analytics that determine the impacts of policy designs and technology deployments.
Essential Functions and Responsibilities:
Data Analysis and Insights Generation
Extract, transform, analyze, and interpret data from diverse sources to meet both internal and external client requirements.
Apply descriptive statistics, statistical models and machine learning techniques to derive insights from data.
Ensure the quality and accuracy of data operations and analysis performed, implementing quality control (QC) measures.
Document analytical methods and contribute to the development of standard operating procedures (SOPs).
Data Visualization and Application Support
Develop and maintain web-based data visualizations, interactive maps, and reporting tools to communicate insights effectively.
Facilitate the extraction and reporting of data from PostgreSQL databases, flat files, columnar file formats, and other data sources.
Work under the mentorship of senior T&I team members to meet project objectives.
QUALIFICATIONS
Essential Knowledge, Skills, and Abilities:
Required
Technical Proficiency
Proficient in Python for data and statistical analysis, utilizing libraries like pandas, matplotlib, and sklearn.
Knowledgeable in object-oriented programming and ETL pipeline development.
Experienced with software version control using Git.
Strong skills in Microsoft Excel, Word, and PowerPoint.
Cloud Computing
Basic knowledge of AWS services such as IAM, EC2 and RDS.
Soft Skills
Exceptional attention to detail, along with strong organizational and problem-solving abilities.
Excellent communication skills, both oral and written.
Self-motivated with the ability to manage deadlines for multiple concurrent projects, using project management tools effectively.
Proactive in communicating with team members in a remote environment and open to seeking and receiving feedback.
Special Interests
A keen interest in data science applications within research and sustainable energy sectors.
Preferred
Skilled in geospatial analysis, including the use of libraries like Geopandas and Shapely.
A foundational understanding of the energy sector, including electric vehicles, energy efficiency, distributed generation, or energy storage.
Experience with data visualization tools (e.g., Tableau, PowerBI, Plotly) and survey platforms (e.g., Alchemer).
Education:
Bachelor’s degree in a field with substantial analytical content, such as statistics, economics, computer science, social science, environmental science, or engineering.
Experience:
1-3 years of experience in data analysis or a related field.
WORKING CONDITIONS
Work Environment:
Works in a home (remote) or office environment
Occasional evening and weekend work may be required to meet project deadlines.

Physical Demands:
The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Must have manual dexterity sufficient to operate a computer keyboard and other equipment customarily present in an office environment.","{""role_summary"":""Support the organization's decarbonization programs by ensuring efficient access to program data, managing and analyzing data, and contributing to analytics that determine policy impacts."",""key_terms"":[{""term"":""Decarbonization programs"",""explanation"":""Initiatives aimed at reducing carbon emissions and mitigating climate change.""},{""term"":""ETL pipeline development"",""explanation"":""Extract, Transform, Load process for managing data workflows.""},{""term"":""Geospatial analysis"",""explanation"":""Analyzing data with geographic or spatial components.""}],""skill_priorities"":{""must_have"":[""Python"",""Data analysis"",""Statistical modeling"",""Machine learning"",""ETL pipeline development"",""Cloud computing (AWS)"",""Microsoft Office (Excel, Word, PowerPoint)"",""Git"",""Attention to detail"",""Organizational skills"",""Problem-solving abilities"",""Communication skills""],""nice_to_have"":[""Geospatial analysis"",""Data visualization tools (Tableau, PowerBI, Plotly)"",""Survey platforms (Alchemer)"",""Energy sector knowledge"",""Project management tools""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure data quality and accuracy in your analysis?"",""example_answer"":""I implement quality control measures, such as data validation and verification, to ensure data accuracy and reliability.""},{""question"":""Can you explain a project where you applied statistical models and machine learning techniques to derive insights from data?"",""example_answer"":""In my previous role, I used regression analysis to identify trends in customer behavior, which informed marketing strategies.""}],""red_flags"":[""Lack of experience with cloud computing (AWS)"",""Inability to work in a remote environment"",""Poor communication skills""],""confidence_score"":90.0}"
Data Scientist (Junior - Senior),Clear Ridge Defense,"Fort George G. Meade, MD",February,2025,"Clear Ridge Defense is seeking TS/SCI cleared professionals to serve as Data Scientists in Fort Meade, MD.

Roles And Responsibilities

You will...

Devise strategies for extracting meaning and value from large datasets.
Make and communicate principled conclusions from data employing mathematics, statistics, computer science, and application-specific knowledge.
Use various forms of analysis methodology to characterize, explore, and assess large complex datasets.
Translate practical mission needs and analytics questions related to large datasets into technical requirements.
Assist teammates in drawing appropriate conclusions from the analysis of such data.
Effectively communicate complex technical concepts to non-technical audiences.
Make informed recommendations regarding technical solutions, while maintaining awareness of unique and dynamic customer collection, processing, storage, and analytic capabilities.

Must-Haves

You possess...

Excellent interpersonal communication skills.
A Top Secret clearance with polygraph.
Years (3+) of relevant experience in machine learning, data science, programming, or statistical analysis.
A Bachelor's Degree in a Computer Science/Mathematics related field.
An ability to work in a fast-paced and dynamic workplace with unique TTPs.

Nice-To-Haves

Leadership experience.

Additional Information

Ranking #5 in Maryland and #7 in Government Services! And see how we were ranked a 2023 Top Workplace by the Baltimore Sun!

Clear Ridge Defense Is The Premier Service Solutions Provider Supporting The Service And Joint Cyberspace Operations And Intelligence Community In Three Core Areas Of Expertise

Cyber Systems & Software Engineering
Cyber Intelligence & Operations Planning
Security Risk Analysis, Mitigation & Training

All delivered by highly talented and focused team members that are supported by an unmatched professional and family-oriented culture that leverages and builds on sound, proven principles.

Benefits Snapshot

100% Fully-Covered Health, Dental, and Vision Insurance
100% Fully-Covered Short-Term and Long-Term Disability Insurance
100% Fully-Covered Life and AD&D Insurance
Unique Flexible PTO
11 Paid Federal Holidays
$500 New Uniform Bonus for Transitioning Military
Monthly Tax-Free Cell Phone Stipend
Monthly Tax-Free Gym Wellness / Streaming Subscription Stipend to include Amazon Prime, Netflix, Audible, etc.
Competitive 401k Matching to plan for retirement
Free financial advising from qualified experts
Annual $5,000 Training Allotment
One-of-a-kind Referral Program: $5,000 per referral OR $250/mo indefinitely, with no limit to number of referrals
Business Development and Client Expansion Bonuses
Monthly Company-Paid Socials and Events
Access to our Company Swag Store

Benefits

CRD fully supports Maryland’s Equal Pay for Equal Work – Wage Range Transparency law, which mandates employers to provide detailed wage and benefits information in all job postings. The salary range for this position is:

$98,000 - $215,000 / year

Salary Ranges Provided Are Subject To The Following Variables And Circumstances, Which May Impact Whether The Actual Paid Salary Falls Within The Range

The contract the employee is assigned to support. For example, this advertised position may support multiple contracts.
The negotiated rates between CRD and our client.
The option year of the contract the employee is assigned to.
Annual performance of the employee and/or the company.
If the employee takes on additional company responsibilities.
If the company makes a strategic hiring decision (e.g., investment in the employee) for growth opportunities.
If the employee does not meet the qualifications fully but a waiver is provided by CRD or our clients.
If the employee is assigned a lower-level labor category due to external circumstances than they actually qualify for.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.","{""role_summary"":""Work as a Data Scientist in Fort Meade, MD, to extract insights from large datasets, communicate complex concepts to non-technical recommendations, and assist in drawing conclusions from data analysis."",""key_terms"":[{""term"":""TS/SCI cleared"",""explanation"":""A security clearance level required for this role, ensuring the candidate can handle sensitive information.""},{""term"":""Machine learning"",""explanation"":""A subfield of artificial intelligence that involves training models to make predictions or decisions based on data.""},{""term"":""Data science"",""explanation"":""A multidisciplinary approach to extracting insights and knowledge from structured and unstructured data.""},{""term"":""Polygraph"",""explanation"":""A lie detector test used to verify the candidate's trustworthiness for handling sensitive information.""}],""skill_priorities"":{""must_have"":[""Excellent interpersonal communication skills"",""Top Secret clearance with polygraph"",""3+ years of relevant experience in machine learning, data science, programming, or statistical analysis"",""Bachelor's Degree in a Computer Science/Mathematics related field""],""nice_to_have"":[""Leadership experience""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a complex technical concept to a non-technical audience?"",""example_answer"":""I'd be happy to explain how machine learning models work. Imagine you're trying to sort different types of fruits into baskets. The model learns from the data to identify patterns, so it can accurately sort the fruits into the correct baskets.""},{""question"":""How do you stay current with new developments in data science and machine learning?"",""example_answer"":""I regularly read industry blogs, attend conferences, and participate in online forums to stay updated on the latest trends and advancements.""}],""red_flags"":[""Avoid candidates without a Top Secret clearance with polygraph, as it's a non-negotiable requirement.""],""confidence_score"":95.0}"
"Data Scientist, Gmail and Chat AI Model Quality",Google,"New York, NY",March,2025,"For United States Applicants:

The application window will be open until at least March 4, 2025. This opportunity will remain online based on business needs which may be before or after the specified date.

Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Sunnyvale, CA, USA; Boulder, CO, USA; Kirkland, WA, USA; New York, NY, USA; San Francisco, CA, USA; Waterloo, ON, Canada; Los Angeles, CA, USA; Seattle, WA, USA.Minimum qualifications:

Bachelor's degree in Statistics, Mathematics, Data Science, Engineering, Physics, Economics, or a related quantitative field.
13 years of work experience using analytics to solve product or business problems, performing statistical analysis, and coding (e.g., Python, R, SQL) (or 10 years work experience and a Master's degree).

Preferred qualifications:

Master's degree in Statistics, Mathematics, Data Science, Engineering, Physics, Economics, or a related quantitative field.
12 years of experience solving product or business problems, performing statistical analysis, and coding (e.g., Python, R, SQL).
Experience in extracting large sets of data with SQL and in designing ETL flows.
Experience working with Developers and Product Managers, especially around providing product-centric insights.
Track record of solving unstructured business problems with data science, translating results into impactful business recommendations, and measuring the success of those initiatives.

About The Job

Help serve Google's worldwide user base of more than a billion people. Data Scientists provide quantitative support, market understanding and a strategic perspective to our partners throughout the organization. As a data-loving member of the team, you serve as an analytics expert for your partners, using numbers to help them make better decisions. You will weave stories with meaningful insight from data. You will make critical recommendations for your fellow Googlers in Developing and Product Management. You relish tallying up the numbers one minute and communicating your findings to a team leader the next.

The Communications & Time Management (CTM) Data Science team shapes decision-making and provides actionable insights to guide product development and strategy for popular Google products like Gmail, Chat, and Calendar.

As a Data Scientist on the team, you will work closely with product and Developer teams to build products enjoyed by users globally.

This is a high-visibility role that partners closely with CTMI Product and Developer leads. You will also regularly share your findings and present your work to Workspace leadership.

Google is an engineering company at heart. We hire people with a broad set of technical skills who are ready to take on some of technology's greatest challenges and make an impact on users around the world. At Google, Developers not only revolutionize search, they routinely work on scalability and storage solutions, large-scale applications and entirely new platforms for developers around the world. From Google Ads to Chrome, Android to YouTube, social to local, Google Developers are changing the world one technological achievement after another.

The US base salary range for this full-time position is $227,000-$320,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .

Responsibilities

Perform data exploration to understand user behavior and identify opportunities for improving GenAI models across Gmail and Chat.
Perform evaluations of model performance across assistive writing, summarization, and inbox highlights.
Define, own, and evolve model evaluation metrics and frameworks.
Lead the design, analysis, and interpretation of product experiments.
Partner with Product, Developers, and cross-functional teams to influence, prioritize, and support product strategy.


Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .","{""role_summary"":""As a Data Scientist, you will provide quantitative support, market understanding, and strategic perspective to partners throughout the organization, using data to help make better decisions and drive product development and strategy."",""key_terms"":[{""term"":""ETL flows"",""explanation"":""The process of extracting, transforming, and loading data from one system to another for analysis and reporting.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and manipulating data in relational database management systems.""},{""term"":""Data Science"",""explanation"":""The process of extracting insights and knowledge from data using various techniques, including machine learning and statistical analysis.""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in Statistics, Mathematics, Data Science, Engineering, Physics, Economics, or a related quantitative field"",""13 years of work experience using analytics to solve product or business problems, performing statistical analysis, and coding (e.g., Python, R, SQL)""],""nice_to_have"":[""Master's degree in Statistics, Mathematics, Data Science, Engineering, Physics, Economics, or a related quantitative field"",""Experience in extracting large sets of data with SQL and in designing ETL flows"",""Experience working with Developers and Product Managers, especially around providing product-centric insights""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach solving an unstructured business problem using data science?"",""example_answer"":""I would start by clarifying the problem and identifying the key stakeholders, then use data to understand the problem and develop a solution, and finally communicate the results and recommendations to the stakeholders.""},{""question"":""How do you stay current with new tools and technologies in the field of data science?"",""example_answer"":""I regularly read industry blogs and attend conferences, and participate in online forums to stay up-to-date with the latest developments and advancements in data science.""}],""red_flags"":[""Lack of experience working with large datasets and performing statistical analysis"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":95.0}"
Machine Learning / Deep Learning Engineer,Waymo,"Mountain View, CA",March,2025,"About the Company - Waymo is an autonomous driving technology company with the mission to be the most trusted driver. Since its start as the Google Self-Driving Car Project in 2009, Waymo has focused on building the Waymo Driver—The World's Most Experienced Driver™—to improve access to mobility while saving thousands of lives now lost to traffic crashes. The Waymo Driver powers Waymo One, a fully autonomous ride-hailing service, and can also be applied to a range of vehicle platforms and product use cases. The Waymo Driver has provided over one million rider-only trips, enabled by its experience autonomously driving tens of millions of miles on public roads and tens of billions in simulation across 13+ U.S. states.

About the Role - Our Perception team builds the system that ""sees"" the world around the self-driving car. We conduct research to address real-world problems and collaborate with research teams at Alphabet. We have access to millions of miles of driving data from a diverse set of sensors, enabling researchers like you to develop complex models and techniques at scale. In this hybrid role, you will report into an Engineering Director.


Responsibilities -

Experience applying machine learning techniques to build multi-modal sensor fusion architectures including object detection and tracking, segmentation, road understanding, flow estimation and future prediction.
Design large-scale foundation models trained on our vast data
Develop data mining, labeling, training and evaluation pipelines to help the Waymo Driver

Qualifications - Bachelors in Computer Science or a similar discipline, or an equivalent amount of deep learning experience


Required Skills -

3+ years experience in Computer Vision and Machine Learning
Experience with Python/C++


Preferred Skills -

PhD degree in Computer Science or a similar discipline
Publications at top-tier conferences like CVPR, ICCV, ECCV, ICLR, ICML, ICRA, RSS, NeurIPS, AAAI, IJCV, PAMI


Pay range and compensation package - The expected base salary range for this full-time position across US locations is listed below. Actual starting pay will be based on job-related factors, including exact work location, experience, relevant training and education, and skill level. Your recruiter can share more about the specific salary range for the role location or, if the role can be performed remote, the specific salary range for your preferred location, during the hiring process. Waymo employees are also eligible to participate in Waymo’s discretionary annual bonus program, equity incentive plan, and generous Company benefits program, subject to eligibility requirements.


Equal Opportunity Statement - Include a statement on commitment to diversity and inclusivity.","{""role_summary"":""Develop and apply machine learning techniques to improve the perception system of self-driving cars, focusing on sensor fusion, object detection, and road understanding."",""key_terms"":[{""term"":""Multi-modal sensor fusion"",""explanation"":""Combining data from various sensors to create a comprehensive view of the environment.""},{""term"":""Object detection and tracking"",""explanation"":""Locating and following objects in the environment.""},{""term"":""Segmentation"",""explanation"":""Dividing the environment into distinct parts for analysis.""},{""term"":""Road understanding"",""explanation"":""Interpreting the road layout, including lanes, traffic signals, and obstacles.""}],""skill_priorities"":{""must_have"":[""3+ years experience in Computer Vision and Machine Learning"",""Experience with Python/C++""],""nice_to_have"":[""PhD degree in Computer Science or a similar discipline"",""Publications at top-tier conferences""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a multi-modal sensor fusion architectures for object detection and tracking?"",""example_answer"":""I would start by analyzing the available sensor data and identifying the most relevant features for object detection. Then, I would design a fusion architecture that combines the strengths of each modality, ensuring robustness and accuracy.""},{""question"":""How do you stay current with advancements in computer vision and machine learning?"",""example_answer"":""I regularly read research papers, attend top-tier conferences, and participate in online forums to stay updated on the latest developments and breakthroughs.""}],""red_flags"":[""Lack of experience with large-scale data processing and model training"",""Inability to explain complex technical concepts in simple terms""],""confidence_score"":85.0}"
Data Scientist - Product Analytics,LatentView Analytics,"Mountain View, CA",March,2025,"LatentView Analytics is a leading global analytics and decision sciences provider, delivering solutions that help companies drive digital transformation and use data to gain a competitive advantage. With analytics solutions that provide a 360-degree view of the digital consumer, fuel machine learning capabilities and support artificial intelligence initiatives., LatentView Analytics enables leading global brands to predict new revenue streams, anticipate product trends and popularity, improve customer retention rates, optimize investment decisions, and turn unstructured data into valuable business assets.


6+ years of experience working in a data scientist role
Produces insights into business performance, KPI trends, drivers etc.
Performs business analysis using various techniques, e.g. statistical analysis, explanatory and predictive modeling, data mining.
Determines best practices and develops actionable insights and recommendations for the current business operations.
Produce adhoc reports, conduct data discovery and quality checks needed for reports

Skills:
Fluency in data analysis, including defining KPIs, statistical and predictive modeling concepts, descriptive statistics, customer segmentation, and funnel analysis
Hands-on expertise with SQL, R/Python and statistical modeling techniques (e.g. regression, classification, time series) to answer a wide range of measurement questions.
Ability to tell stories clearly and concisely with data, and how they drive business outcomes
Demonstrates strong business acumen and curiosity
Excellent problem-solving skills and end-to-end quantitative thinking","{""role_summary"":""A data scientist who analyzes business performance, identifies trends, and develops actionable insights to drive business outcomes."",""key_terms"":[{""term"":""Predictive modeling"",""explanation"":""A statistical technique used to forecast future outcomes or behaviors.""},{""term"":""Descriptive statistics"",""explanation"":""A branch of statistics that summarizes and describes the basic features of data.""},{""term"":""Customer segmentation"",""explanation"":""The process of dividing customers into distinct groups based on shared characteristics to better understand their needs.""},{""term"":""Funnel analysis"",""explanation"":""A method used to measure the steps users take to complete a specific goal, such as making a purchase.""},{""term"":""Regression"",""explanation"":""A statistical technique used to establish relationships between variables.""},{""term"":""Classification"",""explanation"":""A machine learning technique used to categorize data into predefined categories.""},{""term"":""Time series"",""explanation"":""A sequence of data points measured at regular time intervals, used to forecast future values.""}],""skill_priorities"":{""must_have"":[""Fluency in data analysis"",""Hands-on expertise with SQL, R/Python"",""Ability to tell stories with data"",""Strong business acumen and curiosity"",""Excellent problem-solving skills and end-to-end quantitative thinking""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach a predictive modeling project to forecast customer churn?"",""example_answer"":""I would start by collecting relevant data, then use techniques like regression and decision trees to identify key drivers of churn. Next, I would develop a predictive model and validate its accuracy. Finally, I would present my findings and recommendations to the business.""},{""question"":""How do you stay current with new developments in data science and analytics?"",""example_answer"":""I regularly read industry blogs and publications, attend conferences, and participate in online forums to stay up-to-date with the latest techniques and tools.""}],""red_flags"":[""Lack of experience working with large datasets"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
ML Engineer/Data Scientist,Adapty.io,United States,March,2025,"Adapty is a revenue management platform for mobile apps that simplifies subscription implementation and paywall management. We help developers quickly monetize their apps, serving 7,000 apps and processing $1 billion in in-app subscriptions annually. Backed by top investors like 500 Startups and Surface Ventures.

At Adapty, we pride ourselves on offering the best analytics for subscription apps. In addition, we provide powerful predictive tools, including the ability to forecast the outcomes of A/B tests and predict revenue and LTV for cohorts.

We’re looking for ML Engineer/Data Scientist to join us and drive our machine learning and data science initiatives even further.

What You Will Do

Take ownership of your models, guiding them from initial research to full deployment in production, and ensuring they continue to deliver value over time.
Build and improve models to predict customer revenue and lifetime value (LTV) for mobile apps, helping our customers make better business decisions.
Providing benchmarks for customer metrics, including Install-to-Trial conversions, Install-to-Paid conversions, and LTV compared to industry standards.
Make A/B testing smarter by developing tools that identify winning strategies faster and with less data.
Create models that design highly effective paywalls tailored to each app’s category and audience, optimizing pricing, layout, and content.
Use data to uncover actionable insights, such as identifying where a small price adjustment could significantly boost revenue.

What We Expect

Strong Analytical Foundation: You have a solid grasp of math, statistics, and probability theory.
Machine Learning Expertise: You know how to build both interpretable and advanced black-box machine learning models, and you’ve put them into production before.
Revenue-Focused Experience: You’ve worked on predictive models for metrics like revenue and LTV, and you understand the challenges in these areas.
End-to-End Ownership: You’re comfortable taking a model from an idea to a live, production-ready system—and keeping it running smoothly.
Product-based Approach: You focus on results that make a difference for users, driving value with every project you take on.

What We Offer

Flexible Remote Work: Work from anywhere with a schedule that fits your life. While our core team operates in Europe, we welcome global candidates via deel.com.
Perfect Product Fit: Promote a product that aligns seamlessly with market needs, making your work impactful and fulfilling.
Direct Communication: A transparent and efficient work environment focused on achieving goals.
Fast-Track Impact: Receive clear, market-driven feedback on your work as we expand into the US and beyond.
Additional Benefits: Enjoy perks like free English lessons, sports and laptop reimbursements, and ample opportunities for professional growth.

Join Adapty and help shape the future of mobile app monetization through cutting-edge machine learning and data science solutions!

Share This Job

Job Information

Department

Development

Location

Remote

Employee Type

Full-time

Apply for a job now","{""role_summary"":""Develop and deploy machine learning models to drive revenue and lifetime value for mobile apps, providing actionable insights to improve business decisions."",""key_terms"":[{""term"":""A/B testing"",""explanation"":""A method of comparing two versions of a product to determine which one performs better.""},{""term"":""LTV (Lifetime Value)"",""explanation"":""The total value a customer is expected to bring to a business over their lifetime.""},{""term"":""Machine Learning Models"",""explanation"":""Algorithms that enable computers to learn from data and make predictions or decisions.""},{""term"":""Revenue Forecasting"",""explanation"":""The process of predicting future revenue based on historical data and trends.""}],""skill_priorities"":{""must_have"":[""Strong analytical foundation in math, statistics, and probability theory"",""Machine learning expertise with experience in building and deploying models"",""Revenue-focused experience with predictive models for metrics like revenue and LTV""],""nice_to_have"":[""Experience with A/B testing and identifying winning strategies"",""Knowledge of product-based approach and driving value with every project""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach building a machine learning model to predict customer revenue for mobile apps?"",""example_answer"":""I would start by collecting and preprocessing the data, then use techniques like gradient boosting or random forest to build the model. I would also consider using techniques like feature engineering and hyperparameter tuning to improve the model's performance.""},{""question"":""How do you ensure that your models are interpretable and explainable, especially when working with black-box models?"",""example_answer"":""I use techniques like feature importance, partial dependence plots, and SHAP values to understand how the model is making predictions. I also ensure that the model is transparent and explainable, so that stakeholders can understand the results.""}],""red_flags"":[""Lack of experience in building and deploying machine learning models in production"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Data Scientist (L5) - Cloud Games Quality of Experience,Netflix,United States,March,2025,"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

This data scientist role will focus on characterizing the quality of experience specific to our nascent cloud games offering, and operationalizing it across the business to illuminate and drive prioritization against the highest impact opportunities. You will join the team of Analytics Engineers, Data Scientists, and Data Engineers who partner with our infrastructure engineering teams to create metrics, perform analysis, and develop the tools and data products that help us make better decisions about our infrastructure and its impact on our product’s quality of experience.

What You’ll Do

Establish the fundamental set of quality of experience metrics used to evaluate our Cloud Games sessions, which is likely to include research and development of several new metrics.
Become the resident expert on all things Cloud Games Quality of Experience, partnering closely with Games Engineering and Games Studio teams to drive a culture of data-informed decision-making about our games title portfolio and the games platform infrastructure.
Develop deep expertise in how the Cloud Games infrastructure works, and understand how data, analytics, experimentation, and algorithms can play an impactful role in driving improvements to its performance.
Use a combination of experiment and observational data to understand the Netflix member perspective on their gaming experiences. Help us understand the Netflix member perspective on their experiences.
Translate valuable insights and data from this domain to initiatives in other parts of the business.

You Have

Advanced training in a quantitative field (Data Science, Statistics, Mathematics, Engineering, Physics, Economics, etc) or commensurate work experience.
Fluent in SQL. Comfortable prototyping pipelines of moderate complexity, with the ability to effectively partner with data engineering teams building more scalable solutions for important use cases
Strong Quantitative Programming skills in Python, R experience a plus
Passion for instrumenting and analyzing products to drive improvements to user experience, backed by strong product knowledge and intuition - ideally utilized in consumer/user interface settings or internally serving technical audiences such as engineers.
Demonstrated effectiveness at developing meaningful stakeholder relationships and deep domain expertise.
The demonstrated ability to communicate technical and statistical concepts clearly and concisely among audiences at many different levels.
Comfort with ambiguity, and the ability to thrive with minimal oversight and process.
Embodied the Netflix values while bringing a new perspective to continue improving our culture.

Generally, our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000.

Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here.

Netflix is a unique culture and environment. Learn more here.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.","{""role_summary"":""This data scientist role focuses on characterizing the quality of experience for Netflix's cloud games, operationalizing it across the business to drive prioritization and improvement."",""key_terms"":[{""term"":""Cloud Games Quality of Experience"",""explanation"":""A measure of how well Netflix's cloud-based games perform and meet user expectations.""},{""term"":""Analytics Engineers"",""explanation"":""A team that partners with infrastructure engineering teams to create metrics, perform analysis, and develop tools to inform business decisions.""},{""term"":""Data-informed decision-making"",""explanation"":""Using data analysis and insights to drive business decisions, particularly in the context of games title portfolio and infrastructure.""}],""skill_priorities"":{""must_have"":[""Advanced training in a quantitative field"",""Fluent in SQL"",""Strong Quantitative Programming skills in Python""],""nice_to_have"":[""R experience"",""Passion for instrumenting and analyzing products to drive user experience improvements""]},""proposed_screening_questions_with_answers"":[{""question"":""How would you establish fundamental quality of experience metrics for cloud games sessions?"",""example_answer"":""I would research and develop new metrics, considering factors like game performance, user engagement, and overall experience.""},{""question"":""Can you give an example of how you'd drive data-informed decision-making in a games engineering team?"",""example_answer"":""I'd work closely with the team to develop metrics, analyze data, and provide insights to inform decisions that improve the gaming experience.""}],""red_flags"":[""Lack of experience in cloud gaming or infrastructure"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":80.0}"
"Data Scientist, Healthcare - Remote",Experian,United States,March,2025,"Job Posting - Salary Range: $87,248 - $151,230

Company Description

Experian is a global data and technology company, powering opportunities for people and businesses around the world. We help to redefine lending practices, uncover and prevent fraud, simplify healthcare, create marketing solutions, and gain deeper insights into the automotive market, all using our unique combination of data, analytics and software. We also assist millions of people to realise their financial goals and help them save time and money.

We operate across a range of markets, from financial services to healthcare, automotive, agribusiness, insurance, and many more industry segments.

We invest in people and new advanced technologies to unlock the power of data. As a FTSE 100 Index company listed on the London Stock Exchange (EXPN), we have a team of 22,500 people across 32 countries. Our corporate headquarters are in Dublin, Ireland. Learn more at experianplc.com

Job Description

Reporting to the Director of Analytics, the Data Scientist drives development efforts on Experian Health priority data science and machine learning projects.

You Will

You are innovative and will help build data science models that addresses critical healthcare challenges for patients.
Have a strong background in statistics, analyzing large data sets, building machine learning models, implementing MLOps best practices, and designing experiments with appropriate documentation and cataloging.
Have experience as a full-stack data scientist, developing models from project ideation through production.

Qualifications

Qualifications:

Degree(s) in Machine Learning, Data Science, Statistics, Computer Science, Computer Engineering, Electrical Engineering, Physics, Applied Math or other quantitative fields
1+ years industry experience in data science and predictive modeling
Knowledge of machine learning algorithms, statistical methods, and data mining techniques, with experience applying them to real-world problems
Familiarity with MLOps practices and tools for model deployment, monitoring, and management in production environments (e.g., Sagemaker, MLflow, or similar ML platform)
Experience with model governance including model versioning and experiment tracking
Strong proficiency in Python and SQL
As a full-stack data scientist, experience creating data pipelines to source new data for model building
Proven ability to work independently on development of models with extremely large and complex data structures

Desired Expertise With

Strong understanding of healthcare concepts, terminologies, and data (e.g., claims/EHR data, ICD, CPT)
Experience with big data technologies such as Spark
Agile methods for software development

Benefits/Perks

You will be fully remote from within the US
Great compensation package and bonus plan
Core benefits including medical, dental, vision, and matching 401K
Flexible work environment, ability to work remote, hybrid or in-office
Flexible time off including volunteer time off, vacation, sick and 12-paid holidays

Additional Information

Our uniqueness is that we celebrate yours. Experian's culture and people are important differentiators. We take our people agenda very seriously and focus on what matters; DEI, work/life balance, development, authenticity, collaboration, wellness, reward & recognition, volunteering... the list goes on. Experian's people first approach is award-winning; World's Best Workplaces™ 2024 (Fortune Top 25), Great Place To Work™ in 24 countries, and Glassdoor Best Places to Work 2024 to name a few. Check out Experian Life on social or our Careers Site to understand why.

Experian is proud to be an Equal Opportunity and Affirmative Action employer. Innovation is an important part of Experian's DNA and practices, and our diverse workforce drives our success. Everyone can succeed at Experian and bring their whole self to work, irrespective of their gender, ethnicity, religion, colour, sexuality, physical ability or age. If you have a disability or special need that requires accommodation, please let us know at the earliest opportunity.","{""role_summary"":""The Data Scientist drives development efforts on Experian Health priority data science and machine learning projects, addressing critical healthcare challenges for patients."",""key_terms"":[{""term"":""MLOps"",""explanation"":""Machine Learning Operations, a set of practices to deploy, monitor, and manage machine learning models in production environments.""},{""term"":""Full-stack data scientist"",""explanation"":""A data scientist who can handle all aspects of data science projects, from ideation to production.""},{""term"":""Model governance"",""explanation"":""The process of ensuring models are properly versioned, tracked, and managed throughout their lifecycle.""}],""skill_priorities"":{""must_have"":[""Degree in a quantitative field"",""1+ years of industry experience in data science and predictive modeling"",""Knowledge of machine learning algorithms and statistical methods"",""Familiarity with MLOps practices and tools"",""Strong proficiency in Python and SQL"",""Experience creating data pipelines""],""nice_to_have"":[""Strong understanding of healthcare concepts and data"",""Experience with big data technologies like Spark"",""Agile methods for software development""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a recent project where you applied machine learning algorithms to a real-world problem?"",""example_answer"":""In my previous role, I developed a predictive model using logistic regression to identify high-risk patients. I implemented the model using Python and deployed it using MLflow.""},{""question"":""How do you ensure model governance in your projects?"",""example_answer"":""I use model versioning tools like MLflow to track changes to my models and ensure reproducibility. I also maintain detailed documentation of my experiments and results.""}],""red_flags"":[""Lack of experience with MLOps practices and tools"",""Inability to work independently on complex data science projects""],""confidence_score"":95.0}"
Data Scientist - Deep Learning Focus,Sense,United States,March,2025,"About Sense:

At Sense, our mission is to make all homes intelligent by keeping people informed about what's happening in their homes, helping to make them safer, more efficient, and more reliable.

We are committed to making a real impact on climate change by developing cutting-edge AI solutions for energy monitoring and smart home intelligence.

About the Role:

We are looking for a Data scientist with a passion for deep learning and time series analysis to join our team. In this role, you will work on developing and optimizing machine learning models that help detect and analyze energy usage in homes.

This is a great opportunity for someone early in their career to gain hands-on experience with real-world machine learning applications, work with large datasets, and contribute to both cloud and embedded AI deployments.

Responsibilities:

Assist in designing and training deep learning models for device disaggregation
Perform data preprocessing and analysis to prepare datasets for model training
Conduct experiments with different model architectures and hyperparameters to optimize performance
Help curate ground truth datasets for model evaluation
Work with the engineering team to support model deployment in both cloud-based and embedded systems
Stay updated on deep learning advancements and contribute to best practices in model development
Collaborate with senior data scientists and engineers to improve data science infrastructure

Qualifications:

Bachelor's or Master's degree in Computer Science, Machine Learning, Electrical Engineering, or a related field
1 to 3 years of professional experience in data science or machine learning
Familiarity with deep learning frameworks like TensorFlow or PyTorch
Basic understanding of neural network architectures (CNNs, RNNs, Transformers)
Proficiency in Python and relevant data science libraries (NumPy, Pandas, Scikit-learn)
Experience working with large datasets is a plus
Strong problem-solving and analytical skills
Enthusiasm for learning and growing in a collaborative, fast-paced environment


Benefits

Flexible time away policy
Paid parental leave
A wide range of difficult and interesting problems to be solved
Work with a small team of experienced entrepreneurs creating revolutionary technology
Great opportunity to gain experience at a consumer smart home startup
Competitive compensation and generous healthcare benefits
A great office in Central Square in Cambridge, MA right by the Red Line
Compensation 170k to 190k
Stock Options and 401k with up to 10k match


Why Sense

Join Sense and be part of our mission to reduce global carbon emissions by making homes smart and more efficient. Our energy data and tools demystify home energy use, empower people to take command of their usage, and enable utilities to build a cleaner and more resilient grid.

Sense supports a diverse and inclusive workplace where we all learn from each other. We welcome candidates with backgrounds that are traditionally underrepresented in tech, and we strive to foster an engaging, respectful and supportive community where everyone feels empowered to do their best work. Sense is committed to be an equal opportunity employer.

Be a part of building something that will make a difference in the world
Have a big impact at a VC-backed consumer startup that's doing big things:
Best Startups in Cambridge - Tech Tribune
""One of the world's top 100 AI companies"" - VentureBeat
Clean Tech Company of the Year - New England Venture Capital Association
50 on Fire - BostInno
Top 100 - Red Herring
Best Consumer AI Technology - AI Dev World
Global Cleantech 100","{""role_summary"":""Work as a Data Scientist at Sense, a startup making homes intelligent and energy-efficient, by developing and deploying machine learning models for energy usage detection and analysis."",""key_terms"":[{""term"":""Deep learning"",""explanation"":""A subset of machine learning that uses neural networks to analyze data.""},{""term"":""Time series analysis"",""explanation"":""A method of analyzing data points in a series of time-ordered data to identify patterns and trends.""},{""term"":""TensorFlow or PyTorch"",""explanation"":""Popular deep learning frameworks used for building and deploying machine learning models.""},{""term"":""Neural network architectures (CNNs, RNNs, Transformers)"",""explanation"":""Different types of neural network designs used for various machine learning tasks.""}],""skill_priorities"":{""must_have"":[""Bachelor's or Master's degree in Computer Science, Machine Learning, Electrical Engineering, or a related field"",""Familiarity with deep learning frameworks like TensorFlow or PyTorch"",""Basic understanding of neural network architectures (CNNs, RNNs, Transformers)"",""Proficiency in Python and relevant data science libraries (NumPy, Pandas, Scikit-learn)""],""nice_to_have"":[""1 to 3 years of professional experience in data science or machine learning"",""Experience working with large datasets""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach designing and training a deep learning model for device disaggregation?"",""example_answer"":""I would start by analyzing the dataset and identifying the most relevant features for the task. Then, I would experiment with different model architectures and hyperparameters to optimize performance.""},{""question"":""How do you stay updated on the latest advancements and contribute to best practices in model development?"",""example_answer"":""I regularly read research papers and articles on deep learning and attend conferences to stay updated. I contribute to open-source projects and share my knowledge with the team to improve our model development process.""}],""red_flags"":[""Lack of experience with deep learning frameworks like TensorFlow or PyTorch"",""Inability to explain neural network architectures (CNNs, RNNs, Transformers)""],""confidence_score"":95.0}"
Data Scientist - Energy Markets,GridStor,United States,March,2025,"Company Overview:

GridStor is a rapidly growing, grid-scale energy storage developer, owner and operator backed by Goldman Sachs Asset Management (“GSAM”) and led by experienced clean energy industry professionals. We acquire and develop battery storage projects in markets across North America. GridStor’s mission is to accelerate the transition to a carbon-free, resilient grid by rapidly deploying stand-alone energy storage at scale.

GridStor is based in Portland, Oregon, and offers competitive compensation and a wide selection of benefits including unlimited paid time off. Read more about life at GridStor at: https://gridstor.com/careers/

Role Summary:

GridStor is looking for an experienced Data Scientist to help advance our growing company. This role will work closely with the Analytics, Solutions, and Market Operations team members to create advanced data pipelines, design optimization tools for battery storage assets in support of trading activities, and analyze market behavior for competitor and market intelligence. The data scientist will be given significant responsibility across the modeled markets and will be exposed to dynamic market environments within a growing, entrepreneurial business. This position reports to the Vice President of Analytics.

Key Responsibilities:

Data Pipelines and ETL: Work closely with Solutions to create data pipelines that enable the development of machine learning and artificial intelligence models on platforms such as AWS using serverless functions, PostgreSQL, and various TCP application protocols, with a focus on data quality, structure, and processing.
Model Development: Design and implement sophisticated time series models to forecast and analyze asset performance, delivering actionable insights to the Commercial organization. Leverage advanced statistical techniques, machine learning, and artificial intelligence to generate robust backcasts, forecasts, and performance analyses.
Market Optimization: Maintain and develop optimization tools for day-ahead and real-time energy markets for BESS assets in coordination with the Trading Desk. Focus both on optimal bidding strategies and forecasting (short-term modeling of multiple price series).
Competitor and Market Intelligence: Develop approaches to measuring and benchmarking competitor performance and market participation across wholesale energy markets.
Reporting: Communicate key commercial takeaways to organization leadership to improve both market operations and provide feedback to stakeholders such as Development, Transmission/Interconnection, and M&A teams.


Qualifications & Competencies:

Education: Bachelor’s degree in computer science, data science, engineering, or other quantitative field, with a Masters or PhD required.
Experience: A minimum of 3+ years of prior work experience in the energy industry (developer, IPP, consulting, ISOs, or other).
Clear expertise in deploying statistical and optimization tools to wholesale power markets.
Experience and knowledge of ERCOT and CAISO market policy and protocols.
Location & Availability: Must be based in Portland or LA with periodic travel to Portland as needed. Standard 40-hour workweek, additional hours may be required as needed for projects.
Organizational Skills: Exceptional organizational abilities with keen attention to detail. Capable of managing multiple tasks simultaneously in a fast-paced environment and seeing delegated projects through to completion.
Adaptability: Ability to be agile and flexible, readily taking on tasks outside the typical scope of the role as needed.
Confidentiality: Proven ability to handle highly confidential information with utmost discretion.
Integrity & Judgment: Strong track record of excellent judgment and integrity in previous roles.
Technical Proficiency: Demonstrated proficiency in the Microsoft Office suite and TEAMS.
Visualization experience (Tableau, Qlikview, Shiny, seaborn, or other).
Experience with machine learning/artificial intelligence models on time series, linear/mixed integer programming, and stochastic modeling.
Knowledge of data pipeline development and engineering on relevant cloud platforms (AWS, GCP, Azure, etc.) and big-data technologies (ex: Hadoop).
Expertise in Python-based development environments, APIs, and packages.
Communication Skills: Excellent verbal and written communication skills.
Problem-Solving: Adaptable, with the ability to prioritize tasks effectively and approach challenges with a creative, proactive mindset.
Team Orientation: Highly motivated to support and collaborate with team members, contributing to collective success.


Compensation and Benefits:

GridStor offers an attractive Total Rewards package, including:
Competitive base salaries commensurate with experience with an annual cash bonus (based on Company and individual performance)
Generous paid leave
Employee participation in Long Term Incentive Plan
Comprehensive benefits package including medical, dental, vision, life, and disability insurance, including coverage for domestic partners and eligible domestic partner children
HSA/FSA for participating employees
401(k) plan with company match and immediate vesting
Continuing education and professional development
Cellphone reimbursement, hybrid work environment, healthy snacks, volunteer opportunities, company outings, and more.
Company Operating Principles:

GridStor’s Operating Principles represent who we are, how we work, and what we believe.

We Collaborate. We believe trust is given, not earned. We honor each other’s zone of genius and seek to challenge ideas, not each other. We listen to each other’s points of view and work hard to find the better solution. We are one team.

We Are Humble. We like hard work, but don’t make work hard. We know we have a lot to learn and never grandstand or take up all the space in the room. We are kind. We are welcoming. We are inspired by our mission to decarbonize the grid.

We Create the Future. We are curious. We go deep, search for the best idea, and then move fast. We always focus on the few things that matter most. We know there will be setbacks, so we show up every day ready to learn and be better, together.

We Show Up for Each Other. We keep each other fully informed. We seek to understand. We coach, we don’t blame. We share our points of view and seek to make each other better every day. We believe everyone creates culture in every moment, every day.

We Do Hard Things. We view challenges as opportunities. We are resilient. We are all owners, and we act like it. We understand change requires taking risks and we push ourselves and our partners. We do what is right as opposed to what might be best for any one of us.

Apply online at www.gridstor.com/careers","{""role_summary"":""GridStor is seeking an experienced Data Scientist to advance their growing company, working closely with the Analytics, Solutions, and Market Operations teams to create advanced data pipelines, design optimization tools for battery storage assets, and analyze market behavior."",""key_terms"":[{""term"":""Machine learning"",""explanation"":""A type of artificial intelligence that enables computers to learn from data and make predictions or decisions without being explicitly programmed.""},{""term"":""Artificial intelligence"",""explanation"":""The development of computer systems that can perform tasks that typically require human intelligence, such as visual perception, speech recognition, and decision-making.""},{""term"":""Time series models"",""explanation"":""Statistical models that analyze and forecast data with a temporal component, often used in finance and energy markets.""},{""term"":""ERCOT and CAISO market policy and protocols"",""explanation"":""Regulatory frameworks and guidelines governing the operation of wholesale energy markets in Texas (ERCOT) and California (CAISO).""}],""skill_priorities"":{""must_have"":[""Bachelor's degree in computer science, data science, engineering, or other quantitative field"",""Minimum 3+ years of prior work experience in the energy industry"",""Clear expertise in deploying statistical and optimization tools to wholesale power markets"",""Experience and knowledge of ERCOT and CAISO market policy and protocols""],""nice_to_have"":[""Master's or PhD degree"",""Experience with machine learning/artificial intelligence models on time series, linear/mixed integer programming, and stochastic modeling"",""Knowledge of data pipeline development and engineering on relevant cloud platforms (AWS, GCP, Azure, etc.) and big-data technologies (e.g., Hadoop)""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design and implement a time series model to forecast and analyze asset performance in a wholesale energy market?"",""example_answer"":""I would use a combination of statistical techniques, such as ARIMA and Prophet, and machine learning algorithms, such as LSTM and Prophet, to develop a robust model that can accurately forecast asset performance. I would also consider incorporating external factors, such as weather and market trends, to improve its accuracy.""},{""question"":""How would you approach developing optimization tools for day-ahead and real-time energy markets for BESS assets in coordination with the Trading Desk?"",""example_answer"":""I would use a combination of linear and mixed-integer programming techniques to develop an optimization model that can efficiently allocate BESS assets in day-ahead and real-time markets. I would also consider using machine learning algorithms, such as reinforcement learning, to improve the model's performance and adaptability.""}],""red_flags"":[""Lack of experience in the energy industry or with wholesale power markets"",""Inability to work effectively in a fast-paced environment"",""Poor communication and collaboration skills""],""confidence_score"":95.0}"
Data Scientist - All Levels,Interclypse,"Reston, VA",March,2025,"Description

Interclypse is seeking Data Scientists.

The Interclypse difference is our emphasis on employee growth and development through continuous learning, mentorship, and empowerment. Interclypse employees grow in a positive cultivating work environment with endless career opportunities. Let Interclypse empower you by putting you in the driver's seat of your career.

Currently, Interclypse is seeking motivated, career and customer-oriented Data Scientists to join our team to provide exemplary support to our customers and to begin an exciting and rewarding career within Interclypse. As a Data Scientist, you will enjoy leading edge work developing innovative solutions to address data analytics challenges, to collect large volumes of data from varying sources, perform data cleansing, transformation, interpretation, inferencing, create solutions to overcome mission challenges, and communicate with interested stakeholders.

Requirements

Education

Degree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science is required.

Primary Responsibilities

Engage in developing innovative solutions to address data analytics challenges, to collect large volumes of data from varying sources, perform data cleansing, transformation, interpretation, inferencing, create solutions to overcome mission challenges, and communicate with interested stakeholders.
To succeed in this position; you need to be curious, creative, and tech-savvy.
You need to stay up to date with data processing software and algorithms, have an in-depth understanding of statistics and mathematics and be proficient in writing data processing algorithms.
You must be persistent and have excellent analytical and problem-solving skills.
Devise strategies for extracting semantic value from large datasets.
Develop conclusions from data using mathematics, statistics, computer science, and application specific knowledge and concisely communicate these conclusions.
Provide informed recommendations regarding competing technical solutions through awareness of the constantly shifting collections, processing, storage and analytic capabilities and limitations.

Required Skills/Experience

Experience with SQL databases and data models (e.g., PostgreSQL , Amazon Aurora)
Experience with programming in R, Python, Java
Experience with NoSQL databases ( e.g., MongoDB, Accumulo)
Experience designing data models and approaches
Experience working in a cloud environment ( e.g., AWS, Azure)
Experience with Linux
Excellent interpersonal skills and ability to get along with data scientists, engineers, and customers at all levels
Ability to work in a dynamic team-oriented environment, demonstrate teamwork and initiative, and function productively in a dynamic work environment

Desired Skills/Experience

Experience with programming in TensorFlow, PyTorch
Experience with Hadoop, MapReduce
Experience with Tableau
Experience with Cognos
Experience with designing, implementing, and using REST APIs
Experience with RDF/OWL, SPARQL, and Semantic Web technologies
Experience with Statistical and ML analytics and modeling (e.g., R, Spark, etc.) or other deep learning frameworks a plus
Experience with Data catalogs and data management
Ability to help visualize the data for analysis and to display results

Why You Might Like This Job

You’re tired of working for a massive organization.
You want to work for an established company that values your stable career.
You want to work with a team who loves their job and making cool stuff.
You want to be part of a team focused on making a positive impact.
You want to grow your skills in management or work toward becoming an expert.
You want to have the option for career mentorship, both in technology and in business.
You value a company with a strong culture of growth and support.

Benefits

Employee Impact Program. Every employee has the opportunity to define and get rewarded for their contributions they can make toward the long-term health of the company, customer, and employee. This program in combination with our comprehensive time off and leave programs allow you to design a career and compensation program that enables near infinite flexibility while ensuring both company, customer, and individual health and prosperity.
Comprehensive time off and leave programs:
31 Days (248 hours) of Paid Personal Time Off (PTO) for any vacation, holidays, illnesses, and birthdays
Parental Leave: 40 Hours
Bereavement Leave: 24 hours.
Military Reserve Leave (up to 80 hours, see employee handbook for details).
Jury Duty Leave 16 hours.
Retirement: Unlimited 401K match up to 8% of your salary up to the federal maximum
Health Insurance (Medical, Dental, Vision): Premium is 100% company paid (contact us for specific plan details).
Health Savings Account (HSA): Interclypse contributes $750 for individuals and $1500 for families
Vision Insurance
Dental Insurance includes orthodontics coverage
Life Insurance
Accidental Death and Dismemberment Insurance
Disability: Short-term and long-term disability coverage
Educational support: reimbursement up to the federal max of $5,250
Company apparel: $200 for company apparel each year
Social events: Holiday Party, Spring Picnic, Fall Picnic, happy hours and moreInterclypse isn’t your typical company. We strive to have a positive & transformational impact on our community, our industry, and individuals. We keep this focus through our motto: ""Doing What is Right"". Apply today to see how you can join our winning team and start down the career path that’s right for you!
EOE AA M/F/Vet/Disability

Interclypse is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.

The base salary range provided is not adjusted for geographic differences associated with where the work is being performed. Actual salaries will vary depending on factors including but not limited to location, candidate’s experience and education/training, internal peer equity, and market and business consideration.","{""role_summary"":""As a Data Scientist at Interclypse, you will lead edge work developing innovative solutions to data analytics challenges, collect large volumes of data, perform data cleansing, and communicate with stakeholders."",""key_terms"":[{""term"":""Data Analytics"",""explanation"":""The process of examining data sets to draw conclusions and make informed decisions.""},{""term"":""Data Cleansing"",""explanation"":""The process of identifying and correcting errors, inconsistencies, and inaccuracies in data.""},{""term"":""Data Models"",""explanation"":""A conceptual representation of data structures and relationships to organize and store data.""},{""term"":""Cloud Environment"",""explanation"":""A computing environment that provides on-demand access to a shared pool of computing resources over the internet.""},{""term"":""NoSQL Databases"",""explanation"":""A type of database that does not use the traditional table-based relational model used in relational databases.""}],""skill_priorities"":{""must_have"":[""SQL databases and data models"",""Programming in R, Python, Java"",""Experience with NoSQL databases"",""Experience designing data models and approaches"",""Experience working in a cloud environment"",""Experience with Linux""],""nice_to_have"":[""Experience with programming in TensorFlow, PyTorch"",""Experience with Hadoop, MapReduce"",""Experience with Tableau"",""Experience with Cognos"",""Experience with designing, implementing, and using REST APIs"",""Experience with RDF/OWL, SPARQL, and Semantic Web technologies"",""Experience with Statistical and ML analytics and modeling"",""Experience with Data catalogs and data management""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you stay up to date with data processing software and algorithms?"",""example_answer"":""I regularly read industry blogs and attend conferences to stay current with the latest developments in data processing software and algorithms.""},{""question"":""Can you give an example of a time when you had to devise a strategy for extracting value from a large dataset?"",""example_answer"":""In my previous role, I developed a strategy for extracting insights from a large dataset using machine learning algorithms and data visualization techniques.""}],""red_flags"":[""Lack of experience with SQL databases and data models"",""Inability to work in a dynamic team-oriented environment""],""confidence_score"":90.0}"
Staff Data Scientist,SoFi,"San Francisco, CA",March,2025,"Employee Applicant Privacy Notice

Who we are:

Shape a brighter financial future with us.

Together with our members, we’re changing the way people think about and interact with personal finance.

We’re a next-generation financial services company and national bank using innovative, mobile-first technology to help our millions of members reach their goals. The industry is going through an unprecedented transformation, and we’re at the forefront. We’re proud to come to work every day knowing that what we do has a direct impact on people’s lives, with our core values guiding us every step of the way. Join us to invest in yourself, your career, and the financial world.

The role:

The Risk Data Science team is looking for a Staff Data Scientist to develop advanced machine learning models, guide measurement, strategy, and data-driven decision making to support various credit risk areas at SoFi. The Staff Data Scientist will work closely with Credit Risk, Product, Engineering teams to design solutions for credit underwriting. These tasks involve researching and applying state of the art machine learning modeling methodologies to solve complex business problems. This role is very rewarding as your work will have a direct and immediate impact on the business’ profitability.

By joining SoFi, you'll become part of a forward-thinking company that is transforming financial services for the better. We offer the excitement of a rapidly growing startup with the stability of an industry leading leadership team.

What you’ll o:

The Staff Data Scientist will help SoFi develop better data driven model solutions by:


Proactively identify opportunities and collaborate cross functionally to develop, implement, and continuously improve machine learning models and strategies that support credit underwriting
Proactively identify opportunities to apply AI and advanced machine learning approaches to solve complex business problems
Evaluate alternative data sources and external vendor solutions by defining and driving proof of concept projects to demonstrate the solutions’ business values
Explore and leverage in-house, external, and other open-source machine learning software/algorithms
Contribute in enhancing SoFi’s risk model development code base by developing customized Python scripts or packages
Collaborate with Model Risk Management team and Fair Lending team to demonstrate models are developed with high level rigor that satisfy Model Risk Management requirements, Fair Lending requirements, and other regulatory requirements
Spearhead model deployment by collaborating with cross functional teams including Credit, Product, Engineering, and Business Unit
Present model performance and insights to Credit, Risk, and Business Unit leaders


What you’ll need:


6+ years of work experience in the related areas especially unsecured loan underwriting with a Master’s or PhD degree in Statistics, Mathematics, Economics, Engineering, Computer Science, or a quantitative field.
Excellent knowledge and experience of machine learning and statistical modeling methods for supervised and unsupervised learning. These methods include (but not limited to) regression, clustering, outlier detection, novelty detection, decision trees, nearest neighbors, support vector machines, ensemble methods and boosting, neural networks, deep learning and its various applications. Continuously follow the advancement of machine learning and artificial intelligence to update your knowledge and skills in order to solve business problems with the most efficient methodologies
Strong knowledge of AI and AI safety
Strong programming skills in Python
Strong knowledge of databases and related languages/tools such as SQL, NoSQL, Hive, etc.
Strong presentation skills: able to use data to tell a clear and compelling story; comfortable with public speaking across various forums, including regulatory examinations, and able to effectively and logically communicate when information is being challenged in an open forum.
Ability and confidence to exercise influence over a wide range of individuals at different levels of technical and business leadership.
Someone who is highly motivated and drives change, is eager to learn and able to work collaboratively in a complex and fluid environment


Nice to have:


Experience in communicating with OCC, Fed, and CFPB


Compensation And Benefits

The base pay range for this role is listed below. Final base pay offer will be determined based on individual factors such as the candidate’s experience, skills, and location.

To view all of our comprehensive and competitive benefits, visit our Benefits at SoFi page!

SoFi provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion (including religious dress and grooming practices), sex (including pregnancy, childbirth and related medical conditions, breastfeeding, and conditions related to breastfeeding), gender, gender identity, gender expression, national origin, ancestry, age (40 or over), physical or medical disability, medical condition, marital status, registered domestic partner status, sexual orientation, genetic information, military and/or veteran status, or any other basis prohibited by applicable state or federal law.

The Company hires the best qualified candidate for the job, without regard to protected characteristics.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

New York applicants: Notice of Employee Rights

SoFi is committed to embracing diversity. As part of this commitment, SoFi offers reasonable accommodations to candidates with physical or mental disabilities. If you need accommodations to participate in the job application or interview process, please let your recruiter know or email accommodations@sofi.com.

Due to insurance coverage issues, we are unable to accommodate remote work from Hawaii or Alaska at this time.

Internal Employees

If you are a current employee, do not apply here - please navigate to our Internal Job Board in Greenhouse to apply to our open roles.","{""role_summary"":""Develop advanced machine learning models to support credit risk areas, guide measurement, strategy, and data-driven decision making, and collaborate with cross-functional teams to design solutions for credit underwriting."",""key_terms"":[{""term"":""Machine learning modeling methodologies"",""explanation"":""Approaches to develop and apply machine learning models to solve complex business problems.""},{""term"":""AI and advanced machine learning approaches"",""explanation"":""Using artificial intelligence and machine learning techniques to solve complex business problems.""},{""term"":""Model Risk Management requirements"",""explanation"":""Regulatory requirements to ensure that models are reliable and accurate.""},{""term"":""Fair Lending requirements"",""explanation"":""Regulatory requirements to ensure that lending practices are fair and unbiased.""}],""skill_priorities"":{""must_have"":[""6+ years of work experience in related areas"",""Master's or PhD degree in Statistics, Mathematics, Economics, Engineering, Computer Science, or a quantitative field"",""Excellent knowledge and experience of machine learning and statistical modeling methods"",""Strong programming skills in Python"",""Strong knowledge of databases and related languages/tools such as SQL, NoSQL, Hive, etc."",""Strong presentation skills""],""nice_to_have"":[""Experience in communicating with OCC, Fed, and CFPB""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would develop and implement machine learning models to support credit underwriting?"",""example_answer"":""I would start by identifying the key business problems and then research and apply state-of-the-art machine learning modeling methodologies to develop and implement models that meet the business requirements.""},{""question"":""How do you stay updated with the latest advancements in machine learning and artificial intelligence?"",""example_answer"":""I regularly read industry publications and research papers, attend conferences, and participate in online forums to stay updated with the latest advancements in machine learning and artificial intelligence.""}],""red_flags"":[""Lack of experience in unsecured loan underwriting"",""Inability to communicate complex technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Data Scientist - Python (US Remote),KnowBe4,United States,March,2025,"About KnowBe4

KnowBe4, the provider of the world's largest security awareness training and simulated phishing platform, is used by tens of thousands of organizations around the globe. KnowBe4 enables organizations to manage the ongoing problem of social engineering by helping them train employees to make smarter security decisions, every day.

Fortune has ranked us as a best place to work for women, for millennials, and in technology for four years in a row! We have been certified as a ""Great Place To Work"" in 8 countries, plus we've earned numerous other prestigious awards, including Glassdoor's Best Places To Work.

Our team values radical transparency, extreme ownership, and continuous professional development in a welcoming workplace that encourages all employees to be themselves. Whether working remotely or in-person, we strive to make every day fun and engaging; from team lunches to trivia competitions to local outings, there is always something exciting happening at KnowBe4.

Remote positions open to the US only.

Data scientists work closely with business stakeholders to understand their goals and identify data-driven strategies to achieve those goals. They design data modeling processes, create algorithms and predictive models to extract the insight the business needs and help analyze the data to increase the productivity and efficiency of the business.

Responsibilities

Expertise working experience with programming languages like Python, R, and SQL
Solid understanding of statistics, probability, and machine learning
Research, design, and implement Machine Learning algorithms to solve complex problems
Communicate complex concepts and statistical models to non-technical audiences through data visualizations

Required Skills

BS or equivalent plus 3 years experience
MS/Ph.D. or equivalent; no experience required
Expert-level SQL proficiency with experience in Snowflake, dbt, and Looker
Advanced Python programming with demonstrated expertise in data science libraries (numpy, pandas, matplotlib, scikit-learn)
Strong foundation in statistics and mathematical principles underlying data science algorithms
Extensive experience in developing and deploying machine learning models, including
Feature engineering and selection, Model training, validation, and testing, Sampling and data reduction techniques
Experience in establishing and implementing DataOps and MLOps best practices
Demonstrated ability to quantify and communicate business impact through data-driven insights
Track record of identifying and leading high-impact data science initiatives
Experience in building and maintaining stakeholder relationships across all organizational levels
Excellent communication skills, particularly in explaining technical concepts to non-technical audiences

The base pay for this position ranges from $100,000 - $120,000, which will vary depending on how well an applicant's skills and experience align with the job description listed above.

We will accept applications until 5/25/2025.

Our Fantastic Benefits

We offer company-wide bonuses based on monthly sales targets, employee referral bonuses, adoption assistance, tuition reimbursement, certification reimbursement, certification completion bonuses, and a relaxed dress code - all in a modern, high-tech, and fun work environment. For more details about our benefits in each office location, please visit www.knowbe4.com/careers/benefits.

Note: An applicant assessment and background check may be part of your hiring procedure.

Individuals seeking employment at KnowBe4 are considered without prejudice to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, sexual orientation or any other characteristic protected under applicable federal, state, or local law. If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please visit www.knowbe4.com/careers/request-accommodation.

No recruitment agencies, please.","{""role_summary"":""Work with business stakeholders to develop data-driven strategies, design data modeling processes, and create algorithms and predictive models to extract insights and increase productivity."",""key_terms"":[{""term"":""Machine Learning algorithms"",""explanation"":""A type of artificial intelligence that enables computers to learn from experience and improve their performance on a task without being explicitly programmed.""},{""term"":""DataOps and MLOps"",""explanation"":""Practices that combine data management and machine learning operations to improve collaboration, efficiency, and quality.""},{""term"":""Feature engineering and selection"",""explanation"":""The process of selecting and transforming raw data into features that are suitable for modeling.""}],""skill_priorities"":{""must_have"":[""Python programming"",""SQL proficiency"",""Statistics and mathematical principles"",""Machine learning algorithms"",""Data visualization"",""Communication skills""],""nice_to_have"":[""R programming"",""MS/Ph.D. or equivalent""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach developing a machine learning model to solve a complex business problem?"",""example_answer"":""I would start by understanding the business goals and identifying the key performance indicators. Then, I would design a data modeling process, create algorithms, and implement predictive models to extract insights. Finally, I would communicate the results to stakeholders through data visualization.""},{""question"":""How do you stay current with new developments in machine learning and data science?"",""example_answer"":""I regularly read industry blogs and research papers, attend conferences, and participate in online forums to stay updated on the latest trends and advancements.""}],""red_flags"":[""Lack of experience in developing and deploying machine learning models"",""Inability to communicate complex technical concepts to non-technical audiences""],""confidence_score"":90.0}"
Data Scientist - Bellevue,RESULTICKS,"Bellevue, WA",March,2025,"JOB DESCRIPTION - Data Scientist
Title: Data Scientist
Job Function: Product
Role Type: Full time
Location: Bellevue, WA
Reporting to: Head Data Scientist
Stakeholders: Project Managers/Head of Product
About Resulticks
Resulticks is a fully integrated, real-time marketing automation platform designed to help brands worldwide reach, acquire, and retain satis&#64257;ed customers. Built from the ground up by experts in marketing, technology, and business management, Resulticks enables brands to make a transformational leap to conversion-driven, growth-focused personalized engagement. With an advanced CDP at its core. Resulticks offers AI-powered omnichannel orchestration, complete analytics, next-best engagement, attribution at the segment-of-one level, and the world’s first marketing block chain.
Resulticks has been named to the Gartner’s Magic Quadrant 2022 for Multichannel Marketing Hubs for six years in a row and has been awarded with the Microsoft “Elevating Customer Experience with AI” award.
Headquartered in Singapore and New York City, Resulticks is one of the top global martech solutions servicing both B2B/B2B2C and B2C segments. Resulticks’ global presence includes the United States, India, Singapore, Indonesia, Malaysia, Vietnam, Thailand, and the Philippines.
Watch video on RESULTICKS - https://www.youtube.com/watch?v=G_OwGy6unP8
Candidate Profile
Resulticks seeks an optimistic, experienced data scientist who can analyze data and deliver insights on a regular basis to join our team.
The ideal candidate will have mathematical and statistical experience while also having a creative mind. Problem-solving is an integral skill for this position for interpreting various data sets and making clear recommendations based on that.
You must also have the ability to work in a team with members from multiple disciplines to solve any issues that may arise or improve on any processes where there is scope. The ideal candidate must be confident to present their findings and recommendations in front of senior management who will be involved in big business decisions.
Key Responsibilities
Work with large, complex data sets and solve problems by applying advanced analytical methods.
Conduct end-to-end analysis which includes data gathering, processing, visualization, etc.
Develop comprehensive understanding of data structures and metrics, advocating for change where needed.
Build and prototype analysis pipelines iteratively to provide insights at scale.
Work closely with engineers to identify opportunities for improved design and suggest improvements to products.
Make business recommendations by presenting your findings to multiple levels of stakeholders.
Research and develop forecasting, and optimization methods to improve the quality of our user facing products.
Interact cross-functionally with a wide variety of people and teams.
Pre-Requisites
5 years of relevant work experience in data science
Proficiency with data mining, mathematics, and statistical analysis
Experience with Tableau, SQL, Excel, PowerPoint, and programming languages
Ability to work effectively in a dynamic, research-oriented group that has several concurrent projects.
Desirable Skills
Experience with statistical software and database languages.
Skills in selecting the right statistical tools given a data analysis problem
Two or more years of project management experience
Professional certification.
Experience and Academic Qualifications
At minimum, MSc statistician degree in a quantitative discipline
Advanced marketing degree, or MBA is a plus
Must have authorization to work in the United States
Resulticks is an equal opportunity employer that is committed to diversity and inclusion in the workplace. We prohibit discrimination and harassment of any kind based on race, color, gender, religion, sexual orientation, national origin, disability, genetic information, pregnancy, or any other protected characteristic as outlined by federal, state, or local laws.
Powered by JazzHR
ZT8Fn6QCY5","{""role_summary"":""A data scientist responsible for analyzing data, delivering insights, and making recommendations to senior management, with a focus on improving product design and quality."",""key_terms"":[{""term"":""CDP"",""explanation"":""Customer Data Platform, a core component of Resulticks' marketing automation platform.""},{""term"":""Omnichannel orchestration"",""explanation"":""The ability to manage and coordinate multiple marketing channels to provide a unified customer experience.""},{""term"":""Segment-of-one level attribution"",""explanation"":""The ability to attribute marketing efforts to individual customers, enabling personalized engagement.""},{""term"":""Marketing blockchain"",""explanation"":""A decentralized, secure, and transparent way to manage marketing data and interactions.""}],""skill_priorities"":{""must_have"":[""Data mining"",""Mathematics"",""Statistical analysis"",""Tableau"",""SQL"",""Excel"",""PowerPoint"",""Programming languages""],""nice_to_have"":[""Statistical software"",""Database languages"",""Project management experience"",""Professional certification""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing a complex data set to identify insights and opportunities for improvement?"",""example_answer"":""I would start by understanding the business problem and the stakeholders involved. Next, I would gather and process the data, applying advanced analytical methods to identify patterns and trends. Finally, I would present my findings and recommendations to senior management.""},{""question"":""How do you stay current with new tools and methodologies in data science?"",""example_answer"":""I regularly read industry publications and attend conferences to stay up-to-date on the latest developments. I also participate in online forums and communities to learn from others and share my own experiences.""}],""red_flags"":[""Lack of experience working with large, complex data sets"",""Inability to effectively communicate technical insights to non-technical stakeholders""],""confidence_score"":90.0}"
Data Scientist I (Clinical),"Pyramid Consulting, Inc","Waltham, MA",March,2025,"Immediate need for a talented Data Scientist I (Clinical). This is a 12+months contract opportunity with long-term potential and is located in Waltham, MA (Onsite). Please review the job description below and contact me ASAP if you are interested.

Job ID:25-63119
Pay Range: $50 - $55/hour. Employee benefits include, but are not limited to, health insurance (medical, dental, vision), 401(k) plan, and paid sick leave (depending on work location).
Key Responsibilities:

Work hands-on with R&B Scientists & technicians in specific sites to upgrade current data operations and practices to build impactful ways of working.
Work hands-on with R&B users to build automated data workflows where not available (new technologies) and trouble shoot workflows that are flawed or inefficient.
In association with data continuum and digital team ensure proper functioning of data collection process, integration, software and Internet applications.
Design, develop, and modify data infrastructure and templates to help scientist accelerate the processes of data analysis and reporting.
Organize appropriate data collection and raw data processing methods at various users/experimental read outs across R&B teams leading to harmonized data management and utilization.
Resolve data ingestion issues for benchling including legacy and current data. Deploy simplification and or data automation tools
Towards Data management & Continuum
Create and implement digital tracking, inventory management, and automated QC dashboard within Benchling.
Support R&B scientists to organize and ingest unstructured data.
Collaborate with Data Science to maintain data management plans for all critical data related to test articles at R&B – Dashboards, meta data etc.
Ensure scientists at R&B have visibility and access to dashboards and meta data
Assess system performance and make recommendations and updates for hardware, software, and data storage improvements.

Key Requirements and Technology Experience:

Key Skills: Benchling, NGS, Data Visualization, computational biology, bioinformatic .
Hands on basic IT environment and script programming for automated tools in data acquisition, integration, cleaning, and data management.
Experience of programing with C#, C++ or Python, SQL.
Thorough understanding of management and data administration duties such as collection, analysis, and distribution.
In-depth understanding of modern database and information technologies and ability to organize large volumes of data.
Ability to develop tools to interface with electronic lab notebook Benchling.
Ability to develop, evaluate, and implement workflows for technology, optimize and standardized existing techniques and workflows with respect to experimental HT mRNA generation process workflow including DNA & IVT-RNA production, and in vitro/in vivo screening is desired.
Working knowledge of nucleic acids DNA/RNA analytical performance assessment tools: PCR, Cloning/plasmid generation and design, Quality control on DNA/RNA (capillary electrophoresis, UV quantification, Sanger sequencing, NGS…) is desired.
Past experience with Data mining, data base, functional analysis, machine learning algorithm, dashboarding and data visualization is desirable.
Function in highly collaborative, cross functional team (EU/US) emphasize with networking.
Open to work and to share information across different groups, as well as identify key needs.

Our client is a leading Pharmaceutical Industry, and we are currently interviewing to fill this and other similar contract positions. If you are interested in this position, please apply online for immediate consideration.

Pyramid Consulting, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, colour, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

By applying to our jobs you agree to receive calls, AI-generated calls, text messages, or emails from Pyramid Consulting, Inc. and its affiliates, and contracted partners. Frequency varies for text messages. Message and data rates may apply. Carriers are not liable for delayed or undelivered messages. You can reply STOP to cancel and HELP for help. You can access our privacy policy here.","{""role_summary"":""Collaborate with R&B scientists and technicians to upgrade data operations, build automated workflows, and ensure proper data collection and management."",""key_terms"":[{""term"":""R&B"",""explanation"":""Research and Development""},{""term"":""Benchling"",""explanation"":""An electronic lab notebook for managing and tracking experimental data""},{""term"":""NGS"",""explanation"":""Next-Generation Sequencing, a high-throughput DNA sequencing technology""},{""term"":""Data Continuum"",""explanation"":""A framework for managing and integrating data across different stages of the research and development process""}],""skill_priorities"":{""must_have"":[""Benchling"",""NGS"",""Data Visualization"",""Computational biology"",""Bioinformatic"",""Script programming (C#, C++, Python, SQL)"",""Data management and administration""],""nice_to_have"":[""Data mining"",""Database"",""Functional analysis"",""Machine learning algorithm"",""Dashboarding"",""Nucleic acids DNA/RNA analytical performance assessment tools"",""Experience with experimental HT mRNA generation process workflow""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would troubleshoot a flawed data workflow?"",""example_answer"":""I would first identify the specific issue, then use tools like Benchling to track the data and identify the root cause. Next, I would work with the R&B team to develop a plan to resolve the issue and implement it.""},{""question"":""How do you ensure data quality and integrity in your workflows?"",""example_answer"":""I use a combination of automated tools and manual checks to ensure data quality. I also work closely with the data continuum team to ensure that data is properly collected, integrated, and stored.""}],""red_flags"":[""Lack of experience with Benchling or similar electronic lab notebooks"",""Inability to program in C#, C++, Python, or SQL"",""Limited understanding of data management and administration""],""confidence_score"":90.0}"
Data Scientist - (Remote - US),Jobgether,United States,February,2025,"Jobgether has ALL remote jobs globally. We match you to roles where you're most likely to succeed, and provide feedback on every application to help you learn. No more guesswork, application black holes, or recruiter ghosting in your job search.

For one of our clients, we are looking for a Data Scientist, remotely from the United States.

As a Data Scientist, you will be part of a growing team dedicated to improving pediatric healthcare by utilizing data science to enhance clinical outcomes for children with special healthcare needs. This role will involve developing machine learning (ML) models, analyzing data from clinical, claims, and social determinants of health (SDoH), and delivering insights that directly impact patient care. Your work will support the strategic goals of the business by providing actionable data-driven recommendations that enhance decision-making across the organization.

Accountabilities:

Work closely with business stakeholders to translate healthcare goals into actionable ML/AI models aimed at improving clinical outcomes
Collaborate with cross-functional teams to define requirements, optimize data collection, and build data assets
Develop and refine ML models using clinical, claims, and SDoH data to generate insights and improve patient care
Independently query and manage data in Snowflake, preparing it for exploratory analysis and modeling
Present findings and insights to non-technical staff in a clear and accessible manner


Requirements

At least 3 years of experience, with proficiency in Python and SQL
Strong background in study design, causal inference, hypothesis testing, and research methods
Experience in working with healthcare data and a deep understanding of its complexities is preferred
Ability to communicate technical findings to non-technical stakeholders across the organization
Experience working in a startup or growth environment is essential
Familiarity with Snowflake, AWS, and Tableau is a plus


Benefits

Base salary range of $135,000 - $170,000, plus annual bonus incentive
Competitive medical, dental, and vision insurance
Healthcare and Dependent Care FSA, and company-funded HSA
401(k) with a 4% match, vested 100% from day one
Employer-paid short and long-term disability
Life insurance equal to 1x annual salary
20 days of PTO, 10 company holidays, and 2 floating holidays
Paid new parent leave
Additional benefits to be detailed in the offer","{""role_summary"":""Work as a Data Scientist to improve pediatric healthcare by utilizing data science to enhance clinical outcomes for children with special healthcare needs."",""key_terms"":[{""term"":""Machine Learning (ML) models"",""explanation"":""Developing models that enable machines to learn from data and make predictions or decisions.""},{""term"":""Social Determinants of Health (SDoH)"",""explanation"":""Factors that affect health outcomes, such as socioeconomic status, education, and environment.""},{""term"":""Causal Inference"",""explanation"":""The process of drawing conclusions about cause-and-effect relationships between variables.""},{""term"":""Snowflake"",""explanation"":""A cloud-based data warehousing platform for storing and analyzing large datasets.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""3+ years of experience""],""nice_to_have"":[""Experience in working with healthcare data"",""Familiarity with Snowflake, AWS, and Tableau""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach developing a machine learning model to improve clinical outcomes for children with special healthcare needs?"",""example_answer"":""I would start by collaborating with stakeholders to define the problem, then use techniques like causal inference to identify relevant data sources and develop a model that can be used to inform decision-making.""},{""question"":""How do you stay current with new developments in machine learning and data science?"",""example_answer"":""I regularly read industry publications, attend conferences, and participate in online forums to stay up-to-date on the latest techniques and tools.""}],""red_flags"":[""Lack of experience working with healthcare data"",""Inability to communicate technical findings to non-technical stakeholders""],""confidence_score"":90.0}"
"Data Scientist, Legal",Meta,"New York, NY",March,2025,"We are looking for a Data Scientist to work on our eDiscovery & Information Governance Legal team. You will enjoy working with one of the richest data sets in the world, cutting edge technology, and the opportunity to have your insights turned into real world impact. Join us to dive into the technical details of our large-scale data stack. Help us to answer some of the most challenging and novel data issues facing the technology industry.

Data Scientist, Legal Responsibilities:

Collaborate with a variety of technical and non-technical stakeholders (including engineers, data scientists, and attorneys) to understand and identify data needs, understand business problems and design analytics solutions
Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
Design and communicate analytics solutions to help drive understanding across some of the largest data sets in the world
Mentor others and contribute to development of documentation, protocols and procedures, training guides, workflows, etc.

Minimum Qualifications:

3+ years of experience doing quantitative analysis
Experience with SQL and at least one programming language (e.g., Python, C, R.)
Bachelor's degree in Computer Science, Economics, or relevant technical field
Experience initiating and driving projects to completion with minimal guidance
Experience working cross-functionally and communicating technical content to general audiences

Preferred Qualifications:

MBA or Masters in a technical discipline
Experience with Unix/Linux
Experience with distributed computing (Hive/Hadoop)
Experience with Machine Learning/AI to automate tasks, identify patterns, make predictions
Experience working in technology industry

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$124,000/year to $176,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.","{""role_summary"":""Work as a Data Scientist on the eDiscovery & Information Governance team, collaborating with stakeholders to identify data needs, design analytics solutions, and drive insights from large-scale data sets."",""key_terms"":[{""term"":""eDiscovery"",""explanation"":""A professional responsible for identifying, collecting, and preserving electronic data for legal proceedings.""},{""term"":""Information Governance"",""explanation"":""A set of policies, procedures, and controls to manage and protect organizational information.""},{""term"":""Data Stack"",""explanation"":""A collection of technologies used to store, manage, and process large amounts of data.""}],""skill_priorities"":{""must_have"":[""3+ years of experience in quantitative analysis"",""Experience with SQL and at least one programming language (e.g., Python, C, R.)"",""Bachelor's degree in Computer Science, Economics, or relevant technical field"",""Experience initiating and driving projects to completion with minimal guidance"",""Experience working cross-functionally and communicating technical content to general audiences""],""nice_to_have"":[""MBA or Masters in a technical discipline"",""Experience with Unix/Linux"",""Experience with distributed computing (Hive/Hadoop)"",""Experience with Machine Learning/AI to automate tasks, identify patterns, make predictions"",""Experience working in technology industry""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a project where you had to communicate complex technical information to a non-technical audience?"",""example_answer"":""In my previous role, I worked on a project where I had to present data insights to a group of non-technical stakeholders. I used visualizations and simple language to explain the findings, and received positive feedback from the stakeholders.""},{""question"":""How do you ensure data quality and security standards in your analytics solutions?"",""example_answer"":""I follow best practices for data quality and security, such as data encryption, access controls, and regular data backups. I also stay up-to-date with industry standards and regulations, such as GDPR and CCPA.""}],""red_flags"":[""Lack of experience working with large-scale data sets"",""Inability to communicate technical information to non-technical stakeholders""],""confidence_score"":90.0}"
Data Scientist (III or IV),Donegal Insurance Group,"Marietta, PA",March,2025,"About the Role
Donegal Insurance Grouphas an opening fora Data Scientist (III or IV). The Data Scientist is responsible for developing predictive models and complex analytical solutions.This position may be preformed remotely or onsite at our Marietta, PA corporate office. Job Summary
Develop predictive models and complex analytical solutions in support of Underwriting, Pricing, Claims, and Marketing.
Provide requirements or build tools to integrate analytical solutions to enhance decision-making and/or refine operations
Interpret results from multiple sources using a variety of techniques, ranging from simple data aggregation via statistical analysis to complex data mining
Design, develop, and implement business solutions for the organization
Prepare big data, implement data models and develop database to support the business solutions
Work on advanced, complex technical projects or business issues requiring state of the art technical or industry knowledge. Goals are generally communicated in solution or project goal terms.
Serve as a leadership role for the work group through knowledge in the area of specialization.
Responsibilities and Duties
Identify business trends and problems through complex big data analysis
Use various quantitative modeling techniques to analyze company specific experience and external data to better market, price, and underwrite company products
Develop financial and/or quantitative models to gauge the impact of corporate decisions
Ensure duties are performed in adherence to all Federal, State, and Local laws and regulations
Comply with guidelines, policies, and directives outlined in the company handbook and department manuals
Provide timely, courteous, and quality customer service to customers
Clearly demonstrate commitment and participation to team goals and objectives
Reliable attendance and punctuality
Qualifications and Skills
Experience dependent on the level of Data Scientist. The current opening requires a minimumof 3 years of experience, at least 5 years experience preferred
Experience working with property/casualty insurance preferred
Bachelor’s Degree in Data Science, Data & Analytics, Mathematics, Statistics, Actuarial Science or related field
Master’s Degree or continuing education in a similar field preferred
PC skills to include:
Python
A Python model framework (Sklearn, Keras, H2O, Tensorflow, etc.)
Flask / Django exposure (or other web development framework exposure) for deployment focused role
Pandas package (+ data wrangling skills)
Additional preferred skills:
SQL
Docker
Linux command line
git
Data visualization
Hardware requirements
Database platforms
Industry specific software applications applicable to performance of position responsibilities
Microsoft Office applications
Starting Pay:The pay range for this position is $100,000 to $140,000 annually. The specific offer will vary based on an applicant's education, qualifications, professional experience, skills, abilities, and any applicable designations/certifications. The posted pay range reflects our ability to hire at different position titles and levels depending on background and experience. The pay range may also be adjusted based on an applicant's geographic location.The base pay is just one component of Donegal's total compensation package for employees. This role may also be eligible to participate in a discretionary annual incentive program. The amount of any bonus varies and is subject to the terms and conditions of the applicable incentive plan.Application deadline to apply is March 14, 2025. For full consideration, applications must be received by the deadline; however, the posting will be kept open until the position is filled.
To apply, please submit your resume and online application


Competitive Benefits Package


Donegal Insurance Group offers a comprehensive benefits package for all full-time, permanent positions including:



Medical, Dental, and Vision Coverage: Available to you and your dependents. Coverage begins the first of the month after start date.

401(k) with the first 3% matched at 100%: the next 6% is matched at 50%

Paid Time Off: Paid vacation, sick days, paid holidays, & bereavement days

Career Development: Including college partnership discounts and industry designation(s) reimbursements



Additional benefits include company-paid basic life insurance; short & long-term disability insurance; employee stock purchase plan; and employee assistance program (EAP). Learn more about our full benefit offerings by visiting our Benefits page.


Who We Are


Donegal Insurance Group provides commercial and personal insurance products through a network of independent agents in 21 states and across several regions of the U.S. In Texas, Colorado, Utah, New Mexico and Arizona, business is conducted under the Mountain States Insurance Group name; and in Michigan, business is conducted under the Michigan Insurance name.


Headquartered in Lancaster County, Pennsylvania, along with four (4) regional offices located in: Athens, GA, Grand Rapids, MI, Albuquerque, NM, and Glen Allen, VA, our steady growth and successes have allowed us to establish a culture of which we're proud. Check out our Glassdoor profile where our rating speaks for itself:




By joining the Donegal family, you would be joining a team of dedicated, hard-working employees, all with a common goal of providing peace of mind to our policyholders and being There when it matters most.™.


Work Arrangement


With each department and position being different, the work arrangement for a specific position will be reviewed with candidates during a initial phone screening. For a position not requiring an onsite expectation at one of our offices, the ideal candidate must live within our Donegal footprint. Current approved states are: AL, AZ, CT, DE, FL, GA, IA, IL, IN, MD, MI, MN, MO, NC, ND, NE, NH, NJ, NM, NY, OH, PA, SC, SD, TN, TX, UT, VA, WI, and, WV. (Please note, this list is subject to change without notice.)


E-Verify


Donegal Insurance Group participates in E-Verify in the following states: Alabama, Arizona, Florida, Georgia, Louisiana, Mississippi, Nebraska, North Carolina, South Carolina, Tennessee, and Utah. If you reside in one of the listed states, please review the ""Notice of E-Verify Participation"" and the ""Right to Work Poster"" on the links below:



Notice of E-Verify Participation Poster (English and Spanish)

Right to Work Poster (English and Spanish)

Powered by JazzHR
g4IygZpdPh","{""role_summary"":""Develop predictive models and complex analytical solutions to support Underwriting, Pricing, Claims, and Marketing."",""key_terms"":[{""term"":""Predictive models"",""explanation"":""Statistical models that forecast outcomes based on historical data and patterns.""},{""term"":""Complex analytical solutions"",""explanation"":""Advanced data analysis techniques to identify trends and opportunities.""},{""term"":""Big data"",""explanation"":""Large datasets that require specialized tools and techniques to process and analyze.""}],""skill_priorities"":{""must_have"":[""Python"",""Pandas"",""Bachelor's Degree in Data Science, Data & Analytics, Mathematics, Statistics, Actuarial Science or related field""],""nice_to_have"":[""Master's Degree or continuing education"",""SQL"",""Docker"",""Linux command line"",""git"",""Data visualization"",""Hardware requirements"",""Database platforms"",""Industry specific software applications"",""Microsoft Office applications""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach developing predictive models for complex analytical solutions?"",""example_answer"":""I use a combination of statistical techniques and machine learning algorithms to develop models that accurately forecast outcomes.""},{""question"":""Can you explain how you would integrate analytical solutions to enhance decision-making and refine operations?"",""example_answer"":""I would use data visualization tools to present insights to stakeholders and develop dashboards to track key performance indicators.""}],""red_flags"":[""Lack of experience working with property/casualty insurance"",""Inability to work with big data"",""Limited knowledge of industry-specific software applications""],""confidence_score"":90.0}"
Stanowisko ds. zarządzania obszarem BI i HD-specjalność analityki biznesowej,ZUS,"Left Hand, WV",March,2025,"Nazwa jednostki organizacyjnej

ZUS III Oddział w Warszawie

Nazwa komórki organizacyjnej

Departament Statystyki i Prognoz Aktuarialnych

Miejsce pracy

ZUS III Oddział w Warszawie

Adres miejsca pracy

ul. Czerniakowska 16, 00-701 Warszawa

Województwo

mazowieckie

Nazwa stanowiska

Stanowisko ds. zarządzania obszarem BI i HD-specjalność analityki biznesowej

Zadania

Zadania

gromadzić, rejestrować, analizować i nadzorować realizację wymagań użytkowników w zakresie tworzenia i rozwoju systemów i narzędzi Business Intelligence i Hurtowni Danych w ZUS.
odpowiadać za analizę potrzeb biznesowych z obszaru analityki danych oraz ich specyfikację w formie realizowalnych wymagań dla systemów informatycznych w ramach przygotowywanych i realizowanych projektów.
utrzymywać portfel potrzeb i projektów w obszarze Business Intelligence i Hurtowni Danych .
brać udział w realizacji projektów informatycznych związanych z rozwojem środowiska Business Intelligence i Hurtowni Danych.
uczestniczyć w pracach wdrożeniowych i testowych w obszarze Business Intelligence i Hurtowni Danych.
proponować usprawnienia dla realizowanych procesów i zmiany w dokumentacji.
uczestniczyć w przygotowaniu planu rozwoju (roadmapy) dla środowiska Business Intelligence i Hurtowni Danych.
Wymagania

Wymagania Niezbędne

wykształcenie wyższe
doświadczenie zawodowe minimum 1 rok (w pracy związanej z planowaniem, tworzeniem i rozwojem w obszarach Business Intelligence i\lub Hurtowni Danych)
staż pracy ogółem minimum 2 lata

Mile Widziane

wykształcenie wyższe (matematyka, informatyka, statystyka)
doświadczenie zawodowe minimum 2 lata (w pracy związanej z planowaniem, tworzeniem i rozwojem w obszarach Business Intelligence i\lub Hurtowni Danych)

Wymagania Dodatkowe

umiejętność obsługi programów MS Office
wiedza z zakresu dobrych praktyk zbierania wymagań biznesowych
orientacja na cel
orientacja na jakość
komunikacja
współpraca
elastyczność
nastawienie na rozwój
negocjowanie i wywieranie wpływu
podejmowanie decyzji
umiejętność rozwiązywania problemów
innowacyjność

Wymagane Dokumenty

CV
listu motywacyjnego
skan dokumentów potwierdzających wykształcenie
skan dokumentów potwierdzających wymagane doświadczenie zawodowe
skan świadectw pracy dokumentujących wymagany staż pracy lub zaświadczenie o zatrudnieniu zawierające okresy zatrudnienia, w przypadku pozostania w stosunku pracy

Dokumenty należy przesyłać poprzez formularz aplikacyjny 'Aplikuj', znajdujący się na dole oferty

Dodatkowe Informacje

proces rekrutacji obejmować będzie rozmowę kwalifikacyjną (przeprowadzoną w formie zdalnej przez komunikator internetowy - wywiad on-line) lub stacjonarnie
skontaktujemy się tylko z kandydatami spełniającymi wymagania formalne
oferty niekompletne tj. niezawierające skanu, któregokolwiek wymaganego dokumentu nie będą rozpatrywane
oferty przesłane po terminie nie będą rozpatrywane
miejscem świadczenia pracy będzie Centrala ZUS lub dowolny Oddział ZUS
możliwość pracy w trybie stacjonarnym, zdalnym lub hybrydowym.
Termin, do którego należy składać dokumenty

12-02-2025

Oferujemy

Oferujemy

stabilne zatrudnienie na podstawie umowy o pracę
możliwość rozwoju zawodowego
bogaty pakiet świadczeń socjalnych
system premiowy

Zakład Ubezpieczeń Społecznych jest pracodawcą przyjaznym osobom z niepełnosprawnościami. Stwarza pracownikom optymalne środowisko pracy, uwzględniając ich potrzeby. Istnieje możliwość dostosowania stanowiska pracy i jego wyposażenia do indywidualnych potrzeb osób z niepełnosprawnościami

Wyposażenie Stanowiska Pracy

sprzęt komputerowy,
sprzęt biurowy.

Warunki Wykonywania Pracy

spełniają warunki określone wymogami bhp i ppoż.,
polegają na obsłudze komputera powyżej 4 godzin na dobę,
konieczność poruszania się po całym obiekcie,
konieczność wykonywania pracy poza biurem,
konieczność odbywania podróży służbowych,
budynek 3-piętrowy z windą oraz pomieszczeniami sanitarnymi dostosowanymi do potrzeb osób niepełnosprawnych,
stanowisko pracy zlokalizowane w pomieszczeniach biurowych na 3- piętrze,
miejsce pracy dostosowane do osób poruszających się przy pomocy wózka inwalidzkiego,
wejście do budynku jest zorganizowane z poziomu chodnika,
drzwi przy wejściu do budynku otwierają się automatycznie,
w bezpośrednim sąsiedztwie wejścia do budynku znajdują się miejsca parkingowe dla osób z niepełnosprawnościami","{""role_summary"":""Manage the development and maintenance of Business Intelligence and Data Warehousing systems, ensuring they meet business needs and requirements."",""key_terms"":[{""term"":""Business Intelligence"",""explanation"":""A set of tools and techniques used to analyze and present business data in a way that helps organizations make better decisions.""},{""term"":""Data Warehousing"",""explanation"":""A type of database that is designed to store and manage large amounts of data from various sources, making it possible to analyze and report on the data.""},{""term"":""Analityka biznesowa"",""explanation"":""The practice of using data and analytics to drive business decisions and optimize business outcomes.""}],""skill_priorities"":{""must_have"":[""Experience in planning, creating, and developing Business Intelligence and/or Data Warehousing systems"",""Higher education"",""At least 1 year of professional experience"",""At least 2 years of overall work experience""],""nice_to_have"":[""Higher education in mathematics, computer science, or statistics"",""At least 2 years of professional experience in planning, creating, and developing Business Intelligence and/or Data Warehousing systems""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach analyzing business needs and specifying requirements for a Business Intelligence system?"",""example_answer"":""I would start by conducting stakeholder interviews to understand the business needs, then use tools like use cases and user stories to document the requirements, and finally prioritize the requirements based on business value and complexity.""},{""question"":""How do you stay current with new developments in Business Intelligence and Data Warehousing?"",""example_answer"":""I regularly read industry blogs and attend webinars and conferences to stay current with new developments and trends in Business Intelligence and Data Warehousing.""}],""red_flags"":[""Lack of experience in Business Intelligence and/or Data Warehousing"",""Insufficient education or training in Business Intelligence and/or Data Warehousing""],""confidence_score"":80.0}"
"Data Scientist, Algorithms - Pricing",Lyft,"New York, NY",March,2025,"Location: Software Technology Innovation Center (STIC), Menlo Park, CA, USA

We are seeking scientists and engineers with a strong fundamental understanding of various modern machine-learning methods to address highly challenging scientific & engineering problems

The Data Scientist is responsible for conducting undirected technology development and tackle open-ended data problems and questions. Drawing on an advanced degree in a quantitative field such as computer science, physics, statistics or applied mathematics, the Data Scientist demonstrates the knowledge to invent new algorithms to solve data problems.

The Data Scientist participates in the areas of data science, industrial analytics, data-driven prognostics, data mining, and machine learning. Data scientist researches and assesses next-generation technologies for data-driven modeling and optimization of complex systems and has advanced working knowledge and experience with machine learning algorithms and population-based meta-heuristic and gradient-based optimization methods.

Relationships: Reports to Software Project Manager, Engineering Manager or Team Lead

Essential Responsibilities and Duties:

Research and develop data analytics and/or machine learning systems for business applications;
Work with domain experts to understand needs and constraints;
Work with software engineers to integrate ML solutions in business workflows;
Communicate sophisticated ML concepts to management, clients, and the business community
Research and assess next-generation technologies for inference, predictive modeling, general purpose data-driven modeling and optimization of complex systems. Demonstrate advanced working knowledge and experience with, data analytics, machine learning algorithms and optimization methods.
Generate innovative ideas, establish new technology development directions, and shape and execute on technical projects.
Maintain state-of-the-art knowledge and contribute to technical discussions and reviews as an expert in related areas of responsibility.
Apply theoretical knowledge to solve industrial problems.
Process large multivariate data sets collected from equipment operations, manufacturing tests and diagnostic routines.
Communicate ideas, plans and results effectively via oral and written reports. Works effectively with peers, management, operations groups, and outside organizations
May participate in the relevant technical reviews and audits of the projects
May review, mentor and coach, while define and promote usage of standards, best practices and lessons learned
Work across multiple cross-functional teams in high visibility roles to prototype end-to-end data solutions


Qualifications & Experience:

MS / PhD in computer science, mathematics, applied statistics, physics, engineering or similar disciplines with demonstrated research capability with software experience or education
Probability theory, decision theory, statistics, machine learning, reasoning and inference frameworks
Software development skills and familiarity with database, programming, and data science development languages such as R, Python, TensorFlow and PyTorch
Experience in a few of the following areas: deep neural networks, reinforcement learning, Markov Random Fields, Bayesian networks, semi-supervised learning, computer vision, image processing, signal processing, distributed computing, and/or numerical optimization.
Familiarity with ML frameworks such as Tensorflow, PyTorch. is a plus.
Experience with big-data technologies such as Hadoop/Spark or GCP-BigQuery is a plus.
Strong oral and written communication skills
Ability to work within a team of scientists and engineers and strong oral and written communication skills
Strong data dexterity using current big data analytics tools


Behavior:

An enthusiasm for science and technology
Analytical thinker
Conscious of data quality
Strong communication skills
Function independently and in a team
Provide creative and innovative solutions


Data Scientist will work at Schlumberger Software Technology Innovation Center (STIC) at Menlo Park, California. Schlumberger STIC is the newest facility of Schlumberger, located in the Silicon Valley, working in close collaboration with major players in the Valley network. The STIC offers its professionals a broad aspect of interaction opportunities within leading software industry partners, universities and the large network of Schlumberger Technology Centers around the world, that support Schlumberger activities in more than 85 countries.

STIC is part of the Schlumberger Software Technology organization, responsible for leading the Schlumberger digital technology initiatives. As the oil and gas industry’s leading supplier of technology, integrated project management, and information solutions to customers worldwide, the Schlumberger digital technology development and management initiatives play a key role in driving of the oilfield service industry’s digital technology transformation.

Schlumberger is an equal employment opportunity employer. Qualified applicants are considered without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, status as a protected veteran or other characteristics protected by law. Schlumberger is a VEVRAA Federal Contractor – priority referral Protected Veterans requested.

#Schlumberger","{""role_summary"":""The Data Scientist is responsible for conducting undirected technology development and tackling open-ended data problems and questions, utilizing advanced knowledge to invent new algorithms to solve data problems."",""key_terms"":[{""term"":""Machine Learning"",""explanation"":""A type of artificial intelligence that enables computers to learn from data without being programmed.""},{""term"":""Data Analytics"",""explanation"":""The process of examining data sets to draw conclusions and make informed decisions.""},{""term"":""Gradient-based Optimization"",""explanation"":""A method of finding the optimal solution by minimizing or maximizing a function using gradient descent.""},{""term"":""Population-based Meta-heuristic"",""explanation"":""A high-level optimization technique that uses heuristics to find the optimal solution.""}],""skill_priorities"":{""must_have"":[""MS / PhD in computer science, mathematics, applied statistics, physics, engineering or similar disciplines"",""Software development skills and familiarity with database, programming, and data science development languages such as R, Python, TensorFlow and PyTorch"",""Strong oral and written communication skills""],""nice_to_have"":[""Experience in a few of the following areas: deep neural networks, reinforcement learning, Markov Random Fields, Bayesian networks, semi-supervised learning, computer vision, image processing, signal processing, distributed computing, and/or numerical optimization"",""Familiarity with ML frameworks such as Tensorflow, PyTorch"",""Experience with big-data technologies such as Hadoop/Spark or GCP-BigQuery""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of gradient-based optimization and how it is used in machine learning?"",""example_answer"":""Gradient-based optimization is a method of finding the optimal solution by minimizing or maximizing a function using gradient descent. In machine learning, it is used to optimize the cost function and update the model parameters.""},{""question"":""How do you handle large multivariate data sets collected from equipment operations, manufacturing tests and diagnostic routines?"",""example_answer"":""I use data analytics tools such as R, Python, and TensorFlow to process and analyze the data, and then apply machine learning algorithms to extract insights.""}],""red_flags"":[""Lack of experience with machine learning algorithms and optimization methods"",""Inability to communicate sophisticated ML concepts to management, clients, and the business community""],""confidence_score"":95.0}"
Applied Scientist - Pipeline Data Science,Syngenta,"Durham, NC",March,2025,"Company Description

Syngenta is one of the world’s leading companies with more than 27.000 employees in over 90 countries dedicated to our purpose: Bringing plant potential to life. Through world-class science, global reach and commitment to our customers we help to increase crop productivity, protect the environment and improve health and quality of life. For more information about us please go to www.syngenta.com.

Job Description

The Seeds Development department for Syngenta seeks a passionate candidate for a full-time position of:

Applied Scientist - Pipeline Data Science

Type: Permanent

Department: Seeds Development / Vegetables

Location: Durham, NC, USA

Into action

Do you thrive at the intersection of data engineering, predictive analytics, and innovation? As our Applied Scientist - Pipeline Data Science, you will play a crucial role in designing scalable data solutions that drive actionable insights. By consolidating complex datasets into robust, efficient pipelines, you’ll empower teams to make better decisions and uncover new possibilities in plant breeding. This is your opportunity to work on impactful projects in a collaborative and cutting-edge environment where data drives transformation.

The challenge

Responsibilities

As an Applied Scientist, you’ll focus on building the infrastructure that makes data accessible, reliable, and actionable for diverse stakeholders. Your key responsibilities will include:

Building Scalable Data Pipelines: Design, implement, and optimize data pipelines that integrate and consolidate data from multiple sources, ensuring seamless data flow and availability.
Ensuring Data Quality and Reliability: Develop systems to track, monitor, and maintain the quality, consistency, and integrity of data to ensure robust outputs for analysis and decision-making.
Driving Data Modeling and Mining: Create and implement processes for advanced data modeling and mining to support innovative analytical approaches.
Collaborating Across Teams: Work closely with IT, applied data science teams, and business stakeholders to align data solutions with organizational goals, addressing unique data needs efficiently.
Identify opportunities to incorporate advanced analytics, including machine learning frameworks and cloud platforms to continuously improve predictive pipelines.
Influence adoption of prediction methods, contribute towards their integration in the breeding process and the transformation of breeding schemes.

This role combines creativity and problem-solving with a focus on real-world applications. You’ll not only shape the way data is managed but also contribute to meaningful outcomes in plant breeding and sustainable agriculture. Every dataset you refine and every system you enhance will drive smarter decisions and impactful innovations.

Qualifications

Your profile

We’re Looking For a Driven And Detail-oriented Applied Scientist With a Master’s Degree In Computer Science, Statistics, Applied Mathematics, Or a Related Field. You Bring a Strong Mix Of Technical Expertise, Analytical Acumen, And a Collaborative Mindset

Programming: Proficiency in Python, R, and SQL. Experience in both relational and NoSQL databases.
Cloud Proficiency: Familiarity with AWS services and cloud infrastructure
Analytical Acumen: Exceptional analytical skills, with the ability to identify patterns and trends in large and diverse datasets and translate them into meaningful recommendations.
Collaboration & Communication: A strong team player who thrives in cross-functional settings and communicates technical concepts effectively to diverse stakeholders.
Additionally, hands-on experience with containerization tools (e.g., Docker, Kubernetes) and machine learning frameworks (e.g., Keras, PyTorch, scikit-learn), along with an interest in plant breeding or agricultural innovation, would make you an ideal fit for this role.

Take your chance!

Syngenta is proud of its unique culture and the values that are at the heart of it. We also foster a strong learning culture with plenty of opportunities for personal development. Why? Because our work matters! We offer a competitive salary package, flexible working hours and excellent benefits.

Are you ready to grow your career with us?

Additional Information

All your information will be kept confidential according to EEO guidelines.","{""role_summary"":""Design and implement scalable data pipelines to drive actionable insights in plant breeding, ensuring data quality and accessibility for diverse stakeholders."",""key_terms"":[{""term"":""Data Pipelines"",""explanation"":""A series of processes that extract, transform, and load data into a target system for analysis and decision-making.""},{""term"":""Predictive Analytics"",""explanation"":""Statistical techniques to forecast future events or behaviors based on historical data and machine learning algorithms.""},{""term"":""Cloud Platforms"",""explanation"":""On-demand computing resources and services provided over the internet, such as AWS, Azure, or Google Cloud.""},{""term"":""Machine Learning Frameworks"",""explanation"":""Software libraries that simplify the development of machine learning models, such as scikit-learn, PyTorch, or Keras.""}],""skill_priorities"":{""must_have"":[""Python"",""R"",""SQL"",""Cloud Proficiency (AWS)"",""Analytical Acumen"",""Collaboration & Communication""],""nice_to_have"":[""Containerization tools (Docker, Kubernetes)"",""Hands-on experience with machine learning frameworks"",""Interest in plant breeding or agricultural innovation""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you ensure data quality and reliability in complex pipelines?"",""example_answer"":""I implement data validation checks, monitor data flow, and maintain data consistency to ensure robust outputs for analysis and decision-making.""},{""question"":""Can you give an example of a successful data modeling and mining project you've worked on?"",""example_answer"":""I developed a predictive model using Python and scikit-learn that improved crop yield prediction by 15%.""}],""red_flags"":[""Lack of experience with cloud platforms or machine learning frameworks"",""Inability to communicate technical concepts effectively to diverse stakeholders""],""confidence_score"":95.0}"
Data Scientist V,INSPYR Solutions,"New York, NY",March,2025,"Title: Data Scientist V
Location: Remote (EST))
Duration: 6+ Month Contract
Compensation: $84.00 - 104.00
Work Requirements: US Citizen, GC Holders or Authorized to Work in the U.S.

Job Description: Summary:
The main function of the Data Scientist is to produce innovative solutions driven by exploratory data analysis from complex and high-dimensional datasets.

Job Responsibilities:
• Apply knowledge of statistics, machine learning, programming, data modeling, simulation, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries leading to prototype development and product improvement.
• Use a flexible, analytical approach to design, develop, and evaluate predictive models and advanced algorithms that lead to optimal value extraction from the data.
• Generate and test hypotheses and analyze and interpret the results of product experiments.
• Work with product engineers to translate prototypes into new products, services, and features and provide guidelines for large-scale implementation.
• Provide Business Intelligence (BI) and data visualization support, which includes, but limited to support for the online customer service dashboards and other ad-hoc requests requiring data analysis and visual support.

Skills:
8+ years of experience as a Data Scientist
Experience with Media data or Media analytic companies 
Experienced in either programming languages such as SQL/Python and/or R, big data tools such as Hadoop, or data visualization tools such as Tableau.
 Experience with building data pipelines
The ability to communicate effectively in writing, including conveying complex information and promoting in-depth engagement on course topics.
Experience working with large datasets.
Education/Experience:
• Bachelors of Science degree in computer science or in a relevant field.

Our benefits package includes: 
Comprehensive medical benefits
Competitive pay
401(k) retirement plan
…and much more!
 
About INSPYR Solutions


Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.
 
INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.
 ","{""role_summary"":""The Data Scientist will develop innovative solutions using exploratory data analysis to complex datasets, driving business improvements and product development."",""key_terms"":[{""term"":""Exploratory data analysis"",""explanation"":""A method of analyzing data to identify patterns, trends, and relationships, often used to inform business decisions.""},{""term"":""Predictive models"",""explanation"":""Mathematical models that forecast future events or behaviors based on historical data.""},{""term"":""Data pipelines"",""explanation"":""A series of processes that extract, transform, and load data into a target system for analysis or storage.""},{""term"":""Big data tools"",""explanation"":""Software used to handle and process large datasets, such as Hadoop.""},{""term"":""Data visualization"",""explanation"":""The process of creating graphical representations of data to facilitate understanding and communication of insights.""}],""skill_priorities"":{""must_have"":[""8+ years of experience as a Data Scientist"",""Experience with Media data or Media analytic companies"",""Experience with programming languages such as SQL/Python and/or R, big data tools such as Hadoop, or data visualization tools such as Tableau"",""Experience building data pipelines"",""Ability to convey complex information in writing""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a project where you developed a predictive model that drove business value?"",""example_answer"":""In my previous role, I built a model that predicted customer churn, resulting in a 20% reduction in churn rate.""},{""question"":""How do you approach data visualization to communicate insights to non-technical stakeholders?"",""example_answer"":""I use tools like Tableau to create interactive dashboards that allow stakeholders to explore the data themselves, and I focus on clear, concise labeling and storytelling to ensure the insights are actionable.""}],""red_flags"":[""Lack of experience with large datasets"",""Inability to communicate complex technical information to non-technical stakeholders""],""confidence_score"":95.0}"
Stanowisko ds. zarządzania obszarem BI i HD-specjalność inżynierii systemów Business Intelligence,ZUS,"Left Hand, WV",March,2025,"Nazwa jednostki organizacyjnej

ZUS III Oddział w Warszawie

Nazwa komórki organizacyjnej

Departament Statystyki i Prognoz Aktuarialnych

Miejsce pracy

ZUS III Oddział w Warszawie

Adres miejsca pracy

ul. Czerniakowska 16, 00-701 Warszawa

Województwo

mazowieckie

Nazwa stanowiska

Stanowisko ds. zarządzania obszarem BI i HD-specjalność inżynierii systemów Business Intelligence

Zadania

Zadania

zapewniać utrzymanie i rozwój architektury biznesowej i technicznej obszaru Business Intelligence
współpracować w realizacji zleceń analityczno-raportowych pochodzących od komórek i jednostek biznesowych Zakładu
odpowiadać za proponowanie, budowanie i wdrażanie rozwiązań z zakresu technologii przetwarzania dużych zbiorów danych (Big Data), m.in. modelowania danych, wizualizacji danych
uczestniczyć w przygotowaniu planu rozwoju (roadmapy) dla środowiska Business Intelligence i Hurtowni Danych
uczestniczyć w planowaniu inicjatyw i projektów mających na celu rozbudowę i optymalizację wykorzystywanych rozwiązań Business Intelligence
uczestniczyć w pracach projektowych, wdrożeniowych i testowych w obszarze Business Intelligence
wspierać użytkowników w ramach wdrożeń systemów i narzędzi w obszarze Business Intelligence
proponować usprawnienia dla realizowanych procesów i zmiany w dokumentacji
współpracować w realizacji zleceń analityczno-raportowych pochodzących od komórek i jednostek biznesowych Zakładu
Wymagania

Wymagania Niezbędne

wykształcenie wyższe
doświadczenie zawodowe minimum 1 rok (w pracy związanej z planowaniem, tworzeniem i rozwojem w obszarach Business Intelligence i\lub Hurtowni Danych)
staż pracy ogółem minimum 2 lata

Mile Widziane

wykształcenie wyższe (matematyka, informatyka, statystyka)
doświadczenie zawodowe minimum 2 lata (w pracy związanej z planowaniem, tworzeniem i rozwojem w obszarach Business Intelligence i\lub Hurtowni Danych)

Wymagania Dodatkowe

umiejętność obsługi programów MS Office
znajomości tworzenia szablonów formularzy lub raportów dynamicznych
znajomość tworzenia paneli wizualizacyjnych lub cocpitów
orientacja na cel
orientacja na jakość
komunikacja
współpraca
elastyczność
nastawienie na rozwój
negocjowanie i wywieranie wpływu
podejmowanie decyzji
umiejętność rozwiązywania problemów
innowacyjność

Wymagane Dokumenty

CV
listu motywacyjnego
skan dokumentów potwierdzających wykształcenie
skan dokumentów potwierdzających wymagane doświadczenie zawodowe
skan świadectw pracy dokumentujących wymagany staż pracy lub zaświadczenie o zatrudnieniu zawierające okresy zatrudnienia, w przypadku pozostania w stosunku pracy

Dokumenty należy przesyłać poprzez formularz aplikacyjny 'Aplikuj', znajdujący się na dole oferty

Dodatkowe Informacje

proces rekrutacji obejmować będzie rozmowę kwalifikacyjną (przeprowadzoną w formie zdalnej przez komunikator internetowy - wywiad on-line) lub stacjonarnie
skontaktujemy się tylko z kandydatami spełniającymi wymagania formalne
oferty niekompletne tj. niezawierające skanu, któregokolwiek wymaganego dokumentu nie będą rozpatrywane
oferty przesłane po terminie nie będą rozpatrywane
miejscem świadczenia pracy będzie Centrala ZUS lub dowolny Oddział ZUS
możliwość pracy w trybie stacjonarnym, zdalnym lub hybrydowym.
Termin, do którego należy składać dokumenty

12-02-2025

Oferujemy

Oferujemy

stabilne zatrudnienie na podstawie umowy o pracę
możliwość rozwoju zawodowego
bogaty pakiet świadczeń socjalnych
system premiowy

Zakład Ubezpieczeń Społecznych jest pracodawcą przyjaznym osobom z niepełnosprawnościami. Stwarza pracownikom optymalne środowisko pracy, uwzględniając ich potrzeby. Istnieje możliwość dostosowania stanowiska pracy i jego wyposażenia do indywidualnych potrzeb osób z niepełnosprawnościami

Wyposażenie Stanowiska Pracy

sprzęt komputerowy,
sprzęt biurowy.

Warunki Wykonywania Pracy

spełniają warunki określone wymogami bhp i ppoż.,
polegają na obsłudze komputera powyżej 4 godzin na dobę,
konieczność poruszania się po całym obiekcie,
konieczność wykonywania pracy poza biurem,
konieczność odbywania podróży służbowych,
budynek 3-piętrowy z windą oraz pomieszczeniami sanitarnymi dostosowanymi do potrzeb osób niepełnosprawnych,
stanowisko pracy zlokalizowane w pomieszczeniach biurowych na 3- piętrze,
miejsce pracy dostosowane do osób poruszających się przy pomocy wózka inwalidzkiego,
wejście do budynku jest zorganizowane z poziomu chodnika,
drzwi przy wejściu do budynku otwierają się automatycznie,
w bezpośrednim sąsiedztwie wejścia do budynku znajdują się miejsca parkingowe dla osób z niepełnosprawnościami","{""role_summary"":""Manage and develop the Business Intelligence and Data Warehousing area, ensuring the maintenance and development of business and technical architecture, proposing and implementing solutions, and supporting users in system implementation."",""key_terms"":[{""term"":""Business Intelligence"",""explanation"":""A set of tools and techniques used to transform raw data into meaningful and useful business information.""},{""term"":""Big Data"",""explanation"":""A large and complex set of data that requires specialized processing and analysis to extract useful information.""},{""term"":""Data Modeling"",""explanation"":""The process of creating a conceptual framework for organizing and structuring data to facilitate efficient data management and analysis.""},{""term"":""Data Visualization"",""explanation"":""The process of creating graphical representations of data to facilitate better understanding and decision-making.""}],""skill_priorities"":{""must_have"":[""Business Intelligence"",""Data Modeling"",""Data Visualization""],""nice_to_have"":[""Big Data"",""MS Office"",""Reporting""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach developing a data warehouse for a large organization?"",""example_answer"":""I would start by understanding the organization's data requirements and then design a data warehouse that meets those needs. I would also ensure that the data warehouse is scalable and can handle large volumes of data.""},{""question"":""How do you stay current with new technologies and trends in Business Intelligence?"",""example_answer"":""I regularly read industry publications and attend conferences to stay up-to-date with the latest developments in Business Intelligence and Data Warehousing.""}],""red_flags"":[""Lack of experience in Business Intelligence and Data Warehousing"",""Inability to communicate technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Data Scientist (L5) - Games Product Measurement Research,Netflix,United States,March,2025,"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

We are seeking a Senior Data Scientist with strong causal inference and experimentation experience to elevate and evolve the Games experience for our members. In this role, you will lead Games research to establish core product metrics and tradeoffs and deepen our understanding of product behavior among gamers. Working in a highly collaborative and cross-functional environment, you will be responsible for partnering with our Product and Engineering teams to identify, incubate, and enable product innovations leveraging robust measurement techniques (e.g. experimentation, modeling, analytics).

As a Data Scientist, you’ll be at the forefront of product innovation and measurement. You’ll work with other data scientists, research scientists, data and analytics engineers, and business teams to drive product vision and advance measurement strategy through new metrics, methodological approaches, and deep-dive analyses. You will be jumping in at a critical time in our Games adventure - this is an exciting time to help us redefine what a Netflix subscription means for our members around the world!

In This Role, You Will

Drive causal inference research to establish a robust measurement of game engagement within the Netflix ecosystem, informing core product metrics, innovation budgets, and tradeoffs.
Develop experimentation and measurement frameworks to increase the velocity of investments and aid complex decision-making, including long-term holdback and meta-analysis approaches.
Deepen our understanding of product behavior among gamers to guide strategy for game promotion on our shared product canvases.
Establish strong partnerships with PMs, data scientists, and engineers across the company to improve our product understanding and measurement approaches.
Be flexible to changing circumstances—Netflix Games and our core Product experience are evolving rapidly, and this role will help shape that joint evolution.

To Be Successful In This Role, You Have

Advanced degree in Statistics, Mathematics, Computer Science, Economics, or related quantitative field.
5+ years of relevant experience designing experiments and conducting causal studies with demonstrated impact. ML depth is a plus.
Strong Quantitative Programming skills in a language such as Python.
Exceptional oral and written communication skills, with demonstrated experience managing large stakeholder landscapes.
Passion for driving product vision and innovation strategy by leveraging a broad set of techniques and building strong partnerships with stakeholders.
Ability to work independently and drive your own projects.
Embodies Netflix values while bringing a new perspective to continue to improve our culture.

Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000.

Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here.

Netflix is a unique culture and environment. Learn more here.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.","{""role_summary"":""Lead Games research to establish core product metrics and tradeoffs, and deepen understanding of product behavior among gamers, partnering with Product and Engineering teams to drive product innovations."",""key_terms"":[{""term"":""Causal inference"",""explanation"":""A statistical technique to establish cause-and-effect relationships, used to measure game engagement and inform product metrics.""},{""term"":""Experimentation"",""explanation"":""A method to test hypotheses and measure the impact of product changes, used to increase the velocity of investments and aid complex decision-making.""},{""term"":""Meta-analysis"",""explanation"":""A statistical technique to combine results from multiple studies, used to inform product metrics and innovation budgets.""}],""skill_priorities"":{""must_have"":[""Advanced degree in Statistics, Mathematics, Computer Science, Economics, or related quantitative field"",""5+ years of relevant experience designing experiments and conducting causal studies with demonstrated impact"",""Strong Quantitative Programming skills in a language such as Python""],""nice_to_have"":[""ML depth"",""Passion for driving product vision and innovation strategy""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a time when you used causal inference to inform product metrics and drive business decisions?"",""example_answer"":""In my previous role, I used causal inference to measure the impact of a new feature on customer engagement, which led to a 20% increase in sales.""},{""question"":""How do you stay up-to-date with the latest developments in experimentation and measurement techniques?"",""example_answer"":""I regularly attend industry conferences, read research papers, and participate in online forums to stay current with the latest developments in experimentation and measurement techniques.""}],""red_flags"":[""Lack of experience with experimentation and causal inference"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":95.0}"
"Data Scientist, Product Analytics",Meta,United States,February,2025,"As a Data Scientist at Meta, you will shape the future of people-facing and business-facing products we build across our entire family of applications (Facebook, Instagram, Messenger, WhatsApp, Oculus). By applying your technical skills, analytical mindset, and product intuition to one of the richest data sets in the world, you will help define the experiences we build for billions of people and hundreds of millions of businesses around the world. You will collaborate on a wide array of product and business problems with a wide-range of cross-functional partners across Product, Engineering, Research, Data Engineering, Marketing, Sales, Finance and others. You will use data and analysis to identify and solve product development's biggest challenges. You will influence product strategy and investment decisions with data, be focused on impact, and collaborate with other teams. By joining Meta, you will become part of a world-class analytics community dedicated to skill development and career growth in analytics and beyond.Product leadership: You will use data to shape product development, quantify new opportunities, identify upcoming challenges, and ensure the products we build bring value to people, businesses, and Meta. You will help your partner teams prioritize what to build, set goals, and understand their product's ecosystem.Analytics: You will guide teams using data and insights. You will focus on developing hypotheses and employ a varied toolkit of rigorous analytical approaches, different methodologies, frameworks, and technical approaches to test them.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.

Data Scientist, Product Analytics Responsibilities:

Work with large and complex data sets to solve a wide array of challenging problems using different analytical and statistical approaches
Apply technical expertise with quantitative analysis, experimentation, data mining, and the presentation of data to develop strategies for our products that serve billions of people and hundreds of millions of businesses
Identify and measure success of product efforts through goal setting, forecasting, and monitoring of key product metrics to understand trends
Define, understand, and test opportunities and levers to improve the product, and drive roadmaps through your insights and recommendations
Partner with Product, Engineering, and cross-functional teams to inform, influence, support, and execute product strategy and investment decisions

Minimum Qualifications:

A minimum of 6 years of work experience in analytics (minimum of 4 years with a Ph.D.)
Bachelor's degree in Mathematics, Statistics, a relevant technical field, or equivalent practical experience
Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R)

Preferred Qualifications:

Master's or Ph.D. Degree in a quantitative field

About Meta:

Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.

$173,000/year to $242,000/year + bonus + equity + benefits

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.","{""role_summary"":""As a Data Scientist at Meta, you will use your technical skills and analytical mindset to shape the future of people-facing and business-facing products, collaborating with cross-functional partners to identify and solve product development challenges."",""key_terms"":[{""term"":""Product Analytics"",""explanation"":""A Data Scientist role focused on using data to shape product development, identify opportunities, and ensure products bring value to people and businesses.""},{""term"":""Quantitative Analysis"",""explanation"":""Using technical expertise with quantitative analysis, experimentation, data mining, and presentation of data to develop strategies for products serving billions of users.""},{""term"":""Data Mining"",""explanation"":""Extracting insights from large and complex data sets to solve challenging problems using different analytical and statistical approaches.""}],""skill_priorities"":{""must_have"":[""6 years of work experience in analytics"",""Bachelor's degree in Mathematics, Statistics, or a relevant technical field"",""Experience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R)""],""nice_to_have"":[""Master's or Ph.D. Degree in a quantitative field""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach solving complex problems using large and complex data sets?"",""example_answer"":""I use a structured approach, breaking down the problem into smaller components, and then applying different analytical and statistical techniques to identify insights and opportunities.""},{""question"":""Can you give an example of how you have influenced product strategy and investment decisions with data in the past?"",""example_answer"":""In my previous role, I used data to identify opportunities to improve user engagement, and worked with cross-functional teams to develop and implement new features that resulted in a 20% increase in user engagement.""}],""red_flags"":[""Lack of experience working with large and complex data sets"",""Inability to communicate complex technical insights effectively to non-technical stakeholders""],""confidence_score"":95.0}"
Associate Data Scientist,The Home Depot,"Atlanta, GA",March,2025,"Req137897

Key Responsibilities

Implement data science projects that drive profitability, optimize efficiency, and enhance customer experience.
Develop solutions by applying advanced machine learning methods and algorithms for identifying trends and providing business solutions.
Create and implement algorithms and models for analyzing large datasets yielding valuable business insights.
Support data science projects by conducting effective analysis to solve business problems.
Execute tasks with high levels of efficiency and quality.
Consult with Data Scientists or Senior Data Scientists on appropriate selection, utilization, and interpretation of advanced analytical methodologies.
Gain familiarity with the relevant business domains to enhance problem-solving by integrating domain-specific expertise.
Articulate findings and recommendations to both technical and non-technical stakeholders with clarity and impact.
Provide reports, updates and/or presentations related to progress made on a project or solution.
Highlight potential impacts of recommendations to drive alignment and appropriate implementation.
Stay up to date on industry trends, best practices, and emerging methodologies.
Continuously improve your data science skills and seek out practical applications for your knowledge.
Telecommuting available.

Minimum Qualifications

Must be eighteen years of age or older.
Must be legally permitted to work in the United States.
Master’s degree in Business Analytics, Supply Chain Management, Mathematics, Statistics, Economics, or a related field. The following skills are required:
Python and SQL
Statistics and Probability
Machine Learning Techniques

Apply End Date: 03/27/2025","{""role_summary"":""Develop and implement data science projects to drive business growth, optimize efficiency, and enhance customer experience by applying advanced machine learning methods and algorithms."",""key_terms"":[{""term"":""Machine Learning Techniques"",""explanation"":""Using algorithms to enable machines to learn from data and make predictions or decisions.""},{""term"":""Python"",""explanation"":""A programming language used for data analysis, machine learning, and automation.""},{""term"":""SQL"",""explanation"":""A language used to manage and analyze data stored in databases.""},{""term"":""Statistics and Probability"",""explanation"":""Mathematical concepts used to understand and analyze data.""}],""skill_priorities"":{""must_have"":[""Python"",""SQL"",""Statistics and Probability"",""Machine Learning Techniques""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would apply machine learning techniques to drive business growth?"",""example_answer"":""I would use machine learning algorithms to identify trends and patterns in customer data, and then develop predictive models to drive business growth.""},{""question"":""How do you stay up to date with industry trends and emerging methodologies?"",""example_answer"":""I regularly read industry publications, attend conferences, and participate in online forums to stay current with the latest developments in data science.""}],""red_flags"":[""Lack of experience with Python and SQL"",""Inability to articulate complex technical concepts to non-technical stakeholders""],""confidence_score"":90.0}"
Machine Learning / Research Engineer - Deep Learning - Capital Markets,CoTalent,"Miami, FL",March,2025,"Machine Learning / Research Engineer - Python, C++, CUDA
Capital Markets - Tier 1 Finance Firm
Miami, FL
FTE

As a Machine Learning / Research Engineer you will advance the deep learning library at a leading global market maker, collaborating closely with researchers to enhance functionality and optimize workflows for improved training speeds and cost efficiency. Leveraging cutting-edge technologies and financial market expertise, your work will enable over 100 researchers to accelerate their agendas and unlock new experimental possibilities.

In this role, you will grow and maintain the internal deep learning library, integrating open-source tools with proprietary systems. You’ll work with researchers to identify needs, add functionality, and collaborate with HPC experts to optimize distributed workflows. This includes scaling PyTorch-based workflows, applying Python, CUDA, and C++ expertise, and ensuring the system remains at the forefront of innovation.

The ideal candidate has 5+ years of experience in machine learning and software development, strong distributed systems skills, and a proven track record with large-scale deep learning frameworks.","{""role_summary"":""Develop and maintain a deep learning library to accelerate research and improve cost efficiency in a financial institution."",""key_terms"":[{""term"":""Deep Learning"",""explanation"":""A subfield of machine learning that involves neural networks to analyze data.""},{""term"":""CUDA"",""explanation"":""A parallel computing platform for NVIDIA graphics processing units (GPUs) to accelerate computations.""},{""term"":""HPC"",""explanation"":""High-Performance Computing, which refers to the use of computer systems for complex computations.""},{""term"":""PyTorch"",""explanation"":""An open-source machine learning library for building and training neural networks.""}],""skill_priorities"":{""must_have"":[""Machine Learning"",""Software Development"",""Distributed Systems""],""nice_to_have"":[""CUDA"",""C++"",""PyTorch""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize distributed workflows for deep learning frameworks?"",""example_answer"":""I would collaborate with HPC experts to identify bottlenecks and apply parallel processing techniques to scale PyTorch-based workflows.""},{""question"":""Can you describe your experience with large-scale deep learning frameworks?"",""example_answer"":""I have worked on multiple projects involving deep learning frameworks like TensorFlow and PyTorch, and have successfully deployed models on distributed systems.""}],""red_flags"":[""Lack of experience with large-scale deep learning frameworks"",""Inability to work with distributed systems""],""confidence_score"":90.0}"
ML Research Scientist,Seer,"New York, United States",March,2025,"Seer are currently partnered with an AI-powered drug discovery business pushing the frontier of state-of-the-art generative Machine Learning models for biomolecular design.

They're now searching for ML Research Scientists/Engineers with the following experience:

Experience:
4+ years of experience building and running deep learning models.
Demonstrated capability to summarize scientific content to navigate complex and unknown problems.
Experience working with industrial scale models on distributed infrastructure.
Experience with Protein Generative Models or Molecular Biology are a plus.

Responsibilities:
Build machine learning tooling and library code that enables an efficient, flexible, and scalable platform
Integrate feedback from biological labs performing large-scale experiments on proteins and cancer cells.
Build and run deep learning models, preferably with LLMs.
Manage cloud-based state-of-the-art generative models for biomolecular design.

They're offering competitive salaries and benefits packages with the role being fully remote across the East Coast!","{""role_summary"":""Develop and integrate machine learning models for biomolecular design, working with large-scale experiments and cloud infrastructure."",""key_terms"":[{""term"":""Generative Machine Learning models"",""explanation"":""AI-powered models that generate new biomolecular designs.""},{""term"":""Biomolecular design"",""explanation"":""The process of designing new molecules for pharmaceutical applications.""},{""term"":""Protein Generative Models"",""explanation"":""Machine learning models that generate new protein structures.""},{""term"":""Distributed infrastructure"",""explanation"":""A computing environment where multiple machines work together to process data.""},{""term"":""LLMs"",""explanation"":""Large Language Models, a type of deep learning model used for natural language processing.""}],""skill_priorities"":{""must_have"":[""Deep learning model development"",""Distributed infrastructure experience"",""Scientific content summarization""],""nice_to_have"":[""Protein Generative Models experience"",""Molecular Biology knowledge""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize deep learning models for distributed infrastructure?"",""example_answer"":""I use techniques like model parallelism and data parallelism to scale my models.""},{""question"":""Can you summarize a complex scientific paper on biomolecular design?"",""example_answer"":""I'd break down the paper into key findings, highlighting the methodology and results.""}],""red_flags"":[""Lack of experience with cloud-based infrastructure"",""Inability to summarize complex scientific content""],""confidence_score"":90.0}"
AI Data Scientist,Insilicom,United States,March,2025,"AI Data Scientist Full-time | Remote (U.S.-based) | Entry Level

Company Overview: Insilicom provides AI-driven solutions to harness Big Data and accelerate research and development efforts in both industry and academia. We specialize in document retrieval, information extraction, knowledge management, and knowledge discovery using knowledge graph-based AI algorithms.

Position Summary: We are seeking an innovative AI Data Scientist to join our team in advancing biomedical research through artificial intelligence. This role combines expertise in machine learning, deep learning, and large language models (LLMs) with a focus on biomedical data analysis and natural language processing.

Work Authorization: Must be legally authorized to work in the United States (including OPT, H-1B, or other valid work authorizations)

Key Responsibilities:
●    Develop and implement advanced deep learning and NLP models for biomedical data analysis.
●    Design, optimize, and fine-tune LLMs (e.g., GPT-4, Claude, or similar models) for entity recognition, classification, relation extraction, and text generation.
●    Lead end-to-end model development, from data preprocessing to production deployment, ensuring scalable and efficient performance.
●    Utilize neural network architectures (transformers, RNNs, CNNs, etc.) for various machine learning tasks.
●    Engineer and optimize prompting techniques for improving LLM performance in knowledge discovery and information retrieval.
●    Collaborate with cross-functional teams to integrate AI models into production pipelines.
●    Conduct thorough model evaluation, hyperparameter tuning, and performance optimization.
●    Maintain well-documented, modular, and reusable Python code and AI model repositories.
●    Stay current with cutting-edge research in AI, machine learning, and NLP, and apply best practices.

Required Qualifications:
●    Master's or Ph.D. in Computer Science, Statistics, Computational Biology, Bioinformatics, Physics, or related fields.
●    Strong proficiency in Python (NumPy, Pandas, TensorFlow, PyTorch, Hugging Face Transformers).
●    Experience with Linux OS, shell scripting, and version control (Git).
●    Expertise in:
Neural networks and deep learning architectures (e.g., transformers, LSTMs, CNNs).
Natural Language Processing (NLP) and information retrieval techniques.
LLM prompt engineering and optimization (e.g., GPT-4, Claude).
Large-scale data processing, training, and fine-tuning models.
●    Proven ability to develop, optimize, and deploy machine learning models in production environments.
●    Strong analytical, problem-solving, and collaborative skills.
 Preferred Qualifications:
●    Hands-on experience with fine-tuning transformer-based architectures (e.g., BERT, T5, LLaMA).
●    Familiarity with cloud platforms (AWS, GCP, Azure) for AI model deployment.
●    Advanced knowledge of feature engineering, hyperparameter tuning, and model optimization.
●    Published research or industry experience in ML/AI, NLP, or LLMs.
●    Strong communication skills with the ability to explain complex AI models to non-technical stakeholders.

Application Requirements:
1.   Resume/CV (PDF format)
2.   Responses to the following questions in your LinkedIn application:
Educational background confirmation
Technical expertise verification
Machine learning knowledge assessment
U.S. work authorization status

Application Process: Rolling applications with priority consideration for early submissions. Candidates are encouraged to apply promptly, as interviews will begin immediately.","{""role_summary"":""Develop and implement AI models for biomedical data analysis, focusing on natural language processing and machine learning."",""key_terms"":[{""term"":""LLMs"",""explanation"":""Large Language Models, such as GPT-4, used for entity recognition, classification, and text generation.""},{""term"":""NLP"",""explanation"":""Natural Language Processing, a subfield of AI that deals with human-computer interaction.""},{""term"":""Transformers"",""explanation"":""A type of neural network architecture used for various machine learning tasks.""}],""skill_priorities"":{""must_have"":[""Python"",""NumPy"",""Pandas"",""TensorFlow"",""PyTorch"",""Hugging Face Transformers"",""Linux OS"",""shell scripting"",""version control (Git)"",""Neural networks and deep learning architectures"",""Natural Language Processing (NLP) and information retrieval techniques"",""LLM prompt engineering and optimization""],""nice_to_have"":[""Hands-on experience with fine-tuning transformer-based architectures"",""Familiarity with cloud platforms (AWS, GCP, Azure) for AI model deployment"",""Advanced knowledge of feature engineering, hyperparameter tuning, and model optimization"",""Published research or industry experience in ML/AI, NLP, or LLMs"",""Strong communication skills with the ability to explain complex AI models to non-technical stakeholders""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain the concept of transformers in neural networks?"",""example_answer"":""Transformers are a type of neural network architecture that's particularly well-suited for sequential data, such as natural language processing tasks.""},{""question"":""How do you approach optimizing LLMs for biomedical data analysis?"",""example_answer"":""I would start by fine-tuning the pre-trained model on a relevant dataset, then experiment with different hyperparameters and optimization techniques to improve performance.""}],""red_flags"":[""Lack of experience with large language models or natural language processing techniques"",""Inability to explain complex AI models to non-technical stakeholders""],""confidence_score"":95.0}"
Machine Learning Engineer (L4/5) - Studio Media Algorithms,Netflix,United States,March,2025,"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.

The Studio Media Algorithms team is at the forefront of innovation to enhance and support the vision of the creators of movies, TV shows and other multimedia work. This team's work is responsible for increasing member value, and driving efficiency of the content creation process, ultimately creating more joy for viewers all over the world. To learn more about the domain, here are some links related to what we do: Creating Media with Machine Learning and Computer Vision Research at Netflix.

We are looking for a software engineer with experience in the machine learning (ML), computer vision (CV), and/or graphics domain to design and develop scalable systems and infrastructure for that effort. These systems will be used by our researchers to develop CV, graphics, audio, and natural language processing (NLP) algorithms to analyze, create, and transform media assets.

In This Role, You Will

Design and develop systems and reusable algorithms and frameworks for the full cycle of machine learning in the multimedia domain, such as data processing, feature extraction, distributed model training with GPUs, and deploying the produced models into production.
Collaborate cross-functionally with research scientists, product managers, as well as creative and business partners and stakeholders, to help define and prioritize system requirements.
Work closely with ML/CV/Graphics researchers and Studio teams to productize algorithms and models, and efficiently run human-in-the-loop inference tasks.
Participate in algorithm development and propose scalable designs.
Promote and facilitate software engineering best practices in the team.

About You

Industry experience with machine learning engineering in a production setting
Passion for turning ideas into products and improving the user experience
Experience with research and comfort with the ambiguity of an emerging field
Skills in OO programming (Python, Java, or C++)
Experience with ML, CV, and/or graphics pipelines
Excellent communication and people engagement skills
Experience with large-scale distributed data processing systems and cloud infrastructure
Industry experience in the content creation domain, such as animation, games, or visual effects
Experience with models and tools for generative models, such as Diffusion models and ComfyUI

Bonus Experience

Building end-to-end multimedia systems and algorithms
Deep learning frameworks such as PyTorch and Tensorflow
Computer graphics and VFX tools and game engines such as Unreal Engine, Unity, Maya, or Nuke

Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $150,000 - $750,000.

Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.

We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.

Job is open for no less than 7 days and will be removed when the position is filled.","{""role_summary"":""Design and develop scalable systems and infrastructure for machine learning, computer vision, and graphics algorithms to analyze, create, and transform media assets, enhancing the content creation process and increasing member value."",""key_terms"":[{""term"":""Machine Learning (ML)"",""explanation"":""A type of artificial intelligence that enables systems to learn from data and improve their performance on a task without being explicitly programmed.""},{""term"":""Computer Vision (CV)"",""explanation"":""A field of study that focuses on enabling computers to interpret and understand visual information from the world.""},{""term"":""Graphics"",""explanation"":""The process of creating visual content using computer-aided design, modeling, and animation techniques.""},{""term"":""Natural Language Processing (NLP)"",""explanation"":""A subfield of artificial intelligence that deals with the interaction between computers and humans in natural language.""}],""skill_priorities"":{""must_have"":[""Machine learning engineering experience in a production setting"",""Experience with research and comfort with ambiguity in an emerging field"",""Skills in OO programming (Python, Java, or C++)"",""Experience with ML, CV, and/or graphics pipelines"",""Excellent communication and people engagement skills"",""Experience with large-scale distributed data processing systems and cloud infrastructure""],""nice_to_have"":[""Industry experience in the content creation domain, such as animation, games, or visual effects"",""Experience with models and tools for generative models, such as Diffusion models and ComfyUI"",""Building end-to-end multimedia systems and algorithms"",""Deep learning frameworks such as PyTorch and Tensorflow"",""Computer graphics and VFX tools and game engines such as Unreal Engine, Unity, Maya, or Nuke""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you approach designing scalable systems for machine learning in the multimedia domain?"",""example_answer"":""I would focus on developing reusable algorithms and frameworks for the full cycle of machine learning, considering data processing, feature extraction, distributed model training with GPUs, and deploying produced models into production.""},{""question"":""Can you give an example of how you've collaborated with research scientists and stakeholders to define and prioritize system requirements in a previous role?"",""example_answer"":""In my previous role, I worked closely with research scientists to develop a scalable ML pipeline for image classification, ensuring that the system met the requirements of our stakeholders and was deployed efficiently.""}],""red_flags"":[""Lack of experience with machine learning engineering in a production setting"",""Inability to communicate technical concepts to non-technical partners""],""confidence_score"":95.0}"
Data Scientist (Marketing Science),Intelliswift - An LTTS Company,United States,March,2025,"Job Title: Data Scientist (Marketing Science)
Locations: Remote
Duration: 06 Months to start
W2 Contract

The main function of the Data Scientist is to produce innovative solutions driven by exploratory data analysis from complex and high-dimensional datasets.

Must-Have Skills:
The role is more focused on marketing science and advertising performance
Experience with building data pipelines and working with large datasets
Experienced in either programming languages such as SQL/Python and big data tools such as Hadoop, or data visualization tools such as Tableau
The ability to communicate effectively in writing, including conveying complex information and promoting in-depth engagement on course topics.

Nice-to-have Skills:
Experience with Media data or Media analytics companies
Experience with Marketing, from the advertising/business teams

Education/Experience:
Bachelors of Science degree in computer science or in a relevant field.","{""role_summary"":""Develop innovative solutions using complex data analysis to drive marketing science and advertising performance."",""key_terms"":[{""term"":""Exploratory data analysis"",""explanation"":""A method of analyzing data to identify patterns and relationships, often used to inform business decisions.""},{""term"":""High-dimensional datasets"",""explanation"":""Large datasets with many variables or features, often requiring specialized tools and techniques to analyze.""},{""term"":""Data pipelines"",""explanation"":""A series of processes for extracting, transforming, and loading data for analysis.""},{""term"":""Big data tools"",""explanation"":""Software used to handle and process large datasets, such as Hadoop.""},{""term"":""Data visualization tools"",""explanation"":""Software used to create interactive and dynamic representations of data, such as Tableau.""}],""skill_priorities"":{""must_have"":[""Experience with building data pipelines"",""Experience with SQL/Python"",""Experience with big data tools/Hadoop"",""Experience with data visualization tools/Tableau"",""Effective written communication skills""],""nice_to_have"":[""Experience with Media data/Media analytics companies"",""Experience with Marketing/advertising/business teams""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a project where you built a data pipeline and worked with large datasets?"",""example_answer"":""In my previous role, I built a data pipeline using Apache NiFi to process customer data from various sources, and then used Tableau to create interactive dashboards for stakeholders.""},{""question"":""How do you ensure effective communication of complex data insights to non-technical stakeholders?"",""example_answer"":""I use clear and concise language, avoiding technical jargon, and focus on the business implications of the insights. I also use data visualization tools to help stakeholders understand complex data.""}],""red_flags"":[""Lack of experience with marketing science and advertising performance"",""Inability to communicate complex data insights effectively""],""confidence_score"":85.0}"
Machine Learning Engineer - Early in Career,Splunk,"California, United States",March,2025,"Splunk, a Cisco company, is building a safer and more resilient digital world with an end-to-end full stack platform made for a hybrid, multi-cloud world. Leading enterprises use our unified security and observability platform to keep their digital systems secure and reliable. Our customers love our technology, but it's our caring employees that make Splunk stand out as an amazing career destination. No matter where in the world or what level of the organization, we approach our work with kindness. So bring your work experience, problem-solving skills and talent, of course, but also bring your joy, your passion and all the things that make you, you. Come help organizations be their best, while you reach new heights with a team that has your back.

Role Summary

Splunk is looking for Bachelor’s or Master's graduates to join our team! As a Machine Learning Engineer, you will work on a real project (or a few) and have an opportunity to enjoy our dynamic environment.

You will experience Splunking and what defines our culture while honing the skills which separate our development teams from others. Working to support internal and external customer needs, you will collaborate with multi-functional teams, receive mentorship, and gain insight into our values-driven process. Our goal is both to support your growth and development while empowering you for a successful start to your career.

What you'll get to do

Integrate AI/ML solutions into Splunk products and services
Achieve data science and software engineering goals set by you and your mentor
Learn about Splunk, both the product and the company
Collaborate closely with software engineers, data scientists, and product managers

Must-have Qualifications

Actively pursuing a Bachelor’s or Master's in Computer Science, Software Engineering, Computer Engineering, Electrical Engineering, Mathematics or a related technical field, and a strong record of academic achievement

Nice-to-have Qualifications

We’ve taken special care to separate the must-have qualifications from the nice-to-haves. “Nice-to-have” means just that Nice. To. Have. So, don’t worry if you can’t check off every box. We’re not hiring a list of bullet points–we’re interested in the whole you.

Coursework or research experience in artificial intelligence and machine learning topics such as time series analysis (univariate and multivariate), anomaly detection, generative AI technology and Large Language Models (LLM)
Experience programming in a large software project – at school, professionally, or in an open source context
Coursework and project or internship experience in big data systems or distributed systems
Exposure to ML frameworks (e.g., TensorFlow, PyTorch, Ray, vLLM) and Python
Ability to work well with others in a fast-paced environment
Strong communication skills, verbal and written
Enthusiasm for solving interesting problems

Splunk is an Equal Opportunity Employer

Splunk, a Cisco company, is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, national origin, genetic information, age, disability, veteran status, or any other legally protected basis.

Note

Base Pay Range

SF Bay Area, Seattle Metro, and New York City Metro Area

Base Pay Range $119,200.00 - 163,900.00 per year

California (excludes SF Bay Area), Washington (excludes Seattle Metro), Washington DC Metro, and Massachusetts

Base Pay Range $107,280.00 - 147,510.00 per year

All other cities and states excluding California, Washington, Massachusetts, New York City Metro Area and Washington DC Metro Area.

Base Pay Range $95,360.00 - 131,120.00 per year

Splunk provides flexibility and choice in the working arrangement for most roles, including remote and/or in-office roles. We have a market-based pay structure which varies by location. Please note that the base pay range is a guideline and for candidates who receive an offer, the base pay will vary based on factors such as work location as set out above, as well as the knowledge, skills and experience of the candidate. In addition to base pay, this role is eligible for incentive compensation and may be eligible for equity or long-term cash awards.

Benefits are an important part of Splunk's Total Rewards package. This role is eligible for a competitive benefits package which includes medical, dental, vision, a 401(k) plan and match, paid time off and much more! Learn more about our next-level benefits at https //splunkbenefits.com.","{""role_summary"":""As a Machine Learning Engineer, you will work on real projects, collaborate with multi-functional teams, and gain insight into our values-driven process, while honing skills that separate our development teams from others."",""key_terms"":[{""term"":""AI/ML solutions"",""explanation"":""Integrating artificial intelligence and machine learning capabilities into Splunk products and services.""},{""term"":""Time series analysis"",""explanation"":""Analyzing data in a sequence of time to identify patterns and trends.""},{""term"":""Anomaly detection"",""explanation"":""Identifying unusual patterns or data points that do not conform to expected norms.""},{""term"":""Generative AI technology"",""explanation"":""Artificial intelligence that generates new, original content, such as images or text.""},{""term"":""Large Language Models (LLM)"",""explanation"":""Artificial intelligence models that process and generate human-like language.""},{""term"":""ML frameworks"",""explanation"":""Software libraries that provide tools and structures for building machine learning models.""}],""skill_priorities"":{""must_have"":[""Bachelor's or Master's in Computer Science, Software Engineering, Computer Engineering, Electrical Engineering, Mathematics or a related technical field""],""nice_to_have"":[""Coursework or research experience in artificial intelligence and machine learning topics"",""Experience programming in a large software project"",""Coursework and project or internship experience in big data systems or distributed systems"",""Exposure to ML frameworks and Python"",""Ability to work well with others in a fast-paced environment"",""Strong communication skills, verbal and written"",""Enthusiasm for solving interesting problems""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain a project where you applied machine learning concepts to solve a real-world problem?"",""example_answer"":""In my previous project, I used machine learning algorithms to predict customer churn, resulting in a 20% reduction in customer loss.""},{""question"":""How do you stay current with the latest developments in machine learning and AI?"",""example_answer"":""I regularly read industry blogs and research papers, and participate in online forums and discussions to stay up-to-date.""}],""red_flags"":[""Lack of experience with machine learning frameworks and Python"",""Lack of enthusiasm for solving complex problems""],""confidence_score"":90.0}"
Manufacturing Data Scientist,KLA,"Ann Arbor, MI",March,2025,"Company Overview

KLA is a global leader in diversified electronics for the semiconductor manufacturing ecosystem. Virtually every electronic device in the world is produced using our technologies. No laptop, smartphone, wearable device, voice-controlled gadget, flexible screen, VR device or smart car would have made it into your hands without us. KLA invents systems and solutions for the manufacturing of wafers and reticles, integrated circuits, packaging, printed circuit boards and flat panel displays. The innovative ideas and devices that are advancing humanity all begin with inspiration, research and development. KLA focuses more than average on innovation and we invest 15% of sales back into R&D. Our expert teams of physicists, engineers, data scientists and problem-solvers work together with the world’s leading technology providers to accelerate the delivery of tomorrow’s electronic devices. Life here is exciting and our teams thrive on tackling really hard problems. There is never a dull moment with us.

Job Description/Preferred Qualifications

Manufacturing and Tools Data Scientist is responsible for collecting, analyzing, and interpreting data from KLA products during various stages of a manufacturing process to identify trends, inefficiencies, and opportunities for improvement, utilizing data visualization tools to present findings and collaborate with cross-functional teams to implement data-driven solutions for optimized production and quality control.

This is an enabling Role to support the analysis based on the data generated during the manufacturing process of KLA tools
This is a single contributor member of a multi-disciplinary team with common goals
Design and enable the creation of an analytics platform for Manufacturing
Create clear and concise data visualizations (charts, graphs, dashboards using Power BI) to communicate insights to stakeholders and decision-makers.
Develop Analytics using statistical methods, heuristics and ML Models.
Develop project plans and timelines for Analytics Products
Act as liaison between the business (Manufacturing) and the IT organization (Snowflake, Power BI and Software Developers)
Prepare the Business Requirement Document for all Analytics project derived from the tools during the manufacturing process.


Preferred Qualifications:

Proficiency in Snowflake
Bachelor's degree or equivalent experience in statistics, mathematics, computer science, industrial engineering, or a related field


Minimum Qualifications

Minimum of 5 years of related experience with a bachelor's degree; or 3 years with a master’s degree
2- 4 years of Validated experience in data analysis and reporting using data analytics tools, and working on Cloud based Data Warehouse
Expertise in data visualization tools (e.g., Tableau, Power BI)
Ability to work in a multicultural team, and with groups located in other regions like: Israel, Singapore, Wales and Germany
Ability to communicate complex subjects in simple terms is fundamental
Proficiency in SQL for data extraction and manipulation.
Programming languages like Python is a must
Experience in a manufacturing environment with a strong understanding of production processes
Excellent project Management Skills, with experience on leading and implementing Analytics Products


Base Pay Range: $88,900.00 - $151,100.00 Annually

Primary Location: USA-MI-Ann Arbor-KLA

KLA’s total rewards package for employees may also include participation in performance incentive programs and eligibility for additional benefits including but not limited to: medical, dental, vision, life, and other voluntary benefits, 401(K) including company matching, employee stock purchase program (ESPP), student debt assistance, tuition reimbursement program, development and career growth opportunities and programs, financial planning benefits, wellness benefits including an employee assistance program (EAP), paid time off and paid company holidays, and family care and bonding leave.

Interns are eligible for some of the benefits listed. Our pay ranges are determined by role, level, and location. The range displayed reflects the pay for this position in the primary location identified in this posting. Actual pay depends on several factors, including state minimum pay wage rates, location, job-related skills, experience, and relevant education level or training. We are committed to complying with all applicable federal and state minimum wage requirements where applicable. If applicable, your recruiter can share more about the specific pay range for your preferred location during the hiring process.

KLA is proud to be an Equal Opportunity Employer. We do not discriminate on the basis of race, religion, color, national origin, sex, gender identity, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other status protected by applicable law. We will ensure that qualified individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us at talent.acquisition@kla.com or at +1-408-352-2808 to request accommodation.

Be aware of potentially fraudulent job postings or suspicious recruiting activity by persons that are currently posing as KLA employees. KLA never asks for any financial compensation to be considered for an interview, to become an employee, or for equipment. Further, KLA does not work with any recruiters or third parties who charge such fees either directly or on behalf of KLA. Please ensure that you have searched KLA’s Careers website for legitimate job postings. KLA follows a recruiting process that involves multiple interviews in person or on video conferencing with our hiring managers. If you are concerned that a communication, an interview, an offer of employment, or that an employee is not legitimate, please send an email to talent.acquisition@kla.com to confirm the person you are communicating with is an employee. We take your privacy very seriously and confidentially handle your information.","{""role_summary"":""The Manufacturing and Tools Data Scientist role is responsible for collecting, analyzing, and presenting data insights to improve manufacturing processes, collaborating with cross-functional teams, and developing data visualization tools to communicate findings."",""key_terms"":[{""term"":""Snowflake"",""explanation"":""A cloud-based data warehouse platform used for data analysis.""},{""term"":""Power BI"",""explanation"":""A data visualization tool used to create charts, graphs, and dashboards to communicate insights.""},{""term"":""ML Models"",""explanation"":""Machine learning models used for data analysis and prediction.""}],""skill_priorities"":{""must_have"":[""Proficiency in Snowflake"",""Data visualization tools (e.g., Power BI)"",""SQL for data extraction and manipulation"",""Programming languages like Python"",""Experience in a manufacturing environment"",""Excellent project Management Skills""],""nice_to_have"":[""Bachelor's degree or equivalent experience in statistics, mathematics, computer science, industrial engineering, or a related field"",""Experience in a multicultural team""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach data analysis for manufacturing process improvement?"",""example_answer"":""I would start by collecting data from various stages of the manufacturing process, and then use statistical methods and ML models to identify trends and inefficiencies. Finally, I would present my findings using clear and concise data visualizations to stakeholders.""},{""question"":""How do you ensure effective communication of complex data insights to non-technical stakeholders?"",""example_answer"":""I use data visualization tools like Power BI to create dashboards and charts that are easy to understand, and I focus on presenting the key insights and actions needed, rather than getting bogged down in technical details.""}],""red_flags"":[""Lack of experience in a manufacturing environment"",""Inability to communicate complex data insights effectively""],""confidence_score"":90.0}"
Machine Learning Research Engineer/Scientist,Rise Technical,"New York, United States",March,2025,"Machine Learning Research Engineer/Scientist
$2500,000 - $450,000 + Equity + Flexible PTO + Benefits + Progression

Are you passionate about working on the edge of AI innovation, and looking for a high impact role within a well-funded startup that’s looking to rethink how AI should be implemented within government post-AGI?

This is an excellent opportunity to join a high-calibre team in a role that blends theoretical research with practical application, within a fast-paced, start-up meritocracy.

My client is looking to reshape the outdated government AI automation space, in order to allow agencies to focus on iteration and improvement, as opposed to development. This is a massive use case that is currently largely underserved by incumbent enterprises – something this company is looking to change.

Within this role, you will be building AI agents for specialised government tasks across a range of applications, with a strong focus on bring groundbreaking research into practical use.

This role would be an excellent fit for someone looking to join a fast-paced, mission driven team whist having a huge real-world impact on the deployment of compliant AI within government.

The Person:
Strong portfolio of research projects
Has worked at a top AI/ML company
Looking to join a fast paced startup

The Role:
Build AI agents for specialised government tasks
Research ML/RL theory
5 days a week on site in New York, NY
Strong benefits package","{""role_summary"":""Develop and implement AI agents for specialized government tasks, bridging research and practical application in a fast-paced startup environment."",""key_terms"":[{""term"":""AI agents"",""explanation"":""Software programs that perform tasks autonomously, in this case, for specialized government tasks.""},{""term"":""ML/RL theory"",""explanation"":""Machine Learning and Reinforcement Learning concepts applied to develop AI agents.""}],""skill_priorities"":{""must_have"":[""Strong portfolio of research projects"",""Experience working at a top AI/ML company""],""nice_to_have"":[]},""proposed_screening_questions_with_answers"":[{""question"":""Can you share an example of a research project you led that had a significant impact on AI development?"",""example_answer"":""I developed an AI model that improved the accuracy of disease diagnosis by 30%. The project was published in a top-tier AI conference and is now being used in a real-world application.""},{""question"":""How do you stay updated with the latest ML/RL theories and advancements?"",""example_answer"":""I regularly read research papers, attend AI conferences, and participate in online forums to stay current with the latest developments.""}],""red_flags"":[""Lack of experience working with government agencies or in a startup environment.""],""confidence_score"":85.0}"
"Scientist, Data",Royal Caribbean Group,"Miami, FL",March,2025,"Journey with us! Combine your career goals and sense of adventure by joining our incredible team of employees at Royal Caribbean Group. We are proud to offer a competitive compensation and benefits package, and excellent career development opportunities, each offering unique ways to explore the world. We are proud to be the vacation-industry leader with global brands — including Royal Caribbean International, Celebrity Cruises and Silversea Cruises — the most innovative fleet and private destinations, and the best people. Together, we are dedicated to turning the vacation of a lifetime into a lifetime of vacations for our guests.

Royal Caribbean Group’s Data Analytics has an exciting career opportunity for a full time Scientist, Data reporting to the Senior Manager , Data Science.

This position will work on-site in Miami, Florida.

Position Summary

Royal Caribbean is seeking a seasoned, experienced and inquisitive Data Scientist that will lead our Research & Development initiatives and assimilate new, cutting-edge technologies into our broader Artificial Intelligence and Machine Learning capabilities. The position demands an inquisitive individual who can direct a team of other data scientists and machine learning professionals to deliver.

This Data Scientist will focus on architecting, deploying and evaluating the feasibility of emerging technologies within the fields of Data Science, Artificial Intelligence and Machine Learning. They are expected to work independently and in collaboration with other Data Scientists to explore new capabilities that will continue to keep Royal Caribbean Cruise Lines ahead of its competitors in this space. While research oriented, the success of role will be dependent on the tangible value their efforts and the efforts of the Data Science team will add.

Essential Duties And Responsibilities

A successful candidate will possess a strong background, either professionally or academically, in statistics, mathematics, artificial intelligence, research methods, experiment design, developing novel solutions beyond the use of well-established methods, and taking new technologies to a prototype state that can be expanded into a robust product.
The candidate should demonstrate a progressive maturation of prior research projects, publications, patents or similar capabilities in the field of applied research.
This individual will be responsible for scripting / programming, mentorship, stakeholder presentation, collaboration with other team members to execute a research experiment within the framework of implementing, utilizing and expanding R&D capabilities within the broader Data Science team.

Major Responsibilities Include

Research and apply emerging forms of statistical, machine learning (neural networks / deep networks, ensemble methods, natural language processing, computer vision) and engineering methods to Royal Caribbean Cruise Lines, data science and AI ecosystem.
Must be comfortable doing so with little or not documentation or reliance on research articles and papers.
Evaluate the progress of Data Scientists, the AI & Robotics team, and company at large on the acclimation of research methods towards the rapid delivery of experimental technologies to a prototype state.
Execute these objectives with respect to both purely exploratory endeavors as well as established products requiring novel ingenuity to meet known stakeholder objectives.
Manipulates high-volume, high-dimensionality data from varying sources to highlight patterns, anomalies, relationships and trends.
Empower and enhance the capabilities of Data Scientists and the AI & Robotics team as whole to properly design R&D explorations, rapidly experiment with, prototype, and demonstrate the viability of in-house research.
Collaborate with Digital, IT, Business stakeholders to design and implement R&D prototypes into broader automated systems and establish a Minimum Viable Product.
Assist with research related to customer based analytical practice and develop communications for management and strategies for building institutional knowledge. Work with product and enterprise teams via both Agile and Waterfall Methodologies.
Foster a data-driven culture based on pragmatism and strategic decision through rigorous factual analysis at all levels. Should be willing to engage outside the immediate team to expand data science footprint throughout organization.

Qualifications, Knowledge And Skills

Master’s degree required in Statistics, Operations Research, Mathematics, Economics, Computer Science, Engineering, Physics, Chemical Engineering or field of comparable foundations in mathematical and statistical analysis through the use of models, algorithms or programmed solutions.
5+ years’ experience with any of the following programming languages: R, Python, Java, C++, C#, Scala, SAS, MATLAB or similar scripting languages. Similar experience and proficiency with SQL required.
5+ years’ experience across a breadth of data science, AI and machine learning disciplines including, but not limited to: forecasting, natural language processing (topic modeling, semantic search, text classification), deep learning and GPU-based algorithms (CNN, LSTM), computer vision
5+ years designing experiments and researching novel solutions beyond established literature or documentation
Experience with data mining processes (SEMMA, CRISP-DM), data preparation, consolidation, imputation, transformation, interaction, variable reduction, modeling, maintenance, and post-mortem analysis.
Experience with statistical methods such t-test of means, Tukey-HSD tests of means on groups, ANOVA, Proportion tests, data normalization and scaling, univariate and multivariate outlier detection.
Experience with modeling techniques such as linear models, decision trees, neural networks, k-nearest-neighbor, support vector machines, cluster analyses, and ensemble methods.
Strong Oral and Written skills.

We know there's a lot to consider. As you go through the application process, our recruiters will be glad to provide guidance, and more relevant details to answer any additional questions. Thank you again for your interest in Royal Caribbean Group. We'll hope to see you onboard soon!

It is the policy of the Company to ensure equal employment and promotion opportunity to qualified candidates without discrimination or harassment on the basis of race, color, religion, sex, age, national origin, disability, sexual orientation, sexuality, gender identity or expression, marital status, or any other characteristic protected by law. Royal Caribbean Group and each of its subsidiaries prohibit and will not tolerate discrimination or harassment.","{""role_summary"":""Lead Research & Development initiatives, assimilate new technologies into Artificial Intelligence and Machine Learning capabilities, and direct a team of data scientists and machine learning professionals."",""key_terms"":[{""term"":""Artificial Intelligence"",""explanation"":""The development of computer systems able to perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation.""},{""term"":""Machine Learning"",""explanation"":""A type of Artificial Intelligence that enables computers to learn from data without being explicitly programmed, improving their accuracy and decision-making over time.""},{""term"":""Neural Networks"",""explanation"":""A type of Machine Learning model inspired by the structure and function of the human brain, composed of interconnected nodes (neurons) that process and transmit information.""},{""term"":""Deep Learning"",""explanation"":""A subfield of Machine Learning focused on developing algorithms that can learn complex patterns in data, such as images, speech, and text, using multiple layers of neural networks.""},{""term"":""Natural Language Processing"",""explanation"":""A subfield of Artificial Intelligence focused on developing algorithms that can understand, interpret, and generate human language, enabling computers to perform tasks such as text classification, sentiment analysis, and language translation.""},{""term"":""Computer Vision"",""explanation"":""A subfield of Artificial Intelligence focused on developing algorithms that can interpret and understand visual data from the world, such as images and videos, enabling applications such as image recognition, object detection, and facial recognition.""}],""skill_priorities"":{""must_have"":[""Master's degree in Statistics, Operations Research, Mathematics, Economics, Computer Science, Engineering, Physics, Chemical Engineering"",""5+ years' experience with programming languages: R, Python, Java, C++, C#, Scala, SAS, MATLAB"",""5+ years' experience with data science, AI, and machine learning disciplines"",""5+ years designing experiments and researching novel solutions"",""Experience with statistical methods and modeling techniques""],""nice_to_have"":[""Experience with data mining processes"",""Experience with statistical methods such as t-test of means, Tukey-HSD tests of means on groups, ANOVA, Proportion tests"",""Experience with modeling techniques such as linear models, decision trees, neural networks, k-nearest-neighbor, support vector machines, cluster analyses, and ensemble methods""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you describe a research project you led that involved applying emerging technologies in data science, AI, and machine learning?"",""example_answer"":""In my previous role, I led a project that applied deep learning algorithms to improve customer sentiment analysis. I worked with a team of data scientists to design and implement the project, and we were able to increase the accuracy of our sentiment analysis model.""},{""question"":""How do you stay current with emerging trends and technologies in AI and machine learning?"",""example_answer"":""I attend industry conferences, read research papers and articles, and participate in online forums and discussions to stay current with emerging trends and technologies in AI and machine learning.""}],""red_flags"":[""Lack of experience with emerging technologies in data science, AI, and machine learning"",""Inability to work independently and collaboratively with a team of data scientists and machine learning professionals""],""confidence_score"":95.0}"
Senior Data Scientist (AI & ML Expert),"Novisync, Inc","Dallas, TX",March,2025,"Key Responsibilities

Develop and deploy ML models for classification, prediction, and automation.
Design and implement end-to-end AI/ML solutions from data preprocessing to model deployment.
Utilize NLP techniques for text processing, sentiment analysis, and entity recognition.
Leverage Generative AI to create AI-driven automation solutions.
Work with large datasets to extract insights and optimize model performance.
Build and integrate automation agents using AI-driven approaches.
Collaborate with data engineers and MLOps teams for model deployment and scalability.
Stay updated with latest advancements in AI, ML, and automation technologies.

Primary Skills

Machine Learning & Deep Learning (TensorFlow, PyTorch, Scikit-learn)
Natural Language Processing (NLP) (BERT, GPT, LLMs, SpaCy)
Predictive Modeling & Classification
Generative AI & LLMs (OpenAI, Hugging Face, LangChain)
Automation Agents & AI-based Workflows
End-to-End ML Pipelines (Data preprocessing, Feature Engineering, Model Deployment)
Big Data & Cloud Platforms (AWS, GCP, Azure)
MLOps & Model Optimization (Kubeflow, MLflow, Docker, Kubernetes)
Programming (Python, SQL)","{""role_summary"":""Develop and deploy AI/ML solutions, leveraging NLP and automation techniques to extract insights and optimize model performance."",""key_terms"":[{""term"":""TensorFlow"",""explanation"":""An open-source machine learning framework.""},{""term"":""BERT"",""explanation"":""A natural language processing technique for contextualized embeddings.""},{""term"":""Generative AI"",""explanation"":""A type of artificial intelligence that generates new, original content.""},{""term"":""MLOps"",""explanation"":""A set of practices that combines machine learning and DevOps to improve collaboration and efficiency.""},{""term"":""Kubeflow"",""explanation"":""An open-source machine learning platform for deploying and managing ML workflows.""}],""skill_priorities"":{""must_have"":[""Machine Learning & Deep Learning"",""Natural Language Processing (NLP)"",""Predictive Modeling & Classification"",""Programming (Python, SQL)""],""nice_to_have"":[""Generative AI & LLMs"",""Automation Agents & AI-based Workflows"",""End-to-End ML Pipelines"",""Big Data & Cloud Platforms"",""MLOps & Model Optimization""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize the performance of a machine learning model?"",""example_answer"":""I use techniques such as hyperparameter tuning, regularization, and feature engineering to improve model performance.""},{""question"":""Can you explain the concept of transfer learning in NLP?"",""example_answer"":""Transfer learning allows us to leverage pre-trained models on new, related tasks, reducing the need for large datasets and computational resources.""}],""red_flags"":[""Lack of experience with cloud platforms (AWS, GCP, Azure)"",""Inability to explain NLP concepts (BERT, GPT, LLMs)""],""confidence_score"":95.0}"
Machine Learning Operations (MLOps) Engineer,LVIS,"Palo Alto, CA",March,2025,"Company Description

LVIS, through our advanced brain network analysis tools, provides Live Visualization to innovate how neurological diseases are diagnosed and treated. LVIS is a leader in cutting edge neural information analysis technologies that can decode brain networks and find cures for neurological diseases. LVIS owns patented technologies and our team includes leaders with strong expertise in neuroscience and engineering from Stanford University. LVIS has been selected to be a member of the Stanford StartX community and the NVIDIA inception program. We have an international team with our headquarter located in Palo Alto, California, USA and we have an office in Gangnam, Seoul, South Korea. We are looking for talented individuals to join us in transforming the neurology health care industry.

LVIS provides an environment where everyone is expected to grow with the company. We are looking for self motivated team members who will be at the leading edge of technology.

Responsibilities

Develop and maintain APIs: Deploy machine learning models as APIs and build scalable API services
Optimize machine learning workloads on the cloud: Improve performance and cost-efficiency of ML models on AWS
Ensure operational stability: Design and implement real-time data processing, logging, monitoring, and model performance tracking systems
Deploy ML models in real-world environments: Ensure reliable deployment and management of ML models and data drift in production
Utilize GPU and GPU clusters: Configure and optimize GPU-based environments for model training and inference (on Cloud and on-premise)
Build MLOps pipelines on AWS and Kubernetes: Deploy and manage containerized ML workflows in Kubernetes environments


Basic Qualifications

Bachelor's degree or higher in Computer Science, Data Science, AI, or related fields
3+ years of experience in MLOps or ML Engineering
Experience of ML related programming languages and frameworks (Python, PyTorch, TensorFlow, etc.)
Experience deploying and managing ML models using tools like MLflow, TensorFlow Serving, or TorchServe
Hands-on experience with AWS
Proficiency in managing and orchestrating containers using Kubernetes and Docker
Experience with GPU-based model training and optimization
Experience building large-scale data processing pipelines (Airflow, Kafka, etc.)


Preferred Qualifications

Hands-on experience with CI/CD pipelines (Jenkins, ArgoCD, etc.)
Experience in large-scale AI model serving
Knowledge of real-time data streaming and batch processing
Preferably DevOps experience along with MLOps","{""role_summary"":""Develop and maintain machine learning APIs, optimize performance and cost-efficiency, and deploy models in real-world settings, ensuring operational stability and reliability."",""key_terms"":[{""term"":""MLOps"",""explanation"":""The practice of collaboration and communication between data scientists and engineers to productionalize machine learning.""},{""term"":""GPU clusters"",""explanation"":""A group of computers connected together to perform complex computations, often used for machine learning model training and inference.""},{""term"":""Kubernetes"",""explanation"":""An open-source container orchestration system for automating deployment, scaling, and management of containerized applications.""}],""skill_priorities"":{""must_have"":[""MLOps or ML Engineering experience"",""Experience with ML related programming languages and frameworks (Python, PyTorch, TensorFlow, etc.)"",""Hands-on experience with AWS"",""Proficiency in managing and orchestrating containers using Kubernetes and Docker"",""Experience building large-scale data processing pipelines (Airflow, Kafka, etc.)""],""nice_to_have"":[""Hands-on experience with CI/CD pipelines (Jenkins, ArgoCD, etc.)"",""Experience in large-scale AI model serving"",""Knowledge of real-time data streaming and batch processing"",""DevOps experience along with MLOps""]},""proposed_screening_questions_with_answers"":[{""question"":""How do you optimize machine learning model performance on the cloud?"",""example_answer"":""I would use techniques like model pruning, knowledge distillation, and hyperparameter tuning to optimize model performance on the cloud.""},{""question"":""Can you explain your experience with deploying and managing ML models using tools like MLflow, TensorFlow Serving, or TorchServe?"",""example_answer"":""I have experience deploying and managing ML models using MLflow and TensorFlow Serving, ensuring reliable deployment and management of ML models and data drift in production.""}],""red_flags"":[""Lack of experience with MLOps or ML Engineering"",""Inability to work with AWS"",""Limited knowledge of container orchestration using Kubernetes and Docker""],""confidence_score"":95.0}"
Data Scientist - TikTok Live,TikTok,"San Jose, CA",March,2025,"Responsibilities
TikTok is the leading destination for short-form mobile video. At TikTok, our mission is to inspire creativity and bring joy. TikTok's global headquarters are in Los Angeles and Singapore, and its offices include New York, London, Dublin, Paris, Berlin, Dubai, Jakarta, Seoul, and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.
Join us.

About the Team
TikTok Live Data Science team is responsible for Live growth, ecosystem and revenue strategy analytical work. We work closely with Algorithm team and Product team. The goal of the team is to generate actionable insights from data, driving Live to create an environment that brings communities together in real time to create meaningful and interactive connections around the globe. Our main tasks include metrics defining, root cause analysis, experimentation methodology, strategy evaluation and exploratory analysis to find more opportunities.

About the Role
The primary role of a Data Scientist is to conduct deep analysis of user behavior and content ecosystems to generate business insights that could be applied to actionable improving initiatives. You will work closely with cross-function teams, such as PM\RD\MLE, to improve user experience and fulfill the growth of TikTok Live

Responsibilities - What You'II Do
1. Conduct data analysis in LIVE related business, including watching experience, creator ecosystem, agency management, algorithm improvement and etc..
2. Design metrics framework to measure product healthiness, keep tracking of core metrics and understand root causes of metric movements.
3. Conduct scientific evaluation with statistical methods, including A/B testing and casual inference.
4. Identify growth opportunities with data analytics, and drive business decisions. Work with PM/MLE/RD to deliver product and strategy improvement.
5. Research data science theories and methodology, improve analysis efficiency and data product tools.

Qualifications
Minimum Qualifications
1. Bachelor's degree in data science, statistics, econometrics or a related scientific major,
2. 2+ years of experience in Data Science or related role
3. Expertise in SQL
4. Strong analytical and causal reasoning mindset, and rigidity on statistical correctness. Strong communication and passion about product challenges.

Preferred Qualifications
1.Experience of LIVE related business.
2. Knowledge of machine learning and recommendation systems.
3. Experience programming with Python or R

TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://shorturl.at/cdpT2



Job Information
【For Pay Transparency】Compensation Description (Annually)
The base salary range for this position in the selected city is $144000 - $240000 annually.
Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.
Benefits may vary depending on the nature of employment and the country work location. Employees have day one access to medical, dental, and vision insurance, a 401(k) savings plan with company match, paid parental leave, short-term and long-term disability coverage, life insurance, wellbeing benefits, among others. Employees also receive 10 paid holidays per year, 10 paid sick days per year and 17 days of Paid Personal Time (prorated upon hire with increasing accruals by tenure).
The Company reserves the right to modify or change these benefits programs at any time, with or without notice.
For Los Angeles County (unincorporated) Candidates:
Qualified applicants with arrest or conviction records will be considered for employment in accordance with all federal, state, and local laws including the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act. Our company believes that criminal history may have a direct, adverse and negative relationship on the following job duties, potentially resulting in the withdrawal of the conditional offer of employment:
1. Interacting and occasionally having unsupervised contact with internal/external clients and/or colleagues;
2. Appropriately handling and managing confidential information including proprietary and trade secret information and access to information technology systems; and
3. Exercising sound judgment.","{""role_summary"":""As a Data Scientist at TikTok, you will conduct deep analysis of user behavior and content ecosystems to generate business insights that can be applied to improve user experience and drive the growth of TikTok Live."",""key_terms"":[{""term"":""A/B testing"",""explanation"":""A statistical method to compare two versions of a product to determine which one performs better.""},{""term"":""Causal inference"",""explanation"":""A statistical method to identify cause-and-effect relationships between variables.""},{""term"":""Machine learning"",""explanation"":""A type of artificial intelligence that enables systems to learn from experience and improve their performance over time.""},{""term"":""Recommendation systems"",""explanation"":""Algorithms that suggest items to users based on their past behavior and preferences.""}],""skill_priorities"":{""must_have"":[""SQL"",""Analytical and causal reasoning mindset"",""Strong communication and passion about product challenges""],""nice_to_have"":[""Experience of LIVE related business"",""Knowledge of machine learning and recommendation systems"",""Experience programming with Python or R""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would design a metrics framework to measure product healthiness?"",""example_answer"":""I would identify key performance indicators, such as user engagement and retention, and develop a dashboard to track these metrics over time. I would also conduct root cause analysis to understand the drivers of metric movements.""},{""question"":""How would you approach conducting scientific evaluation with statistical methods?"",""example_answer"":""I would identify the research question, select the appropriate statistical method, and ensure the sample size is sufficient. I would also consider potential biases and limitations of the study.""}],""red_flags"":[""Lack of experience in data science or related role"",""Inability to communicate complex technical concepts to cross-functional teams""],""confidence_score"":90.0}"
"Data Scientist, Cloud Learning Services",Google,"Cambridge, MA",March,2025,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Cambridge, MA, USA; Atlanta, GA, USA; Austin, TX, USA; Seattle, WA, USA.Minimum qualifications:

Master's degree in a quantitative discipline such as Statistics, Engineering, Sciences, or equivalent practical experience
4 years of experience using analytics to solve product or business problems, coding (e.g., Python, R, SQL), querying databases or statistical analysis.
4 years of experience in business visualization tools like Looker, Tableau, etc.

Preferred qualifications:

Master's degree in Computer Science, Economics, or Mathematics, or a related field.
5 years of work experience in data science or quantitative analytics with focus on statistical modeling, Machine Learning, and AI.
Experience with both SQL and Python.
Experience with Machine Learning, AI or AI Pipeline.
Experience in Google Cloud Platform.

About The Job

Cloud Learning Services (CLS) is revolutionizing direct cloud learning. We empower users of all levels with interactive labs and guided experiences to build practical skills on Google Cloud Platform and other leading technologies. Our mission is to make the cloud accessible, engaging, and enjoyable to learn.

As a Business Data Scientist, you will play a key role in uncovering valuable insights from diverse data sources to solve critical business tests. You will address a wide range of exciting projects, from establishing new measurement frameworks to identifying meaningful patterns in large datasets, ultimately empowering stakeholders to make data-driven decisions.

In this role, you will need to be a detail-oriented problem-solver with a strong foundation in data analytics, data visualization, and Artificial Intelligence/Machine Learning. You will solve the real-world problems and a commitment to continuous learning. Exceptional communication and stakeholder management skills are essential, as you will collaborate extensively with cross-functional teams. If you succeed in dynamic environments and are eager to make a real impact with data, we encourage you to apply!

The US base salary range for this full-time position is $166,000-$244,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .

Responsibilities

Extract actionable insights from large, complex datasets and build data products like dashboards to operationalize them, driving measurable improvements in Key Performance Indicators (KPIs).
Present and communicate actionable insights and recommendations to executives, leaders, and cross-functional partners, including Product, Engineering, and Marketing teams.
Serve as a peer-reviewer and consultant to other members of the team, fostering a collaborative and knowledge-sharing environment.
Learn and share knowledge of the latest advancements in AI/ML and data science that are relevant to our work.


Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .","{""role_summary"":""As a Business Data Scientist, you will uncover valuable insights from diverse data sources to solve critical business tests, empowering stakeholders to make data-driven decisions."",""key_terms"":[{""term"":""Machine Learning"",""explanation"":""A type of Artificial Intelligence that enables machines to learn from data without being explicitly programmed.""},{""term"":""Artificial Intelligence"",""explanation"":""The development of computer systems that can perform tasks that typically require human intelligence, such as decision-making and problem-solving.""},{""term"":""Google Cloud Platform"",""explanation"":""A suite of cloud computing services offered by Google, including data analytics, machine learning, and storage.""},{""term"":""SQL"",""explanation"":""A programming language used for managing and querying relational databases.""},{""term"":""Python"",""explanation"":""A high-level programming language used for data analysis, machine learning, and web development.""}],""skill_priorities"":{""must_have"":[""Master's degree in a quantitative discipline"",""4 years of experience using analytics to solve product or business problems"",""4 years of experience in business visualization tools like Looker, Tableau, etc.""],""nice_to_have"":[""Master's degree in Computer Science, Economics, or Mathematics"",""5 years of work experience in data science or quantitative analytics"",""Experience with Machine Learning, AI or AI Pipeline"",""Experience in Google Cloud Platform""]},""proposed_screening_questions_with_answers"":[{""question"":""Can you explain how you would approach solving a complex business problem using analytics?"",""example_answer"":""I would start by identifying the key stakeholders and their requirements, then gather relevant data and develop a hypothesis. Next, I would apply statistical models and machine learning algorithms to analyze the data and identify patterns. Finally, I would present my findings and recommendations to stakeholders.""},{""question"":""How do you stay current with advancements in AI/ML and data science?"",""example_answer"":""I regularly read industry publications and research papers, attend conferences and webinars, and participate in online communities to stay up-to-date with the latest developments.""}],""red_flags"":[""Lack of experience with Google Cloud Platform"",""Inability to communicate complex technical concepts to non-technical stakeholders""],""confidence_score"":95.0}"
